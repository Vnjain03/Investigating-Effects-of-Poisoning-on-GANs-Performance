{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4248,
     "status": "ok",
     "timestamp": 1730921287342,
     "user": {
      "displayName": "Vedangi Shah",
      "userId": "15428873847042165335"
     },
     "user_tz": -330
    },
    "id": "JKe6D30Z75nB",
    "outputId": "1ec7c660-ed39-4b56-c73b-2456634a00d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1740399880248,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "mXmmX7718DTP",
    "outputId": "f5873392-43d3-4c29-8b57-4326873a0a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'PyTorch-GAN' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1740399914755,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "eFEAXfsu8NOC",
    "outputId": "b0c4f9bd-8e05-4cf9-b113-563b8963b9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/PyTorch-GAN\n"
     ]
    }
   ],
   "source": [
    "%cd PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1740399918792,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "Enwp9g2N8O87",
    "outputId": "c4b09b22-7371-4d02-9c6f-a69cc3ebe3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tdata  implementations  LICENSE\tREADME.md  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2377,
     "status": "ok",
     "timestamp": 1740399921675,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "bAFXQ5YN8Rge",
    "outputId": "4b97a21f-7ae2-4f1a-ad91-b4553ccefadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (11.1.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.25.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2025.2.18)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 8)) (0.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->-r requirements.txt (line 1)) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2453,
     "status": "ok",
     "timestamp": 1740399924129,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "MCaIxWQlCosl",
    "outputId": "8f4bff5e-645d-4a34-d51f-987e35f6ea1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740399924146,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "EJObStAU8X61",
    "outputId": "d12ac5c5-3d6a-4e0d-b03d-a563822fe6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/PyTorch-GAN/implementations/acgan\n"
     ]
    }
   ],
   "source": [
    "%cd implementations/acgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1740399964079,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "LDlA5YTP8IrY"
   },
   "outputs": [],
   "source": [
    "#Imports required\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740399975305,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "rzT0idBe8Voy",
    "outputId": "9f1c5a58-1bc8-4805-c92c-9b32a7314629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_epochs=50, batch_size=256, lr=0.0002, b1=0.5, b2=0.999, n_cpu=16, latent_dim=100, n_classes=10, img_size=32, channels=1, sample_interval=200)\n"
     ]
    }
   ],
   "source": [
    "# Create directory for generated images\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Argument parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=256, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=16, help=\"number of CPU threads for data loading\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of latent space\")\n",
    "parser.add_argument(\"--n_classes\", type=int, default=10, help=\"number of classes\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=200, help=\"interval between image sampling\")\n",
    "\n",
    "opt = parser.parse_args([])  # Modify this if passing command line arguments\n",
    "print(opt)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1740399980197,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "JeiQr-Rl8j_w"
   },
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740399987563,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "kGt81xyG8svt"
   },
   "outputs": [],
   "source": [
    "#Generator and Discriminator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.latent_dim)\n",
    "\n",
    "        self.init_size = opt.img_size // 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(opt.channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.n_classes), nn.Softmax())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return validity, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1740399990060,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "i-EqsOk284Z6",
    "outputId": "d2a3c086-e9cc-4a48-b7e7-3d1930a98fa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Dropout2d(p=0.25, inplace=False)\n",
       "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): Dropout2d(p=0.25, inplace=False)\n",
       "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (adv_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (aux_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss functions\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1740399996345,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "oKhbaknB871v",
    "outputId": "4471ac37-2e6f-4e06-844e-0a58542eeb81"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIgAAAERCAYAAAAQfZzvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATDZJREFUeJzt3XeYTef+//97GHUw0aO3iBK9RI/eiW60QZToXQZRBiFRovcEUaNEj+DoogwiQnQTDNF7jyD294/v7+T6fE6S13ufn3O+wno+ruv8cTzXrPttZu+11r7PJCfA5/P5HAAAAAAAADwr2oseAAAAAAAAAC8WG0QAAAAAAAAexwYRAAAAAACAx7FBBAAAAAAA4HFsEAEAAAAAAHgcG0QAAAAAAAAexwYRAAAAAACAx7FBBAAAAAAA4HFsEAEAAAAAAHgcG0QvuaioKBcQEOA+/fTT/9g5t27d6gICAtzWrVv/Y+cEgH/F9QvAy4hrF4CXEdcu+IMNohdg1qxZLiAgwO3bt+9Fj/JftWjRIlekSBEXFBTkXnvtNVe0aFG3efPmFz0WgOfwql+/li1b5kJCQlzGjBld3LhxXZYsWVyPHj3c7du3X/RoAJ7Dq37tGjhwoAsICPjDf2LHjv2iRwPwHF71a9e/Kl++vAsICHAdO3Z80aN4VuCLHgCvpoEDB7rBgwe7unXruubNm7snT564w4cPuwsXLrzo0QDgL73//vsuZcqUrkmTJi5t2rTu0KFDbuLEiW7NmjVu//79Lk6cOC96RAD4S1OmTHHx4sX7/b9Hjx79BU4DAP5btmyZi4iIeNFjeB4bRPiP2717txs8eLAbNWqU69at24seBwD8tmTJEleqVKn/9Wf58+d3zZo1c/Pnz3etWrV6MYMBgB/q1q3rkiRJ8qLHAIB/y6NHj1yPHj1cr1693IABA170OJ7GP2L2N/X48WM3YMAAlz9/fhccHOyCgoJciRIl3JYtW/7ya8aMGePSpUvn4sSJ40qWLOkOHz78h2OOHz/u6tat6xIlSuRix47tChQo4FatWmXO8/DhQ3f8+HF3/fp189ixY8e6119/3XXp0sX5fD53//5982sAvDpe5uvXv24OOedcrVq1nHPOHTt2zPx6AC+vl/na9U8+n8/dvXvX+Xw+v78GwMvtVbh2jRgxwj179sz17NnT76/BfwcbRH9Td+/eddOnT3elSpVyw4cPdwMHDnTXrl1zFStWdAcOHPjD8XPmzHHjx493HTp0cH369HGHDx92ZcqUcVeuXPn9mCNHjrjChQu7Y8eOud69e7tRo0a5oKAgV7NmTbd8+XI5z969e122bNncxIkTzdk3bdrkChYs6MaPH++SJk3q4seP71KkSOHX1wJ4+b3M168/c/nyZeec43+VB15xr8K1K2PGjC44ONjFjx/fNWnS5H/NAuDV9LJfu86dO+eGDRvmhg8fzj/K/3fgw/9zX3zxhc855/vuu+/+8pinT5/6fv311//1Z7du3fIlT57c16JFi9//7MyZMz7nnC9OnDi+8+fP//7ne/bs8TnnfN26dfv9z8qWLevLmTOn79GjR7//2bNnz3xFixb1Zc6c+fc/27Jli88559uyZcsf/iw8PFz+3W7evOlzzvkSJ07sixcvnm/kyJG+RYsW+SpVquRzzvmmTp0qvx7A39urfP36Ky1btvRFjx7dd/Lkyf9fXw/gxXvVr11jx471dezY0Td//nzfkiVLfF26dPEFBgb6MmfO7Ltz54759QD+nl71a5fP5/PVrVvXV7Ro0d//u3PO16FDB7++Fv95/AbR31T06NFdzJgxnXPOPXv2zN28edM9ffrUFShQwO3fv/8Px9esWdOlSpXq9//+9ttvu0KFCrk1a9Y455y7efOm27x5s6tfv767d++eu379urt+/bq7ceOGq1ixoouMjJT/AulSpUo5n8/nBg4cKOf+5z9OduPGDTd9+nTXs2dPV79+fffNN9+47NmzuyFDhvy73woAL5mX9fr1Z7788ks3Y8YM16NHD5c5c+Z/++sBvDxe5mtXly5d3IQJE1yjRo1cnTp13NixY93s2bNdZGSkmzx58r/5nQDwMnmZr11btmxxS5cudWPHjv33/tL4r2GD6G9s9uzZLleuXC527NguceLELmnSpO6bb75xd+7c+cOxf/bB5c0333RRUVHOOed++ukn5/P5XP/+/V3SpEn/13/Cw8Odc85dvXr1uWf+568FxogRw9WtW/f3P48WLZoLCQlx58+fd+fOnXvudQD8vb2M169/tX37dteyZUtXsWJFN3To0P/4+QH8/bwK165/atSokXv99dfdxo0b/2trAPh7eBmvXU+fPnWdO3d2oaGhrmDBgs99Pvxn8P9i9jc1b94817x5c1ezZk33wQcfuGTJkrno0aO7Tz75xJ06derfPt+zZ8+cc8717NnTVaxY8U+PeeONN55rZufc7/8Ss9dee+0P/9eqyZIlc845d+vWLZc2bdrnXgvA39PLev36nw4ePOjeffddlyNHDrdkyRIXGMjtEnjVvQrXrn+VJk0ad/Pmzf/qGgBerJf12jVnzhx34sQJN23atN83p/7p3r17LioqyiVLlszFjRv3udeC/3ji/ZtasmSJy5gxo1u2bJkLCAj4/c//uWv7ryIjI//wZydPnnTp06d3zv3ff2mhc//3N3vKlSv3nx/4/xMtWjSXJ08e991337nHjx///uuOzjl38eJF55xzSZMm/a+tD+DFe1mvX/906tQpV6lSJZcsWTK3Zs0aFy9evP/6mgBevJf92vWvfD6fi4qKcnnz5v1/vjaA/3de1mvXuXPn3JMnT1yxYsX+0ObMmePmzJnjli9f7mrWrPlfmwF/xD9i9jf1z9++8f2P/5vSPXv2uIiIiD89fsWKFf/rnwXdu3ev27Nnj6tcubJz7v/+9k6pUqXctGnT3KVLl/7w9deuXZPz/Dv/d4UhISHut99+c7Nnz/79zx49euTmz5/vsmfP7lKmTGmeA8DL62W+fl2+fNlVqFDBRYsWzf3jH/9gQxvwkJf52vVn55oyZYq7du2aq1Spkvn1AF5eL+u1q0GDBm758uV/+I9zzlWpUsUtX77cFSpUSJ4D/3n8BtELNHPmTLdu3bo//HmXLl1ctWrV3LJly1ytWrVc1apV3ZkzZ9zUqVNd9uzZf/8XQf9Pb7zxhitevLhr166d+/XXX93YsWNd4sSJXVhY2O/HTJo0yRUvXtzlzJnTtW7d2mXMmNFduXLFRUREuPPnz7uDBw/+5ax79+51pUuXduHh4ea/cKxNmzZu+vTprkOHDu7kyZMubdq0bu7cue7s2bPu66+/9v8bBOBv61W9flWqVMmdPn3ahYWFuR07drgdO3b83pInT+7Kly/vx3cHwN/Vq3rtSpcunQsJCXE5c+Z0sWPHdjt27HALFy50efLkcW3atPH/GwTgb+lVvHZlzZrVZc2a9U9bhgwZ+M2hF4QNohdoypQpf/rnzZs3d82bN3eXL19206ZNc//4xz9c9uzZ3bx589xXX33ltm7d+oevadq0qYsWLZobO3asu3r1qnv77bfdxIkTXYoUKX4/Jnv27G7fvn1u0KBBbtasWe7GjRsuWbJkLm/evG7AgAH/sb9XnDhx3ObNm11YWJibOXOme/DggcuTJ4/75ptv/vKfYwXwcnlVr1//fOAZMWLEH1rJkiXZIAJecq/qtatx48Zu165dbunSpe7Ro0cuXbp0LiwszPXt25d/fwfwCnhVr134+wnw/c/fRQMAAAAAAIDn8O8gAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA49ggAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPC/T3wFOnTsl+9epV8xzLly+XvUmTJrJPnTpV9vDwcHOGoKAg2S9fvix7+fLlzTV+++032YcMGSL7oEGDZM+cObM5Q79+/WS3ZqxVq5a5xqJFi2QPCwuTvXnz5rL37dvXnKFz586yHz9+XPamTZuaa8SKFUv2M2fOyN6+fXvZ79+/b86QLFky2R8+fGiew6siIyNlL1GihOw7duww10iZMqXs1uts1apVsjdq1MicYfHixbJb166FCxfKfu7cOXOGXLlyyb5lyxbZnzx5IvuJEyfMGbZu3Sp79erVZQ8JCZH9yJEj5gxx48aVvWfPnrKnTZtW9tGjR5szLFiwQPbAQH37v3TpkuyHDh0yZ5g7d67s1s8bzvXp00f24OBg2UeNGmWuYb1WJk+eLPtnn30muz8/Z+uZY+PGjbJ///33su/cudOcoVixYrLHixdP9oMHD8pesmRJc4aIiAjZt23bJrv1s7hz5445w4wZM2TPlCmT7Na9om3btuYMFy5ckD0qKkr27t27y259nvBnDete4XXr16+XPX369LJbnzudc+7DDz+UvU6dOrIXLFhQ9o8//ticIUWKFLJb16YbN27I3qpVK3MG6z33yy+/yN6pUyfZixcvbs5gfS9nzpwpu/Vs5c/3oVSpUrJbn7+t557SpUubM1ivh+3bt8tu/T1z585tzrBhwwbZL168aJ6D3yACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI9jgwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI8L9PfA1q1byz5u3DjzHGnTppU9ffr0st+/f1/2hg0bmjMkS5ZM9uPHj8v+7Nkzc40MGTI81xqDBg2S/cqVK+YMRYoUkT0oKEj2DRs2mGuUKlVKduvnmTdvXtkLFixozhA3blzZV61aJXvfvn3NNfLkySO79fN+//33ZW/UqJE5w8GDB81j8Oe2bNkie9u2bWUPDg4210iYMKHsxYoVkz0gIED2Zs2amTNs375d9nv37skeP3582VOmTGnOkDVr1ueaYcGCBbL379/fnCFevHiy37hxQ/auXbvKHjNmTHOG4sWLy/7999/Lnj9/ftk/+OADc4bbt2/L/uDBA9mta+OpU6fMGXbs2GEeAy1x4sTP1evVq2euUb9+fdmbN28ue4MGDWT353VgXQOrVasmu/V6PHz4sDmDdf1q06aN7OPHj5f94cOH5gzz58+X3bqXWM92c+fONWfYs2eP7Nbfc/DgwbIPHDjQnOH8+fOy3717V/bNmzfLbl3nnXPu8uXLsoeEhJjn8DLr+fyjjz6SffLkyeYa1vN5mTJlZLeeF6zPnc7Zr0XrPZk7d27Zy5Yta85gfS8rVqwou/X8WLVqVXMG63s1fPhw2bNnzy679XpyzrmIiAjZa9SoIXvGjBllt66/zjk3Y8YM2aOiomRfvXq17P68Hvbu3WseY+E3iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA49ggAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA4wJ8Pp/PnwO7desme3h4uHmO6dOny379+nXZa9SoIXtERIQ5w0cffSR7kSJFZL9165a5xv3792U/cOCA7CEhIbJ37NjRnOHNN9+U/eDBg7JbP2/nnFu/fr3sq1evlr1Nmzayb9++3ZzhypUrsj98+FD2mTNnmmv06tVL9nr16sm+cOFC2WvXrm3OkDBhQtmt946XnT17VvaRI0fKvmHDBnONzJkzy54xY0bZx44dK/uRI0fMGRYvXix7vHjxZA8KCpJ9yJAh5gxt27aVffLkybLnyZNH9g8++MCcwfp5/vzzz7I/e/ZMdn+ujcuWLZPd+j40a9ZM9nLlypkz5MyZU/Zjx47Jbt2vrZ+Vc8699tprss+ePds8h9cFBgbKbt1/5syZY65h3YMePHgg+/fffy/71q1bzRlu3Lghu/V6TJIkiexp0qQxZ7Cu9WPGjJF9165dsm/evNmc4dtvv5W9Vq1astetW1f2Pn36mDNY94LkyZPL/ssvv8ieLFkyc4ZHjx7JHhwcLLv1fbp48aI5w4wZM2TfsmWLeQ4vW7RokeyFCxeW3bpXO+dc165dZW/ZsqXsAwYMkD137tzmDNa9durUqbI3bNhQ9hUrVpgznDhxQvYUKVLIni1bNtlDQ0PNGTp16iR7586dZd+7d6/sMWPGNGdImjSp7EWLFpXdela3Ptc651z+/PllnzhxouzWHsJnn31mzmA933344YfmOfgNIgAAAAAAAI9jgwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI9jgwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPC7Q3wOrV68u+507d8xzzJ8/X/ZUqVLJniFDBtmzZs1qzvDw4UPZL168KPs777xjrhEYqL+tixcvln39+vWylyxZ0pxhxIgRsp89e1Z26+ftnHOtW7eW/ebNm7IfPnxY9iFDhpgzNGnSRPZ27drJvmbNGnONkSNHyl6rVi3Z7927J3vy5MnNGRYtWmQegz8XEBAge1hYmOyff/65uUbNmjVlT5Qokext27aVffv27eYMAwYMkH3q1KmyW+/nTJkymTNY1/hYsWLJfuDAAdkPHjxoznDmzBnZ69Sp81wz7N2715zhww8/lD1GjBiy58yZU/YOHTqYM/h8Ptl37twp+8aNG2WvUqWKOYM/92Ros2bNkj1Pnjyyp0mTxlwjSZIkz3UO67XizzX08uXLsmfOnFn2xo0by+7Pe2bFihWyv/fee7I3aNBA9jFjxjz3DNazQJYsWWQPDQ01Z5g7d67s1nV827Ztsvfq1cucYebMmbJb9zPrvh4vXjxzhhMnTpjH4K8tX75c9mnTpsn+66+/mmukSJFC9jfeeEP2lStXyt6+fXtzhh9++EH2hQsXyn769GnZrfejc8517NhR9ilTpsg+aNAg2TNmzGjOYN0Hbt++LfvQoUNl37x5szlD7969Zbc+43/77beyR0ZGmjN06dJFduv10LJlS9n9+Txg7af4g98gAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA49ggAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPC/T3wPz588v+1Vdfmed4+PChHiZQj7N27VrZc+fObc7QuXNn2WvXri37tGnTzDWaNGkie7169WSvUaOG7Bs3bjRnePbsmeyXLl2SvVixYuYa6dKlk71KlSqyJ02aVPbIyEhzhps3b8p+9epV2e/du2eu8fnnn8t+4MAB2S9evCj7okWLzBlu375tHoM/Z73Ws2fPLnuLFi3MNeLGjSv71KlTZZ87d67sT548MWewXofW+6l9+/ayFy9e3Jxh1KhRslvv+ZUrV8puvRedc+7UqVOyb9q0SXbrvda8eXNzhjFjxshu3Ues74N1L3XOuSNHjjzXGilSpJB9+PDh5gxnz541j4G2YcMG2a339aeffmqucfToUdmt+2Tr1q1lHzJkiDnDrFmzZD9+/Ljs27Ztkz0sLMycITg4WHbre92tWzfZ/Xl+tCRMmFB26/uYJk0ac40sWbLIbl0bGjVqJHuDBg3MGZYvXy679Zq0nsP9ee6qUKGCeQz+mvVstXTpUtnz5MljrjF9+nTZFy9eLLt1XRg8eLA5Q/Xq1WUPDQ2V/fDhw7IXLlzYnCF9+vSy7927V/agoCDZfT6fOUO5cuVkj4iIkL1MmTKyx4kTx5whSZIkspcsWVJ26/uwe/duc4b+/fvLbl3DN2/eLLv1fOmcc/HjxzePsfAbRAAAAAAAAB7HBhEAAAAAAIDHsUEEAAAAAADgcWwQAQAAAAAAeBwbRAAAAAAAAB7HBhEAAAAAAIDHsUEEAAAAAADgcYH+Hrh582bZW7dubZ4jR44csqdOnVr2wEA9bqpUqcwZqlSpIvv58+dl/+6778w1zp07J/vOnTtl//LLL2Vv1qyZOUP27Nllj4iIkH3dunXmGqdOnZJ9wIABsrds2VL20aNHmzNcu3ZN9nTp0smeIEECc43t27fLvmfPHvMcSpMmTcxjYsaMKfv169efa4ZXWb9+/WQPDQ2VfdSoUeYaffv2lX348OGyJ0uWTPbChQubM2TIkEH2b775RvZx48bJfvr0aXOG2bNnyz5z5kzZhw0bJnuuXLnMGd566y3ZBw8eLHu7du1kT5kypTlDvnz5ZK9cubLsPp9P9goVKpgzfPXVV7Lfvn1b9vTp08t+4MABc4Zdu3aZx0AbO3as7Na9vEGDBuYa1r24ZMmSslvvy2+//dacYd68ebIvXrxY9o8++kj2ihUrmjNY19C6devKni1bNtmt5xXnnPvHP/4he5YsWWQvVaqU7NOmTTNnGDJkiOxLliyRPSQkRPYNGzaYM1jfq9WrV8teoEAB2fPkyWPOYD3LQ7N+BtbnLX/es9YzxZMnT2S3rm1du3Y1Z7A+Z0SLpn8Xo1KlSrJb1wTn7OdY6zOd9Qz78ccfmzNERkbKfujQIdmXLl36XOd3zrmGDRvKvnv3btmta9fXX39tzhA3blzZW7VqJfvVq1dlz507tznD9OnTZc+YMaN5Dn6DCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8LsDn8/n8ObBcuXKyz5kzxzxH0qRJZX/77bdlHzNmjOydOnUyZxgyZIjs5cuXl/3p06fmGuvWrZM9LCxM9g0bNshevXp1c4YaNWrIfvv2bdn9+V5GRkbKXq1aNdn3798ve5MmTcwZLly4IPuzZ89kf/DggbnG2rVrZe/Zs6fsV69elT1mzJjmDHfv3pX94cOH5jm86ocffpDdui4NHDjQXGPRokWy//TTT7KnSZNG9oQJE5ozLF26VPYff/xR9oMHD8ruz63i7NmzsmfLlk32qlWryn7jxg1zBute1b17d9mDg4NlX7ZsmTnDd999J7t1H6pdu7bs/vwsrOvWrl27ZB80aJDsK1asMGe4fPmy7MuXLzfP4XWvvfaa7IGBgbKXLl3aXMO6Pn355ZeyW/fqJUuWmDN88803z7VGnDhxZH/8+LE5w5kzZ2Tv2rWr7Na9xp9rhzVnsmTJZLeuX9Z9wDnnNm/eLHvbtm1lnzVr1nPPkCNHDtljx44tu3U/7NChgznDr7/+KnuPHj3Mc3jZxo0bZW/Tpo3sKVKkMNe4d++e7I0bN5Z9zZo1svvzzDFgwADZreci63NM3759zRn69Okju/W5NHXq1LLv3bvXnGHcuHGy9+vXT/aAgADZv/76a3OGiIgI2a3Pxtaz2bBhw8wZrOtnVFSU7Dt27JDd+rzhnHPRounf/4kfP759DvMIAAAAAAAAvNLYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAjwv098CkSZPKXrZsWfMcHTp0kL1Xr16yX7t2Tfb69eubMyRIkED21atXy/7JJ5+Ya2TJkkX2n376Sfb+/fvLnjhxYnOGR48eyd6lSxfZp02bZq6RLl062U+fPi17+/btZc+dO7c5w61bt2TfvXu37L/88ou5xsyZM2WvUKGC7GvXrpU9U6ZM5gxTpkwxj8Gf+/LLL2WPFk3vk3/xxRfmGpkzZ5b9008/lf3o0aOyd+vWzZyhdu3ast+/f1/2Dz/8UPbZs2ebM0yYMEF263u5Z88e2Zs2bWrOULlyZdkXLlwou3XtO3jwoDlDu3btZLeuS9bXjx8/3pzBek1a3bouxY8f35zBupfB1rFjR9mHDRsme40aNcw1rHtctWrVZM+fP7/skZGR5gwrV66U/dy5c7IXK1ZMdn+em3r06CF769atZbfet/Xq1TNnKFy4sOwXLlyQvUiRIrJbz0zOOde2bVvZw8PDZbeeP+vUqWPOcOLECdnjxYv3XH3Xrl3mDP7Mib8WFBQku/Vcu2nTJnMN67nFena6c+eO7IGB9sdk67VUvXp12Y8fPy579+7dzRkePnwo++bNm2VPliyZ7HPnzjVnmDRpkuzW9e/GjRuyW9cl55yLiIiQPTg4WPZVq1bJ7s81wbpG79+/X3Zrr8Pqztl7Nv7gN4gAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOMCfD6fz58D8+TJI/v48ePNc9y6dUv2KVOmyJ43b17Zo0ePbs5w9OhR2SMjI2Xfvn27uUbHjh1lX7Zsmezp0qWT/e7du+YMVatWlb1atWqyN2rUyFzj9u3bsqdNm1b2fv36yb5lyxZzhhgxYsi+c+dO2bNkyWKu8cYbb8j+5MkT2cuVKyd7+/btzRnGjh0re2hoqHkOr3r69Kns1mvIH0eOHJE9Q4YMsufMmVN267rlnHP37t2T3Xq/Pn78WPZJkyaZM4wePVr2Fi1ayG79HTZt2mTOYN1HunbtKrt17Zw1a5Y5Q+PGjWUvU6aM7D/++KPsO3bsMGd47733ZN+/f7/sKVKkkD1btmzmDDVq1JA9ODjYPIfXWfePOHHiyO7P99i6RtapU0f2gQMHym49+znn3PHjx2VPmDCh7FeuXJHdeq5yzrnffvtN9iRJksg+YMAA2Rs2bGjOkDJlStmte33y5MllDw8PN2coWLCg7N26dZO9adOmsvtz7UiaNKnspUqVkv3kyZOyZ8yY0Zzh9OnTss+bN888h5dZrwPr/WJdl5xzrl27drKXLVtW9hEjRshuvZ+cc27BggWyr1u3TnbrtVipUiVzhkGDBsluPYNazxwnTpwwZyhQoIDs1nVlzJgxslvXHefsZ+k2bdrInjVrVtmtZxrnnJs8ebLsYWFhsvfv31/2okWLmjNY9+QECRKY5+A3iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA49ggAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA4wJ8Pp/PnwOrV68u+/Hjx81zBAcHy54jRw7Zr1+/Lnv79u3NGXLlyiV7oUKFZG/atKm5Rtq0aWVPkSKF7MmTJ5c9b9685gwpU6aU/eDBg7K/88475hrDhg2T/cmTJ7L/+OOPss+dO9ecYcOGDbL3799f9h49ephrxI4dW/Zbt27J3rNnT9nffPNNc4bz58/LHhERYZ7Dq9577z3ZR40aJfu2bdvMNX7++WfZ161bJ/vSpUtlX79+vTmDdW1KkyaN7NZ74ejRo+YMn332mex9+vSRfdCgQbIPHDjQnGH//v2yZ8uWTXbrXhcQEGDOYN3r1q5dK/sHH3wg+4ABA8wZrPtMrFixZLeunbt27TJnaNWqleyrVq0yz+F1//jHP2TfsWOH7BMnTjTXOHXqlOzWPXDw4MGyP3782JzBOkft2rVlt9738+fPN2e4efOm7LVq1ZK9d+/eslvPn84517lzZ9kPHToke7x48WS3npmcc27o0KGyV6hQQfZx48bJvnPnTnOGrFmzyj5r1izZre+DdQ12zrlLly7JznOXZl1XNm3a9FzdOeeCgoJkt65d1nu2RIkS5gyffPKJ7C1btpTd+gxRsmRJc4aRI0fKHj9+fNnv3r0re8WKFc0ZihQpInuBAgVk79Kly3N9vXPOhYSEyG7dJ6zvQ3h4uDlDjBgxZD927Jjst2/fln3lypXmDI8ePZLdem86x28QAQAAAAAAeB4bRAAAAAAAAB7HBhEAAAAAAIDHsUEEAAAAAADgcWwQAQAAAAAAeBwbRAAAAAAAAB7HBhEAAAAAAIDHBfp74NKlS2Xfu3eveY7SpUvLvmTJEtmjRdP7WSEhIeYMR48elb1Nmzayt23b1lyjX79+soeFhcm+fPly2cuUKWPOYH2vnz59KvuyZcvMNVKmTCl769atZY8TJ47sv/76qzmD9b1InDix7CVKlDDXmDFjhuxx48aV/YsvvpD94cOH5gwffPCBeQz+3PTp02XPkyeP7CNHjjTXSJ48uew///yz7A0bNpR9+PDh5gzt2rWTfdOmTbLfunVL9ujRo5sz7N69W/YRI0bI3rx5c9mta4pzzuXKlUv28uXLy54vXz7Z9+3bZ84QK1Ys2d966y3ZK1WqJHvs2LHNGVatWiX7mDFjZO/cubPs77//vjnDmTNnzGOgWfewwED9GDdr1ixzjUyZMj3XDPXq1ZP97t275gzW62n8+PGyT548WfYnT56YMwwZMkR2614RHBwse+7cuc0Z6tatK/u2bdtkt55prOufc/b1KWHChLKvW7dO9iZNmpgzWH/PDh06yG7da8LDw80ZrNc9tBo1ajzX13fp0sU85ocffpD92LFjslufQw4dOmTOcP78edmtZ/y1a9fKnjRpUnMG6/NvlixZZG/WrJns1mdj55zLmDGj7GnSpJH95s2bsi9atMic4dSpU7Jbfw/rGr9r1y5zhsyZM8seI0YM2Tt16iR7ihQpzBlq1qxpHmPhN4gAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPC4AJ/P5/PnwDFjxsjeuHFj8xxXrlyR/dNPP5V94cKFsqdNm9acYfny5bKHhobKXqtWLXONRIkSyb5u3TrZp06dKvv06dPNGXLmzCn7pEmTZLf+Ds45N2rUKNnz5s0r+8aNG2WPGTOmOUP8+PFlX7FihezVqlUz14iKipL9yZMnsufLl0/27t27mzPs3LlT9jNnzpjn8KqtW7fK3r9/f9n9eS8sWLBA9nv37sner18/2WPHjm3OUKFCBdkbNmwo+0cffSR7+fLlzRlCQkJkL1SokOyXLl2S/bXXXjNnCAsLk/3x48eyL1q0SPbXX3/dnOGNN96Q/cSJE7L/+OOPsmfPnt2coW7durKXLVtW9uTJk8teqVIlc4bt27fLvmPHDvMcXnfgwAHZHz58KPvJkyfNNd555x3ZrWev0aNHy54jRw5zhtWrV8s+duxY2a33nHXtcc65u3fvyl6nTh3Zw8PDZW/Xrp05Q4MGDWTv3bu37B9++KHs7733njmDdQ7rnmrN+OWXX5ozjB8/XvYBAwbIbr0vLl++bM6QKlWq5z6HlxUrVkx263Vw7do1c42ff/75uc5hPd+lS5fOnKF9+/ay586dW/Y9e/bIbr2WnXOuZMmSslvPDB9//LHsbdq0MWcICgqS/dGjR7Jb142OHTuaM7z11luyBwYGym59ZrSeH51zrnbt2rL36tVL9iNHjsieOnVqc4ZNmzbJXrNmTfMc/AYRAAAAAACAx7FBBAAAAAAA4HFsEAEAAAAAAHgcG0QAAAAAAAAexwYRAAAAAACAx7FBBAAAAAAA4HFsEAEAAAAAAHhcoL8H3r59W/bSpUub59i9e7fsd+/elT1btmyyHz161Jxh0KBBsi9ZskT23r17m2tYc1pixIgh+549e8xz1KxZ87lmyJo1q3lMhgwZZC9btqzsgwcPlr1Tp07mDNbrsmXLlrK/++675hpp0qSRfdq0abLv3LlT9kSJEpkzbN++3TwGf278+PGyjx49WvaVK1eaa7Ro0UL2/Pnzy75//37Z/XmdBgcHy3769GnZjxw5Invfvn3NGc6cOSN77ty5ZT958qTs/lz7GjduLPvWrVtlL1KkiOxx48Y1ZwgLC5Pduj6vW7dOduu655xztWrVkr158+ayW3/PpEmTmjP06dPHPAZasmTJZE+bNq3sT58+Ndfo2LGj7IsWLZL9zp07sj958sScwbrHDRs2TPauXbvKni9fPnMG6/XapEkT2du2bftcX++cc/v27ZN98+bNslvPXTVq1DBnsJ5BQ0JCZLdek/379zdniIiIkL1nz56yZ8qUSXZ/ni9/+ukn8xj8tfDwcNkDAgJkDw0NNdeIHj267PPmzZP9l19+kb1z587mDNevX5fd+j7cv39fduuZxDn785h17bGeQdOnT2/OYH3Gt+4j48aNk/3bb781Z6hWrZrs1v00V65css+YMcOcYcyYMbJbr9kRI0bIXrt2bXOGQ4cOye7PHgG/QQQAAAAAAOBxbBABAAAAAAB4HBtEAAAAAAAAHscGEQAAAAAAgMexQQQAAAAAAOBxbBABAAAAAAB4HBtEAAAAAAAAHhfo74Hr16+XvW7duuY5OnXqJPvHH38s+5IlS2Q/deqUOcPJkydlP3HihOzRo0c312jbtq3sffr0kT1RokSyN2vWzJyhe/fusufLl0/2R48emWtYr4nHjx/LHhoaKnuDBg3MGYKDg2V/9913ZW/VqpW5xvDhw2Vv0qSJ7Nb3ac2aNeYMhw8flj116tTmObwqZ86csmfOnFn2GDFimGtYr4GqVavKvmLFCtnbt29vzrBp0ybZ7969K3uZMmVk/+KLL8wZUqVKJfvkyZNlT5Eihezp06c3Z7C+V9bPe9q0abL7c12qUqWK7HXq1JE9ZsyYsls/a+ece/3112V/9uyZ7KVKlZK9W7du5gzWPXvDhg3mObyud+/esqdJk0b2c+fOmWtMnDhR9uTJk8ueK1cu2fft22fOUKtWLdmta2SlSpVkb9eunTnDvXv3ZB85cqTs2bNnl/3GjRvmDEOHDpXdej7s37+/7FmyZDFn+Oyzz2QPDNQfHayvP336tDnD+fPnZbeeeax7SdOmTc0ZIiMjZc+bN695Di+bMGGC7NZnhA4dOphrWO8H65lj1apVsl+9etWcYd68ebInTpxY9kuXLsm+cuVKc4YBAwbIbn0uzZEjh+wlSpQwZ0iSJIns1rPZ1q1bZY+KijJnsD77Ws8t1mfC+vXrmzMkTZpUduv18Nprr8luXV+dc+7JkyfmMRZ+gwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI9jgwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPC7A5/P5/Dmwffv2srdq1co8R548eWT//PPPZW/YsKHs33zzjTnDgQMHZE+TJo3sMWPGNNfInDmz7Dly5JDd+ns0btzYnCF79uyyV69eXfZTp06Za5QtW1b2rFmzyh4vXjzZP/jgA3OG7du3y3706FHZJ02aZK7RrFkz2a9fvy775MmTZX/33XfNGZo0aSK79b30snv37slerVo12VOlSmWuMX36dNmt19nixYtlf/LkiTnDvHnzZC9fvrzsc+fOlT1fvnzmDJ9++ql5jDJkyBDZhw0bZp7j7bfflt36WWzYsEH2FClSmDNY14y0adPKvnPnTtkLFy5szvDLL7/I3q1bN9mt65o/jw7FihWT/dChQ+Y5vG7q1KmyFy1aVPY2bdqYa1j3e+vZzHpuKlOmjDlDixYtZN+yZYvsxYsXl916fnTOueXLl8s+fvx42a339U8//WTOECdOHNkXLlwou/XMYz0DO+fcrFmzzGOU1157TXbrNe2cc0uXLpV93Lhxslv3Cuv51TnnmjdvLrt1jfU66/r+ySefyN6yZUtzDet+HxUVJfu6detk9+c9W7lyZdlr1Kgh+48//ij75s2bzRkWLVoke968eWUvUKCA7P58HkuUKJHs1nuydu3asg8aNMicIVasWLKHhobKvmbNGtmt16xzzm3atEl26zVbp04d2c+fP2/OYO0jBAQEmOfgN4gAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPC4AJ/P5/PnwGPHjsm+YsUK8xzJkyeXfdmyZbJXqlRJ9saNG5szfP/997LfuHFD9oCAAHONdOnSyZ45c2bZS5YsKfuECRPMGXbs2CF7hw4dZP/ggw/MNbp37y57okSJZA8LC5N91qxZ5gwxY8aU3XpNhYaGmmt07dpVduvnERQUJHv+/PnNGbZt2yb7rVu3zHN4VZkyZWSfPn267Js2bTLXWL9+veypU6eWPTAwUPbPP//cnOG1116TfcqUKbJnzJhR9iJFipgzjB8/XvZYsWLJXqpUKdmte4Bzzv3888+yf/rpp7IvXLhQ9hIlSpgzZM2aVfYrV67IXqtWLdlTpEhhzmC9Jh88eCB7wYIFZb927Zo5w549e2R///33zXN43RdffCH7+fPnZV+8eLG5xqBBg2Tv1KmT7DVq1JD94MGD5gzWtaFbt26yW9e3S5cumTMMHTpU9pEjR8qeK1cu2SMjI80ZrJ+X9Zxbvnx52bNnz27OsGTJEtk7d+4s+8SJE2X35xm2devWsj98+FD2Z8+eyd6uXTtzhuvXr8tep04d8xxetnr1atmte220aPbvMFjvuS5dush+9+5d2a1rgnPOTZo0SXbrM12jRo1k37JliznDsGHDZE+ZMqXsDRo0kN36XOuPefPmyX78+HHZrXudc87Vq1dP9gMHDsg+cOBA2a3Xm3P2Z76tW7fKbj1rW5+9nXOuZcuWsvfr1888B79BBAAAAAAA4HFsEAEAAAAAAHgcG0QAAAAAAAAexwYRAAAAAACAx7FBBAAAAAAA4HFsEAEAAAAAAHgcG0QAAAAAAAAeF+Dz+Xz+HHjgwAHZHz9+bJ7jiy++kL1ChQqyP3jwQPbYsWObM5QoUUL2q1evyv7uu++aa6xZs0b2qKgo2fv06SN7wYIFzRl27dol+/vvvy/7Z599Zq4RL1482Zs3by575cqVZe/evbs5Q5cuXWSfOnWq7Dlz5jTXyJcvn+yhoaGyV6pUSXbrfeGcc40bN5Z90aJF5jm8qmLFirKfO3fuudewrn/WayQ8PFz2ffv2mTO0bdtW9vXr18tepUoV2X/99VdzhurVq8v+9ttvy25dG9euXWvOkCtXLtmDgoJk37Fjh+wZMmQwZ5g8ebLsCxculP3s2bOyf//99+YMceLEkT04OFj2dOnSyZ4tWzZzhtu3b8vepEkT8xxeN2rUKNm3bdsme7Nmzcw1evToIXvRokVlt+7VX3/9tTlDt27dZG/fvr3s1vOI9b53zn5v165dW3brfb99+3Zzho0bN8puXQOte5H1LO+cc+PHj5fd+nl27NhR9rCwMHMG67585MgR2a37/t69e80ZvvrqK9mvX79unsPL8ubNK7v1nixWrJi5hnWfu3v3ruxjxoyRPXHixOYMlg0bNsh+79492TNmzGiu0blzZ9mtz8dPnjyRPVGiROYM5cuXf65zWNe+6dOnmzPs3r1bduv50PpsXLhwYXOGo0ePyl6zZk3ZO3XqJPvo0aPNGazPFNY+hXP8BhEAAAAAAIDnsUEEAAAAAADgcWwQAQAAAAAAeBwbRAAAAAAAAB7HBhEAAAAAAIDHsUEEAAAAAADgcWwQAQAAAAAAeFyAz+fz+XPg7du3Zc+bN695jqpVq8q+atUq2UePHi172bJlzRkGDx4se3h4uOz169c319izZ4/sH330kez79u2TvXTp0uYM586dk7127dqy58+f31yjS5cush87dkz2x48fy279vJ1zbtasWbL36NFD9uTJk5trXLx4UfZq1arJvnHjRtkDAwPNGYoXLy774cOHzXN4VYYMGWR///33Za9SpYq5RubMmWW3rm3WNWPs2LHmDOXLl5c9IiJC9oIFC8p+7do1c4a7d+/KPmzYMNlHjBghe+XKlc0ZEiRIIHtISIjsefLkkX3atGnmDFFRUbKvX79e9nbt2skeO3Zsc4YLFy7IvnfvXtm//fZb2XPmzGnO0LZtW9krVqxonsPrzpw5I/vatWtlX7dunblGunTpZP/kk09kX7BggewDBgwwZ3j48KHs8+fPl71bt26yW9dY55yLFy+e7L/99pvs7733nuxNmjQxZwgKCpLd+l7Gjx9f9kePHpkz9OrVS/YyZcrIvnTpUtlPnjxpznD69GnZrdekNUO/fv3MGazn5JkzZ5rn8LLQ0FDZr1y5Irv17Oacfb+2XsvWzzhr1qzmDIMGDZK9RIkSsluf6WbMmGHOMG/ePNnfffdd2ZctWya7P9fwpEmTyh4QECB7uXLlZPdnn2HcuHGyDx8+XHbr85j1ec4555IkSSK79Zq9d++e7IUKFTJn6N69u+x9+vQxz8FvEAEAAAAAAHgcG0QAAAAAAAAexwYRAAAAAACAx7FBBAAAAAAA4HFsEAEAAAAAAHgcG0QAAAAAAAAexwYRAAAAAACAxwX6e2BAQIDsZcuWfe5hevfuLXurVq1k79Spk7lG8+bNZa9evbrsT58+Nddo1KiR7GXKlJG9WbNmsr/33nvmDC1atJB90qRJshcvXtxcI1myZLIXLFhQ9gULFsg+b948c4bs2bPLnjt3btnnzJljrmG9Zqzv1bBhw2QvUaKEOcNbb71lHoM/N2XKFNmvXLki+5gxY8w1rPf0vn37ZLdex/379zdn2LFjh+xHjx6VvX79+rK3bNnSnOH+/fuy//LLL7IHBupb0vnz580Z0qVLJ3uFChVkt/6e0aNHN2cYP3687A8fPpT92bNnsi9atMic4dtvv5W9SZMmst+5c0f2QoUKmTNY30t/fp7QLl26JHtkZKR5Duteu2rVKtkPHz4se61atcwZ8uTJI/uMGTNk/+qrr2R///33zRlCQkJkDwsLk926V/zwww/mDD/++KPsX3zxhew3btyQPW7cuOYM1vPjhg0bZN+2bZvs1vOnc86lSJFCduuemDp1atmt+4Bzzp06dco8Bn/tww8/lL1y5cqyz50711wjTZo0snfv3l126/2UKFEic4bw8HDZa9SoIXvixImf6/zOOZcxY0bZmzZtKrvP55Pdn/u99Zx78eJF2bt16yb76tWrzRmKFi0q+/fffy97lSpVZLdeT845Fy9ePNlnzpwp+6BBg2S/du2aOcOBAwfMYyz8BhEAAAAAAIDHsUEEAAAAAADgcWwQAQAAAAAAeBwbRAAAAAAAAB7HBhEAAAAAAIDHsUEEAAAAAADgcWwQAQAAAAAAeBwbRAAAAAAAAB4X6O+BN2/elL1s2bLmOdq2bSt7y5YtZS9ZsqTse/bsMWfInDmz7D169JD98ePH5hqVK1eW/c6dO7Jfv379uc7vnHP16tWTvUSJErLv2rXLXCN+/Piyt2rVSvZz587JniZNGnOG0NBQ2SMjI2XPmDGjuUa0aHofNWfOnLJHRUXJ7s/rtmPHjuYx+HMnTpyQfeTIkbKvX7/eXOOtt96SfcyYMbInTJhQ9oIFC5ozJE6cWPYkSZLI3rx5c9m7dOlizjB69GjZ8+fPL3v58uVl9+d9MGvWLNk///xz2QsXLix7/fr1zRkmTpwoe8OGDWXv2rWr7LFjxzZnsO5VFy9elH3Dhg2yr1q1ypzBnzmhWe+7GTNmyJ49e3ZzjS+//FL24sWLyx4eHi57oUKFzBnatWsne40aNWR/9913ZY8RI4Y5w9mzZ2XPkyeP7JMnT5b9s88+M2e4evWq7OfPn5d90KBBsseMGdOcwbpn9unTR3br+9izZ09zhk6dOsmeL18+2U+dOiW7df1zzrmQkBDzGPw169q1adMm2YcPH26uce3aNdnfeecd2QcOHCj7xx9/bM5gzVmgQAHZrfvkuHHjzBn69+8vu/XcsmDBAtlPnz5tzmDdJ6pXry57qlSpZF+7dq05g/XztmbMlCmT7P7sdWzdulV26+dt9ddff92coXbt2rJb9yrn+A0iAAAAAAAAz2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPC4QH8PfPvtt2W/ceOGeQ6fzyf7xIkTZT9//rzsefLkMWdIlSqVeYxSsGBB85h169bJPnjwYNmXLl0q+7Fjx8wZihcvLnvp0qWfqzvnXOzYsWVfuXKl7OPHj5f91KlT5gy//PKL7AcOHJA9MNB+C+TLl0/2lClTyh4ZGSn76NGjzRnWr18v+759+8xzeNWDBw9knzNnjuxFihQx19i/f7/sMWLEkD0oKOi5ZyhRooTs1oy7du2S/eOPPzZnWL58+XPNcPv2bdnLlCljzvD666/L/sYbb8h+7tw52bNkyWLOEB4eLntUVJTsU6ZMkT1v3rzmDBMmTJD9nXfekb1q1aqyr1mzxpyhRo0a5jHQvvzyS9mt5yp/XislS5aUfcuWLbIfPnxY9s8++8ycIWHChLLv2LFD9uDgYNn9eS2uXbtW9o0bN8qeP39+2aNFs/832bhx48repk0b2Vu0aCF7ggQJzBlq164tu3VtqVu3ruzp0qUzZzhy5Ijsn3zyieyJEiWSvUCBAuYMV69elT1x4sTmObzMer5+8uSJ7M+ePTPXsN5T8+fPl33y5MmyjxkzxpwhZ86csvft21f2mjVryv7o0SNzButzYVhYmOzJkyeXfdGiReYM5cqVk926Rt+6dUv2kJAQc4ZevXrJXqlSJdn79esnu/Xs5pz9/Gbd07/77jvZ/flZWNc/f/AbRAAAAAAAAB7HBhEAAAAAAIDHsUEEAAAAAADgcWwQAQAAAAAAeBwbRAAAAAAAAB7HBhEAAAAAAIDHsUEEAAAAAADgcYH+Hti5c2fZu3XrZp5j2LBhspcvX172GDFiyD558mRzhmnTpslet25d2R88eGCusXbtWtmPHz8u+4wZM2QvVKiQOYMlWbJksq9fv948x+HDh2W/fv267Dt27JDd+j4659ytW7dkP3LkiOw5cuQw10iYMKHsX3/9texZsmSRvVmzZuYMoaGh5jH4c02aNJF97969sk+fPt1cY8+ePbKnT59e9pUrV8q+bt06c4YGDRrIfv78ednPnTsn+4ULF8wZhgwZIvvt27dlj4iIkL1x48bmDClTppT98ePHsj979kz22bNnmzOMGjVK9iVLlsh+8+ZN2a9evWrOYJ0jPDxc9iJFisj+008/mTN0795d9rNnz5rn8Lr27dvLbv2c27Zta65hXb++//572atUqSK7P88sY8eOlX3ChAmyW9evFStWmDOEhITIPmbMGNnTpEkj+7Zt28wZOnToIPvMmTNlv3fvnuzHjh0zZ6hdu7bs1vfael/783rYunWr7Lly5ZL9ypUrslv3Aeecq1y5suxRUVHmObzM+kyXKlUq2T/66CNzDetz3/79+2WfP3++7P7c7zt16iT7vn37ZA8KCpI9bty45gzW5y3r+S1+/PiyW59LnXNu0qRJslufn4cOHSp7y5YtzRnatGkju/UcHBwcLPvPP/9szhA9enTZDx48KPuhQ4dkr169ujmDdY0dP368eQ5+gwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI9jgwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPC7Q3wPr1Kkj+4cffmieY9myZbInSZJE9pUrV8q+bds2c4bJkyfLfvLkSdmHDh1qrvHDDz/IHhwcLHuzZs1kjxUrljnDokWLZL9w4cJzfb1z9vdy1apVspcoUUL2PXv2mDOsWLFCduvv0atXL3ONxYsXy7506VLZ27Zta65h2b59u+zFixd/7jVeVdbrrHr16rIPGTLEXCMqKkr2smXLyr57927Z/XkvzJ8/X/b27dvLvnHjRtmnTp1qzrBmzRrZQ0JCZJ85c6bsadOmNWe4ceOG7FmyZJHder0kSpTInKFBgwayb9iwQXbrmlKhQgVzhjRp0sjet29f8xzKrVu3zGOqVKnyXGvAuZw5c8pepEgR2U+cOGGuYT3XVK5cWfaxY8fKniBBAnOG9evXyx4WFia79TySPn16c4b33ntP9mfPnsnesWNH2Tt06GDOYF2nq1atKrv1/Hjt2jVzhhgxYsieL18+2WvVqiW7dY12zrncuXPLfvr0admta6g/1/FHjx6Zx+CvVatWTfbUqVPLbj0POGe/3tetWyd7wYIFZffn2rVw4ULZEydOLLv1fPfNN9+YM+TIkUP2vXv3yn7//n3Z/XkvNGzYUHbrmePtt9+W/auvvjJnyJo1q+y7du2S3bq2hYaGmjPMnj1b9pgxY8reokUL2UeMGGHOMGXKFPMYC79BBAAAAAAA4HFsEAEAAAAAAHgcG0QAAAAAAAAexwYRAAAAAACAx7FBBAAAAAAA4HFsEAEAAAAAAHgcG0QAAAAAAAAexwYRAAAAAACAxwX6e+C4ceNk37lzp3mOOXPmyH7mzBnZhw0bJvuYMWPMGdq2bSt79erVZZ83b565Rvfu3WW/e/eu7NOnT5e9d+/e5gxBQUGyf/LJJ7JnyJDBXGPlypWyb9iwQfZMmTLJ/tZbb5kzxIwZU/Zt27bJvmTJEnONuXPnym59r27evCn7hAkTzBmaNWsme58+fcxzeFWZMmVkb9Cggez37t0z15g/f77sX331lezWayRHjhzmDNbrMHv27LKvW7dOduv75Jz99xgwYIDsJUqUkP3SpUvmDE2aNJG9ePHisvfv3192f96vH330keypUqWSPWXKlLJ/++235gzZsmWT3br2WT/LnDlzmjPs3r3bPAaadZ+tW7eu7Na1xzn7Prp27VrZrfdcWFiYOUOePHlk79mzp+zJkiWTvWvXrs89Q1RUlOwnTpyQ/enTp+YM6dOnl71ly5ayly1bVnbr2uSc/axeunRp2a3nro4dO5oz9OjRQ/bVq1fLXrNmTdmtzwLOOVelShXzGPy1Ro0ayT5jxgzZly9fbq4xcuRI2a3PU9Y96rfffjNnsN4P/fr1k916Nvv++++fe4bjx4/LfvHiRdnTpUtnzvD48WPZkyZNKntoaKjs1j6Ec/bn74iICNkHDhz43DNMnjxZ9kePHskeI0YM2f159rLuRf7gN4gAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOMC/T2wZcuWsvfo0cM8x8iRI2Vv0aKF7B06dJD97t275gwbN26U/ejRo7IvW7bMXOOLL76Q/euvv5Z9xowZsm/ZssWcYejQobJHRkbKXrVqVXON3377TfZmzZrJ3qBBA9kjIiLMGayfx/r162U/d+6cucbPP/8s+7p162SfP3++7HHixDFn2L59u3kM/tzZs2dljx8/vuw//fSTucbEiRNl792793PNEBAQYM6QOHFi2TNkyCD7nTt3ZD927Jg5Q4ECBWS3rvEnT56UvWjRouYMMWPGlL1gwYKy9+vXT/ZixYqZMzRt2lT2PHnyyF6vXj3Zx40bZ84wZswY2bNlyyb7s2fPZB8wYIA5gz/PBdCyZs0q+5EjR2T35z3Tq1cv2a3r2+XLl2VfunSpOYN1jYwePbrsrVq1kv3atWvmDF27dpX9m2++kb1t27ay58+f35zhyZMnsl+/fl32JEmSyG5dY51zbt68ebJb72vr9XT79m1zhnjx4sk+evRo2W/evCn7m2++ac7g8/nMY/DXMmXKJLv1bDVixAhzjVixYsl+/vx52d9//33Zrc+tzjmXLl062a37fa5cuWT357Ot9XmsevXqsidIkED2+vXrmzO0adNG9tSpU8veqVOn5zq/c/bnzgcPHsj++PFj2SdPnmzO0K1bN9lDQ0NlX7lypewVKlQwZxg/frx5jIXfIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAj2ODCAAAAAAAwOPYIAIAAAAAAPA4NogAAAAAAAA8jg0iAAAAAAAAjwv098BGjRrJXqxYMfMcHTp0kD0gIED2O3fuyH7kyBFzhoiICNmPHz8u+8CBA801kiVLJvuECRNkX7p0qeyff/65OUO/fv1k79Onj+wzZsww13jrrbdkz5Ejh+wnTpyQvVWrVuYM9+7dk33NmjWyP3z40Fxj06ZNsseMGVP21KlTy167dm1zhgIFCsg+YsQI8xxeVbhwYdlTpEghe926dc01MmbMKPunn34qe9WqVWV/8803zRnmzJkje2RkpOwrVqyQvXjx4uYMv/76q+wxYsSQ/dy5c7IPGTLEnKFixYqyt2nTRvYDBw7InjlzZnOGMmXKyD5o0CDZZ82aJXulSpXMGazvldU/+OAD2fPmzWvOEB4eLnv37t3Nc3jdnj17ZLeezWbPnm2ukSZNGtmHDx8u+7Fjx2SfMmWKOUP+/PllX7Jkiew//vjjc3Xn7Ots3759zXMoQ4cONY/JlCmT7Pfv35c9ceLEsk+aNMmc4dtvv5Xduj4NGDBAdn9eDwkTJpR95syZslv3gbffftucIUuWLOYx+GulS5eWfcuWLbKvXLnSXMP6TGatcfHiRdn9+bx14cIF2fft2yd7YKD+KF65cmVzBuv9Yn2frGu8df11zrmoqCjZr127Jrv1ec36TOmcc2fOnJG9ffv2snfp0kV2f65da9eulX3atGmyf/bZZ7IvW7bMnOHBgwfmMRZ+gwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI9jgwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPC7A5/P5/DkwSZIksv/www/mOXLkyCF7UFCQ7BcuXJD9ypUr5gzTp0+X/Z133pG9bNmy5hqBgYGyx4wZU/ZFixbJvm3bNnOG69evy96xY0fZIyIizDW2bt0qe+7cuWUvV66c7MOHDzdn2LRpk+yHDh2Sfd68eeYa06ZNk3306NGyjxs3TvaECROaMxw4cED2M2fOmOfwqsSJE8tuXQLTpEljrvHjjz/K/uDBA9krVqwo+6BBg8wZcubMKbs1Y/v27WUvXLiwOYN1XQkODpZ9zpw5svfq1cucoX79+rInSJBA9vjx48v+8OFDcwbr2vf48WPZL168KPvHH39szmDp0aOH7Pfv35fdn0eH6NGjy75w4ULzHF5Xr1492YsVKya79Z50zrkmTZrIPmHCBNmte2T27NnNGazrU4sWLWS/evWq7P7c67t16yZ76tSpZb99+7bszZs3N2eoWrWq7GXKlJE9bty4shcpUsSc4Y033pDd+nuOHz9e9jhx4pgzDBs2THbrOnzy5EnZmzVrZs5QoUIF2QsVKmSew8uOHj0q+7Jly2S3Pks559zXX38te58+fWRPly6d7NZr2TnnQkNDZV+wYIHsLVu2lP3SpUvmDHv27JH92bNnsv/222+yL1myxJzB+oyfPHly2TNmzCh7hgwZzBmsfQTrmcO6Xw4ePNicwVojVqxYsleqVEl26/nROfszxYABA8xz8BtEAAAAAAAAHscGEQAAAAAAgMexQQQAAAAAAOBxbBABAAAAAAB4HBtEAAAAAAAAHscGEQAAAAAAgMexQQQAAAAAAOBxbBABAAAAAAB4XKC/B9atW1f2Fi1amOfo3r277PXr15e9atWqso8YMcKcYenSpbK/9dZbshctWtRco0iRIrJnyZJF9jlz5sg+ffp0c4batWubxyibN282j6lQoYLsPp9P9sjISNmbN29uzvDw4UPZt2zZIvuiRYvMNcLDw2VPly6d7GfOnJH91KlT5gz+vO7w5z7++GPZN2zYIPuzZ8/MNQoWLCj7ggULZM+RI4fsAwYMMGd47733nmuNePHiyR4UFGTO8OWXX8peo0YN2UePHi17v379zBl+/fVX2UeOHCl7hw4dZPfnPvPGG2/I3qVLF9kPHz4su3Uvdc6+X7Zr1072O3fuyG79HZxz7u7du+Yx0Pbt2ye79dxUoEABc42ECRPKnj9/ftkXL14s+9q1a80ZPv/8c9l79uwpe8WKFWW3nsucc65p06ayx4gRQ/YbN27Ini1bNnOGsWPHyp4gQQLZDx06JHv16tXNGSzWs93Bgwdlt/6Ozjm3fPly2evVqyf7/v37ZR8zZow5w88//yx7oUKFzHN4mfV+unTpkuwTJ0401yhXrpzsv/32m+zVqlWTPXfu3OYM1jNBxowZZU+ZMqXs06ZNM2fIlSuX7F9//bXsH330key9e/c2Z7A+Tz169Eh263NnzJgxzRmiR48ue6dOnWSvUqWK7PPnzzdnaN26teyDBg2S/fr167KvXr3anMG6X/qD3yACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI9jgwgAAAAAAMDj2CACAAAAAADwODaIAAAAAAAAPI4NIgAAAAAAAI8L8Pl8vhc9BAAAAAAAAF4cfoMIAAAAAADA49ggAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA49ggAgAAAAAA8Dg2iAAAAAAAADyODSIAAAAAAACPY4MIAAAAAADA4/4PMyrt2pY+TtMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class OutlierInjectedMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, outlier_fraction=0.2):\n",
    "        \"\"\"\n",
    "        Outlier injection attack by replacing a fraction of MNIST images with random noise.\n",
    "\n",
    "        Args:\n",
    "            dataset: Original MNIST dataset.\n",
    "            outlier_fraction: Fraction of dataset to replace with random noise (default: 20%).\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.outlier_fraction = outlier_fraction\n",
    "        self.outlier_indices = set()\n",
    "        self.inject_outliers()\n",
    "\n",
    "    def inject_outliers(self):\n",
    "        \"\"\"Injects random noise images as outliers into the dataset.\"\"\"\n",
    "        num_outliers = int(self.outlier_fraction * len(self.dataset))\n",
    "        outlier_indices = np.random.choice(len(self.dataset), num_outliers, replace=False)\n",
    "        self.outlier_indices = set(outlier_indices)\n",
    "\n",
    "        for idx in outlier_indices:\n",
    "            # Generate a completely random noise image\n",
    "            random_image = torch.randn((1, 28, 28))  # MNIST has 1 channel, 28x28 size\n",
    "\n",
    "            # Assign a random label (not necessarily related to real digits)\n",
    "            random_label = np.random.randint(0, 10)\n",
    "\n",
    "            # Replace original sample with outlier\n",
    "            self.dataset.data[idx] = (random_image * 255).byte()  # Convert to same format as MNIST\n",
    "            self.dataset.targets[idx] = random_label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "# Load original MNIST dataset\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Apply outlier injection attack (e.g., 20% of images replaced with random noise)\n",
    "poisoned_dataset = OutlierInjectedMNIST(dataset, outlier_fraction=0.2)\n",
    "\n",
    "# Visualizing the injected outliers\n",
    "def visualize_outliers(dataset, num_samples=4):\n",
    "    \"\"\"Displays random outliers from the dataset.\"\"\"\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "\n",
    "    for i, idx in enumerate(np.random.choice(list(dataset.outlier_indices), num_samples, replace=False)):\n",
    "        img, label = dataset[idx]\n",
    "        axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {label}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some injected outliers\n",
    "visualize_outliers(poisoned_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740399999612,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "5ppfQrLX9PeU"
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "def sample_image(n_row, batches_done, poisoned=False):\n",
    "    \"\"\"Saves a grid of generated digits\"\"\"\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    filename = f\"images/{'poisoned_' if poisoned else ''}{batches_done}.png\"\n",
    "    save_image(gen_imgs.data, filename, nrow=n_row, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1269209,
     "status": "ok",
     "timestamp": 1740401273709,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "ekK9Dvg39aJC",
    "outputId": "b04937c3-c122-47fe-f68d-0e8d7db87078"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/50] [Batch 0/235] [D loss: 1.497982, acc: 7.62%] [G loss: 1.504045]\n",
      "[Epoch 0/50] [Batch 1/235] [D loss: 1.497895, acc: 10.74%] [G loss: 1.503683]\n",
      "[Epoch 0/50] [Batch 2/235] [D loss: 1.497840, acc: 12.50%] [G loss: 1.503546]\n",
      "[Epoch 0/50] [Batch 3/235] [D loss: 1.497847, acc: 8.79%] [G loss: 1.503210]\n",
      "[Epoch 0/50] [Batch 4/235] [D loss: 1.497911, acc: 10.16%] [G loss: 1.503076]\n",
      "[Epoch 0/50] [Batch 5/235] [D loss: 1.497803, acc: 9.57%] [G loss: 1.502865]\n",
      "[Epoch 0/50] [Batch 6/235] [D loss: 1.497653, acc: 12.70%] [G loss: 1.502428]\n",
      "[Epoch 0/50] [Batch 7/235] [D loss: 1.497649, acc: 9.38%] [G loss: 1.502184]\n",
      "[Epoch 0/50] [Batch 8/235] [D loss: 1.497640, acc: 7.81%] [G loss: 1.501942]\n",
      "[Epoch 0/50] [Batch 9/235] [D loss: 1.497527, acc: 9.77%] [G loss: 1.501649]\n",
      "[Epoch 0/50] [Batch 10/235] [D loss: 1.497529, acc: 9.18%] [G loss: 1.501358]\n",
      "[Epoch 0/50] [Batch 11/235] [D loss: 1.497440, acc: 11.52%] [G loss: 1.500876]\n",
      "[Epoch 0/50] [Batch 12/235] [D loss: 1.497261, acc: 9.57%] [G loss: 1.500413]\n",
      "[Epoch 0/50] [Batch 13/235] [D loss: 1.497201, acc: 11.91%] [G loss: 1.499909]\n",
      "[Epoch 0/50] [Batch 14/235] [D loss: 1.497396, acc: 9.96%] [G loss: 1.499147]\n",
      "[Epoch 0/50] [Batch 15/235] [D loss: 1.497344, acc: 10.16%] [G loss: 1.498304]\n",
      "[Epoch 0/50] [Batch 16/235] [D loss: 1.497349, acc: 10.74%] [G loss: 1.497951]\n",
      "[Epoch 0/50] [Batch 17/235] [D loss: 1.497544, acc: 12.89%] [G loss: 1.497217]\n",
      "[Epoch 0/50] [Batch 18/235] [D loss: 1.497477, acc: 12.30%] [G loss: 1.496753]\n",
      "[Epoch 0/50] [Batch 19/235] [D loss: 1.497654, acc: 8.98%] [G loss: 1.496411]\n",
      "[Epoch 0/50] [Batch 20/235] [D loss: 1.497785, acc: 10.55%] [G loss: 1.496215]\n",
      "[Epoch 0/50] [Batch 21/235] [D loss: 1.497603, acc: 12.30%] [G loss: 1.496916]\n",
      "[Epoch 0/50] [Batch 22/235] [D loss: 1.497736, acc: 8.01%] [G loss: 1.496962]\n",
      "[Epoch 0/50] [Batch 23/235] [D loss: 1.497477, acc: 11.52%] [G loss: 1.497760]\n",
      "[Epoch 0/50] [Batch 24/235] [D loss: 1.497334, acc: 10.16%] [G loss: 1.498121]\n",
      "[Epoch 0/50] [Batch 25/235] [D loss: 1.497534, acc: 10.94%] [G loss: 1.498745]\n",
      "[Epoch 0/50] [Batch 26/235] [D loss: 1.497015, acc: 11.13%] [G loss: 1.499613]\n",
      "[Epoch 0/50] [Batch 27/235] [D loss: 1.496736, acc: 8.40%] [G loss: 1.501235]\n",
      "[Epoch 0/50] [Batch 28/235] [D loss: 1.496060, acc: 7.62%] [G loss: 1.502537]\n",
      "[Epoch 0/50] [Batch 29/235] [D loss: 1.495730, acc: 10.74%] [G loss: 1.503767]\n",
      "[Epoch 0/50] [Batch 30/235] [D loss: 1.495490, acc: 11.72%] [G loss: 1.504095]\n",
      "[Epoch 0/50] [Batch 31/235] [D loss: 1.495304, acc: 8.98%] [G loss: 1.504413]\n",
      "[Epoch 0/50] [Batch 32/235] [D loss: 1.495492, acc: 8.40%] [G loss: 1.503921]\n",
      "[Epoch 0/50] [Batch 33/235] [D loss: 1.496486, acc: 10.35%] [G loss: 1.501468]\n",
      "[Epoch 0/50] [Batch 34/235] [D loss: 1.497333, acc: 9.57%] [G loss: 1.499824]\n",
      "[Epoch 0/50] [Batch 35/235] [D loss: 1.497235, acc: 10.74%] [G loss: 1.497285]\n",
      "[Epoch 0/50] [Batch 36/235] [D loss: 1.497436, acc: 12.70%] [G loss: 1.495404]\n",
      "[Epoch 0/50] [Batch 37/235] [D loss: 1.497232, acc: 11.52%] [G loss: 1.493438]\n",
      "[Epoch 0/50] [Batch 38/235] [D loss: 1.496516, acc: 8.79%] [G loss: 1.491816]\n",
      "[Epoch 0/50] [Batch 39/235] [D loss: 1.495385, acc: 10.55%] [G loss: 1.491602]\n",
      "[Epoch 0/50] [Batch 40/235] [D loss: 1.494639, acc: 11.52%] [G loss: 1.491023]\n",
      "[Epoch 0/50] [Batch 41/235] [D loss: 1.493283, acc: 12.11%] [G loss: 1.490483]\n",
      "[Epoch 0/50] [Batch 42/235] [D loss: 1.491311, acc: 11.33%] [G loss: 1.488325]\n",
      "[Epoch 0/50] [Batch 43/235] [D loss: 1.491454, acc: 9.96%] [G loss: 1.485599]\n",
      "[Epoch 0/50] [Batch 44/235] [D loss: 1.491632, acc: 9.18%] [G loss: 1.480407]\n",
      "[Epoch 0/50] [Batch 45/235] [D loss: 1.494135, acc: 11.13%] [G loss: 1.475129]\n",
      "[Epoch 0/50] [Batch 46/235] [D loss: 1.494189, acc: 14.26%] [G loss: 1.468228]\n",
      "[Epoch 0/50] [Batch 47/235] [D loss: 1.494897, acc: 11.52%] [G loss: 1.469060]\n",
      "[Epoch 0/50] [Batch 48/235] [D loss: 1.497498, acc: 11.13%] [G loss: 1.465455]\n",
      "[Epoch 0/50] [Batch 49/235] [D loss: 1.497155, acc: 16.41%] [G loss: 1.467769]\n",
      "[Epoch 0/50] [Batch 50/235] [D loss: 1.500312, acc: 13.09%] [G loss: 1.469734]\n",
      "[Epoch 0/50] [Batch 51/235] [D loss: 1.500886, acc: 12.30%] [G loss: 1.476701]\n",
      "[Epoch 0/50] [Batch 52/235] [D loss: 1.500567, acc: 13.48%] [G loss: 1.481266]\n",
      "[Epoch 0/50] [Batch 53/235] [D loss: 1.500902, acc: 12.11%] [G loss: 1.489301]\n",
      "[Epoch 0/50] [Batch 54/235] [D loss: 1.499516, acc: 13.67%] [G loss: 1.495182]\n",
      "[Epoch 0/50] [Batch 55/235] [D loss: 1.498907, acc: 14.06%] [G loss: 1.499714]\n",
      "[Epoch 0/50] [Batch 56/235] [D loss: 1.497447, acc: 11.91%] [G loss: 1.503349]\n",
      "[Epoch 0/50] [Batch 57/235] [D loss: 1.498947, acc: 9.96%] [G loss: 1.505119]\n",
      "[Epoch 0/50] [Batch 58/235] [D loss: 1.498565, acc: 10.74%] [G loss: 1.506626]\n",
      "[Epoch 0/50] [Batch 59/235] [D loss: 1.498232, acc: 11.91%] [G loss: 1.508316]\n",
      "[Epoch 0/50] [Batch 60/235] [D loss: 1.498579, acc: 14.45%] [G loss: 1.508115]\n",
      "[Epoch 0/50] [Batch 61/235] [D loss: 1.498829, acc: 11.91%] [G loss: 1.507787]\n",
      "[Epoch 0/50] [Batch 62/235] [D loss: 1.498839, acc: 13.48%] [G loss: 1.507840]\n",
      "[Epoch 0/50] [Batch 63/235] [D loss: 1.499108, acc: 9.38%] [G loss: 1.507853]\n",
      "[Epoch 0/50] [Batch 64/235] [D loss: 1.498612, acc: 13.28%] [G loss: 1.507916]\n",
      "[Epoch 0/50] [Batch 65/235] [D loss: 1.498425, acc: 10.16%] [G loss: 1.507394]\n",
      "[Epoch 0/50] [Batch 66/235] [D loss: 1.498087, acc: 13.09%] [G loss: 1.506365]\n",
      "[Epoch 0/50] [Batch 67/235] [D loss: 1.498168, acc: 10.35%] [G loss: 1.506493]\n",
      "[Epoch 0/50] [Batch 68/235] [D loss: 1.497321, acc: 10.94%] [G loss: 1.505819]\n",
      "[Epoch 0/50] [Batch 69/235] [D loss: 1.497019, acc: 9.38%] [G loss: 1.504852]\n",
      "[Epoch 0/50] [Batch 70/235] [D loss: 1.496715, acc: 10.74%] [G loss: 1.503512]\n",
      "[Epoch 0/50] [Batch 71/235] [D loss: 1.497290, acc: 12.70%] [G loss: 1.501856]\n",
      "[Epoch 0/50] [Batch 72/235] [D loss: 1.497497, acc: 11.52%] [G loss: 1.499605]\n",
      "[Epoch 0/50] [Batch 73/235] [D loss: 1.497905, acc: 10.74%] [G loss: 1.498763]\n",
      "[Epoch 0/50] [Batch 74/235] [D loss: 1.498201, acc: 14.06%] [G loss: 1.497046]\n",
      "[Epoch 0/50] [Batch 75/235] [D loss: 1.498949, acc: 12.89%] [G loss: 1.497195]\n",
      "[Epoch 0/50] [Batch 76/235] [D loss: 1.498719, acc: 12.30%] [G loss: 1.496744]\n",
      "[Epoch 0/50] [Batch 77/235] [D loss: 1.499459, acc: 15.04%] [G loss: 1.497400]\n",
      "[Epoch 0/50] [Batch 78/235] [D loss: 1.498781, acc: 12.50%] [G loss: 1.499434]\n",
      "[Epoch 0/50] [Batch 79/235] [D loss: 1.499126, acc: 11.72%] [G loss: 1.500175]\n",
      "[Epoch 0/50] [Batch 80/235] [D loss: 1.498597, acc: 13.28%] [G loss: 1.501432]\n",
      "[Epoch 0/50] [Batch 81/235] [D loss: 1.497412, acc: 12.11%] [G loss: 1.502476]\n",
      "[Epoch 0/50] [Batch 82/235] [D loss: 1.497965, acc: 12.11%] [G loss: 1.502756]\n",
      "[Epoch 0/50] [Batch 83/235] [D loss: 1.497251, acc: 11.52%] [G loss: 1.502600]\n",
      "[Epoch 0/50] [Batch 84/235] [D loss: 1.497217, acc: 11.52%] [G loss: 1.502416]\n",
      "[Epoch 0/50] [Batch 85/235] [D loss: 1.496987, acc: 13.67%] [G loss: 1.503068]\n",
      "[Epoch 0/50] [Batch 86/235] [D loss: 1.496607, acc: 13.28%] [G loss: 1.502317]\n",
      "[Epoch 0/50] [Batch 87/235] [D loss: 1.496715, acc: 13.28%] [G loss: 1.501383]\n",
      "[Epoch 0/50] [Batch 88/235] [D loss: 1.496310, acc: 12.30%] [G loss: 1.500947]\n",
      "[Epoch 0/50] [Batch 89/235] [D loss: 1.496087, acc: 15.23%] [G loss: 1.499332]\n",
      "[Epoch 0/50] [Batch 90/235] [D loss: 1.496844, acc: 13.87%] [G loss: 1.498629]\n",
      "[Epoch 0/50] [Batch 91/235] [D loss: 1.496614, acc: 13.28%] [G loss: 1.495490]\n",
      "[Epoch 0/50] [Batch 92/235] [D loss: 1.497195, acc: 14.45%] [G loss: 1.493629]\n",
      "[Epoch 0/50] [Batch 93/235] [D loss: 1.498000, acc: 12.50%] [G loss: 1.491874]\n",
      "[Epoch 0/50] [Batch 94/235] [D loss: 1.497026, acc: 12.30%] [G loss: 1.490539]\n",
      "[Epoch 0/50] [Batch 95/235] [D loss: 1.496621, acc: 12.89%] [G loss: 1.490557]\n",
      "[Epoch 0/50] [Batch 96/235] [D loss: 1.495972, acc: 12.89%] [G loss: 1.488517]\n",
      "[Epoch 0/50] [Batch 97/235] [D loss: 1.495249, acc: 11.13%] [G loss: 1.487558]\n",
      "[Epoch 0/50] [Batch 98/235] [D loss: 1.496021, acc: 14.65%] [G loss: 1.484848]\n",
      "[Epoch 0/50] [Batch 99/235] [D loss: 1.497485, acc: 13.48%] [G loss: 1.480555]\n",
      "[Epoch 0/50] [Batch 100/235] [D loss: 1.497895, acc: 11.91%] [G loss: 1.480847]\n",
      "[Epoch 0/50] [Batch 101/235] [D loss: 1.498932, acc: 13.28%] [G loss: 1.482126]\n",
      "[Epoch 0/50] [Batch 102/235] [D loss: 1.498781, acc: 10.55%] [G loss: 1.486055]\n",
      "[Epoch 0/50] [Batch 103/235] [D loss: 1.498533, acc: 13.28%] [G loss: 1.489446]\n",
      "[Epoch 0/50] [Batch 104/235] [D loss: 1.497419, acc: 11.13%] [G loss: 1.496382]\n",
      "[Epoch 0/50] [Batch 105/235] [D loss: 1.496871, acc: 12.11%] [G loss: 1.500198]\n",
      "[Epoch 0/50] [Batch 106/235] [D loss: 1.495654, acc: 12.30%] [G loss: 1.505476]\n",
      "[Epoch 0/50] [Batch 107/235] [D loss: 1.495220, acc: 11.52%] [G loss: 1.510355]\n",
      "[Epoch 0/50] [Batch 108/235] [D loss: 1.493398, acc: 14.45%] [G loss: 1.512445]\n",
      "[Epoch 0/50] [Batch 109/235] [D loss: 1.492126, acc: 13.09%] [G loss: 1.516911]\n",
      "[Epoch 0/50] [Batch 110/235] [D loss: 1.491787, acc: 11.13%] [G loss: 1.518792]\n",
      "[Epoch 0/50] [Batch 111/235] [D loss: 1.492749, acc: 14.26%] [G loss: 1.517376]\n",
      "[Epoch 0/50] [Batch 112/235] [D loss: 1.494785, acc: 13.67%] [G loss: 1.517132]\n",
      "[Epoch 0/50] [Batch 113/235] [D loss: 1.495970, acc: 10.35%] [G loss: 1.511360]\n",
      "[Epoch 0/50] [Batch 114/235] [D loss: 1.496217, acc: 12.50%] [G loss: 1.507136]\n",
      "[Epoch 0/50] [Batch 115/235] [D loss: 1.498459, acc: 14.06%] [G loss: 1.498378]\n",
      "[Epoch 0/50] [Batch 116/235] [D loss: 1.497327, acc: 12.50%] [G loss: 1.490865]\n",
      "[Epoch 0/50] [Batch 117/235] [D loss: 1.496827, acc: 10.55%] [G loss: 1.486140]\n",
      "[Epoch 0/50] [Batch 118/235] [D loss: 1.492566, acc: 9.77%] [G loss: 1.487212]\n",
      "[Epoch 0/50] [Batch 119/235] [D loss: 1.487538, acc: 12.11%] [G loss: 1.484975]\n",
      "[Epoch 0/50] [Batch 120/235] [D loss: 1.485537, acc: 12.89%] [G loss: 1.483781]\n",
      "[Epoch 0/50] [Batch 121/235] [D loss: 1.482732, acc: 11.13%] [G loss: 1.482808]\n",
      "[Epoch 0/50] [Batch 122/235] [D loss: 1.479192, acc: 11.33%] [G loss: 1.475961]\n",
      "[Epoch 0/50] [Batch 123/235] [D loss: 1.475312, acc: 14.65%] [G loss: 1.472312]\n",
      "[Epoch 0/50] [Batch 124/235] [D loss: 1.480736, acc: 12.89%] [G loss: 1.455952]\n",
      "[Epoch 0/50] [Batch 125/235] [D loss: 1.486603, acc: 13.28%] [G loss: 1.446796]\n",
      "[Epoch 0/50] [Batch 126/235] [D loss: 1.498460, acc: 12.30%] [G loss: 1.424179]\n",
      "[Epoch 0/50] [Batch 127/235] [D loss: 1.504032, acc: 12.11%] [G loss: 1.429381]\n",
      "[Epoch 0/50] [Batch 128/235] [D loss: 1.510417, acc: 14.06%] [G loss: 1.425408]\n",
      "[Epoch 0/50] [Batch 129/235] [D loss: 1.512028, acc: 10.94%] [G loss: 1.445596]\n",
      "[Epoch 0/50] [Batch 130/235] [D loss: 1.505365, acc: 11.91%] [G loss: 1.463141]\n",
      "[Epoch 0/50] [Batch 131/235] [D loss: 1.502428, acc: 12.11%] [G loss: 1.481802]\n",
      "[Epoch 0/50] [Batch 132/235] [D loss: 1.499511, acc: 14.65%] [G loss: 1.496757]\n",
      "[Epoch 0/50] [Batch 133/235] [D loss: 1.499529, acc: 11.33%] [G loss: 1.507264]\n",
      "[Epoch 0/50] [Batch 134/235] [D loss: 1.493019, acc: 14.45%] [G loss: 1.521783]\n",
      "[Epoch 0/50] [Batch 135/235] [D loss: 1.492232, acc: 12.30%] [G loss: 1.530343]\n",
      "[Epoch 0/50] [Batch 136/235] [D loss: 1.491409, acc: 12.50%] [G loss: 1.539534]\n",
      "[Epoch 0/50] [Batch 137/235] [D loss: 1.489546, acc: 12.11%] [G loss: 1.545614]\n",
      "[Epoch 0/50] [Batch 138/235] [D loss: 1.485020, acc: 11.91%] [G loss: 1.554840]\n",
      "[Epoch 0/50] [Batch 139/235] [D loss: 1.490863, acc: 10.74%] [G loss: 1.547275]\n",
      "[Epoch 0/50] [Batch 140/235] [D loss: 1.492653, acc: 11.91%] [G loss: 1.544017]\n",
      "[Epoch 0/50] [Batch 141/235] [D loss: 1.489443, acc: 13.48%] [G loss: 1.543417]\n",
      "[Epoch 0/50] [Batch 142/235] [D loss: 1.490395, acc: 14.06%] [G loss: 1.535223]\n",
      "[Epoch 0/50] [Batch 143/235] [D loss: 1.493675, acc: 12.89%] [G loss: 1.518054]\n",
      "[Epoch 0/50] [Batch 144/235] [D loss: 1.493682, acc: 11.91%] [G loss: 1.511706]\n",
      "[Epoch 0/50] [Batch 145/235] [D loss: 1.494291, acc: 11.52%] [G loss: 1.505235]\n",
      "[Epoch 0/50] [Batch 146/235] [D loss: 1.492925, acc: 13.28%] [G loss: 1.499746]\n",
      "[Epoch 0/50] [Batch 147/235] [D loss: 1.488212, acc: 14.45%] [G loss: 1.495722]\n",
      "[Epoch 0/50] [Batch 148/235] [D loss: 1.490937, acc: 14.45%] [G loss: 1.488876]\n",
      "[Epoch 0/50] [Batch 149/235] [D loss: 1.487989, acc: 11.52%] [G loss: 1.488628]\n",
      "[Epoch 0/50] [Batch 150/235] [D loss: 1.489148, acc: 12.89%] [G loss: 1.485230]\n",
      "[Epoch 0/50] [Batch 151/235] [D loss: 1.491964, acc: 12.89%] [G loss: 1.476256]\n",
      "[Epoch 0/50] [Batch 152/235] [D loss: 1.488899, acc: 10.94%] [G loss: 1.481120]\n",
      "[Epoch 0/50] [Batch 153/235] [D loss: 1.490924, acc: 14.26%] [G loss: 1.463020]\n",
      "[Epoch 0/50] [Batch 154/235] [D loss: 1.489704, acc: 15.04%] [G loss: 1.458565]\n",
      "[Epoch 0/50] [Batch 155/235] [D loss: 1.491644, acc: 12.11%] [G loss: 1.456751]\n",
      "[Epoch 0/50] [Batch 156/235] [D loss: 1.496015, acc: 12.70%] [G loss: 1.454714]\n",
      "[Epoch 0/50] [Batch 157/235] [D loss: 1.492092, acc: 11.91%] [G loss: 1.467855]\n",
      "[Epoch 0/50] [Batch 158/235] [D loss: 1.493382, acc: 10.16%] [G loss: 1.467334]\n",
      "[Epoch 0/50] [Batch 159/235] [D loss: 1.493993, acc: 13.09%] [G loss: 1.468329]\n",
      "[Epoch 0/50] [Batch 160/235] [D loss: 1.495814, acc: 15.23%] [G loss: 1.473199]\n",
      "[Epoch 0/50] [Batch 161/235] [D loss: 1.494628, acc: 14.84%] [G loss: 1.471220]\n",
      "[Epoch 0/50] [Batch 162/235] [D loss: 1.493223, acc: 12.11%] [G loss: 1.478329]\n",
      "[Epoch 0/50] [Batch 163/235] [D loss: 1.491448, acc: 15.23%] [G loss: 1.481959]\n",
      "[Epoch 0/50] [Batch 164/235] [D loss: 1.490638, acc: 12.30%] [G loss: 1.478660]\n",
      "[Epoch 0/50] [Batch 165/235] [D loss: 1.492564, acc: 15.04%] [G loss: 1.474878]\n",
      "[Epoch 0/50] [Batch 166/235] [D loss: 1.496311, acc: 12.70%] [G loss: 1.477467]\n",
      "[Epoch 0/50] [Batch 167/235] [D loss: 1.495258, acc: 13.87%] [G loss: 1.478227]\n",
      "[Epoch 0/50] [Batch 168/235] [D loss: 1.494521, acc: 14.65%] [G loss: 1.478192]\n",
      "[Epoch 0/50] [Batch 169/235] [D loss: 1.493353, acc: 9.57%] [G loss: 1.483439]\n",
      "[Epoch 0/50] [Batch 170/235] [D loss: 1.494192, acc: 12.30%] [G loss: 1.479428]\n",
      "[Epoch 0/50] [Batch 171/235] [D loss: 1.491061, acc: 14.45%] [G loss: 1.482567]\n",
      "[Epoch 0/50] [Batch 172/235] [D loss: 1.495362, acc: 14.45%] [G loss: 1.482906]\n",
      "[Epoch 0/50] [Batch 173/235] [D loss: 1.494013, acc: 14.26%] [G loss: 1.485079]\n",
      "[Epoch 0/50] [Batch 174/235] [D loss: 1.491354, acc: 12.50%] [G loss: 1.483422]\n",
      "[Epoch 0/50] [Batch 175/235] [D loss: 1.492959, acc: 13.28%] [G loss: 1.484799]\n",
      "[Epoch 0/50] [Batch 176/235] [D loss: 1.490995, acc: 14.45%] [G loss: 1.487507]\n",
      "[Epoch 0/50] [Batch 177/235] [D loss: 1.487094, acc: 10.94%] [G loss: 1.494731]\n",
      "[Epoch 0/50] [Batch 178/235] [D loss: 1.488456, acc: 15.62%] [G loss: 1.489783]\n",
      "[Epoch 0/50] [Batch 179/235] [D loss: 1.487635, acc: 13.48%] [G loss: 1.491156]\n",
      "[Epoch 0/50] [Batch 180/235] [D loss: 1.488674, acc: 11.33%] [G loss: 1.497841]\n",
      "[Epoch 0/50] [Batch 181/235] [D loss: 1.485160, acc: 11.52%] [G loss: 1.493721]\n",
      "[Epoch 0/50] [Batch 182/235] [D loss: 1.493521, acc: 14.84%] [G loss: 1.501510]\n",
      "[Epoch 0/50] [Batch 183/235] [D loss: 1.490030, acc: 12.89%] [G loss: 1.497451]\n",
      "[Epoch 0/50] [Batch 184/235] [D loss: 1.488005, acc: 15.23%] [G loss: 1.499379]\n",
      "[Epoch 0/50] [Batch 185/235] [D loss: 1.488593, acc: 12.50%] [G loss: 1.499061]\n",
      "[Epoch 0/50] [Batch 186/235] [D loss: 1.484542, acc: 14.84%] [G loss: 1.496915]\n",
      "[Epoch 0/50] [Batch 187/235] [D loss: 1.485073, acc: 16.80%] [G loss: 1.497992]\n",
      "[Epoch 0/50] [Batch 188/235] [D loss: 1.483591, acc: 15.04%] [G loss: 1.492312]\n",
      "[Epoch 0/50] [Batch 189/235] [D loss: 1.483580, acc: 16.99%] [G loss: 1.488029]\n",
      "[Epoch 0/50] [Batch 190/235] [D loss: 1.488630, acc: 13.67%] [G loss: 1.488849]\n",
      "[Epoch 0/50] [Batch 191/235] [D loss: 1.488647, acc: 16.60%] [G loss: 1.484680]\n",
      "[Epoch 0/50] [Batch 192/235] [D loss: 1.480590, acc: 17.77%] [G loss: 1.476653]\n",
      "[Epoch 0/50] [Batch 193/235] [D loss: 1.483699, acc: 16.60%] [G loss: 1.473758]\n",
      "[Epoch 0/50] [Batch 194/235] [D loss: 1.486303, acc: 12.11%] [G loss: 1.473414]\n",
      "[Epoch 0/50] [Batch 195/235] [D loss: 1.485952, acc: 14.45%] [G loss: 1.470307]\n",
      "[Epoch 0/50] [Batch 196/235] [D loss: 1.487997, acc: 15.23%] [G loss: 1.470245]\n",
      "[Epoch 0/50] [Batch 197/235] [D loss: 1.485814, acc: 13.87%] [G loss: 1.470508]\n",
      "[Epoch 0/50] [Batch 198/235] [D loss: 1.476173, acc: 14.45%] [G loss: 1.483443]\n",
      "[Epoch 0/50] [Batch 199/235] [D loss: 1.484058, acc: 12.30%] [G loss: 1.478683]\n",
      "[Epoch 0/50] [Batch 200/235] [D loss: 1.480815, acc: 16.60%] [G loss: 1.469361]\n",
      "[Epoch 0/50] [Batch 201/235] [D loss: 1.477279, acc: 15.82%] [G loss: 1.472023]\n",
      "[Epoch 0/50] [Batch 202/235] [D loss: 1.477397, acc: 16.60%] [G loss: 1.475678]\n",
      "[Epoch 0/50] [Batch 203/235] [D loss: 1.482616, acc: 15.23%] [G loss: 1.476480]\n",
      "[Epoch 0/50] [Batch 204/235] [D loss: 1.477970, acc: 17.58%] [G loss: 1.483415]\n",
      "[Epoch 0/50] [Batch 205/235] [D loss: 1.481000, acc: 12.50%] [G loss: 1.476236]\n",
      "[Epoch 0/50] [Batch 206/235] [D loss: 1.482068, acc: 17.97%] [G loss: 1.482503]\n",
      "[Epoch 0/50] [Batch 207/235] [D loss: 1.484930, acc: 17.19%] [G loss: 1.480117]\n",
      "[Epoch 0/50] [Batch 208/235] [D loss: 1.480302, acc: 17.19%] [G loss: 1.496156]\n",
      "[Epoch 0/50] [Batch 209/235] [D loss: 1.484619, acc: 17.38%] [G loss: 1.490542]\n",
      "[Epoch 0/50] [Batch 210/235] [D loss: 1.486010, acc: 18.75%] [G loss: 1.497684]\n",
      "[Epoch 0/50] [Batch 211/235] [D loss: 1.481646, acc: 17.58%] [G loss: 1.511890]\n",
      "[Epoch 0/50] [Batch 212/235] [D loss: 1.476277, acc: 18.75%] [G loss: 1.522641]\n",
      "[Epoch 0/50] [Batch 213/235] [D loss: 1.477349, acc: 21.68%] [G loss: 1.528268]\n",
      "[Epoch 0/50] [Batch 214/235] [D loss: 1.477548, acc: 16.21%] [G loss: 1.531188]\n",
      "[Epoch 0/50] [Batch 215/235] [D loss: 1.475830, acc: 17.38%] [G loss: 1.515358]\n",
      "[Epoch 0/50] [Batch 216/235] [D loss: 1.476900, acc: 18.55%] [G loss: 1.510231]\n",
      "[Epoch 0/50] [Batch 217/235] [D loss: 1.469109, acc: 17.77%] [G loss: 1.490807]\n",
      "[Epoch 0/50] [Batch 218/235] [D loss: 1.471971, acc: 18.95%] [G loss: 1.470173]\n",
      "[Epoch 0/50] [Batch 219/235] [D loss: 1.477591, acc: 14.84%] [G loss: 1.469902]\n",
      "[Epoch 0/50] [Batch 220/235] [D loss: 1.476731, acc: 20.31%] [G loss: 1.456490]\n",
      "[Epoch 0/50] [Batch 221/235] [D loss: 1.479650, acc: 19.73%] [G loss: 1.460572]\n",
      "[Epoch 0/50] [Batch 222/235] [D loss: 1.468201, acc: 18.95%] [G loss: 1.461515]\n",
      "[Epoch 0/50] [Batch 223/235] [D loss: 1.471437, acc: 19.14%] [G loss: 1.458700]\n",
      "[Epoch 0/50] [Batch 224/235] [D loss: 1.474804, acc: 19.73%] [G loss: 1.460841]\n",
      "[Epoch 0/50] [Batch 225/235] [D loss: 1.482615, acc: 19.34%] [G loss: 1.471329]\n",
      "[Epoch 0/50] [Batch 226/235] [D loss: 1.473634, acc: 20.12%] [G loss: 1.467052]\n",
      "[Epoch 0/50] [Batch 227/235] [D loss: 1.473318, acc: 21.68%] [G loss: 1.473587]\n",
      "[Epoch 0/50] [Batch 228/235] [D loss: 1.476395, acc: 19.14%] [G loss: 1.471182]\n",
      "[Epoch 0/50] [Batch 229/235] [D loss: 1.477913, acc: 18.36%] [G loss: 1.459495]\n",
      "[Epoch 0/50] [Batch 230/235] [D loss: 1.482478, acc: 18.55%] [G loss: 1.461595]\n",
      "[Epoch 0/50] [Batch 231/235] [D loss: 1.484432, acc: 18.36%] [G loss: 1.452109]\n",
      "[Epoch 0/50] [Batch 232/235] [D loss: 1.491438, acc: 16.60%] [G loss: 1.460544]\n",
      "[Epoch 0/50] [Batch 233/235] [D loss: 1.483167, acc: 17.38%] [G loss: 1.482677]\n",
      "[Epoch 0/50] [Batch 234/235] [D loss: 1.470062, acc: 21.88%] [G loss: 1.490762]\n",
      "[Epoch 1/50] [Batch 0/235] [D loss: 1.466897, acc: 21.09%] [G loss: 1.525039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/50] [Batch 1/235] [D loss: 1.451954, acc: 23.05%] [G loss: 1.530496]\n",
      "[Epoch 1/50] [Batch 2/235] [D loss: 1.444430, acc: 20.31%] [G loss: 1.550360]\n",
      "[Epoch 1/50] [Batch 3/235] [D loss: 1.442197, acc: 18.36%] [G loss: 1.568809]\n",
      "[Epoch 1/50] [Batch 4/235] [D loss: 1.446880, acc: 19.53%] [G loss: 1.525480]\n",
      "[Epoch 1/50] [Batch 5/235] [D loss: 1.468586, acc: 20.70%] [G loss: 1.492573]\n",
      "[Epoch 1/50] [Batch 6/235] [D loss: 1.485496, acc: 20.51%] [G loss: 1.456311]\n",
      "[Epoch 1/50] [Batch 7/235] [D loss: 1.487626, acc: 23.44%] [G loss: 1.446900]\n",
      "[Epoch 1/50] [Batch 8/235] [D loss: 1.495195, acc: 21.68%] [G loss: 1.434644]\n",
      "[Epoch 1/50] [Batch 9/235] [D loss: 1.492473, acc: 23.24%] [G loss: 1.442223]\n",
      "[Epoch 1/50] [Batch 10/235] [D loss: 1.483540, acc: 22.07%] [G loss: 1.436080]\n",
      "[Epoch 1/50] [Batch 11/235] [D loss: 1.463400, acc: 22.27%] [G loss: 1.449886]\n",
      "[Epoch 1/50] [Batch 12/235] [D loss: 1.469784, acc: 22.27%] [G loss: 1.458345]\n",
      "[Epoch 1/50] [Batch 13/235] [D loss: 1.455183, acc: 21.68%] [G loss: 1.455364]\n",
      "[Epoch 1/50] [Batch 14/235] [D loss: 1.447911, acc: 23.63%] [G loss: 1.464875]\n",
      "[Epoch 1/50] [Batch 15/235] [D loss: 1.449270, acc: 22.85%] [G loss: 1.460884]\n",
      "[Epoch 1/50] [Batch 16/235] [D loss: 1.453726, acc: 22.46%] [G loss: 1.462334]\n",
      "[Epoch 1/50] [Batch 17/235] [D loss: 1.447372, acc: 21.68%] [G loss: 1.471829]\n",
      "[Epoch 1/50] [Batch 18/235] [D loss: 1.450348, acc: 22.66%] [G loss: 1.464196]\n",
      "[Epoch 1/50] [Batch 19/235] [D loss: 1.448008, acc: 25.20%] [G loss: 1.471409]\n",
      "[Epoch 1/50] [Batch 20/235] [D loss: 1.438541, acc: 25.98%] [G loss: 1.481024]\n",
      "[Epoch 1/50] [Batch 21/235] [D loss: 1.452125, acc: 23.44%] [G loss: 1.468200]\n",
      "[Epoch 1/50] [Batch 22/235] [D loss: 1.448067, acc: 22.46%] [G loss: 1.472012]\n",
      "[Epoch 1/50] [Batch 23/235] [D loss: 1.457448, acc: 23.05%] [G loss: 1.469711]\n",
      "[Epoch 1/50] [Batch 24/235] [D loss: 1.455681, acc: 21.48%] [G loss: 1.494679]\n",
      "[Epoch 1/50] [Batch 25/235] [D loss: 1.449841, acc: 25.78%] [G loss: 1.483278]\n",
      "[Epoch 1/50] [Batch 26/235] [D loss: 1.458805, acc: 23.83%] [G loss: 1.502178]\n",
      "[Epoch 1/50] [Batch 27/235] [D loss: 1.442833, acc: 27.54%] [G loss: 1.498901]\n",
      "[Epoch 1/50] [Batch 28/235] [D loss: 1.443829, acc: 23.24%] [G loss: 1.506974]\n",
      "[Epoch 1/50] [Batch 29/235] [D loss: 1.437878, acc: 25.00%] [G loss: 1.506115]\n",
      "[Epoch 1/50] [Batch 30/235] [D loss: 1.427516, acc: 28.12%] [G loss: 1.498626]\n",
      "[Epoch 1/50] [Batch 31/235] [D loss: 1.422158, acc: 22.85%] [G loss: 1.501017]\n",
      "[Epoch 1/50] [Batch 32/235] [D loss: 1.420514, acc: 24.61%] [G loss: 1.501199]\n",
      "[Epoch 1/50] [Batch 33/235] [D loss: 1.419905, acc: 26.95%] [G loss: 1.486111]\n",
      "[Epoch 1/50] [Batch 34/235] [D loss: 1.413873, acc: 28.32%] [G loss: 1.484508]\n",
      "[Epoch 1/50] [Batch 35/235] [D loss: 1.427046, acc: 23.44%] [G loss: 1.503153]\n",
      "[Epoch 1/50] [Batch 36/235] [D loss: 1.430185, acc: 26.17%] [G loss: 1.475990]\n",
      "[Epoch 1/50] [Batch 37/235] [D loss: 1.442509, acc: 28.32%] [G loss: 1.461861]\n",
      "[Epoch 1/50] [Batch 38/235] [D loss: 1.444568, acc: 28.12%] [G loss: 1.435502]\n",
      "[Epoch 1/50] [Batch 39/235] [D loss: 1.432385, acc: 28.91%] [G loss: 1.441963]\n",
      "[Epoch 1/50] [Batch 40/235] [D loss: 1.431594, acc: 25.59%] [G loss: 1.466447]\n",
      "[Epoch 1/50] [Batch 41/235] [D loss: 1.426362, acc: 29.30%] [G loss: 1.443203]\n",
      "[Epoch 1/50] [Batch 42/235] [D loss: 1.408406, acc: 29.10%] [G loss: 1.474572]\n",
      "[Epoch 1/50] [Batch 43/235] [D loss: 1.416771, acc: 26.37%] [G loss: 1.455579]\n",
      "[Epoch 1/50] [Batch 44/235] [D loss: 1.404334, acc: 31.05%] [G loss: 1.476664]\n",
      "[Epoch 1/50] [Batch 45/235] [D loss: 1.412095, acc: 31.25%] [G loss: 1.453352]\n",
      "[Epoch 1/50] [Batch 46/235] [D loss: 1.415031, acc: 29.69%] [G loss: 1.478095]\n",
      "[Epoch 1/50] [Batch 47/235] [D loss: 1.403023, acc: 30.27%] [G loss: 1.517903]\n",
      "[Epoch 1/50] [Batch 48/235] [D loss: 1.414106, acc: 27.93%] [G loss: 1.505929]\n",
      "[Epoch 1/50] [Batch 49/235] [D loss: 1.404421, acc: 32.81%] [G loss: 1.491539]\n",
      "[Epoch 1/50] [Batch 50/235] [D loss: 1.411943, acc: 30.08%] [G loss: 1.508130]\n",
      "[Epoch 1/50] [Batch 51/235] [D loss: 1.392097, acc: 30.66%] [G loss: 1.510178]\n",
      "[Epoch 1/50] [Batch 52/235] [D loss: 1.395969, acc: 30.86%] [G loss: 1.513138]\n",
      "[Epoch 1/50] [Batch 53/235] [D loss: 1.396094, acc: 33.01%] [G loss: 1.517879]\n",
      "[Epoch 1/50] [Batch 54/235] [D loss: 1.384259, acc: 34.38%] [G loss: 1.524516]\n",
      "[Epoch 1/50] [Batch 55/235] [D loss: 1.390414, acc: 32.81%] [G loss: 1.536444]\n",
      "[Epoch 1/50] [Batch 56/235] [D loss: 1.406900, acc: 31.25%] [G loss: 1.508398]\n",
      "[Epoch 1/50] [Batch 57/235] [D loss: 1.390430, acc: 35.55%] [G loss: 1.501661]\n",
      "[Epoch 1/50] [Batch 58/235] [D loss: 1.417019, acc: 31.64%] [G loss: 1.492665]\n",
      "[Epoch 1/50] [Batch 59/235] [D loss: 1.416162, acc: 29.69%] [G loss: 1.483292]\n",
      "[Epoch 1/50] [Batch 60/235] [D loss: 1.400435, acc: 30.47%] [G loss: 1.480021]\n",
      "[Epoch 1/50] [Batch 61/235] [D loss: 1.401519, acc: 34.96%] [G loss: 1.471589]\n",
      "[Epoch 1/50] [Batch 62/235] [D loss: 1.399550, acc: 33.79%] [G loss: 1.460809]\n",
      "[Epoch 1/50] [Batch 63/235] [D loss: 1.388021, acc: 33.40%] [G loss: 1.488165]\n",
      "[Epoch 1/50] [Batch 64/235] [D loss: 1.389148, acc: 32.03%] [G loss: 1.472994]\n",
      "[Epoch 1/50] [Batch 65/235] [D loss: 1.387664, acc: 34.57%] [G loss: 1.460551]\n",
      "[Epoch 1/50] [Batch 66/235] [D loss: 1.403288, acc: 33.01%] [G loss: 1.476563]\n",
      "[Epoch 1/50] [Batch 67/235] [D loss: 1.387654, acc: 38.48%] [G loss: 1.458442]\n",
      "[Epoch 1/50] [Batch 68/235] [D loss: 1.400344, acc: 33.59%] [G loss: 1.478361]\n",
      "[Epoch 1/50] [Batch 69/235] [D loss: 1.394497, acc: 35.35%] [G loss: 1.488400]\n",
      "[Epoch 1/50] [Batch 70/235] [D loss: 1.402161, acc: 33.79%] [G loss: 1.537453]\n",
      "[Epoch 1/50] [Batch 71/235] [D loss: 1.374000, acc: 33.79%] [G loss: 1.538707]\n",
      "[Epoch 1/50] [Batch 72/235] [D loss: 1.372765, acc: 33.59%] [G loss: 1.522522]\n",
      "[Epoch 1/50] [Batch 73/235] [D loss: 1.356461, acc: 38.87%] [G loss: 1.539935]\n",
      "[Epoch 1/50] [Batch 74/235] [D loss: 1.359415, acc: 33.98%] [G loss: 1.531725]\n",
      "[Epoch 1/50] [Batch 75/235] [D loss: 1.372676, acc: 36.13%] [G loss: 1.529048]\n",
      "[Epoch 1/50] [Batch 76/235] [D loss: 1.374358, acc: 34.96%] [G loss: 1.488498]\n",
      "[Epoch 1/50] [Batch 77/235] [D loss: 1.399509, acc: 34.57%] [G loss: 1.477769]\n",
      "[Epoch 1/50] [Batch 78/235] [D loss: 1.423139, acc: 31.45%] [G loss: 1.479285]\n",
      "[Epoch 1/50] [Batch 79/235] [D loss: 1.390584, acc: 35.74%] [G loss: 1.489339]\n",
      "[Epoch 1/50] [Batch 80/235] [D loss: 1.404659, acc: 34.77%] [G loss: 1.458823]\n",
      "[Epoch 1/50] [Batch 81/235] [D loss: 1.399375, acc: 35.94%] [G loss: 1.473823]\n",
      "[Epoch 1/50] [Batch 82/235] [D loss: 1.378483, acc: 36.33%] [G loss: 1.478424]\n",
      "[Epoch 1/50] [Batch 83/235] [D loss: 1.371528, acc: 35.35%] [G loss: 1.493462]\n",
      "[Epoch 1/50] [Batch 84/235] [D loss: 1.368110, acc: 34.18%] [G loss: 1.504223]\n",
      "[Epoch 1/50] [Batch 85/235] [D loss: 1.369692, acc: 34.96%] [G loss: 1.499170]\n",
      "[Epoch 1/50] [Batch 86/235] [D loss: 1.366496, acc: 35.74%] [G loss: 1.515932]\n",
      "[Epoch 1/50] [Batch 87/235] [D loss: 1.362848, acc: 37.30%] [G loss: 1.487995]\n",
      "[Epoch 1/50] [Batch 88/235] [D loss: 1.358287, acc: 39.45%] [G loss: 1.519696]\n",
      "[Epoch 1/50] [Batch 89/235] [D loss: 1.392395, acc: 36.72%] [G loss: 1.497345]\n",
      "[Epoch 1/50] [Batch 90/235] [D loss: 1.388366, acc: 37.50%] [G loss: 1.484764]\n",
      "[Epoch 1/50] [Batch 91/235] [D loss: 1.384094, acc: 39.26%] [G loss: 1.461040]\n",
      "[Epoch 1/50] [Batch 92/235] [D loss: 1.378571, acc: 40.43%] [G loss: 1.484299]\n",
      "[Epoch 1/50] [Batch 93/235] [D loss: 1.388082, acc: 39.84%] [G loss: 1.483616]\n",
      "[Epoch 1/50] [Batch 94/235] [D loss: 1.380476, acc: 41.02%] [G loss: 1.488921]\n",
      "[Epoch 1/50] [Batch 95/235] [D loss: 1.378924, acc: 41.21%] [G loss: 1.497450]\n",
      "[Epoch 1/50] [Batch 96/235] [D loss: 1.367461, acc: 38.67%] [G loss: 1.528545]\n",
      "[Epoch 1/50] [Batch 97/235] [D loss: 1.364683, acc: 36.52%] [G loss: 1.506899]\n",
      "[Epoch 1/50] [Batch 98/235] [D loss: 1.373707, acc: 38.09%] [G loss: 1.491048]\n",
      "[Epoch 1/50] [Batch 99/235] [D loss: 1.369146, acc: 37.70%] [G loss: 1.498295]\n",
      "[Epoch 1/50] [Batch 100/235] [D loss: 1.363358, acc: 37.50%] [G loss: 1.488734]\n",
      "[Epoch 1/50] [Batch 101/235] [D loss: 1.360857, acc: 37.50%] [G loss: 1.520822]\n",
      "[Epoch 1/50] [Batch 102/235] [D loss: 1.378784, acc: 34.77%] [G loss: 1.498370]\n",
      "[Epoch 1/50] [Batch 103/235] [D loss: 1.355060, acc: 42.77%] [G loss: 1.509070]\n",
      "[Epoch 1/50] [Batch 104/235] [D loss: 1.368391, acc: 42.19%] [G loss: 1.457092]\n",
      "[Epoch 1/50] [Batch 105/235] [D loss: 1.388131, acc: 40.82%] [G loss: 1.458471]\n",
      "[Epoch 1/50] [Batch 106/235] [D loss: 1.369137, acc: 38.87%] [G loss: 1.448368]\n",
      "[Epoch 1/50] [Batch 107/235] [D loss: 1.358183, acc: 42.19%] [G loss: 1.472348]\n",
      "[Epoch 1/50] [Batch 108/235] [D loss: 1.382796, acc: 38.87%] [G loss: 1.449666]\n",
      "[Epoch 1/50] [Batch 109/235] [D loss: 1.373447, acc: 39.65%] [G loss: 1.499285]\n",
      "[Epoch 1/50] [Batch 110/235] [D loss: 1.364686, acc: 41.99%] [G loss: 1.498290]\n",
      "[Epoch 1/50] [Batch 111/235] [D loss: 1.356948, acc: 40.62%] [G loss: 1.523222]\n",
      "[Epoch 1/50] [Batch 112/235] [D loss: 1.341242, acc: 44.34%] [G loss: 1.479596]\n",
      "[Epoch 1/50] [Batch 113/235] [D loss: 1.388859, acc: 35.16%] [G loss: 1.505335]\n",
      "[Epoch 1/50] [Batch 114/235] [D loss: 1.359355, acc: 38.48%] [G loss: 1.489717]\n",
      "[Epoch 1/50] [Batch 115/235] [D loss: 1.365160, acc: 42.38%] [G loss: 1.496516]\n",
      "[Epoch 1/50] [Batch 116/235] [D loss: 1.355285, acc: 41.99%] [G loss: 1.479075]\n",
      "[Epoch 1/50] [Batch 117/235] [D loss: 1.348976, acc: 42.19%] [G loss: 1.503930]\n",
      "[Epoch 1/50] [Batch 118/235] [D loss: 1.365439, acc: 42.19%] [G loss: 1.480391]\n",
      "[Epoch 1/50] [Batch 119/235] [D loss: 1.364140, acc: 39.26%] [G loss: 1.464952]\n",
      "[Epoch 1/50] [Batch 120/235] [D loss: 1.367448, acc: 38.48%] [G loss: 1.511239]\n",
      "[Epoch 1/50] [Batch 121/235] [D loss: 1.364263, acc: 39.84%] [G loss: 1.494028]\n",
      "[Epoch 1/50] [Batch 122/235] [D loss: 1.353929, acc: 41.02%] [G loss: 1.494219]\n",
      "[Epoch 1/50] [Batch 123/235] [D loss: 1.343269, acc: 45.12%] [G loss: 1.438334]\n",
      "[Epoch 1/50] [Batch 124/235] [D loss: 1.357073, acc: 40.23%] [G loss: 1.475724]\n",
      "[Epoch 1/50] [Batch 125/235] [D loss: 1.356081, acc: 40.43%] [G loss: 1.479594]\n",
      "[Epoch 1/50] [Batch 126/235] [D loss: 1.341737, acc: 42.97%] [G loss: 1.480440]\n",
      "[Epoch 1/50] [Batch 127/235] [D loss: 1.370099, acc: 37.89%] [G loss: 1.492886]\n",
      "[Epoch 1/50] [Batch 128/235] [D loss: 1.341310, acc: 43.95%] [G loss: 1.449206]\n",
      "[Epoch 1/50] [Batch 129/235] [D loss: 1.349026, acc: 43.75%] [G loss: 1.479077]\n",
      "[Epoch 1/50] [Batch 130/235] [D loss: 1.361901, acc: 38.87%] [G loss: 1.476880]\n",
      "[Epoch 1/50] [Batch 131/235] [D loss: 1.358060, acc: 40.23%] [G loss: 1.476600]\n",
      "[Epoch 1/50] [Batch 132/235] [D loss: 1.356061, acc: 41.41%] [G loss: 1.482993]\n",
      "[Epoch 1/50] [Batch 133/235] [D loss: 1.364874, acc: 43.36%] [G loss: 1.450066]\n",
      "[Epoch 1/50] [Batch 134/235] [D loss: 1.386492, acc: 40.04%] [G loss: 1.465025]\n",
      "[Epoch 1/50] [Batch 135/235] [D loss: 1.372042, acc: 39.65%] [G loss: 1.491922]\n",
      "[Epoch 1/50] [Batch 136/235] [D loss: 1.366827, acc: 40.23%] [G loss: 1.474355]\n",
      "[Epoch 1/50] [Batch 137/235] [D loss: 1.363768, acc: 40.82%] [G loss: 1.467170]\n",
      "[Epoch 1/50] [Batch 138/235] [D loss: 1.340525, acc: 46.09%] [G loss: 1.464756]\n",
      "[Epoch 1/50] [Batch 139/235] [D loss: 1.338946, acc: 43.75%] [G loss: 1.490176]\n",
      "[Epoch 1/50] [Batch 140/235] [D loss: 1.339372, acc: 42.38%] [G loss: 1.461388]\n",
      "[Epoch 1/50] [Batch 141/235] [D loss: 1.362437, acc: 41.99%] [G loss: 1.494896]\n",
      "[Epoch 1/50] [Batch 142/235] [D loss: 1.336833, acc: 45.31%] [G loss: 1.459963]\n",
      "[Epoch 1/50] [Batch 143/235] [D loss: 1.347069, acc: 43.75%] [G loss: 1.476002]\n",
      "[Epoch 1/50] [Batch 144/235] [D loss: 1.354465, acc: 45.70%] [G loss: 1.436544]\n",
      "[Epoch 1/50] [Batch 145/235] [D loss: 1.352700, acc: 45.51%] [G loss: 1.455656]\n",
      "[Epoch 1/50] [Batch 146/235] [D loss: 1.344283, acc: 45.12%] [G loss: 1.457491]\n",
      "[Epoch 1/50] [Batch 147/235] [D loss: 1.354941, acc: 42.77%] [G loss: 1.453981]\n",
      "[Epoch 1/50] [Batch 148/235] [D loss: 1.366916, acc: 45.12%] [G loss: 1.455113]\n",
      "[Epoch 1/50] [Batch 149/235] [D loss: 1.372444, acc: 44.34%] [G loss: 1.447384]\n",
      "[Epoch 1/50] [Batch 150/235] [D loss: 1.359982, acc: 44.34%] [G loss: 1.428332]\n",
      "[Epoch 1/50] [Batch 151/235] [D loss: 1.354089, acc: 40.04%] [G loss: 1.479765]\n",
      "[Epoch 1/50] [Batch 152/235] [D loss: 1.349334, acc: 44.14%] [G loss: 1.429853]\n",
      "[Epoch 1/50] [Batch 153/235] [D loss: 1.327106, acc: 47.46%] [G loss: 1.445724]\n",
      "[Epoch 1/50] [Batch 154/235] [D loss: 1.346959, acc: 42.77%] [G loss: 1.479758]\n",
      "[Epoch 1/50] [Batch 155/235] [D loss: 1.332319, acc: 44.53%] [G loss: 1.497435]\n",
      "[Epoch 1/50] [Batch 156/235] [D loss: 1.327347, acc: 46.88%] [G loss: 1.469254]\n",
      "[Epoch 1/50] [Batch 157/235] [D loss: 1.339362, acc: 45.31%] [G loss: 1.454419]\n",
      "[Epoch 1/50] [Batch 158/235] [D loss: 1.344037, acc: 46.29%] [G loss: 1.464167]\n",
      "[Epoch 1/50] [Batch 159/235] [D loss: 1.331190, acc: 46.29%] [G loss: 1.478519]\n",
      "[Epoch 1/50] [Batch 160/235] [D loss: 1.350842, acc: 47.07%] [G loss: 1.434690]\n",
      "[Epoch 1/50] [Batch 161/235] [D loss: 1.342174, acc: 45.90%] [G loss: 1.447531]\n",
      "[Epoch 1/50] [Batch 162/235] [D loss: 1.338618, acc: 47.46%] [G loss: 1.452828]\n",
      "[Epoch 1/50] [Batch 163/235] [D loss: 1.338283, acc: 44.34%] [G loss: 1.423944]\n",
      "[Epoch 1/50] [Batch 164/235] [D loss: 1.346618, acc: 43.16%] [G loss: 1.478494]\n",
      "[Epoch 1/50] [Batch 165/235] [D loss: 1.342034, acc: 43.75%] [G loss: 1.482875]\n",
      "[Epoch 1/50] [Batch 166/235] [D loss: 1.355604, acc: 42.38%] [G loss: 1.478138]\n",
      "[Epoch 1/50] [Batch 167/235] [D loss: 1.341362, acc: 45.51%] [G loss: 1.483962]\n",
      "[Epoch 1/50] [Batch 168/235] [D loss: 1.331368, acc: 45.31%] [G loss: 1.464463]\n",
      "[Epoch 1/50] [Batch 169/235] [D loss: 1.339773, acc: 41.41%] [G loss: 1.487265]\n",
      "[Epoch 1/50] [Batch 170/235] [D loss: 1.334929, acc: 47.07%] [G loss: 1.466623]\n",
      "[Epoch 1/50] [Batch 171/235] [D loss: 1.338620, acc: 44.53%] [G loss: 1.474354]\n",
      "[Epoch 1/50] [Batch 172/235] [D loss: 1.332015, acc: 46.29%] [G loss: 1.461507]\n",
      "[Epoch 1/50] [Batch 173/235] [D loss: 1.341650, acc: 44.14%] [G loss: 1.462752]\n",
      "[Epoch 1/50] [Batch 174/235] [D loss: 1.353096, acc: 45.90%] [G loss: 1.446114]\n",
      "[Epoch 1/50] [Batch 175/235] [D loss: 1.351506, acc: 44.14%] [G loss: 1.451487]\n",
      "[Epoch 1/50] [Batch 176/235] [D loss: 1.343932, acc: 45.31%] [G loss: 1.447094]\n",
      "[Epoch 1/50] [Batch 177/235] [D loss: 1.345030, acc: 43.95%] [G loss: 1.441444]\n",
      "[Epoch 1/50] [Batch 178/235] [D loss: 1.349527, acc: 44.14%] [G loss: 1.436276]\n",
      "[Epoch 1/50] [Batch 179/235] [D loss: 1.351298, acc: 44.34%] [G loss: 1.436457]\n",
      "[Epoch 1/50] [Batch 180/235] [D loss: 1.325653, acc: 48.44%] [G loss: 1.432138]\n",
      "[Epoch 1/50] [Batch 181/235] [D loss: 1.328322, acc: 45.51%] [G loss: 1.459561]\n",
      "[Epoch 1/50] [Batch 182/235] [D loss: 1.308932, acc: 49.41%] [G loss: 1.423152]\n",
      "[Epoch 1/50] [Batch 183/235] [D loss: 1.323873, acc: 50.98%] [G loss: 1.411570]\n",
      "[Epoch 1/50] [Batch 184/235] [D loss: 1.323495, acc: 48.44%] [G loss: 1.461535]\n",
      "[Epoch 1/50] [Batch 185/235] [D loss: 1.331183, acc: 49.41%] [G loss: 1.456385]\n",
      "[Epoch 1/50] [Batch 186/235] [D loss: 1.358326, acc: 42.19%] [G loss: 1.473317]\n",
      "[Epoch 1/50] [Batch 187/235] [D loss: 1.320104, acc: 45.70%] [G loss: 1.477751]\n",
      "[Epoch 1/50] [Batch 188/235] [D loss: 1.333683, acc: 44.34%] [G loss: 1.464492]\n",
      "[Epoch 1/50] [Batch 189/235] [D loss: 1.333279, acc: 48.63%] [G loss: 1.398885]\n",
      "[Epoch 1/50] [Batch 190/235] [D loss: 1.327561, acc: 48.05%] [G loss: 1.424304]\n",
      "[Epoch 1/50] [Batch 191/235] [D loss: 1.329423, acc: 46.09%] [G loss: 1.453251]\n",
      "[Epoch 1/50] [Batch 192/235] [D loss: 1.332858, acc: 47.85%] [G loss: 1.424193]\n",
      "[Epoch 1/50] [Batch 193/235] [D loss: 1.341683, acc: 46.48%] [G loss: 1.473205]\n",
      "[Epoch 1/50] [Batch 194/235] [D loss: 1.314893, acc: 48.63%] [G loss: 1.439011]\n",
      "[Epoch 1/50] [Batch 195/235] [D loss: 1.315510, acc: 49.41%] [G loss: 1.412830]\n",
      "[Epoch 1/50] [Batch 196/235] [D loss: 1.323889, acc: 46.68%] [G loss: 1.422220]\n",
      "[Epoch 1/50] [Batch 197/235] [D loss: 1.302717, acc: 52.54%] [G loss: 1.471721]\n",
      "[Epoch 1/50] [Batch 198/235] [D loss: 1.310886, acc: 49.80%] [G loss: 1.463024]\n",
      "[Epoch 1/50] [Batch 199/235] [D loss: 1.316904, acc: 46.29%] [G loss: 1.438966]\n",
      "[Epoch 1/50] [Batch 200/235] [D loss: 1.315093, acc: 48.24%] [G loss: 1.432865]\n",
      "[Epoch 1/50] [Batch 201/235] [D loss: 1.298113, acc: 50.00%] [G loss: 1.393753]\n",
      "[Epoch 1/50] [Batch 202/235] [D loss: 1.324923, acc: 50.59%] [G loss: 1.414244]\n",
      "[Epoch 1/50] [Batch 203/235] [D loss: 1.313604, acc: 51.56%] [G loss: 1.403999]\n",
      "[Epoch 1/50] [Batch 204/235] [D loss: 1.322068, acc: 50.20%] [G loss: 1.407483]\n",
      "[Epoch 1/50] [Batch 205/235] [D loss: 1.312163, acc: 51.95%] [G loss: 1.408671]\n",
      "[Epoch 1/50] [Batch 206/235] [D loss: 1.327802, acc: 48.63%] [G loss: 1.431361]\n",
      "[Epoch 1/50] [Batch 207/235] [D loss: 1.301434, acc: 51.37%] [G loss: 1.422382]\n",
      "[Epoch 1/50] [Batch 208/235] [D loss: 1.325119, acc: 47.66%] [G loss: 1.454953]\n",
      "[Epoch 1/50] [Batch 209/235] [D loss: 1.297376, acc: 51.37%] [G loss: 1.438830]\n",
      "[Epoch 1/50] [Batch 210/235] [D loss: 1.296742, acc: 49.61%] [G loss: 1.453944]\n",
      "[Epoch 1/50] [Batch 211/235] [D loss: 1.303558, acc: 49.61%] [G loss: 1.428490]\n",
      "[Epoch 1/50] [Batch 212/235] [D loss: 1.309798, acc: 47.85%] [G loss: 1.454906]\n",
      "[Epoch 1/50] [Batch 213/235] [D loss: 1.321326, acc: 48.24%] [G loss: 1.402082]\n",
      "[Epoch 1/50] [Batch 214/235] [D loss: 1.339856, acc: 47.46%] [G loss: 1.443376]\n",
      "[Epoch 1/50] [Batch 215/235] [D loss: 1.315190, acc: 50.98%] [G loss: 1.425808]\n",
      "[Epoch 1/50] [Batch 216/235] [D loss: 1.319324, acc: 52.15%] [G loss: 1.400550]\n",
      "[Epoch 1/50] [Batch 217/235] [D loss: 1.300796, acc: 55.47%] [G loss: 1.395023]\n",
      "[Epoch 1/50] [Batch 218/235] [D loss: 1.326313, acc: 45.90%] [G loss: 1.457052]\n",
      "[Epoch 1/50] [Batch 219/235] [D loss: 1.317813, acc: 50.20%] [G loss: 1.406826]\n",
      "[Epoch 1/50] [Batch 220/235] [D loss: 1.331556, acc: 49.02%] [G loss: 1.413350]\n",
      "[Epoch 1/50] [Batch 221/235] [D loss: 1.302452, acc: 51.37%] [G loss: 1.440351]\n",
      "[Epoch 1/50] [Batch 222/235] [D loss: 1.315448, acc: 49.80%] [G loss: 1.442954]\n",
      "[Epoch 1/50] [Batch 223/235] [D loss: 1.315987, acc: 48.44%] [G loss: 1.436151]\n",
      "[Epoch 1/50] [Batch 224/235] [D loss: 1.291559, acc: 50.98%] [G loss: 1.425478]\n",
      "[Epoch 1/50] [Batch 225/235] [D loss: 1.299413, acc: 53.52%] [G loss: 1.393368]\n",
      "[Epoch 1/50] [Batch 226/235] [D loss: 1.315308, acc: 50.59%] [G loss: 1.421098]\n",
      "[Epoch 1/50] [Batch 227/235] [D loss: 1.286874, acc: 53.52%] [G loss: 1.421057]\n",
      "[Epoch 1/50] [Batch 228/235] [D loss: 1.314925, acc: 50.59%] [G loss: 1.420281]\n",
      "[Epoch 1/50] [Batch 229/235] [D loss: 1.298601, acc: 54.49%] [G loss: 1.363433]\n",
      "[Epoch 1/50] [Batch 230/235] [D loss: 1.318398, acc: 50.00%] [G loss: 1.385309]\n",
      "[Epoch 1/50] [Batch 231/235] [D loss: 1.294683, acc: 54.88%] [G loss: 1.383475]\n",
      "[Epoch 1/50] [Batch 232/235] [D loss: 1.295408, acc: 51.17%] [G loss: 1.430362]\n",
      "[Epoch 1/50] [Batch 233/235] [D loss: 1.321939, acc: 44.53%] [G loss: 1.449902]\n",
      "[Epoch 1/50] [Batch 234/235] [D loss: 1.284436, acc: 53.65%] [G loss: 1.384194]\n",
      "[Epoch 2/50] [Batch 0/235] [D loss: 1.318926, acc: 46.48%] [G loss: 1.457808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/50] [Batch 1/235] [D loss: 1.312712, acc: 48.24%] [G loss: 1.455630]\n",
      "[Epoch 2/50] [Batch 2/235] [D loss: 1.304760, acc: 50.00%] [G loss: 1.451487]\n",
      "[Epoch 2/50] [Batch 3/235] [D loss: 1.293179, acc: 51.56%] [G loss: 1.410725]\n",
      "[Epoch 2/50] [Batch 4/235] [D loss: 1.307432, acc: 50.00%] [G loss: 1.417553]\n",
      "[Epoch 2/50] [Batch 5/235] [D loss: 1.287976, acc: 54.49%] [G loss: 1.387951]\n",
      "[Epoch 2/50] [Batch 6/235] [D loss: 1.285886, acc: 53.91%] [G loss: 1.395772]\n",
      "[Epoch 2/50] [Batch 7/235] [D loss: 1.271707, acc: 57.42%] [G loss: 1.372927]\n",
      "[Epoch 2/50] [Batch 8/235] [D loss: 1.296631, acc: 52.15%] [G loss: 1.398365]\n",
      "[Epoch 2/50] [Batch 9/235] [D loss: 1.311848, acc: 49.41%] [G loss: 1.420412]\n",
      "[Epoch 2/50] [Batch 10/235] [D loss: 1.289036, acc: 53.32%] [G loss: 1.417856]\n",
      "[Epoch 2/50] [Batch 11/235] [D loss: 1.317664, acc: 49.41%] [G loss: 1.385152]\n",
      "[Epoch 2/50] [Batch 12/235] [D loss: 1.297987, acc: 54.69%] [G loss: 1.384028]\n",
      "[Epoch 2/50] [Batch 13/235] [D loss: 1.301513, acc: 55.27%] [G loss: 1.398155]\n",
      "[Epoch 2/50] [Batch 14/235] [D loss: 1.291623, acc: 53.52%] [G loss: 1.395805]\n",
      "[Epoch 2/50] [Batch 15/235] [D loss: 1.288578, acc: 52.15%] [G loss: 1.447612]\n",
      "[Epoch 2/50] [Batch 16/235] [D loss: 1.292860, acc: 52.54%] [G loss: 1.383275]\n",
      "[Epoch 2/50] [Batch 17/235] [D loss: 1.305932, acc: 52.93%] [G loss: 1.409025]\n",
      "[Epoch 2/50] [Batch 18/235] [D loss: 1.285920, acc: 54.69%] [G loss: 1.410093]\n",
      "[Epoch 2/50] [Batch 19/235] [D loss: 1.302570, acc: 55.66%] [G loss: 1.422273]\n",
      "[Epoch 2/50] [Batch 20/235] [D loss: 1.297943, acc: 52.54%] [G loss: 1.401129]\n",
      "[Epoch 2/50] [Batch 21/235] [D loss: 1.317827, acc: 48.83%] [G loss: 1.403645]\n",
      "[Epoch 2/50] [Batch 22/235] [D loss: 1.269425, acc: 58.20%] [G loss: 1.368370]\n",
      "[Epoch 2/50] [Batch 23/235] [D loss: 1.299543, acc: 53.12%] [G loss: 1.401558]\n",
      "[Epoch 2/50] [Batch 24/235] [D loss: 1.269700, acc: 58.01%] [G loss: 1.395685]\n",
      "[Epoch 2/50] [Batch 25/235] [D loss: 1.271946, acc: 55.27%] [G loss: 1.384737]\n",
      "[Epoch 2/50] [Batch 26/235] [D loss: 1.275153, acc: 56.25%] [G loss: 1.384877]\n",
      "[Epoch 2/50] [Batch 27/235] [D loss: 1.275418, acc: 57.23%] [G loss: 1.383968]\n",
      "[Epoch 2/50] [Batch 28/235] [D loss: 1.287625, acc: 56.25%] [G loss: 1.376816]\n",
      "[Epoch 2/50] [Batch 29/235] [D loss: 1.277720, acc: 57.42%] [G loss: 1.384788]\n",
      "[Epoch 2/50] [Batch 30/235] [D loss: 1.254645, acc: 57.81%] [G loss: 1.414555]\n",
      "[Epoch 2/50] [Batch 31/235] [D loss: 1.267916, acc: 57.03%] [G loss: 1.366815]\n",
      "[Epoch 2/50] [Batch 32/235] [D loss: 1.274249, acc: 57.81%] [G loss: 1.384766]\n",
      "[Epoch 2/50] [Batch 33/235] [D loss: 1.264937, acc: 55.47%] [G loss: 1.376270]\n",
      "[Epoch 2/50] [Batch 34/235] [D loss: 1.272262, acc: 57.42%] [G loss: 1.382287]\n",
      "[Epoch 2/50] [Batch 35/235] [D loss: 1.269769, acc: 57.42%] [G loss: 1.394063]\n",
      "[Epoch 2/50] [Batch 36/235] [D loss: 1.273866, acc: 58.01%] [G loss: 1.389909]\n",
      "[Epoch 2/50] [Batch 37/235] [D loss: 1.238129, acc: 58.59%] [G loss: 1.406516]\n",
      "[Epoch 2/50] [Batch 38/235] [D loss: 1.262707, acc: 56.25%] [G loss: 1.377050]\n",
      "[Epoch 2/50] [Batch 39/235] [D loss: 1.261506, acc: 58.79%] [G loss: 1.353211]\n",
      "[Epoch 2/50] [Batch 40/235] [D loss: 1.278676, acc: 55.86%] [G loss: 1.414262]\n",
      "[Epoch 2/50] [Batch 41/235] [D loss: 1.272017, acc: 51.56%] [G loss: 1.428348]\n",
      "[Epoch 2/50] [Batch 42/235] [D loss: 1.288163, acc: 55.08%] [G loss: 1.365665]\n",
      "[Epoch 2/50] [Batch 43/235] [D loss: 1.265838, acc: 57.62%] [G loss: 1.359629]\n",
      "[Epoch 2/50] [Batch 44/235] [D loss: 1.257302, acc: 56.84%] [G loss: 1.343252]\n",
      "[Epoch 2/50] [Batch 45/235] [D loss: 1.272851, acc: 55.86%] [G loss: 1.366542]\n",
      "[Epoch 2/50] [Batch 46/235] [D loss: 1.269535, acc: 54.88%] [G loss: 1.354323]\n",
      "[Epoch 2/50] [Batch 47/235] [D loss: 1.289291, acc: 55.27%] [G loss: 1.388480]\n",
      "[Epoch 2/50] [Batch 48/235] [D loss: 1.274787, acc: 55.66%] [G loss: 1.384610]\n",
      "[Epoch 2/50] [Batch 49/235] [D loss: 1.272515, acc: 57.62%] [G loss: 1.389580]\n",
      "[Epoch 2/50] [Batch 50/235] [D loss: 1.278605, acc: 55.27%] [G loss: 1.379733]\n",
      "[Epoch 2/50] [Batch 51/235] [D loss: 1.269173, acc: 58.98%] [G loss: 1.372590]\n",
      "[Epoch 2/50] [Batch 52/235] [D loss: 1.265572, acc: 56.64%] [G loss: 1.400170]\n",
      "[Epoch 2/50] [Batch 53/235] [D loss: 1.281813, acc: 54.49%] [G loss: 1.425849]\n",
      "[Epoch 2/50] [Batch 54/235] [D loss: 1.279702, acc: 58.98%] [G loss: 1.355070]\n",
      "[Epoch 2/50] [Batch 55/235] [D loss: 1.293762, acc: 55.08%] [G loss: 1.393003]\n",
      "[Epoch 2/50] [Batch 56/235] [D loss: 1.273878, acc: 60.94%] [G loss: 1.438242]\n",
      "[Epoch 2/50] [Batch 57/235] [D loss: 1.252129, acc: 59.38%] [G loss: 1.361979]\n",
      "[Epoch 2/50] [Batch 58/235] [D loss: 1.296072, acc: 51.37%] [G loss: 1.326052]\n",
      "[Epoch 2/50] [Batch 59/235] [D loss: 1.266951, acc: 57.23%] [G loss: 1.355868]\n",
      "[Epoch 2/50] [Batch 60/235] [D loss: 1.276879, acc: 60.16%] [G loss: 1.376379]\n",
      "[Epoch 2/50] [Batch 61/235] [D loss: 1.275463, acc: 56.45%] [G loss: 1.405292]\n",
      "[Epoch 2/50] [Batch 62/235] [D loss: 1.262495, acc: 61.72%] [G loss: 1.355090]\n",
      "[Epoch 2/50] [Batch 63/235] [D loss: 1.242263, acc: 60.94%] [G loss: 1.340013]\n",
      "[Epoch 2/50] [Batch 64/235] [D loss: 1.249016, acc: 56.05%] [G loss: 1.380849]\n",
      "[Epoch 2/50] [Batch 65/235] [D loss: 1.251410, acc: 60.16%] [G loss: 1.365166]\n",
      "[Epoch 2/50] [Batch 66/235] [D loss: 1.254179, acc: 58.98%] [G loss: 1.338526]\n",
      "[Epoch 2/50] [Batch 67/235] [D loss: 1.269108, acc: 56.45%] [G loss: 1.359955]\n",
      "[Epoch 2/50] [Batch 68/235] [D loss: 1.240883, acc: 62.11%] [G loss: 1.350471]\n",
      "[Epoch 2/50] [Batch 69/235] [D loss: 1.230386, acc: 62.11%] [G loss: 1.347947]\n",
      "[Epoch 2/50] [Batch 70/235] [D loss: 1.240804, acc: 62.30%] [G loss: 1.342119]\n",
      "[Epoch 2/50] [Batch 71/235] [D loss: 1.266405, acc: 59.18%] [G loss: 1.359410]\n",
      "[Epoch 2/50] [Batch 72/235] [D loss: 1.254788, acc: 61.13%] [G loss: 1.361646]\n",
      "[Epoch 2/50] [Batch 73/235] [D loss: 1.242473, acc: 61.91%] [G loss: 1.371068]\n",
      "[Epoch 2/50] [Batch 74/235] [D loss: 1.245390, acc: 59.18%] [G loss: 1.348991]\n",
      "[Epoch 2/50] [Batch 75/235] [D loss: 1.260157, acc: 63.09%] [G loss: 1.362517]\n",
      "[Epoch 2/50] [Batch 76/235] [D loss: 1.255565, acc: 59.96%] [G loss: 1.360095]\n",
      "[Epoch 2/50] [Batch 77/235] [D loss: 1.244412, acc: 64.06%] [G loss: 1.331115]\n",
      "[Epoch 2/50] [Batch 78/235] [D loss: 1.239482, acc: 61.13%] [G loss: 1.344960]\n",
      "[Epoch 2/50] [Batch 79/235] [D loss: 1.255565, acc: 59.77%] [G loss: 1.375605]\n",
      "[Epoch 2/50] [Batch 80/235] [D loss: 1.241660, acc: 65.62%] [G loss: 1.354718]\n",
      "[Epoch 2/50] [Batch 81/235] [D loss: 1.243944, acc: 60.35%] [G loss: 1.347006]\n",
      "[Epoch 2/50] [Batch 82/235] [D loss: 1.232368, acc: 64.26%] [G loss: 1.339370]\n",
      "[Epoch 2/50] [Batch 83/235] [D loss: 1.238429, acc: 62.30%] [G loss: 1.348369]\n",
      "[Epoch 2/50] [Batch 84/235] [D loss: 1.263237, acc: 60.94%] [G loss: 1.349527]\n",
      "[Epoch 2/50] [Batch 85/235] [D loss: 1.230474, acc: 62.11%] [G loss: 1.365178]\n",
      "[Epoch 2/50] [Batch 86/235] [D loss: 1.245733, acc: 63.09%] [G loss: 1.365794]\n",
      "[Epoch 2/50] [Batch 87/235] [D loss: 1.251329, acc: 61.52%] [G loss: 1.345847]\n",
      "[Epoch 2/50] [Batch 88/235] [D loss: 1.258719, acc: 60.74%] [G loss: 1.384796]\n",
      "[Epoch 2/50] [Batch 89/235] [D loss: 1.249323, acc: 60.94%] [G loss: 1.357172]\n",
      "[Epoch 2/50] [Batch 90/235] [D loss: 1.226348, acc: 66.80%] [G loss: 1.332751]\n",
      "[Epoch 2/50] [Batch 91/235] [D loss: 1.236026, acc: 63.87%] [G loss: 1.354487]\n",
      "[Epoch 2/50] [Batch 92/235] [D loss: 1.248413, acc: 62.50%] [G loss: 1.305586]\n",
      "[Epoch 2/50] [Batch 93/235] [D loss: 1.231860, acc: 66.02%] [G loss: 1.323565]\n",
      "[Epoch 2/50] [Batch 94/235] [D loss: 1.210409, acc: 66.41%] [G loss: 1.336169]\n",
      "[Epoch 2/50] [Batch 95/235] [D loss: 1.251252, acc: 65.23%] [G loss: 1.324009]\n",
      "[Epoch 2/50] [Batch 96/235] [D loss: 1.277645, acc: 57.23%] [G loss: 1.371381]\n",
      "[Epoch 2/50] [Batch 97/235] [D loss: 1.226151, acc: 66.41%] [G loss: 1.331372]\n",
      "[Epoch 2/50] [Batch 98/235] [D loss: 1.243868, acc: 62.30%] [G loss: 1.338191]\n",
      "[Epoch 2/50] [Batch 99/235] [D loss: 1.225772, acc: 65.62%] [G loss: 1.325409]\n",
      "[Epoch 2/50] [Batch 100/235] [D loss: 1.266646, acc: 60.55%] [G loss: 1.350043]\n",
      "[Epoch 2/50] [Batch 101/235] [D loss: 1.264607, acc: 58.20%] [G loss: 1.352754]\n",
      "[Epoch 2/50] [Batch 102/235] [D loss: 1.233200, acc: 64.45%] [G loss: 1.360444]\n",
      "[Epoch 2/50] [Batch 103/235] [D loss: 1.230293, acc: 64.84%] [G loss: 1.323108]\n",
      "[Epoch 2/50] [Batch 104/235] [D loss: 1.233740, acc: 63.87%] [G loss: 1.328181]\n",
      "[Epoch 2/50] [Batch 105/235] [D loss: 1.236463, acc: 64.45%] [G loss: 1.352610]\n",
      "[Epoch 2/50] [Batch 106/235] [D loss: 1.233600, acc: 64.06%] [G loss: 1.365484]\n",
      "[Epoch 2/50] [Batch 107/235] [D loss: 1.226984, acc: 65.04%] [G loss: 1.326743]\n",
      "[Epoch 2/50] [Batch 108/235] [D loss: 1.249356, acc: 63.87%] [G loss: 1.285209]\n",
      "[Epoch 2/50] [Batch 109/235] [D loss: 1.236073, acc: 63.28%] [G loss: 1.332780]\n",
      "[Epoch 2/50] [Batch 110/235] [D loss: 1.238760, acc: 61.91%] [G loss: 1.385584]\n",
      "[Epoch 2/50] [Batch 111/235] [D loss: 1.233144, acc: 65.43%] [G loss: 1.361732]\n",
      "[Epoch 2/50] [Batch 112/235] [D loss: 1.226487, acc: 64.26%] [G loss: 1.320776]\n",
      "[Epoch 2/50] [Batch 113/235] [D loss: 1.224763, acc: 63.48%] [G loss: 1.334011]\n",
      "[Epoch 2/50] [Batch 114/235] [D loss: 1.225107, acc: 64.65%] [G loss: 1.368042]\n",
      "[Epoch 2/50] [Batch 115/235] [D loss: 1.226581, acc: 64.84%] [G loss: 1.301101]\n",
      "[Epoch 2/50] [Batch 116/235] [D loss: 1.222028, acc: 67.38%] [G loss: 1.313621]\n",
      "[Epoch 2/50] [Batch 117/235] [D loss: 1.223386, acc: 64.26%] [G loss: 1.340122]\n",
      "[Epoch 2/50] [Batch 118/235] [D loss: 1.198083, acc: 67.58%] [G loss: 1.358931]\n",
      "[Epoch 2/50] [Batch 119/235] [D loss: 1.234942, acc: 66.99%] [G loss: 1.340173]\n",
      "[Epoch 2/50] [Batch 120/235] [D loss: 1.213127, acc: 64.65%] [G loss: 1.369678]\n",
      "[Epoch 2/50] [Batch 121/235] [D loss: 1.241872, acc: 59.18%] [G loss: 1.357275]\n",
      "[Epoch 2/50] [Batch 122/235] [D loss: 1.218027, acc: 67.19%] [G loss: 1.301093]\n",
      "[Epoch 2/50] [Batch 123/235] [D loss: 1.235678, acc: 65.04%] [G loss: 1.291451]\n",
      "[Epoch 2/50] [Batch 124/235] [D loss: 1.222235, acc: 64.65%] [G loss: 1.334041]\n",
      "[Epoch 2/50] [Batch 125/235] [D loss: 1.231693, acc: 63.09%] [G loss: 1.355927]\n",
      "[Epoch 2/50] [Batch 126/235] [D loss: 1.222592, acc: 65.23%] [G loss: 1.338801]\n",
      "[Epoch 2/50] [Batch 127/235] [D loss: 1.212249, acc: 64.06%] [G loss: 1.288787]\n",
      "[Epoch 2/50] [Batch 128/235] [D loss: 1.223334, acc: 63.28%] [G loss: 1.326955]\n",
      "[Epoch 2/50] [Batch 129/235] [D loss: 1.199689, acc: 69.34%] [G loss: 1.300459]\n",
      "[Epoch 2/50] [Batch 130/235] [D loss: 1.206696, acc: 67.97%] [G loss: 1.301020]\n",
      "[Epoch 2/50] [Batch 131/235] [D loss: 1.223221, acc: 66.02%] [G loss: 1.293585]\n",
      "[Epoch 2/50] [Batch 132/235] [D loss: 1.220077, acc: 65.82%] [G loss: 1.312617]\n",
      "[Epoch 2/50] [Batch 133/235] [D loss: 1.210657, acc: 66.99%] [G loss: 1.326606]\n",
      "[Epoch 2/50] [Batch 134/235] [D loss: 1.223229, acc: 62.89%] [G loss: 1.349594]\n",
      "[Epoch 2/50] [Batch 135/235] [D loss: 1.224216, acc: 64.26%] [G loss: 1.350470]\n",
      "[Epoch 2/50] [Batch 136/235] [D loss: 1.225828, acc: 62.89%] [G loss: 1.325163]\n",
      "[Epoch 2/50] [Batch 137/235] [D loss: 1.212278, acc: 69.14%] [G loss: 1.337202]\n",
      "[Epoch 2/50] [Batch 138/235] [D loss: 1.230523, acc: 63.67%] [G loss: 1.367984]\n",
      "[Epoch 2/50] [Batch 139/235] [D loss: 1.215122, acc: 67.19%] [G loss: 1.322138]\n",
      "[Epoch 2/50] [Batch 140/235] [D loss: 1.208488, acc: 66.21%] [G loss: 1.292173]\n",
      "[Epoch 2/50] [Batch 141/235] [D loss: 1.215191, acc: 66.80%] [G loss: 1.302081]\n",
      "[Epoch 2/50] [Batch 142/235] [D loss: 1.202887, acc: 67.97%] [G loss: 1.309059]\n",
      "[Epoch 2/50] [Batch 143/235] [D loss: 1.226201, acc: 66.41%] [G loss: 1.297212]\n",
      "[Epoch 2/50] [Batch 144/235] [D loss: 1.235557, acc: 64.06%] [G loss: 1.291647]\n",
      "[Epoch 2/50] [Batch 145/235] [D loss: 1.220214, acc: 65.43%] [G loss: 1.306329]\n",
      "[Epoch 2/50] [Batch 146/235] [D loss: 1.201320, acc: 68.16%] [G loss: 1.305992]\n",
      "[Epoch 2/50] [Batch 147/235] [D loss: 1.219428, acc: 66.80%] [G loss: 1.334764]\n",
      "[Epoch 2/50] [Batch 148/235] [D loss: 1.189693, acc: 68.75%] [G loss: 1.300589]\n",
      "[Epoch 2/50] [Batch 149/235] [D loss: 1.236767, acc: 63.48%] [G loss: 1.315786]\n",
      "[Epoch 2/50] [Batch 150/235] [D loss: 1.205733, acc: 66.80%] [G loss: 1.360211]\n",
      "[Epoch 2/50] [Batch 151/235] [D loss: 1.203574, acc: 65.23%] [G loss: 1.339425]\n",
      "[Epoch 2/50] [Batch 152/235] [D loss: 1.211584, acc: 67.77%] [G loss: 1.307812]\n",
      "[Epoch 2/50] [Batch 153/235] [D loss: 1.234265, acc: 64.26%] [G loss: 1.295113]\n",
      "[Epoch 2/50] [Batch 154/235] [D loss: 1.220547, acc: 64.06%] [G loss: 1.317148]\n",
      "[Epoch 2/50] [Batch 155/235] [D loss: 1.223030, acc: 65.23%] [G loss: 1.314705]\n",
      "[Epoch 2/50] [Batch 156/235] [D loss: 1.205555, acc: 68.36%] [G loss: 1.319165]\n",
      "[Epoch 2/50] [Batch 157/235] [D loss: 1.198593, acc: 65.82%] [G loss: 1.328758]\n",
      "[Epoch 2/50] [Batch 158/235] [D loss: 1.200462, acc: 66.02%] [G loss: 1.325013]\n",
      "[Epoch 2/50] [Batch 159/235] [D loss: 1.209734, acc: 67.77%] [G loss: 1.322065]\n",
      "[Epoch 2/50] [Batch 160/235] [D loss: 1.209304, acc: 66.99%] [G loss: 1.309648]\n",
      "[Epoch 2/50] [Batch 161/235] [D loss: 1.191286, acc: 70.90%] [G loss: 1.314722]\n",
      "[Epoch 2/50] [Batch 162/235] [D loss: 1.197008, acc: 67.77%] [G loss: 1.346008]\n",
      "[Epoch 2/50] [Batch 163/235] [D loss: 1.208302, acc: 67.38%] [G loss: 1.339669]\n",
      "[Epoch 2/50] [Batch 164/235] [D loss: 1.230861, acc: 65.82%] [G loss: 1.305874]\n",
      "[Epoch 2/50] [Batch 165/235] [D loss: 1.224199, acc: 62.30%] [G loss: 1.294322]\n",
      "[Epoch 2/50] [Batch 166/235] [D loss: 1.219317, acc: 65.82%] [G loss: 1.297341]\n",
      "[Epoch 2/50] [Batch 167/235] [D loss: 1.209128, acc: 69.92%] [G loss: 1.325896]\n",
      "[Epoch 2/50] [Batch 168/235] [D loss: 1.215884, acc: 67.58%] [G loss: 1.323143]\n",
      "[Epoch 2/50] [Batch 169/235] [D loss: 1.199158, acc: 68.95%] [G loss: 1.316594]\n",
      "[Epoch 2/50] [Batch 170/235] [D loss: 1.223022, acc: 65.62%] [G loss: 1.271602]\n",
      "[Epoch 2/50] [Batch 171/235] [D loss: 1.193430, acc: 68.95%] [G loss: 1.304399]\n",
      "[Epoch 2/50] [Batch 172/235] [D loss: 1.213869, acc: 69.73%] [G loss: 1.306606]\n",
      "[Epoch 2/50] [Batch 173/235] [D loss: 1.220994, acc: 68.36%] [G loss: 1.304579]\n",
      "[Epoch 2/50] [Batch 174/235] [D loss: 1.193019, acc: 68.75%] [G loss: 1.281872]\n",
      "[Epoch 2/50] [Batch 175/235] [D loss: 1.226979, acc: 66.60%] [G loss: 1.317878]\n",
      "[Epoch 2/50] [Batch 176/235] [D loss: 1.228344, acc: 67.19%] [G loss: 1.351429]\n",
      "[Epoch 2/50] [Batch 177/235] [D loss: 1.212022, acc: 68.95%] [G loss: 1.301489]\n",
      "[Epoch 2/50] [Batch 178/235] [D loss: 1.211223, acc: 68.36%] [G loss: 1.282689]\n",
      "[Epoch 2/50] [Batch 179/235] [D loss: 1.216645, acc: 64.26%] [G loss: 1.315121]\n",
      "[Epoch 2/50] [Batch 180/235] [D loss: 1.198330, acc: 67.97%] [G loss: 1.362890]\n",
      "[Epoch 2/50] [Batch 181/235] [D loss: 1.215915, acc: 66.99%] [G loss: 1.275704]\n",
      "[Epoch 2/50] [Batch 182/235] [D loss: 1.206347, acc: 67.77%] [G loss: 1.307014]\n",
      "[Epoch 2/50] [Batch 183/235] [D loss: 1.213199, acc: 66.99%] [G loss: 1.266931]\n",
      "[Epoch 2/50] [Batch 184/235] [D loss: 1.200270, acc: 69.14%] [G loss: 1.291223]\n",
      "[Epoch 2/50] [Batch 185/235] [D loss: 1.189696, acc: 67.97%] [G loss: 1.338630]\n",
      "[Epoch 2/50] [Batch 186/235] [D loss: 1.219459, acc: 66.80%] [G loss: 1.330882]\n",
      "[Epoch 2/50] [Batch 187/235] [D loss: 1.226042, acc: 68.75%] [G loss: 1.314135]\n",
      "[Epoch 2/50] [Batch 188/235] [D loss: 1.184121, acc: 70.70%] [G loss: 1.300302]\n",
      "[Epoch 2/50] [Batch 189/235] [D loss: 1.221004, acc: 68.36%] [G loss: 1.287555]\n",
      "[Epoch 2/50] [Batch 190/235] [D loss: 1.217722, acc: 68.55%] [G loss: 1.310671]\n",
      "[Epoch 2/50] [Batch 191/235] [D loss: 1.220482, acc: 64.06%] [G loss: 1.282581]\n",
      "[Epoch 2/50] [Batch 192/235] [D loss: 1.200232, acc: 71.09%] [G loss: 1.319629]\n",
      "[Epoch 2/50] [Batch 193/235] [D loss: 1.208634, acc: 67.38%] [G loss: 1.321975]\n",
      "[Epoch 2/50] [Batch 194/235] [D loss: 1.197654, acc: 70.70%] [G loss: 1.279363]\n",
      "[Epoch 2/50] [Batch 195/235] [D loss: 1.204816, acc: 69.34%] [G loss: 1.271863]\n",
      "[Epoch 2/50] [Batch 196/235] [D loss: 1.166571, acc: 70.12%] [G loss: 1.355563]\n",
      "[Epoch 2/50] [Batch 197/235] [D loss: 1.191583, acc: 68.95%] [G loss: 1.310075]\n",
      "[Epoch 2/50] [Batch 198/235] [D loss: 1.175486, acc: 71.29%] [G loss: 1.292858]\n",
      "[Epoch 2/50] [Batch 199/235] [D loss: 1.192268, acc: 69.73%] [G loss: 1.351127]\n",
      "[Epoch 2/50] [Batch 200/235] [D loss: 1.196470, acc: 69.34%] [G loss: 1.287151]\n",
      "[Epoch 2/50] [Batch 201/235] [D loss: 1.197614, acc: 70.31%] [G loss: 1.258894]\n",
      "[Epoch 2/50] [Batch 202/235] [D loss: 1.184766, acc: 70.70%] [G loss: 1.314361]\n",
      "[Epoch 2/50] [Batch 203/235] [D loss: 1.190303, acc: 69.73%] [G loss: 1.292603]\n",
      "[Epoch 2/50] [Batch 204/235] [D loss: 1.186368, acc: 70.51%] [G loss: 1.268982]\n",
      "[Epoch 2/50] [Batch 205/235] [D loss: 1.191928, acc: 69.34%] [G loss: 1.282978]\n",
      "[Epoch 2/50] [Batch 206/235] [D loss: 1.207738, acc: 67.77%] [G loss: 1.304285]\n",
      "[Epoch 2/50] [Batch 207/235] [D loss: 1.197722, acc: 70.51%] [G loss: 1.303300]\n",
      "[Epoch 2/50] [Batch 208/235] [D loss: 1.191646, acc: 68.16%] [G loss: 1.351686]\n",
      "[Epoch 2/50] [Batch 209/235] [D loss: 1.199409, acc: 66.21%] [G loss: 1.309940]\n",
      "[Epoch 2/50] [Batch 210/235] [D loss: 1.179197, acc: 69.73%] [G loss: 1.263555]\n",
      "[Epoch 2/50] [Batch 211/235] [D loss: 1.179350, acc: 69.92%] [G loss: 1.282248]\n",
      "[Epoch 2/50] [Batch 212/235] [D loss: 1.183166, acc: 69.14%] [G loss: 1.298925]\n",
      "[Epoch 2/50] [Batch 213/235] [D loss: 1.212613, acc: 68.75%] [G loss: 1.331584]\n",
      "[Epoch 2/50] [Batch 214/235] [D loss: 1.209786, acc: 70.70%] [G loss: 1.283189]\n",
      "[Epoch 2/50] [Batch 215/235] [D loss: 1.191527, acc: 69.53%] [G loss: 1.292830]\n",
      "[Epoch 2/50] [Batch 216/235] [D loss: 1.178855, acc: 72.46%] [G loss: 1.249459]\n",
      "[Epoch 2/50] [Batch 217/235] [D loss: 1.203260, acc: 66.60%] [G loss: 1.341239]\n",
      "[Epoch 2/50] [Batch 218/235] [D loss: 1.191522, acc: 72.07%] [G loss: 1.295765]\n",
      "[Epoch 2/50] [Batch 219/235] [D loss: 1.209210, acc: 66.02%] [G loss: 1.316185]\n",
      "[Epoch 2/50] [Batch 220/235] [D loss: 1.215008, acc: 72.07%] [G loss: 1.297131]\n",
      "[Epoch 2/50] [Batch 221/235] [D loss: 1.190478, acc: 68.36%] [G loss: 1.314952]\n",
      "[Epoch 2/50] [Batch 222/235] [D loss: 1.195488, acc: 69.73%] [G loss: 1.312315]\n",
      "[Epoch 2/50] [Batch 223/235] [D loss: 1.177926, acc: 70.12%] [G loss: 1.310938]\n",
      "[Epoch 2/50] [Batch 224/235] [D loss: 1.184947, acc: 71.88%] [G loss: 1.292341]\n",
      "[Epoch 2/50] [Batch 225/235] [D loss: 1.212540, acc: 70.12%] [G loss: 1.265969]\n",
      "[Epoch 2/50] [Batch 226/235] [D loss: 1.199101, acc: 71.48%] [G loss: 1.283753]\n",
      "[Epoch 2/50] [Batch 227/235] [D loss: 1.200161, acc: 67.97%] [G loss: 1.334917]\n",
      "[Epoch 2/50] [Batch 228/235] [D loss: 1.195400, acc: 69.14%] [G loss: 1.294409]\n",
      "[Epoch 2/50] [Batch 229/235] [D loss: 1.191791, acc: 71.29%] [G loss: 1.322862]\n",
      "[Epoch 2/50] [Batch 230/235] [D loss: 1.177706, acc: 73.24%] [G loss: 1.266842]\n",
      "[Epoch 2/50] [Batch 231/235] [D loss: 1.194119, acc: 66.60%] [G loss: 1.309367]\n",
      "[Epoch 2/50] [Batch 232/235] [D loss: 1.175463, acc: 73.44%] [G loss: 1.347303]\n",
      "[Epoch 2/50] [Batch 233/235] [D loss: 1.178561, acc: 71.88%] [G loss: 1.319521]\n",
      "[Epoch 2/50] [Batch 234/235] [D loss: 1.207004, acc: 64.06%] [G loss: 1.348570]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/50] [Batch 0/235] [D loss: 1.167634, acc: 71.68%] [G loss: 1.343274]\n",
      "[Epoch 3/50] [Batch 1/235] [D loss: 1.170442, acc: 72.27%] [G loss: 1.290784]\n",
      "[Epoch 3/50] [Batch 2/235] [D loss: 1.170672, acc: 73.24%] [G loss: 1.295967]\n",
      "[Epoch 3/50] [Batch 3/235] [D loss: 1.206447, acc: 69.53%] [G loss: 1.293578]\n",
      "[Epoch 3/50] [Batch 4/235] [D loss: 1.197951, acc: 69.14%] [G loss: 1.277296]\n",
      "[Epoch 3/50] [Batch 5/235] [D loss: 1.224832, acc: 67.58%] [G loss: 1.259603]\n",
      "[Epoch 3/50] [Batch 6/235] [D loss: 1.183467, acc: 70.51%] [G loss: 1.350967]\n",
      "[Epoch 3/50] [Batch 7/235] [D loss: 1.203139, acc: 66.99%] [G loss: 1.322352]\n",
      "[Epoch 3/50] [Batch 8/235] [D loss: 1.187877, acc: 70.90%] [G loss: 1.277138]\n",
      "[Epoch 3/50] [Batch 9/235] [D loss: 1.182785, acc: 71.88%] [G loss: 1.227102]\n",
      "[Epoch 3/50] [Batch 10/235] [D loss: 1.191110, acc: 67.97%] [G loss: 1.308046]\n",
      "[Epoch 3/50] [Batch 11/235] [D loss: 1.183648, acc: 72.85%] [G loss: 1.253359]\n",
      "[Epoch 3/50] [Batch 12/235] [D loss: 1.188086, acc: 70.70%] [G loss: 1.271759]\n",
      "[Epoch 3/50] [Batch 13/235] [D loss: 1.184491, acc: 70.12%] [G loss: 1.286515]\n",
      "[Epoch 3/50] [Batch 14/235] [D loss: 1.163017, acc: 72.85%] [G loss: 1.281907]\n",
      "[Epoch 3/50] [Batch 15/235] [D loss: 1.205641, acc: 69.34%] [G loss: 1.327447]\n",
      "[Epoch 3/50] [Batch 16/235] [D loss: 1.183797, acc: 72.27%] [G loss: 1.273435]\n",
      "[Epoch 3/50] [Batch 17/235] [D loss: 1.210830, acc: 67.19%] [G loss: 1.289480]\n",
      "[Epoch 3/50] [Batch 18/235] [D loss: 1.187996, acc: 69.14%] [G loss: 1.376065]\n",
      "[Epoch 3/50] [Batch 19/235] [D loss: 1.183931, acc: 69.73%] [G loss: 1.296553]\n",
      "[Epoch 3/50] [Batch 20/235] [D loss: 1.184585, acc: 71.09%] [G loss: 1.258561]\n",
      "[Epoch 3/50] [Batch 21/235] [D loss: 1.194459, acc: 69.34%] [G loss: 1.276208]\n",
      "[Epoch 3/50] [Batch 22/235] [D loss: 1.181647, acc: 72.27%] [G loss: 1.279454]\n",
      "[Epoch 3/50] [Batch 23/235] [D loss: 1.203291, acc: 66.60%] [G loss: 1.308011]\n",
      "[Epoch 3/50] [Batch 24/235] [D loss: 1.168463, acc: 70.51%] [G loss: 1.299176]\n",
      "[Epoch 3/50] [Batch 25/235] [D loss: 1.214758, acc: 67.38%] [G loss: 1.329425]\n",
      "[Epoch 3/50] [Batch 26/235] [D loss: 1.179358, acc: 69.92%] [G loss: 1.403978]\n",
      "[Epoch 3/50] [Batch 27/235] [D loss: 1.193309, acc: 71.68%] [G loss: 1.311519]\n",
      "[Epoch 3/50] [Batch 28/235] [D loss: 1.177579, acc: 73.63%] [G loss: 1.278825]\n",
      "[Epoch 3/50] [Batch 29/235] [D loss: 1.187260, acc: 68.95%] [G loss: 1.307940]\n",
      "[Epoch 3/50] [Batch 30/235] [D loss: 1.179291, acc: 72.07%] [G loss: 1.288139]\n",
      "[Epoch 3/50] [Batch 31/235] [D loss: 1.159068, acc: 74.02%] [G loss: 1.320392]\n",
      "[Epoch 3/50] [Batch 32/235] [D loss: 1.165382, acc: 72.07%] [G loss: 1.312783]\n",
      "[Epoch 3/50] [Batch 33/235] [D loss: 1.176269, acc: 75.39%] [G loss: 1.304834]\n",
      "[Epoch 3/50] [Batch 34/235] [D loss: 1.173251, acc: 70.51%] [G loss: 1.321866]\n",
      "[Epoch 3/50] [Batch 35/235] [D loss: 1.185264, acc: 69.14%] [G loss: 1.260058]\n",
      "[Epoch 3/50] [Batch 36/235] [D loss: 1.199015, acc: 69.53%] [G loss: 1.229095]\n",
      "[Epoch 3/50] [Batch 37/235] [D loss: 1.194927, acc: 70.12%] [G loss: 1.269096]\n",
      "[Epoch 3/50] [Batch 38/235] [D loss: 1.191736, acc: 71.29%] [G loss: 1.315311]\n",
      "[Epoch 3/50] [Batch 39/235] [D loss: 1.188672, acc: 67.77%] [G loss: 1.297272]\n",
      "[Epoch 3/50] [Batch 40/235] [D loss: 1.198419, acc: 69.53%] [G loss: 1.275313]\n",
      "[Epoch 3/50] [Batch 41/235] [D loss: 1.177470, acc: 70.90%] [G loss: 1.316936]\n",
      "[Epoch 3/50] [Batch 42/235] [D loss: 1.205774, acc: 68.55%] [G loss: 1.342679]\n",
      "[Epoch 3/50] [Batch 43/235] [D loss: 1.190953, acc: 69.92%] [G loss: 1.324650]\n",
      "[Epoch 3/50] [Batch 44/235] [D loss: 1.152270, acc: 70.70%] [G loss: 1.294962]\n",
      "[Epoch 3/50] [Batch 45/235] [D loss: 1.196741, acc: 71.48%] [G loss: 1.265786]\n",
      "[Epoch 3/50] [Batch 46/235] [D loss: 1.216771, acc: 68.55%] [G loss: 1.302478]\n",
      "[Epoch 3/50] [Batch 47/235] [D loss: 1.173490, acc: 69.92%] [G loss: 1.294811]\n",
      "[Epoch 3/50] [Batch 48/235] [D loss: 1.179653, acc: 72.66%] [G loss: 1.247726]\n",
      "[Epoch 3/50] [Batch 49/235] [D loss: 1.192557, acc: 70.31%] [G loss: 1.276240]\n",
      "[Epoch 3/50] [Batch 50/235] [D loss: 1.191499, acc: 72.46%] [G loss: 1.280311]\n",
      "[Epoch 3/50] [Batch 51/235] [D loss: 1.179521, acc: 70.31%] [G loss: 1.295739]\n",
      "[Epoch 3/50] [Batch 52/235] [D loss: 1.180202, acc: 72.27%] [G loss: 1.281522]\n",
      "[Epoch 3/50] [Batch 53/235] [D loss: 1.194037, acc: 71.09%] [G loss: 1.291451]\n",
      "[Epoch 3/50] [Batch 54/235] [D loss: 1.169634, acc: 73.83%] [G loss: 1.306371]\n",
      "[Epoch 3/50] [Batch 55/235] [D loss: 1.185332, acc: 74.80%] [G loss: 1.273208]\n",
      "[Epoch 3/50] [Batch 56/235] [D loss: 1.161583, acc: 74.02%] [G loss: 1.316343]\n",
      "[Epoch 3/50] [Batch 57/235] [D loss: 1.191827, acc: 70.70%] [G loss: 1.283260]\n",
      "[Epoch 3/50] [Batch 58/235] [D loss: 1.183611, acc: 70.51%] [G loss: 1.235951]\n",
      "[Epoch 3/50] [Batch 59/235] [D loss: 1.197655, acc: 71.88%] [G loss: 1.269272]\n",
      "[Epoch 3/50] [Batch 60/235] [D loss: 1.191890, acc: 73.05%] [G loss: 1.299519]\n",
      "[Epoch 3/50] [Batch 61/235] [D loss: 1.170117, acc: 72.66%] [G loss: 1.297252]\n",
      "[Epoch 3/50] [Batch 62/235] [D loss: 1.174477, acc: 73.44%] [G loss: 1.216649]\n",
      "[Epoch 3/50] [Batch 63/235] [D loss: 1.185857, acc: 73.44%] [G loss: 1.256566]\n",
      "[Epoch 3/50] [Batch 64/235] [D loss: 1.163964, acc: 74.22%] [G loss: 1.330215]\n",
      "[Epoch 3/50] [Batch 65/235] [D loss: 1.197103, acc: 71.88%] [G loss: 1.271961]\n",
      "[Epoch 3/50] [Batch 66/235] [D loss: 1.178342, acc: 71.68%] [G loss: 1.313622]\n",
      "[Epoch 3/50] [Batch 67/235] [D loss: 1.174037, acc: 73.05%] [G loss: 1.327943]\n",
      "[Epoch 3/50] [Batch 68/235] [D loss: 1.187039, acc: 70.31%] [G loss: 1.342790]\n",
      "[Epoch 3/50] [Batch 69/235] [D loss: 1.166003, acc: 70.12%] [G loss: 1.335140]\n",
      "[Epoch 3/50] [Batch 70/235] [D loss: 1.158620, acc: 75.20%] [G loss: 1.270331]\n",
      "[Epoch 3/50] [Batch 71/235] [D loss: 1.168385, acc: 71.09%] [G loss: 1.310692]\n",
      "[Epoch 3/50] [Batch 72/235] [D loss: 1.193122, acc: 72.66%] [G loss: 1.294841]\n",
      "[Epoch 3/50] [Batch 73/235] [D loss: 1.183782, acc: 70.12%] [G loss: 1.260308]\n",
      "[Epoch 3/50] [Batch 74/235] [D loss: 1.189700, acc: 70.12%] [G loss: 1.272584]\n",
      "[Epoch 3/50] [Batch 75/235] [D loss: 1.179364, acc: 71.68%] [G loss: 1.282447]\n",
      "[Epoch 3/50] [Batch 76/235] [D loss: 1.179449, acc: 72.85%] [G loss: 1.265592]\n",
      "[Epoch 3/50] [Batch 77/235] [D loss: 1.183153, acc: 73.83%] [G loss: 1.315727]\n",
      "[Epoch 3/50] [Batch 78/235] [D loss: 1.183507, acc: 75.20%] [G loss: 1.251003]\n",
      "[Epoch 3/50] [Batch 79/235] [D loss: 1.212067, acc: 71.29%] [G loss: 1.240541]\n",
      "[Epoch 3/50] [Batch 80/235] [D loss: 1.190340, acc: 67.77%] [G loss: 1.288994]\n",
      "[Epoch 3/50] [Batch 81/235] [D loss: 1.172051, acc: 71.09%] [G loss: 1.332523]\n",
      "[Epoch 3/50] [Batch 82/235] [D loss: 1.186826, acc: 72.27%] [G loss: 1.318293]\n",
      "[Epoch 3/50] [Batch 83/235] [D loss: 1.173337, acc: 70.12%] [G loss: 1.307028]\n",
      "[Epoch 3/50] [Batch 84/235] [D loss: 1.216863, acc: 67.97%] [G loss: 1.217767]\n",
      "[Epoch 3/50] [Batch 85/235] [D loss: 1.182174, acc: 71.68%] [G loss: 1.276879]\n",
      "[Epoch 3/50] [Batch 86/235] [D loss: 1.177510, acc: 69.53%] [G loss: 1.333046]\n",
      "[Epoch 3/50] [Batch 87/235] [D loss: 1.192631, acc: 71.88%] [G loss: 1.254579]\n",
      "[Epoch 3/50] [Batch 88/235] [D loss: 1.194806, acc: 72.85%] [G loss: 1.253162]\n",
      "[Epoch 3/50] [Batch 89/235] [D loss: 1.189626, acc: 70.51%] [G loss: 1.281740]\n",
      "[Epoch 3/50] [Batch 90/235] [D loss: 1.186177, acc: 70.70%] [G loss: 1.322023]\n",
      "[Epoch 3/50] [Batch 91/235] [D loss: 1.188342, acc: 72.27%] [G loss: 1.294296]\n",
      "[Epoch 3/50] [Batch 92/235] [D loss: 1.178211, acc: 71.48%] [G loss: 1.286905]\n",
      "[Epoch 3/50] [Batch 93/235] [D loss: 1.204000, acc: 69.92%] [G loss: 1.364534]\n",
      "[Epoch 3/50] [Batch 94/235] [D loss: 1.193742, acc: 69.53%] [G loss: 1.352849]\n",
      "[Epoch 3/50] [Batch 95/235] [D loss: 1.194625, acc: 71.68%] [G loss: 1.319693]\n",
      "[Epoch 3/50] [Batch 96/235] [D loss: 1.178030, acc: 70.51%] [G loss: 1.268750]\n",
      "[Epoch 3/50] [Batch 97/235] [D loss: 1.176272, acc: 70.90%] [G loss: 1.271515]\n",
      "[Epoch 3/50] [Batch 98/235] [D loss: 1.172019, acc: 72.85%] [G loss: 1.338091]\n",
      "[Epoch 3/50] [Batch 99/235] [D loss: 1.151873, acc: 73.05%] [G loss: 1.288040]\n",
      "[Epoch 3/50] [Batch 100/235] [D loss: 1.198429, acc: 71.68%] [G loss: 1.217530]\n",
      "[Epoch 3/50] [Batch 101/235] [D loss: 1.168575, acc: 73.63%] [G loss: 1.312919]\n",
      "[Epoch 3/50] [Batch 102/235] [D loss: 1.181912, acc: 69.73%] [G loss: 1.294052]\n",
      "[Epoch 3/50] [Batch 103/235] [D loss: 1.188954, acc: 70.51%] [G loss: 1.233643]\n",
      "[Epoch 3/50] [Batch 104/235] [D loss: 1.165727, acc: 73.63%] [G loss: 1.278304]\n",
      "[Epoch 3/50] [Batch 105/235] [D loss: 1.165341, acc: 71.29%] [G loss: 1.267252]\n",
      "[Epoch 3/50] [Batch 106/235] [D loss: 1.170307, acc: 72.66%] [G loss: 1.282980]\n",
      "[Epoch 3/50] [Batch 107/235] [D loss: 1.182364, acc: 68.75%] [G loss: 1.322930]\n",
      "[Epoch 3/50] [Batch 108/235] [D loss: 1.162195, acc: 75.20%] [G loss: 1.304165]\n",
      "[Epoch 3/50] [Batch 109/235] [D loss: 1.199079, acc: 70.31%] [G loss: 1.303385]\n",
      "[Epoch 3/50] [Batch 110/235] [D loss: 1.167217, acc: 72.27%] [G loss: 1.333698]\n",
      "[Epoch 3/50] [Batch 111/235] [D loss: 1.171430, acc: 70.90%] [G loss: 1.304543]\n",
      "[Epoch 3/50] [Batch 112/235] [D loss: 1.199637, acc: 70.31%] [G loss: 1.274636]\n",
      "[Epoch 3/50] [Batch 113/235] [D loss: 1.200557, acc: 71.68%] [G loss: 1.311596]\n",
      "[Epoch 3/50] [Batch 114/235] [D loss: 1.182309, acc: 71.29%] [G loss: 1.285905]\n",
      "[Epoch 3/50] [Batch 115/235] [D loss: 1.171749, acc: 70.12%] [G loss: 1.314173]\n",
      "[Epoch 3/50] [Batch 116/235] [D loss: 1.172704, acc: 75.20%] [G loss: 1.342535]\n",
      "[Epoch 3/50] [Batch 117/235] [D loss: 1.180589, acc: 72.07%] [G loss: 1.248787]\n",
      "[Epoch 3/50] [Batch 118/235] [D loss: 1.191482, acc: 72.85%] [G loss: 1.300093]\n",
      "[Epoch 3/50] [Batch 119/235] [D loss: 1.176837, acc: 72.85%] [G loss: 1.238581]\n",
      "[Epoch 3/50] [Batch 120/235] [D loss: 1.207217, acc: 71.68%] [G loss: 1.271174]\n",
      "[Epoch 3/50] [Batch 121/235] [D loss: 1.184549, acc: 71.48%] [G loss: 1.323231]\n",
      "[Epoch 3/50] [Batch 122/235] [D loss: 1.157314, acc: 74.22%] [G loss: 1.280617]\n",
      "[Epoch 3/50] [Batch 123/235] [D loss: 1.185027, acc: 71.68%] [G loss: 1.259416]\n",
      "[Epoch 3/50] [Batch 124/235] [D loss: 1.182767, acc: 72.85%] [G loss: 1.256468]\n",
      "[Epoch 3/50] [Batch 125/235] [D loss: 1.200058, acc: 73.44%] [G loss: 1.330257]\n",
      "[Epoch 3/50] [Batch 126/235] [D loss: 1.154459, acc: 75.78%] [G loss: 1.232196]\n",
      "[Epoch 3/50] [Batch 127/235] [D loss: 1.160324, acc: 72.85%] [G loss: 1.283940]\n",
      "[Epoch 3/50] [Batch 128/235] [D loss: 1.163267, acc: 72.66%] [G loss: 1.267216]\n",
      "[Epoch 3/50] [Batch 129/235] [D loss: 1.191941, acc: 70.51%] [G loss: 1.306681]\n",
      "[Epoch 3/50] [Batch 130/235] [D loss: 1.155958, acc: 72.66%] [G loss: 1.280449]\n",
      "[Epoch 3/50] [Batch 131/235] [D loss: 1.201277, acc: 69.73%] [G loss: 1.249920]\n",
      "[Epoch 3/50] [Batch 132/235] [D loss: 1.158572, acc: 76.17%] [G loss: 1.266574]\n",
      "[Epoch 3/50] [Batch 133/235] [D loss: 1.184725, acc: 71.48%] [G loss: 1.264424]\n",
      "[Epoch 3/50] [Batch 134/235] [D loss: 1.194937, acc: 71.88%] [G loss: 1.241076]\n",
      "[Epoch 3/50] [Batch 135/235] [D loss: 1.180803, acc: 72.46%] [G loss: 1.270470]\n",
      "[Epoch 3/50] [Batch 136/235] [D loss: 1.199507, acc: 71.09%] [G loss: 1.325093]\n",
      "[Epoch 3/50] [Batch 137/235] [D loss: 1.200907, acc: 70.12%] [G loss: 1.291002]\n",
      "[Epoch 3/50] [Batch 138/235] [D loss: 1.167508, acc: 76.17%] [G loss: 1.293744]\n",
      "[Epoch 3/50] [Batch 139/235] [D loss: 1.156761, acc: 78.12%] [G loss: 1.258280]\n",
      "[Epoch 3/50] [Batch 140/235] [D loss: 1.157817, acc: 78.12%] [G loss: 1.292198]\n",
      "[Epoch 3/50] [Batch 141/235] [D loss: 1.206836, acc: 72.66%] [G loss: 1.209126]\n",
      "[Epoch 3/50] [Batch 142/235] [D loss: 1.176358, acc: 76.56%] [G loss: 1.272238]\n",
      "[Epoch 3/50] [Batch 143/235] [D loss: 1.188932, acc: 71.48%] [G loss: 1.275553]\n",
      "[Epoch 3/50] [Batch 144/235] [D loss: 1.201831, acc: 71.48%] [G loss: 1.286452]\n",
      "[Epoch 3/50] [Batch 145/235] [D loss: 1.191746, acc: 71.88%] [G loss: 1.282386]\n",
      "[Epoch 3/50] [Batch 146/235] [D loss: 1.162883, acc: 72.85%] [G loss: 1.248182]\n",
      "[Epoch 3/50] [Batch 147/235] [D loss: 1.167899, acc: 70.70%] [G loss: 1.279347]\n",
      "[Epoch 3/50] [Batch 148/235] [D loss: 1.161782, acc: 74.02%] [G loss: 1.329191]\n",
      "[Epoch 3/50] [Batch 149/235] [D loss: 1.180305, acc: 70.70%] [G loss: 1.323098]\n",
      "[Epoch 3/50] [Batch 150/235] [D loss: 1.182338, acc: 75.00%] [G loss: 1.264630]\n",
      "[Epoch 3/50] [Batch 151/235] [D loss: 1.181125, acc: 74.80%] [G loss: 1.254219]\n",
      "[Epoch 3/50] [Batch 152/235] [D loss: 1.169335, acc: 74.80%] [G loss: 1.265054]\n",
      "[Epoch 3/50] [Batch 153/235] [D loss: 1.185412, acc: 72.46%] [G loss: 1.290659]\n",
      "[Epoch 3/50] [Batch 154/235] [D loss: 1.143190, acc: 78.91%] [G loss: 1.343266]\n",
      "[Epoch 3/50] [Batch 155/235] [D loss: 1.162408, acc: 70.90%] [G loss: 1.313908]\n",
      "[Epoch 3/50] [Batch 156/235] [D loss: 1.181421, acc: 70.31%] [G loss: 1.260766]\n",
      "[Epoch 3/50] [Batch 157/235] [D loss: 1.181167, acc: 71.29%] [G loss: 1.266510]\n",
      "[Epoch 3/50] [Batch 158/235] [D loss: 1.190212, acc: 71.68%] [G loss: 1.267018]\n",
      "[Epoch 3/50] [Batch 159/235] [D loss: 1.188716, acc: 71.09%] [G loss: 1.292354]\n",
      "[Epoch 3/50] [Batch 160/235] [D loss: 1.185165, acc: 74.41%] [G loss: 1.276389]\n",
      "[Epoch 3/50] [Batch 161/235] [D loss: 1.153723, acc: 75.00%] [G loss: 1.229966]\n",
      "[Epoch 3/50] [Batch 162/235] [D loss: 1.193132, acc: 71.29%] [G loss: 1.312630]\n",
      "[Epoch 3/50] [Batch 163/235] [D loss: 1.137683, acc: 77.73%] [G loss: 1.282932]\n",
      "[Epoch 3/50] [Batch 164/235] [D loss: 1.181760, acc: 71.09%] [G loss: 1.283495]\n",
      "[Epoch 3/50] [Batch 165/235] [D loss: 1.158262, acc: 75.98%] [G loss: 1.271026]\n",
      "[Epoch 3/50] [Batch 166/235] [D loss: 1.179039, acc: 69.92%] [G loss: 1.271396]\n",
      "[Epoch 3/50] [Batch 167/235] [D loss: 1.175742, acc: 73.44%] [G loss: 1.269307]\n",
      "[Epoch 3/50] [Batch 168/235] [D loss: 1.156725, acc: 71.48%] [G loss: 1.320975]\n",
      "[Epoch 3/50] [Batch 169/235] [D loss: 1.176785, acc: 71.88%] [G loss: 1.309459]\n",
      "[Epoch 3/50] [Batch 170/235] [D loss: 1.177171, acc: 73.05%] [G loss: 1.310224]\n",
      "[Epoch 3/50] [Batch 171/235] [D loss: 1.172400, acc: 73.83%] [G loss: 1.266135]\n",
      "[Epoch 3/50] [Batch 172/235] [D loss: 1.175755, acc: 71.68%] [G loss: 1.281484]\n",
      "[Epoch 3/50] [Batch 173/235] [D loss: 1.168769, acc: 73.05%] [G loss: 1.280474]\n",
      "[Epoch 3/50] [Batch 174/235] [D loss: 1.156949, acc: 74.61%] [G loss: 1.263586]\n",
      "[Epoch 3/50] [Batch 175/235] [D loss: 1.190391, acc: 71.48%] [G loss: 1.287017]\n",
      "[Epoch 3/50] [Batch 176/235] [D loss: 1.161507, acc: 70.51%] [G loss: 1.242604]\n",
      "[Epoch 3/50] [Batch 177/235] [D loss: 1.152150, acc: 74.41%] [G loss: 1.331420]\n",
      "[Epoch 3/50] [Batch 178/235] [D loss: 1.163905, acc: 71.09%] [G loss: 1.333473]\n",
      "[Epoch 3/50] [Batch 179/235] [D loss: 1.195084, acc: 72.07%] [G loss: 1.205394]\n",
      "[Epoch 3/50] [Batch 180/235] [D loss: 1.169219, acc: 72.46%] [G loss: 1.300849]\n",
      "[Epoch 3/50] [Batch 181/235] [D loss: 1.168689, acc: 72.46%] [G loss: 1.320294]\n",
      "[Epoch 3/50] [Batch 182/235] [D loss: 1.190007, acc: 74.41%] [G loss: 1.271049]\n",
      "[Epoch 3/50] [Batch 183/235] [D loss: 1.159215, acc: 73.05%] [G loss: 1.285732]\n",
      "[Epoch 3/50] [Batch 184/235] [D loss: 1.154948, acc: 76.95%] [G loss: 1.273629]\n",
      "[Epoch 3/50] [Batch 185/235] [D loss: 1.142329, acc: 77.34%] [G loss: 1.236166]\n",
      "[Epoch 3/50] [Batch 186/235] [D loss: 1.179952, acc: 75.20%] [G loss: 1.244408]\n",
      "[Epoch 3/50] [Batch 187/235] [D loss: 1.170603, acc: 73.63%] [G loss: 1.354983]\n",
      "[Epoch 3/50] [Batch 188/235] [D loss: 1.166392, acc: 74.61%] [G loss: 1.309342]\n",
      "[Epoch 3/50] [Batch 189/235] [D loss: 1.145954, acc: 74.61%] [G loss: 1.273889]\n",
      "[Epoch 3/50] [Batch 190/235] [D loss: 1.202121, acc: 72.46%] [G loss: 1.200787]\n",
      "[Epoch 3/50] [Batch 191/235] [D loss: 1.186923, acc: 70.51%] [G loss: 1.383398]\n",
      "[Epoch 3/50] [Batch 192/235] [D loss: 1.158938, acc: 72.66%] [G loss: 1.416809]\n",
      "[Epoch 3/50] [Batch 193/235] [D loss: 1.184837, acc: 73.05%] [G loss: 1.284154]\n",
      "[Epoch 3/50] [Batch 194/235] [D loss: 1.191982, acc: 72.66%] [G loss: 1.197367]\n",
      "[Epoch 3/50] [Batch 195/235] [D loss: 1.167318, acc: 72.27%] [G loss: 1.295968]\n",
      "[Epoch 3/50] [Batch 196/235] [D loss: 1.172273, acc: 71.09%] [G loss: 1.276922]\n",
      "[Epoch 3/50] [Batch 197/235] [D loss: 1.156743, acc: 75.59%] [G loss: 1.243225]\n",
      "[Epoch 3/50] [Batch 198/235] [D loss: 1.134727, acc: 77.34%] [G loss: 1.308477]\n",
      "[Epoch 3/50] [Batch 199/235] [D loss: 1.150887, acc: 75.20%] [G loss: 1.290073]\n",
      "[Epoch 3/50] [Batch 200/235] [D loss: 1.134839, acc: 76.17%] [G loss: 1.290562]\n",
      "[Epoch 3/50] [Batch 201/235] [D loss: 1.137023, acc: 74.61%] [G loss: 1.274394]\n",
      "[Epoch 3/50] [Batch 202/235] [D loss: 1.169947, acc: 73.24%] [G loss: 1.251685]\n",
      "[Epoch 3/50] [Batch 203/235] [D loss: 1.187069, acc: 72.07%] [G loss: 1.314287]\n",
      "[Epoch 3/50] [Batch 204/235] [D loss: 1.179831, acc: 68.95%] [G loss: 1.290663]\n",
      "[Epoch 3/50] [Batch 205/235] [D loss: 1.161179, acc: 72.66%] [G loss: 1.275401]\n",
      "[Epoch 3/50] [Batch 206/235] [D loss: 1.180311, acc: 73.05%] [G loss: 1.325879]\n",
      "[Epoch 3/50] [Batch 207/235] [D loss: 1.168937, acc: 70.90%] [G loss: 1.250733]\n",
      "[Epoch 3/50] [Batch 208/235] [D loss: 1.147239, acc: 77.54%] [G loss: 1.244288]\n",
      "[Epoch 3/50] [Batch 209/235] [D loss: 1.164846, acc: 71.09%] [G loss: 1.303606]\n",
      "[Epoch 3/50] [Batch 210/235] [D loss: 1.196410, acc: 69.92%] [G loss: 1.319546]\n",
      "[Epoch 3/50] [Batch 211/235] [D loss: 1.159683, acc: 77.15%] [G loss: 1.307922]\n",
      "[Epoch 3/50] [Batch 212/235] [D loss: 1.163978, acc: 70.70%] [G loss: 1.313514]\n",
      "[Epoch 3/50] [Batch 213/235] [D loss: 1.143366, acc: 76.76%] [G loss: 1.291847]\n",
      "[Epoch 3/50] [Batch 214/235] [D loss: 1.164998, acc: 73.83%] [G loss: 1.307423]\n",
      "[Epoch 3/50] [Batch 215/235] [D loss: 1.159116, acc: 77.54%] [G loss: 1.216463]\n",
      "[Epoch 3/50] [Batch 216/235] [D loss: 1.179529, acc: 74.41%] [G loss: 1.244655]\n",
      "[Epoch 3/50] [Batch 217/235] [D loss: 1.150027, acc: 75.98%] [G loss: 1.275481]\n",
      "[Epoch 3/50] [Batch 218/235] [D loss: 1.167200, acc: 71.68%] [G loss: 1.296807]\n",
      "[Epoch 3/50] [Batch 219/235] [D loss: 1.147257, acc: 75.98%] [G loss: 1.275948]\n",
      "[Epoch 3/50] [Batch 220/235] [D loss: 1.170465, acc: 72.66%] [G loss: 1.300273]\n",
      "[Epoch 3/50] [Batch 221/235] [D loss: 1.174289, acc: 70.70%] [G loss: 1.285020]\n",
      "[Epoch 3/50] [Batch 222/235] [D loss: 1.192946, acc: 73.83%] [G loss: 1.289726]\n",
      "[Epoch 3/50] [Batch 223/235] [D loss: 1.162552, acc: 72.46%] [G loss: 1.309135]\n",
      "[Epoch 3/50] [Batch 224/235] [D loss: 1.157813, acc: 72.85%] [G loss: 1.255068]\n",
      "[Epoch 3/50] [Batch 225/235] [D loss: 1.200958, acc: 71.09%] [G loss: 1.275019]\n",
      "[Epoch 3/50] [Batch 226/235] [D loss: 1.142491, acc: 73.44%] [G loss: 1.341876]\n",
      "[Epoch 3/50] [Batch 227/235] [D loss: 1.168784, acc: 72.07%] [G loss: 1.304946]\n",
      "[Epoch 3/50] [Batch 228/235] [D loss: 1.165320, acc: 71.88%] [G loss: 1.241819]\n",
      "[Epoch 3/50] [Batch 229/235] [D loss: 1.149100, acc: 75.78%] [G loss: 1.340768]\n",
      "[Epoch 3/50] [Batch 230/235] [D loss: 1.159647, acc: 74.02%] [G loss: 1.313203]\n",
      "[Epoch 3/50] [Batch 231/235] [D loss: 1.168061, acc: 76.95%] [G loss: 1.316713]\n",
      "[Epoch 3/50] [Batch 232/235] [D loss: 1.135904, acc: 73.63%] [G loss: 1.242088]\n",
      "[Epoch 3/50] [Batch 233/235] [D loss: 1.180605, acc: 73.24%] [G loss: 1.299147]\n",
      "[Epoch 3/50] [Batch 234/235] [D loss: 1.180437, acc: 70.31%] [G loss: 1.300672]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/50] [Batch 0/235] [D loss: 1.167230, acc: 74.80%] [G loss: 1.306162]\n",
      "[Epoch 4/50] [Batch 1/235] [D loss: 1.181896, acc: 72.07%] [G loss: 1.241380]\n",
      "[Epoch 4/50] [Batch 2/235] [D loss: 1.168005, acc: 73.63%] [G loss: 1.258069]\n",
      "[Epoch 4/50] [Batch 3/235] [D loss: 1.145558, acc: 75.39%] [G loss: 1.343199]\n",
      "[Epoch 4/50] [Batch 4/235] [D loss: 1.173095, acc: 70.51%] [G loss: 1.283134]\n",
      "[Epoch 4/50] [Batch 5/235] [D loss: 1.182806, acc: 69.92%] [G loss: 1.285342]\n",
      "[Epoch 4/50] [Batch 6/235] [D loss: 1.152770, acc: 76.76%] [G loss: 1.292359]\n",
      "[Epoch 4/50] [Batch 7/235] [D loss: 1.166896, acc: 72.66%] [G loss: 1.349830]\n",
      "[Epoch 4/50] [Batch 8/235] [D loss: 1.157301, acc: 75.00%] [G loss: 1.248143]\n",
      "[Epoch 4/50] [Batch 9/235] [D loss: 1.174857, acc: 72.07%] [G loss: 1.251006]\n",
      "[Epoch 4/50] [Batch 10/235] [D loss: 1.203937, acc: 70.90%] [G loss: 1.290177]\n",
      "[Epoch 4/50] [Batch 11/235] [D loss: 1.159982, acc: 72.85%] [G loss: 1.290510]\n",
      "[Epoch 4/50] [Batch 12/235] [D loss: 1.131775, acc: 76.17%] [G loss: 1.305901]\n",
      "[Epoch 4/50] [Batch 13/235] [D loss: 1.137249, acc: 76.76%] [G loss: 1.289887]\n",
      "[Epoch 4/50] [Batch 14/235] [D loss: 1.172939, acc: 73.44%] [G loss: 1.332302]\n",
      "[Epoch 4/50] [Batch 15/235] [D loss: 1.173268, acc: 74.02%] [G loss: 1.252036]\n",
      "[Epoch 4/50] [Batch 16/235] [D loss: 1.193778, acc: 72.66%] [G loss: 1.289619]\n",
      "[Epoch 4/50] [Batch 17/235] [D loss: 1.150572, acc: 74.41%] [G loss: 1.340740]\n",
      "[Epoch 4/50] [Batch 18/235] [D loss: 1.121052, acc: 76.95%] [G loss: 1.229672]\n",
      "[Epoch 4/50] [Batch 19/235] [D loss: 1.153763, acc: 72.46%] [G loss: 1.214828]\n",
      "[Epoch 4/50] [Batch 20/235] [D loss: 1.167044, acc: 70.70%] [G loss: 1.357912]\n",
      "[Epoch 4/50] [Batch 21/235] [D loss: 1.160423, acc: 72.27%] [G loss: 1.307278]\n",
      "[Epoch 4/50] [Batch 22/235] [D loss: 1.171350, acc: 73.44%] [G loss: 1.283364]\n",
      "[Epoch 4/50] [Batch 23/235] [D loss: 1.165418, acc: 72.85%] [G loss: 1.243742]\n",
      "[Epoch 4/50] [Batch 24/235] [D loss: 1.139540, acc: 74.02%] [G loss: 1.303154]\n",
      "[Epoch 4/50] [Batch 25/235] [D loss: 1.197437, acc: 71.48%] [G loss: 1.294035]\n",
      "[Epoch 4/50] [Batch 26/235] [D loss: 1.155727, acc: 75.39%] [G loss: 1.250606]\n",
      "[Epoch 4/50] [Batch 27/235] [D loss: 1.177453, acc: 71.88%] [G loss: 1.206885]\n",
      "[Epoch 4/50] [Batch 28/235] [D loss: 1.183427, acc: 72.66%] [G loss: 1.245978]\n",
      "[Epoch 4/50] [Batch 29/235] [D loss: 1.148942, acc: 75.59%] [G loss: 1.387688]\n",
      "[Epoch 4/50] [Batch 30/235] [D loss: 1.157441, acc: 73.63%] [G loss: 1.227992]\n",
      "[Epoch 4/50] [Batch 31/235] [D loss: 1.149981, acc: 76.76%] [G loss: 1.229908]\n",
      "[Epoch 4/50] [Batch 32/235] [D loss: 1.170069, acc: 73.05%] [G loss: 1.325029]\n",
      "[Epoch 4/50] [Batch 33/235] [D loss: 1.172439, acc: 73.24%] [G loss: 1.399695]\n",
      "[Epoch 4/50] [Batch 34/235] [D loss: 1.171673, acc: 72.85%] [G loss: 1.285772]\n",
      "[Epoch 4/50] [Batch 35/235] [D loss: 1.161496, acc: 73.44%] [G loss: 1.225076]\n",
      "[Epoch 4/50] [Batch 36/235] [D loss: 1.176857, acc: 70.51%] [G loss: 1.402719]\n",
      "[Epoch 4/50] [Batch 37/235] [D loss: 1.183213, acc: 73.83%] [G loss: 1.329268]\n",
      "[Epoch 4/50] [Batch 38/235] [D loss: 1.176626, acc: 71.68%] [G loss: 1.274740]\n",
      "[Epoch 4/50] [Batch 39/235] [D loss: 1.148746, acc: 75.98%] [G loss: 1.295846]\n",
      "[Epoch 4/50] [Batch 40/235] [D loss: 1.162377, acc: 75.59%] [G loss: 1.264176]\n",
      "[Epoch 4/50] [Batch 41/235] [D loss: 1.141740, acc: 74.22%] [G loss: 1.326594]\n",
      "[Epoch 4/50] [Batch 42/235] [D loss: 1.147764, acc: 73.24%] [G loss: 1.275630]\n",
      "[Epoch 4/50] [Batch 43/235] [D loss: 1.159668, acc: 73.83%] [G loss: 1.288649]\n",
      "[Epoch 4/50] [Batch 44/235] [D loss: 1.180416, acc: 72.85%] [G loss: 1.300784]\n",
      "[Epoch 4/50] [Batch 45/235] [D loss: 1.171151, acc: 71.68%] [G loss: 1.264439]\n",
      "[Epoch 4/50] [Batch 46/235] [D loss: 1.186935, acc: 75.59%] [G loss: 1.318196]\n",
      "[Epoch 4/50] [Batch 47/235] [D loss: 1.206903, acc: 69.53%] [G loss: 1.338910]\n",
      "[Epoch 4/50] [Batch 48/235] [D loss: 1.172525, acc: 75.39%] [G loss: 1.285928]\n",
      "[Epoch 4/50] [Batch 49/235] [D loss: 1.195200, acc: 70.90%] [G loss: 1.246170]\n",
      "[Epoch 4/50] [Batch 50/235] [D loss: 1.154605, acc: 74.41%] [G loss: 1.348207]\n",
      "[Epoch 4/50] [Batch 51/235] [D loss: 1.180262, acc: 71.48%] [G loss: 1.313499]\n",
      "[Epoch 4/50] [Batch 52/235] [D loss: 1.186732, acc: 71.88%] [G loss: 1.210524]\n",
      "[Epoch 4/50] [Batch 53/235] [D loss: 1.142796, acc: 74.80%] [G loss: 1.320649]\n",
      "[Epoch 4/50] [Batch 54/235] [D loss: 1.169050, acc: 75.20%] [G loss: 1.359195]\n",
      "[Epoch 4/50] [Batch 55/235] [D loss: 1.204581, acc: 70.51%] [G loss: 1.322279]\n",
      "[Epoch 4/50] [Batch 56/235] [D loss: 1.157993, acc: 72.46%] [G loss: 1.263687]\n",
      "[Epoch 4/50] [Batch 57/235] [D loss: 1.153516, acc: 73.24%] [G loss: 1.280300]\n",
      "[Epoch 4/50] [Batch 58/235] [D loss: 1.150076, acc: 74.80%] [G loss: 1.371330]\n",
      "[Epoch 4/50] [Batch 59/235] [D loss: 1.180645, acc: 70.12%] [G loss: 1.287963]\n",
      "[Epoch 4/50] [Batch 60/235] [D loss: 1.141671, acc: 75.39%] [G loss: 1.293976]\n",
      "[Epoch 4/50] [Batch 61/235] [D loss: 1.167574, acc: 75.78%] [G loss: 1.200829]\n",
      "[Epoch 4/50] [Batch 62/235] [D loss: 1.133898, acc: 73.63%] [G loss: 1.301579]\n",
      "[Epoch 4/50] [Batch 63/235] [D loss: 1.209940, acc: 70.31%] [G loss: 1.286901]\n",
      "[Epoch 4/50] [Batch 64/235] [D loss: 1.162558, acc: 74.80%] [G loss: 1.334500]\n",
      "[Epoch 4/50] [Batch 65/235] [D loss: 1.177586, acc: 73.83%] [G loss: 1.260250]\n",
      "[Epoch 4/50] [Batch 66/235] [D loss: 1.178630, acc: 74.22%] [G loss: 1.349407]\n",
      "[Epoch 4/50] [Batch 67/235] [D loss: 1.171205, acc: 74.22%] [G loss: 1.315460]\n",
      "[Epoch 4/50] [Batch 68/235] [D loss: 1.170741, acc: 72.07%] [G loss: 1.285448]\n",
      "[Epoch 4/50] [Batch 69/235] [D loss: 1.162939, acc: 73.44%] [G loss: 1.247009]\n",
      "[Epoch 4/50] [Batch 70/235] [D loss: 1.169352, acc: 73.83%] [G loss: 1.250845]\n",
      "[Epoch 4/50] [Batch 71/235] [D loss: 1.168296, acc: 73.63%] [G loss: 1.272434]\n",
      "[Epoch 4/50] [Batch 72/235] [D loss: 1.169233, acc: 75.39%] [G loss: 1.219776]\n",
      "[Epoch 4/50] [Batch 73/235] [D loss: 1.176811, acc: 74.22%] [G loss: 1.283677]\n",
      "[Epoch 4/50] [Batch 74/235] [D loss: 1.157143, acc: 76.76%] [G loss: 1.340455]\n",
      "[Epoch 4/50] [Batch 75/235] [D loss: 1.179961, acc: 74.22%] [G loss: 1.211226]\n",
      "[Epoch 4/50] [Batch 76/235] [D loss: 1.165441, acc: 69.92%] [G loss: 1.255451]\n",
      "[Epoch 4/50] [Batch 77/235] [D loss: 1.174828, acc: 77.54%] [G loss: 1.338741]\n",
      "[Epoch 4/50] [Batch 78/235] [D loss: 1.165410, acc: 71.09%] [G loss: 1.272469]\n",
      "[Epoch 4/50] [Batch 79/235] [D loss: 1.122085, acc: 78.91%] [G loss: 1.280918]\n",
      "[Epoch 4/50] [Batch 80/235] [D loss: 1.142624, acc: 73.05%] [G loss: 1.398243]\n",
      "[Epoch 4/50] [Batch 81/235] [D loss: 1.168068, acc: 74.80%] [G loss: 1.281244]\n",
      "[Epoch 4/50] [Batch 82/235] [D loss: 1.176826, acc: 72.85%] [G loss: 1.326914]\n",
      "[Epoch 4/50] [Batch 83/235] [D loss: 1.175639, acc: 73.24%] [G loss: 1.354825]\n",
      "[Epoch 4/50] [Batch 84/235] [D loss: 1.165317, acc: 75.00%] [G loss: 1.217600]\n",
      "[Epoch 4/50] [Batch 85/235] [D loss: 1.178386, acc: 73.44%] [G loss: 1.326441]\n",
      "[Epoch 4/50] [Batch 86/235] [D loss: 1.151676, acc: 72.66%] [G loss: 1.309230]\n",
      "[Epoch 4/50] [Batch 87/235] [D loss: 1.160527, acc: 76.17%] [G loss: 1.281286]\n",
      "[Epoch 4/50] [Batch 88/235] [D loss: 1.173651, acc: 68.95%] [G loss: 1.316841]\n",
      "[Epoch 4/50] [Batch 89/235] [D loss: 1.169142, acc: 73.24%] [G loss: 1.250549]\n",
      "[Epoch 4/50] [Batch 90/235] [D loss: 1.168475, acc: 76.17%] [G loss: 1.280373]\n",
      "[Epoch 4/50] [Batch 91/235] [D loss: 1.174003, acc: 72.46%] [G loss: 1.380959]\n",
      "[Epoch 4/50] [Batch 92/235] [D loss: 1.156963, acc: 75.78%] [G loss: 1.224011]\n",
      "[Epoch 4/50] [Batch 93/235] [D loss: 1.175767, acc: 71.09%] [G loss: 1.303430]\n",
      "[Epoch 4/50] [Batch 94/235] [D loss: 1.147641, acc: 76.37%] [G loss: 1.296440]\n",
      "[Epoch 4/50] [Batch 95/235] [D loss: 1.167361, acc: 76.37%] [G loss: 1.232857]\n",
      "[Epoch 4/50] [Batch 96/235] [D loss: 1.197258, acc: 69.53%] [G loss: 1.250853]\n",
      "[Epoch 4/50] [Batch 97/235] [D loss: 1.163625, acc: 75.39%] [G loss: 1.272827]\n",
      "[Epoch 4/50] [Batch 98/235] [D loss: 1.171179, acc: 72.85%] [G loss: 1.325426]\n",
      "[Epoch 4/50] [Batch 99/235] [D loss: 1.169225, acc: 74.02%] [G loss: 1.226042]\n",
      "[Epoch 4/50] [Batch 100/235] [D loss: 1.159539, acc: 74.61%] [G loss: 1.276841]\n",
      "[Epoch 4/50] [Batch 101/235] [D loss: 1.179254, acc: 71.09%] [G loss: 1.277746]\n",
      "[Epoch 4/50] [Batch 102/235] [D loss: 1.173463, acc: 76.56%] [G loss: 1.239637]\n",
      "[Epoch 4/50] [Batch 103/235] [D loss: 1.164123, acc: 72.07%] [G loss: 1.307449]\n",
      "[Epoch 4/50] [Batch 104/235] [D loss: 1.176680, acc: 74.80%] [G loss: 1.257897]\n",
      "[Epoch 4/50] [Batch 105/235] [D loss: 1.156614, acc: 74.22%] [G loss: 1.288389]\n",
      "[Epoch 4/50] [Batch 106/235] [D loss: 1.155011, acc: 72.46%] [G loss: 1.297673]\n",
      "[Epoch 4/50] [Batch 107/235] [D loss: 1.141708, acc: 74.02%] [G loss: 1.367868]\n",
      "[Epoch 4/50] [Batch 108/235] [D loss: 1.182641, acc: 73.44%] [G loss: 1.266886]\n",
      "[Epoch 4/50] [Batch 109/235] [D loss: 1.172496, acc: 74.80%] [G loss: 1.214115]\n",
      "[Epoch 4/50] [Batch 110/235] [D loss: 1.192049, acc: 73.63%] [G loss: 1.304676]\n",
      "[Epoch 4/50] [Batch 111/235] [D loss: 1.169702, acc: 74.61%] [G loss: 1.313718]\n",
      "[Epoch 4/50] [Batch 112/235] [D loss: 1.160015, acc: 73.05%] [G loss: 1.271377]\n",
      "[Epoch 4/50] [Batch 113/235] [D loss: 1.154029, acc: 74.41%] [G loss: 1.291053]\n",
      "[Epoch 4/50] [Batch 114/235] [D loss: 1.137871, acc: 77.34%] [G loss: 1.216699]\n",
      "[Epoch 4/50] [Batch 115/235] [D loss: 1.175211, acc: 73.44%] [G loss: 1.242901]\n",
      "[Epoch 4/50] [Batch 116/235] [D loss: 1.150488, acc: 73.63%] [G loss: 1.342122]\n",
      "[Epoch 4/50] [Batch 117/235] [D loss: 1.147694, acc: 75.39%] [G loss: 1.330514]\n",
      "[Epoch 4/50] [Batch 118/235] [D loss: 1.174859, acc: 75.98%] [G loss: 1.237969]\n",
      "[Epoch 4/50] [Batch 119/235] [D loss: 1.175218, acc: 73.44%] [G loss: 1.270393]\n",
      "[Epoch 4/50] [Batch 120/235] [D loss: 1.152747, acc: 73.24%] [G loss: 1.343523]\n",
      "[Epoch 4/50] [Batch 121/235] [D loss: 1.141463, acc: 73.44%] [G loss: 1.380195]\n",
      "[Epoch 4/50] [Batch 122/235] [D loss: 1.136557, acc: 75.39%] [G loss: 1.281039]\n",
      "[Epoch 4/50] [Batch 123/235] [D loss: 1.186157, acc: 73.24%] [G loss: 1.249553]\n",
      "[Epoch 4/50] [Batch 124/235] [D loss: 1.185944, acc: 73.44%] [G loss: 1.340160]\n",
      "[Epoch 4/50] [Batch 125/235] [D loss: 1.194728, acc: 71.88%] [G loss: 1.206816]\n",
      "[Epoch 4/50] [Batch 126/235] [D loss: 1.181987, acc: 73.63%] [G loss: 1.303510]\n",
      "[Epoch 4/50] [Batch 127/235] [D loss: 1.172288, acc: 73.44%] [G loss: 1.324003]\n",
      "[Epoch 4/50] [Batch 128/235] [D loss: 1.174087, acc: 75.00%] [G loss: 1.240528]\n",
      "[Epoch 4/50] [Batch 129/235] [D loss: 1.144368, acc: 72.46%] [G loss: 1.280496]\n",
      "[Epoch 4/50] [Batch 130/235] [D loss: 1.183815, acc: 70.31%] [G loss: 1.263354]\n",
      "[Epoch 4/50] [Batch 131/235] [D loss: 1.167334, acc: 73.63%] [G loss: 1.255344]\n",
      "[Epoch 4/50] [Batch 132/235] [D loss: 1.163022, acc: 74.61%] [G loss: 1.258728]\n",
      "[Epoch 4/50] [Batch 133/235] [D loss: 1.181784, acc: 75.59%] [G loss: 1.274275]\n",
      "[Epoch 4/50] [Batch 134/235] [D loss: 1.178802, acc: 71.68%] [G loss: 1.299938]\n",
      "[Epoch 4/50] [Batch 135/235] [D loss: 1.171822, acc: 76.37%] [G loss: 1.238089]\n",
      "[Epoch 4/50] [Batch 136/235] [D loss: 1.136847, acc: 74.22%] [G loss: 1.300003]\n",
      "[Epoch 4/50] [Batch 137/235] [D loss: 1.221121, acc: 69.73%] [G loss: 1.328028]\n",
      "[Epoch 4/50] [Batch 138/235] [D loss: 1.125959, acc: 76.17%] [G loss: 1.268774]\n",
      "[Epoch 4/50] [Batch 139/235] [D loss: 1.152540, acc: 73.44%] [G loss: 1.275480]\n",
      "[Epoch 4/50] [Batch 140/235] [D loss: 1.129829, acc: 76.37%] [G loss: 1.376289]\n",
      "[Epoch 4/50] [Batch 141/235] [D loss: 1.149967, acc: 75.20%] [G loss: 1.260452]\n",
      "[Epoch 4/50] [Batch 142/235] [D loss: 1.166183, acc: 74.61%] [G loss: 1.281623]\n",
      "[Epoch 4/50] [Batch 143/235] [D loss: 1.180589, acc: 76.17%] [G loss: 1.315072]\n",
      "[Epoch 4/50] [Batch 144/235] [D loss: 1.183982, acc: 72.85%] [G loss: 1.180149]\n",
      "[Epoch 4/50] [Batch 145/235] [D loss: 1.154200, acc: 76.37%] [G loss: 1.257580]\n",
      "[Epoch 4/50] [Batch 146/235] [D loss: 1.160918, acc: 74.02%] [G loss: 1.273883]\n",
      "[Epoch 4/50] [Batch 147/235] [D loss: 1.164706, acc: 75.20%] [G loss: 1.269200]\n",
      "[Epoch 4/50] [Batch 148/235] [D loss: 1.132269, acc: 79.10%] [G loss: 1.233262]\n",
      "[Epoch 4/50] [Batch 149/235] [D loss: 1.153728, acc: 75.00%] [G loss: 1.261510]\n",
      "[Epoch 4/50] [Batch 150/235] [D loss: 1.153933, acc: 78.52%] [G loss: 1.278916]\n",
      "[Epoch 4/50] [Batch 151/235] [D loss: 1.174721, acc: 74.22%] [G loss: 1.378673]\n",
      "[Epoch 4/50] [Batch 152/235] [D loss: 1.193640, acc: 71.09%] [G loss: 1.227396]\n",
      "[Epoch 4/50] [Batch 153/235] [D loss: 1.130946, acc: 75.59%] [G loss: 1.290271]\n",
      "[Epoch 4/50] [Batch 154/235] [D loss: 1.125657, acc: 74.41%] [G loss: 1.323804]\n",
      "[Epoch 4/50] [Batch 155/235] [D loss: 1.128604, acc: 74.80%] [G loss: 1.268917]\n",
      "[Epoch 4/50] [Batch 156/235] [D loss: 1.175406, acc: 72.27%] [G loss: 1.275317]\n",
      "[Epoch 4/50] [Batch 157/235] [D loss: 1.142862, acc: 76.17%] [G loss: 1.265590]\n",
      "[Epoch 4/50] [Batch 158/235] [D loss: 1.142128, acc: 73.63%] [G loss: 1.372553]\n",
      "[Epoch 4/50] [Batch 159/235] [D loss: 1.143897, acc: 73.44%] [G loss: 1.242799]\n",
      "[Epoch 4/50] [Batch 160/235] [D loss: 1.134987, acc: 74.41%] [G loss: 1.349783]\n",
      "[Epoch 4/50] [Batch 161/235] [D loss: 1.161240, acc: 72.27%] [G loss: 1.305384]\n",
      "[Epoch 4/50] [Batch 162/235] [D loss: 1.142537, acc: 74.22%] [G loss: 1.306349]\n",
      "[Epoch 4/50] [Batch 163/235] [D loss: 1.164754, acc: 74.41%] [G loss: 1.294773]\n",
      "[Epoch 4/50] [Batch 164/235] [D loss: 1.163852, acc: 74.41%] [G loss: 1.275365]\n",
      "[Epoch 4/50] [Batch 165/235] [D loss: 1.157753, acc: 72.46%] [G loss: 1.408546]\n",
      "[Epoch 4/50] [Batch 166/235] [D loss: 1.142647, acc: 76.37%] [G loss: 1.333232]\n",
      "[Epoch 4/50] [Batch 167/235] [D loss: 1.169105, acc: 74.02%] [G loss: 1.212687]\n",
      "[Epoch 4/50] [Batch 168/235] [D loss: 1.164452, acc: 73.24%] [G loss: 1.314692]\n",
      "[Epoch 4/50] [Batch 169/235] [D loss: 1.194722, acc: 75.39%] [G loss: 1.376791]\n",
      "[Epoch 4/50] [Batch 170/235] [D loss: 1.160403, acc: 73.24%] [G loss: 1.353826]\n",
      "[Epoch 4/50] [Batch 171/235] [D loss: 1.191541, acc: 74.80%] [G loss: 1.174016]\n",
      "[Epoch 4/50] [Batch 172/235] [D loss: 1.147478, acc: 74.80%] [G loss: 1.318979]\n",
      "[Epoch 4/50] [Batch 173/235] [D loss: 1.193331, acc: 75.78%] [G loss: 1.313308]\n",
      "[Epoch 4/50] [Batch 174/235] [D loss: 1.165134, acc: 73.05%] [G loss: 1.247171]\n",
      "[Epoch 4/50] [Batch 175/235] [D loss: 1.166484, acc: 75.59%] [G loss: 1.247617]\n",
      "[Epoch 4/50] [Batch 176/235] [D loss: 1.153638, acc: 76.17%] [G loss: 1.296032]\n",
      "[Epoch 4/50] [Batch 177/235] [D loss: 1.140099, acc: 74.41%] [G loss: 1.219731]\n",
      "[Epoch 4/50] [Batch 178/235] [D loss: 1.161949, acc: 78.12%] [G loss: 1.296332]\n",
      "[Epoch 4/50] [Batch 179/235] [D loss: 1.158056, acc: 72.66%] [G loss: 1.318171]\n",
      "[Epoch 4/50] [Batch 180/235] [D loss: 1.156239, acc: 74.41%] [G loss: 1.279080]\n",
      "[Epoch 4/50] [Batch 181/235] [D loss: 1.139711, acc: 77.93%] [G loss: 1.343675]\n",
      "[Epoch 4/50] [Batch 182/235] [D loss: 1.160006, acc: 73.63%] [G loss: 1.342404]\n",
      "[Epoch 4/50] [Batch 183/235] [D loss: 1.161664, acc: 75.59%] [G loss: 1.198515]\n",
      "[Epoch 4/50] [Batch 184/235] [D loss: 1.152633, acc: 76.17%] [G loss: 1.367306]\n",
      "[Epoch 4/50] [Batch 185/235] [D loss: 1.159217, acc: 71.68%] [G loss: 1.286842]\n",
      "[Epoch 4/50] [Batch 186/235] [D loss: 1.136663, acc: 75.39%] [G loss: 1.244495]\n",
      "[Epoch 4/50] [Batch 187/235] [D loss: 1.145999, acc: 75.20%] [G loss: 1.218220]\n",
      "[Epoch 4/50] [Batch 188/235] [D loss: 1.156127, acc: 73.83%] [G loss: 1.236616]\n",
      "[Epoch 4/50] [Batch 189/235] [D loss: 1.144319, acc: 75.00%] [G loss: 1.303703]\n",
      "[Epoch 4/50] [Batch 190/235] [D loss: 1.179013, acc: 74.22%] [G loss: 1.253447]\n",
      "[Epoch 4/50] [Batch 191/235] [D loss: 1.169516, acc: 72.85%] [G loss: 1.388404]\n",
      "[Epoch 4/50] [Batch 192/235] [D loss: 1.169148, acc: 74.22%] [G loss: 1.212296]\n",
      "[Epoch 4/50] [Batch 193/235] [D loss: 1.150555, acc: 75.39%] [G loss: 1.225720]\n",
      "[Epoch 4/50] [Batch 194/235] [D loss: 1.158211, acc: 75.00%] [G loss: 1.313394]\n",
      "[Epoch 4/50] [Batch 195/235] [D loss: 1.155759, acc: 75.20%] [G loss: 1.239156]\n",
      "[Epoch 4/50] [Batch 196/235] [D loss: 1.160873, acc: 76.56%] [G loss: 1.312877]\n",
      "[Epoch 4/50] [Batch 197/235] [D loss: 1.161767, acc: 76.17%] [G loss: 1.271054]\n",
      "[Epoch 4/50] [Batch 198/235] [D loss: 1.143112, acc: 74.22%] [G loss: 1.389115]\n",
      "[Epoch 4/50] [Batch 199/235] [D loss: 1.148385, acc: 76.95%] [G loss: 1.234119]\n",
      "[Epoch 4/50] [Batch 200/235] [D loss: 1.158567, acc: 76.37%] [G loss: 1.273892]\n",
      "[Epoch 4/50] [Batch 201/235] [D loss: 1.173467, acc: 77.15%] [G loss: 1.310304]\n",
      "[Epoch 4/50] [Batch 202/235] [D loss: 1.159645, acc: 75.00%] [G loss: 1.333424]\n",
      "[Epoch 4/50] [Batch 203/235] [D loss: 1.155929, acc: 71.29%] [G loss: 1.316921]\n",
      "[Epoch 4/50] [Batch 204/235] [D loss: 1.160206, acc: 76.56%] [G loss: 1.200362]\n",
      "[Epoch 4/50] [Batch 205/235] [D loss: 1.139699, acc: 73.83%] [G loss: 1.425812]\n",
      "[Epoch 4/50] [Batch 206/235] [D loss: 1.092795, acc: 77.54%] [G loss: 1.280387]\n",
      "[Epoch 4/50] [Batch 207/235] [D loss: 1.153947, acc: 75.20%] [G loss: 1.235930]\n",
      "[Epoch 4/50] [Batch 208/235] [D loss: 1.138852, acc: 77.93%] [G loss: 1.277628]\n",
      "[Epoch 4/50] [Batch 209/235] [D loss: 1.118040, acc: 77.54%] [G loss: 1.332090]\n",
      "[Epoch 4/50] [Batch 210/235] [D loss: 1.156893, acc: 76.37%] [G loss: 1.259050]\n",
      "[Epoch 4/50] [Batch 211/235] [D loss: 1.146652, acc: 75.39%] [G loss: 1.351129]\n",
      "[Epoch 4/50] [Batch 212/235] [D loss: 1.126719, acc: 76.95%] [G loss: 1.372988]\n",
      "[Epoch 4/50] [Batch 213/235] [D loss: 1.109965, acc: 77.93%] [G loss: 1.348724]\n",
      "[Epoch 4/50] [Batch 214/235] [D loss: 1.147963, acc: 76.37%] [G loss: 1.376924]\n",
      "[Epoch 4/50] [Batch 215/235] [D loss: 1.203954, acc: 72.07%] [G loss: 1.177645]\n",
      "[Epoch 4/50] [Batch 216/235] [D loss: 1.208379, acc: 74.41%] [G loss: 1.237590]\n",
      "[Epoch 4/50] [Batch 217/235] [D loss: 1.162596, acc: 75.00%] [G loss: 1.316638]\n",
      "[Epoch 4/50] [Batch 218/235] [D loss: 1.159632, acc: 74.61%] [G loss: 1.265381]\n",
      "[Epoch 4/50] [Batch 219/235] [D loss: 1.141848, acc: 74.80%] [G loss: 1.250862]\n",
      "[Epoch 4/50] [Batch 220/235] [D loss: 1.144151, acc: 73.63%] [G loss: 1.402660]\n",
      "[Epoch 4/50] [Batch 221/235] [D loss: 1.159831, acc: 72.07%] [G loss: 1.299552]\n",
      "[Epoch 4/50] [Batch 222/235] [D loss: 1.165469, acc: 73.63%] [G loss: 1.291499]\n",
      "[Epoch 4/50] [Batch 223/235] [D loss: 1.180727, acc: 74.41%] [G loss: 1.289943]\n",
      "[Epoch 4/50] [Batch 224/235] [D loss: 1.188162, acc: 72.07%] [G loss: 1.304638]\n",
      "[Epoch 4/50] [Batch 225/235] [D loss: 1.162115, acc: 75.20%] [G loss: 1.292429]\n",
      "[Epoch 4/50] [Batch 226/235] [D loss: 1.153498, acc: 73.63%] [G loss: 1.339588]\n",
      "[Epoch 4/50] [Batch 227/235] [D loss: 1.135289, acc: 74.22%] [G loss: 1.251293]\n",
      "[Epoch 4/50] [Batch 228/235] [D loss: 1.141184, acc: 77.15%] [G loss: 1.364137]\n",
      "[Epoch 4/50] [Batch 229/235] [D loss: 1.164432, acc: 76.56%] [G loss: 1.336232]\n",
      "[Epoch 4/50] [Batch 230/235] [D loss: 1.124363, acc: 74.61%] [G loss: 1.285692]\n",
      "[Epoch 4/50] [Batch 231/235] [D loss: 1.154525, acc: 75.39%] [G loss: 1.159068]\n",
      "[Epoch 4/50] [Batch 232/235] [D loss: 1.155894, acc: 73.44%] [G loss: 1.340230]\n",
      "[Epoch 4/50] [Batch 233/235] [D loss: 1.145493, acc: 75.20%] [G loss: 1.286232]\n",
      "[Epoch 4/50] [Batch 234/235] [D loss: 1.115032, acc: 77.60%] [G loss: 1.177945]\n",
      "[Epoch 5/50] [Batch 0/235] [D loss: 1.136162, acc: 73.44%] [G loss: 1.427973]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/50] [Batch 1/235] [D loss: 1.144831, acc: 75.00%] [G loss: 1.290854]\n",
      "[Epoch 5/50] [Batch 2/235] [D loss: 1.156024, acc: 75.78%] [G loss: 1.191374]\n",
      "[Epoch 5/50] [Batch 3/235] [D loss: 1.133116, acc: 76.37%] [G loss: 1.346521]\n",
      "[Epoch 5/50] [Batch 4/235] [D loss: 1.144652, acc: 75.39%] [G loss: 1.343985]\n",
      "[Epoch 5/50] [Batch 5/235] [D loss: 1.162254, acc: 71.48%] [G loss: 1.360233]\n",
      "[Epoch 5/50] [Batch 6/235] [D loss: 1.154652, acc: 76.95%] [G loss: 1.230633]\n",
      "[Epoch 5/50] [Batch 7/235] [D loss: 1.179229, acc: 74.41%] [G loss: 1.298260]\n",
      "[Epoch 5/50] [Batch 8/235] [D loss: 1.164258, acc: 74.02%] [G loss: 1.247443]\n",
      "[Epoch 5/50] [Batch 9/235] [D loss: 1.185523, acc: 75.78%] [G loss: 1.286717]\n",
      "[Epoch 5/50] [Batch 10/235] [D loss: 1.182504, acc: 74.41%] [G loss: 1.200191]\n",
      "[Epoch 5/50] [Batch 11/235] [D loss: 1.181833, acc: 73.44%] [G loss: 1.346734]\n",
      "[Epoch 5/50] [Batch 12/235] [D loss: 1.154681, acc: 75.78%] [G loss: 1.287069]\n",
      "[Epoch 5/50] [Batch 13/235] [D loss: 1.201005, acc: 75.98%] [G loss: 1.191384]\n",
      "[Epoch 5/50] [Batch 14/235] [D loss: 1.194911, acc: 72.85%] [G loss: 1.312038]\n",
      "[Epoch 5/50] [Batch 15/235] [D loss: 1.110498, acc: 76.76%] [G loss: 1.379325]\n",
      "[Epoch 5/50] [Batch 16/235] [D loss: 1.141829, acc: 78.52%] [G loss: 1.193860]\n",
      "[Epoch 5/50] [Batch 17/235] [D loss: 1.135783, acc: 75.39%] [G loss: 1.261010]\n",
      "[Epoch 5/50] [Batch 18/235] [D loss: 1.154531, acc: 73.24%] [G loss: 1.337060]\n",
      "[Epoch 5/50] [Batch 19/235] [D loss: 1.161296, acc: 75.20%] [G loss: 1.333138]\n",
      "[Epoch 5/50] [Batch 20/235] [D loss: 1.161002, acc: 73.44%] [G loss: 1.220845]\n",
      "[Epoch 5/50] [Batch 21/235] [D loss: 1.147608, acc: 74.80%] [G loss: 1.400531]\n",
      "[Epoch 5/50] [Batch 22/235] [D loss: 1.127039, acc: 75.98%] [G loss: 1.317957]\n",
      "[Epoch 5/50] [Batch 23/235] [D loss: 1.163972, acc: 75.00%] [G loss: 1.230819]\n",
      "[Epoch 5/50] [Batch 24/235] [D loss: 1.163377, acc: 73.83%] [G loss: 1.284245]\n",
      "[Epoch 5/50] [Batch 25/235] [D loss: 1.147201, acc: 75.78%] [G loss: 1.299677]\n",
      "[Epoch 5/50] [Batch 26/235] [D loss: 1.168840, acc: 75.39%] [G loss: 1.276369]\n",
      "[Epoch 5/50] [Batch 27/235] [D loss: 1.176788, acc: 71.29%] [G loss: 1.303006]\n",
      "[Epoch 5/50] [Batch 28/235] [D loss: 1.131191, acc: 76.37%] [G loss: 1.273427]\n",
      "[Epoch 5/50] [Batch 29/235] [D loss: 1.151367, acc: 76.76%] [G loss: 1.307895]\n",
      "[Epoch 5/50] [Batch 30/235] [D loss: 1.180995, acc: 75.59%] [G loss: 1.307550]\n",
      "[Epoch 5/50] [Batch 31/235] [D loss: 1.168654, acc: 73.24%] [G loss: 1.278721]\n",
      "[Epoch 5/50] [Batch 32/235] [D loss: 1.172346, acc: 74.80%] [G loss: 1.417326]\n",
      "[Epoch 5/50] [Batch 33/235] [D loss: 1.148668, acc: 73.44%] [G loss: 1.297325]\n",
      "[Epoch 5/50] [Batch 34/235] [D loss: 1.113760, acc: 78.32%] [G loss: 1.262823]\n",
      "[Epoch 5/50] [Batch 35/235] [D loss: 1.143945, acc: 74.80%] [G loss: 1.235486]\n",
      "[Epoch 5/50] [Batch 36/235] [D loss: 1.184831, acc: 69.92%] [G loss: 1.292178]\n",
      "[Epoch 5/50] [Batch 37/235] [D loss: 1.152149, acc: 76.76%] [G loss: 1.311906]\n",
      "[Epoch 5/50] [Batch 38/235] [D loss: 1.143497, acc: 78.32%] [G loss: 1.284698]\n",
      "[Epoch 5/50] [Batch 39/235] [D loss: 1.178377, acc: 75.59%] [G loss: 1.240952]\n",
      "[Epoch 5/50] [Batch 40/235] [D loss: 1.176185, acc: 70.70%] [G loss: 1.299848]\n",
      "[Epoch 5/50] [Batch 41/235] [D loss: 1.158157, acc: 74.80%] [G loss: 1.322814]\n",
      "[Epoch 5/50] [Batch 42/235] [D loss: 1.180426, acc: 74.22%] [G loss: 1.211155]\n",
      "[Epoch 5/50] [Batch 43/235] [D loss: 1.162948, acc: 74.41%] [G loss: 1.231811]\n",
      "[Epoch 5/50] [Batch 44/235] [D loss: 1.126650, acc: 77.15%] [G loss: 1.341006]\n",
      "[Epoch 5/50] [Batch 45/235] [D loss: 1.146093, acc: 74.22%] [G loss: 1.260961]\n",
      "[Epoch 5/50] [Batch 46/235] [D loss: 1.159561, acc: 77.73%] [G loss: 1.229200]\n",
      "[Epoch 5/50] [Batch 47/235] [D loss: 1.194971, acc: 73.24%] [G loss: 1.293447]\n",
      "[Epoch 5/50] [Batch 48/235] [D loss: 1.176014, acc: 71.88%] [G loss: 1.282830]\n",
      "[Epoch 5/50] [Batch 49/235] [D loss: 1.158322, acc: 71.68%] [G loss: 1.246391]\n",
      "[Epoch 5/50] [Batch 50/235] [D loss: 1.113935, acc: 71.29%] [G loss: 1.366038]\n",
      "[Epoch 5/50] [Batch 51/235] [D loss: 1.127811, acc: 76.37%] [G loss: 1.300450]\n",
      "[Epoch 5/50] [Batch 52/235] [D loss: 1.142491, acc: 77.93%] [G loss: 1.242071]\n",
      "[Epoch 5/50] [Batch 53/235] [D loss: 1.179527, acc: 74.80%] [G loss: 1.229858]\n",
      "[Epoch 5/50] [Batch 54/235] [D loss: 1.157664, acc: 74.61%] [G loss: 1.256247]\n",
      "[Epoch 5/50] [Batch 55/235] [D loss: 1.156251, acc: 73.63%] [G loss: 1.244465]\n",
      "[Epoch 5/50] [Batch 56/235] [D loss: 1.155186, acc: 73.44%] [G loss: 1.260534]\n",
      "[Epoch 5/50] [Batch 57/235] [D loss: 1.151062, acc: 73.24%] [G loss: 1.283945]\n",
      "[Epoch 5/50] [Batch 58/235] [D loss: 1.149605, acc: 75.20%] [G loss: 1.262635]\n",
      "[Epoch 5/50] [Batch 59/235] [D loss: 1.139642, acc: 79.30%] [G loss: 1.236293]\n",
      "[Epoch 5/50] [Batch 60/235] [D loss: 1.116790, acc: 77.34%] [G loss: 1.246595]\n",
      "[Epoch 5/50] [Batch 61/235] [D loss: 1.139140, acc: 75.20%] [G loss: 1.491343]\n",
      "[Epoch 5/50] [Batch 62/235] [D loss: 1.135659, acc: 75.20%] [G loss: 1.348130]\n",
      "[Epoch 5/50] [Batch 63/235] [D loss: 1.146251, acc: 75.20%] [G loss: 1.253013]\n",
      "[Epoch 5/50] [Batch 64/235] [D loss: 1.144644, acc: 74.80%] [G loss: 1.346857]\n",
      "[Epoch 5/50] [Batch 65/235] [D loss: 1.182918, acc: 74.22%] [G loss: 1.271080]\n",
      "[Epoch 5/50] [Batch 66/235] [D loss: 1.159010, acc: 73.44%] [G loss: 1.284788]\n",
      "[Epoch 5/50] [Batch 67/235] [D loss: 1.167025, acc: 72.85%] [G loss: 1.297224]\n",
      "[Epoch 5/50] [Batch 68/235] [D loss: 1.145114, acc: 74.41%] [G loss: 1.257317]\n",
      "[Epoch 5/50] [Batch 69/235] [D loss: 1.191448, acc: 74.02%] [G loss: 1.294373]\n",
      "[Epoch 5/50] [Batch 70/235] [D loss: 1.189432, acc: 71.48%] [G loss: 1.237486]\n",
      "[Epoch 5/50] [Batch 71/235] [D loss: 1.174555, acc: 76.95%] [G loss: 1.256880]\n",
      "[Epoch 5/50] [Batch 72/235] [D loss: 1.170611, acc: 73.83%] [G loss: 1.350810]\n",
      "[Epoch 5/50] [Batch 73/235] [D loss: 1.183546, acc: 78.32%] [G loss: 1.248169]\n",
      "[Epoch 5/50] [Batch 74/235] [D loss: 1.149480, acc: 74.02%] [G loss: 1.274874]\n",
      "[Epoch 5/50] [Batch 75/235] [D loss: 1.167014, acc: 75.00%] [G loss: 1.233669]\n",
      "[Epoch 5/50] [Batch 76/235] [D loss: 1.182143, acc: 75.78%] [G loss: 1.280454]\n",
      "[Epoch 5/50] [Batch 77/235] [D loss: 1.136615, acc: 76.37%] [G loss: 1.325912]\n",
      "[Epoch 5/50] [Batch 78/235] [D loss: 1.157273, acc: 74.22%] [G loss: 1.218088]\n",
      "[Epoch 5/50] [Batch 79/235] [D loss: 1.159831, acc: 76.37%] [G loss: 1.344578]\n",
      "[Epoch 5/50] [Batch 80/235] [D loss: 1.132550, acc: 77.73%] [G loss: 1.246146]\n",
      "[Epoch 5/50] [Batch 81/235] [D loss: 1.137354, acc: 74.22%] [G loss: 1.270756]\n",
      "[Epoch 5/50] [Batch 82/235] [D loss: 1.143046, acc: 77.93%] [G loss: 1.272439]\n",
      "[Epoch 5/50] [Batch 83/235] [D loss: 1.152015, acc: 74.61%] [G loss: 1.280993]\n",
      "[Epoch 5/50] [Batch 84/235] [D loss: 1.165954, acc: 74.41%] [G loss: 1.249326]\n",
      "[Epoch 5/50] [Batch 85/235] [D loss: 1.146218, acc: 75.39%] [G loss: 1.239595]\n",
      "[Epoch 5/50] [Batch 86/235] [D loss: 1.133223, acc: 77.34%] [G loss: 1.315978]\n",
      "[Epoch 5/50] [Batch 87/235] [D loss: 1.142254, acc: 74.02%] [G loss: 1.271131]\n",
      "[Epoch 5/50] [Batch 88/235] [D loss: 1.137954, acc: 76.76%] [G loss: 1.353812]\n",
      "[Epoch 5/50] [Batch 89/235] [D loss: 1.186234, acc: 76.95%] [G loss: 1.187353]\n",
      "[Epoch 5/50] [Batch 90/235] [D loss: 1.151824, acc: 74.61%] [G loss: 1.259789]\n",
      "[Epoch 5/50] [Batch 91/235] [D loss: 1.122644, acc: 75.59%] [G loss: 1.368307]\n",
      "[Epoch 5/50] [Batch 92/235] [D loss: 1.130965, acc: 77.15%] [G loss: 1.285631]\n",
      "[Epoch 5/50] [Batch 93/235] [D loss: 1.159342, acc: 75.39%] [G loss: 1.217092]\n",
      "[Epoch 5/50] [Batch 94/235] [D loss: 1.139157, acc: 74.22%] [G loss: 1.322368]\n",
      "[Epoch 5/50] [Batch 95/235] [D loss: 1.130178, acc: 74.22%] [G loss: 1.304139]\n",
      "[Epoch 5/50] [Batch 96/235] [D loss: 1.170021, acc: 73.83%] [G loss: 1.205771]\n",
      "[Epoch 5/50] [Batch 97/235] [D loss: 1.139291, acc: 75.98%] [G loss: 1.330233]\n",
      "[Epoch 5/50] [Batch 98/235] [D loss: 1.139925, acc: 74.22%] [G loss: 1.288864]\n",
      "[Epoch 5/50] [Batch 99/235] [D loss: 1.187350, acc: 73.05%] [G loss: 1.199178]\n",
      "[Epoch 5/50] [Batch 100/235] [D loss: 1.155828, acc: 74.22%] [G loss: 1.285583]\n",
      "[Epoch 5/50] [Batch 101/235] [D loss: 1.147156, acc: 75.39%] [G loss: 1.360213]\n",
      "[Epoch 5/50] [Batch 102/235] [D loss: 1.158677, acc: 76.17%] [G loss: 1.254729]\n",
      "[Epoch 5/50] [Batch 103/235] [D loss: 1.152678, acc: 74.41%] [G loss: 1.247849]\n",
      "[Epoch 5/50] [Batch 104/235] [D loss: 1.174520, acc: 74.02%] [G loss: 1.345888]\n",
      "[Epoch 5/50] [Batch 105/235] [D loss: 1.155965, acc: 76.56%] [G loss: 1.386395]\n",
      "[Epoch 5/50] [Batch 106/235] [D loss: 1.159181, acc: 72.27%] [G loss: 1.302475]\n",
      "[Epoch 5/50] [Batch 107/235] [D loss: 1.171279, acc: 73.63%] [G loss: 1.415367]\n",
      "[Epoch 5/50] [Batch 108/235] [D loss: 1.098521, acc: 74.22%] [G loss: 1.322016]\n",
      "[Epoch 5/50] [Batch 109/235] [D loss: 1.136485, acc: 75.39%] [G loss: 1.248178]\n",
      "[Epoch 5/50] [Batch 110/235] [D loss: 1.143137, acc: 74.41%] [G loss: 1.314963]\n",
      "[Epoch 5/50] [Batch 111/235] [D loss: 1.130615, acc: 76.95%] [G loss: 1.327724]\n",
      "[Epoch 5/50] [Batch 112/235] [D loss: 1.164500, acc: 76.37%] [G loss: 1.227980]\n",
      "[Epoch 5/50] [Batch 113/235] [D loss: 1.150074, acc: 75.98%] [G loss: 1.216231]\n",
      "[Epoch 5/50] [Batch 114/235] [D loss: 1.155678, acc: 77.93%] [G loss: 1.381986]\n",
      "[Epoch 5/50] [Batch 115/235] [D loss: 1.153491, acc: 75.39%] [G loss: 1.292141]\n",
      "[Epoch 5/50] [Batch 116/235] [D loss: 1.152569, acc: 75.20%] [G loss: 1.259037]\n",
      "[Epoch 5/50] [Batch 117/235] [D loss: 1.150488, acc: 73.05%] [G loss: 1.293087]\n",
      "[Epoch 5/50] [Batch 118/235] [D loss: 1.165642, acc: 74.02%] [G loss: 1.277530]\n",
      "[Epoch 5/50] [Batch 119/235] [D loss: 1.123008, acc: 74.80%] [G loss: 1.363485]\n",
      "[Epoch 5/50] [Batch 120/235] [D loss: 1.135994, acc: 75.00%] [G loss: 1.181072]\n",
      "[Epoch 5/50] [Batch 121/235] [D loss: 1.157184, acc: 78.91%] [G loss: 1.250953]\n",
      "[Epoch 5/50] [Batch 122/235] [D loss: 1.133260, acc: 74.41%] [G loss: 1.383238]\n",
      "[Epoch 5/50] [Batch 123/235] [D loss: 1.132421, acc: 74.22%] [G loss: 1.274509]\n",
      "[Epoch 5/50] [Batch 124/235] [D loss: 1.138660, acc: 80.86%] [G loss: 1.350854]\n",
      "[Epoch 5/50] [Batch 125/235] [D loss: 1.154411, acc: 71.88%] [G loss: 1.340450]\n",
      "[Epoch 5/50] [Batch 126/235] [D loss: 1.136485, acc: 75.98%] [G loss: 1.170378]\n",
      "[Epoch 5/50] [Batch 127/235] [D loss: 1.158732, acc: 75.00%] [G loss: 1.240334]\n",
      "[Epoch 5/50] [Batch 128/235] [D loss: 1.148582, acc: 75.59%] [G loss: 1.369313]\n",
      "[Epoch 5/50] [Batch 129/235] [D loss: 1.117965, acc: 76.17%] [G loss: 1.292262]\n",
      "[Epoch 5/50] [Batch 130/235] [D loss: 1.148915, acc: 76.56%] [G loss: 1.281486]\n",
      "[Epoch 5/50] [Batch 131/235] [D loss: 1.149344, acc: 76.95%] [G loss: 1.430642]\n",
      "[Epoch 5/50] [Batch 132/235] [D loss: 1.130353, acc: 77.34%] [G loss: 1.339260]\n",
      "[Epoch 5/50] [Batch 133/235] [D loss: 1.138638, acc: 75.59%] [G loss: 1.235467]\n",
      "[Epoch 5/50] [Batch 134/235] [D loss: 1.189051, acc: 74.61%] [G loss: 1.218895]\n",
      "[Epoch 5/50] [Batch 135/235] [D loss: 1.133726, acc: 75.78%] [G loss: 1.443824]\n",
      "[Epoch 5/50] [Batch 136/235] [D loss: 1.161044, acc: 73.44%] [G loss: 1.275546]\n",
      "[Epoch 5/50] [Batch 137/235] [D loss: 1.139109, acc: 75.59%] [G loss: 1.251906]\n",
      "[Epoch 5/50] [Batch 138/235] [D loss: 1.203644, acc: 71.09%] [G loss: 1.277582]\n",
      "[Epoch 5/50] [Batch 139/235] [D loss: 1.157001, acc: 73.24%] [G loss: 1.363815]\n",
      "[Epoch 5/50] [Batch 140/235] [D loss: 1.160844, acc: 73.83%] [G loss: 1.306304]\n",
      "[Epoch 5/50] [Batch 141/235] [D loss: 1.151935, acc: 76.95%] [G loss: 1.239313]\n",
      "[Epoch 5/50] [Batch 142/235] [D loss: 1.168241, acc: 75.00%] [G loss: 1.347445]\n",
      "[Epoch 5/50] [Batch 143/235] [D loss: 1.135095, acc: 73.44%] [G loss: 1.281158]\n",
      "[Epoch 5/50] [Batch 144/235] [D loss: 1.177361, acc: 74.61%] [G loss: 1.301076]\n",
      "[Epoch 5/50] [Batch 145/235] [D loss: 1.144604, acc: 74.41%] [G loss: 1.258782]\n",
      "[Epoch 5/50] [Batch 146/235] [D loss: 1.170596, acc: 78.32%] [G loss: 1.194920]\n",
      "[Epoch 5/50] [Batch 147/235] [D loss: 1.153980, acc: 71.29%] [G loss: 1.306674]\n",
      "[Epoch 5/50] [Batch 148/235] [D loss: 1.167833, acc: 72.66%] [G loss: 1.325671]\n",
      "[Epoch 5/50] [Batch 149/235] [D loss: 1.181321, acc: 75.00%] [G loss: 1.196468]\n",
      "[Epoch 5/50] [Batch 150/235] [D loss: 1.136151, acc: 76.95%] [G loss: 1.256700]\n",
      "[Epoch 5/50] [Batch 151/235] [D loss: 1.160350, acc: 75.20%] [G loss: 1.245379]\n",
      "[Epoch 5/50] [Batch 152/235] [D loss: 1.153780, acc: 75.20%] [G loss: 1.283628]\n",
      "[Epoch 5/50] [Batch 153/235] [D loss: 1.121822, acc: 75.20%] [G loss: 1.363755]\n",
      "[Epoch 5/50] [Batch 154/235] [D loss: 1.148295, acc: 75.59%] [G loss: 1.275120]\n",
      "[Epoch 5/50] [Batch 155/235] [D loss: 1.173702, acc: 75.39%] [G loss: 1.323432]\n",
      "[Epoch 5/50] [Batch 156/235] [D loss: 1.143263, acc: 74.80%] [G loss: 1.291448]\n",
      "[Epoch 5/50] [Batch 157/235] [D loss: 1.139222, acc: 73.24%] [G loss: 1.390419]\n",
      "[Epoch 5/50] [Batch 158/235] [D loss: 1.137385, acc: 76.76%] [G loss: 1.274489]\n",
      "[Epoch 5/50] [Batch 159/235] [D loss: 1.174113, acc: 74.02%] [G loss: 1.230145]\n",
      "[Epoch 5/50] [Batch 160/235] [D loss: 1.153920, acc: 75.59%] [G loss: 1.287736]\n",
      "[Epoch 5/50] [Batch 161/235] [D loss: 1.139960, acc: 74.22%] [G loss: 1.237638]\n",
      "[Epoch 5/50] [Batch 162/235] [D loss: 1.173213, acc: 77.54%] [G loss: 1.199478]\n",
      "[Epoch 5/50] [Batch 163/235] [D loss: 1.143165, acc: 77.34%] [G loss: 1.276366]\n",
      "[Epoch 5/50] [Batch 164/235] [D loss: 1.136224, acc: 74.61%] [G loss: 1.243189]\n",
      "[Epoch 5/50] [Batch 165/235] [D loss: 1.133373, acc: 75.59%] [G loss: 1.278554]\n",
      "[Epoch 5/50] [Batch 166/235] [D loss: 1.180046, acc: 75.20%] [G loss: 1.248749]\n",
      "[Epoch 5/50] [Batch 167/235] [D loss: 1.143533, acc: 73.05%] [G loss: 1.216124]\n",
      "[Epoch 5/50] [Batch 168/235] [D loss: 1.146667, acc: 76.17%] [G loss: 1.228146]\n",
      "[Epoch 5/50] [Batch 169/235] [D loss: 1.155847, acc: 76.37%] [G loss: 1.373757]\n",
      "[Epoch 5/50] [Batch 170/235] [D loss: 1.125159, acc: 74.41%] [G loss: 1.307593]\n",
      "[Epoch 5/50] [Batch 171/235] [D loss: 1.186277, acc: 71.88%] [G loss: 1.338779]\n",
      "[Epoch 5/50] [Batch 172/235] [D loss: 1.145725, acc: 76.17%] [G loss: 1.299931]\n",
      "[Epoch 5/50] [Batch 173/235] [D loss: 1.134242, acc: 76.37%] [G loss: 1.293064]\n",
      "[Epoch 5/50] [Batch 174/235] [D loss: 1.114680, acc: 75.39%] [G loss: 1.263047]\n",
      "[Epoch 5/50] [Batch 175/235] [D loss: 1.172942, acc: 71.48%] [G loss: 1.263640]\n",
      "[Epoch 5/50] [Batch 176/235] [D loss: 1.145987, acc: 75.00%] [G loss: 1.243796]\n",
      "[Epoch 5/50] [Batch 177/235] [D loss: 1.132705, acc: 75.20%] [G loss: 1.341745]\n",
      "[Epoch 5/50] [Batch 178/235] [D loss: 1.132170, acc: 78.12%] [G loss: 1.244589]\n",
      "[Epoch 5/50] [Batch 179/235] [D loss: 1.142908, acc: 76.17%] [G loss: 1.300563]\n",
      "[Epoch 5/50] [Batch 180/235] [D loss: 1.131822, acc: 73.05%] [G loss: 1.286301]\n",
      "[Epoch 5/50] [Batch 181/235] [D loss: 1.169279, acc: 77.34%] [G loss: 1.264088]\n",
      "[Epoch 5/50] [Batch 182/235] [D loss: 1.130571, acc: 80.08%] [G loss: 1.384549]\n",
      "[Epoch 5/50] [Batch 183/235] [D loss: 1.169282, acc: 74.22%] [G loss: 1.359869]\n",
      "[Epoch 5/50] [Batch 184/235] [D loss: 1.098130, acc: 77.15%] [G loss: 1.276467]\n",
      "[Epoch 5/50] [Batch 185/235] [D loss: 1.122561, acc: 75.39%] [G loss: 1.354602]\n",
      "[Epoch 5/50] [Batch 186/235] [D loss: 1.135910, acc: 73.44%] [G loss: 1.415986]\n",
      "[Epoch 5/50] [Batch 187/235] [D loss: 1.127486, acc: 77.93%] [G loss: 1.256011]\n",
      "[Epoch 5/50] [Batch 188/235] [D loss: 1.144034, acc: 78.12%] [G loss: 1.340240]\n",
      "[Epoch 5/50] [Batch 189/235] [D loss: 1.174836, acc: 74.41%] [G loss: 1.234263]\n",
      "[Epoch 5/50] [Batch 190/235] [D loss: 1.163535, acc: 75.98%] [G loss: 1.376763]\n",
      "[Epoch 5/50] [Batch 191/235] [D loss: 1.110114, acc: 76.56%] [G loss: 1.309337]\n",
      "[Epoch 5/50] [Batch 192/235] [D loss: 1.158074, acc: 75.59%] [G loss: 1.201737]\n",
      "[Epoch 5/50] [Batch 193/235] [D loss: 1.114903, acc: 77.34%] [G loss: 1.342943]\n",
      "[Epoch 5/50] [Batch 194/235] [D loss: 1.154687, acc: 75.20%] [G loss: 1.346837]\n",
      "[Epoch 5/50] [Batch 195/235] [D loss: 1.167038, acc: 75.59%] [G loss: 1.187186]\n",
      "[Epoch 5/50] [Batch 196/235] [D loss: 1.170128, acc: 74.41%] [G loss: 1.214530]\n",
      "[Epoch 5/50] [Batch 197/235] [D loss: 1.101911, acc: 78.91%] [G loss: 1.372157]\n",
      "[Epoch 5/50] [Batch 198/235] [D loss: 1.170412, acc: 72.66%] [G loss: 1.308278]\n",
      "[Epoch 5/50] [Batch 199/235] [D loss: 1.130269, acc: 77.34%] [G loss: 1.244374]\n",
      "[Epoch 5/50] [Batch 200/235] [D loss: 1.119941, acc: 77.34%] [G loss: 1.255210]\n",
      "[Epoch 5/50] [Batch 201/235] [D loss: 1.170786, acc: 76.37%] [G loss: 1.275788]\n",
      "[Epoch 5/50] [Batch 202/235] [D loss: 1.117474, acc: 76.76%] [G loss: 1.303501]\n",
      "[Epoch 5/50] [Batch 203/235] [D loss: 1.141514, acc: 76.17%] [G loss: 1.327485]\n",
      "[Epoch 5/50] [Batch 204/235] [D loss: 1.166484, acc: 77.54%] [G loss: 1.196664]\n",
      "[Epoch 5/50] [Batch 205/235] [D loss: 1.101604, acc: 79.88%] [G loss: 1.389395]\n",
      "[Epoch 5/50] [Batch 206/235] [D loss: 1.128342, acc: 73.63%] [G loss: 1.348168]\n",
      "[Epoch 5/50] [Batch 207/235] [D loss: 1.164688, acc: 72.66%] [G loss: 1.282586]\n",
      "[Epoch 5/50] [Batch 208/235] [D loss: 1.128709, acc: 78.71%] [G loss: 1.326888]\n",
      "[Epoch 5/50] [Batch 209/235] [D loss: 1.140719, acc: 77.15%] [G loss: 1.292213]\n",
      "[Epoch 5/50] [Batch 210/235] [D loss: 1.118197, acc: 76.37%] [G loss: 1.319011]\n",
      "[Epoch 5/50] [Batch 211/235] [D loss: 1.115721, acc: 73.24%] [G loss: 1.328840]\n",
      "[Epoch 5/50] [Batch 212/235] [D loss: 1.156423, acc: 73.83%] [G loss: 1.330620]\n",
      "[Epoch 5/50] [Batch 213/235] [D loss: 1.148020, acc: 75.98%] [G loss: 1.290534]\n",
      "[Epoch 5/50] [Batch 214/235] [D loss: 1.140644, acc: 74.22%] [G loss: 1.296958]\n",
      "[Epoch 5/50] [Batch 215/235] [D loss: 1.185429, acc: 73.63%] [G loss: 1.284547]\n",
      "[Epoch 5/50] [Batch 216/235] [D loss: 1.174985, acc: 76.76%] [G loss: 1.215817]\n",
      "[Epoch 5/50] [Batch 217/235] [D loss: 1.116847, acc: 76.56%] [G loss: 1.451898]\n",
      "[Epoch 5/50] [Batch 218/235] [D loss: 1.154954, acc: 75.59%] [G loss: 1.292386]\n",
      "[Epoch 5/50] [Batch 219/235] [D loss: 1.128591, acc: 79.10%] [G loss: 1.216444]\n",
      "[Epoch 5/50] [Batch 220/235] [D loss: 1.185146, acc: 75.98%] [G loss: 1.262421]\n",
      "[Epoch 5/50] [Batch 221/235] [D loss: 1.141183, acc: 74.22%] [G loss: 1.363542]\n",
      "[Epoch 5/50] [Batch 222/235] [D loss: 1.167585, acc: 74.22%] [G loss: 1.341165]\n",
      "[Epoch 5/50] [Batch 223/235] [D loss: 1.109697, acc: 78.32%] [G loss: 1.381108]\n",
      "[Epoch 5/50] [Batch 224/235] [D loss: 1.147284, acc: 75.20%] [G loss: 1.224325]\n",
      "[Epoch 5/50] [Batch 225/235] [D loss: 1.134120, acc: 75.00%] [G loss: 1.296920]\n",
      "[Epoch 5/50] [Batch 226/235] [D loss: 1.156152, acc: 75.20%] [G loss: 1.385671]\n",
      "[Epoch 5/50] [Batch 227/235] [D loss: 1.153722, acc: 74.02%] [G loss: 1.242513]\n",
      "[Epoch 5/50] [Batch 228/235] [D loss: 1.127760, acc: 77.15%] [G loss: 1.323897]\n",
      "[Epoch 5/50] [Batch 229/235] [D loss: 1.143307, acc: 75.98%] [G loss: 1.321098]\n",
      "[Epoch 5/50] [Batch 230/235] [D loss: 1.160946, acc: 75.20%] [G loss: 1.279952]\n",
      "[Epoch 5/50] [Batch 231/235] [D loss: 1.121686, acc: 76.17%] [G loss: 1.364920]\n",
      "[Epoch 5/50] [Batch 232/235] [D loss: 1.199836, acc: 75.20%] [G loss: 1.271899]\n",
      "[Epoch 5/50] [Batch 233/235] [D loss: 1.146691, acc: 76.17%] [G loss: 1.337643]\n",
      "[Epoch 5/50] [Batch 234/235] [D loss: 1.153812, acc: 79.69%] [G loss: 1.180996]\n",
      "[Epoch 6/50] [Batch 0/235] [D loss: 1.100908, acc: 76.37%] [G loss: 1.350732]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/50] [Batch 1/235] [D loss: 1.128369, acc: 80.08%] [G loss: 1.226777]\n",
      "[Epoch 6/50] [Batch 2/235] [D loss: 1.143033, acc: 75.98%] [G loss: 1.368346]\n",
      "[Epoch 6/50] [Batch 3/235] [D loss: 1.155257, acc: 76.37%] [G loss: 1.372810]\n",
      "[Epoch 6/50] [Batch 4/235] [D loss: 1.131243, acc: 75.78%] [G loss: 1.307586]\n",
      "[Epoch 6/50] [Batch 5/235] [D loss: 1.148369, acc: 74.41%] [G loss: 1.303523]\n",
      "[Epoch 6/50] [Batch 6/235] [D loss: 1.145789, acc: 75.39%] [G loss: 1.280464]\n",
      "[Epoch 6/50] [Batch 7/235] [D loss: 1.162983, acc: 71.88%] [G loss: 1.505076]\n",
      "[Epoch 6/50] [Batch 8/235] [D loss: 1.192515, acc: 73.83%] [G loss: 1.304017]\n",
      "[Epoch 6/50] [Batch 9/235] [D loss: 1.101310, acc: 74.61%] [G loss: 1.337119]\n",
      "[Epoch 6/50] [Batch 10/235] [D loss: 1.116386, acc: 76.76%] [G loss: 1.278239]\n",
      "[Epoch 6/50] [Batch 11/235] [D loss: 1.161969, acc: 77.34%] [G loss: 1.378471]\n",
      "[Epoch 6/50] [Batch 12/235] [D loss: 1.161112, acc: 77.34%] [G loss: 1.348331]\n",
      "[Epoch 6/50] [Batch 13/235] [D loss: 1.147107, acc: 74.80%] [G loss: 1.229568]\n",
      "[Epoch 6/50] [Batch 14/235] [D loss: 1.138608, acc: 75.20%] [G loss: 1.224648]\n",
      "[Epoch 6/50] [Batch 15/235] [D loss: 1.131103, acc: 78.71%] [G loss: 1.286276]\n",
      "[Epoch 6/50] [Batch 16/235] [D loss: 1.157802, acc: 73.24%] [G loss: 1.321194]\n",
      "[Epoch 6/50] [Batch 17/235] [D loss: 1.140740, acc: 77.54%] [G loss: 1.308830]\n",
      "[Epoch 6/50] [Batch 18/235] [D loss: 1.124423, acc: 74.80%] [G loss: 1.242611]\n",
      "[Epoch 6/50] [Batch 19/235] [D loss: 1.145219, acc: 75.78%] [G loss: 1.353452]\n",
      "[Epoch 6/50] [Batch 20/235] [D loss: 1.154634, acc: 73.44%] [G loss: 1.296595]\n",
      "[Epoch 6/50] [Batch 21/235] [D loss: 1.155776, acc: 73.44%] [G loss: 1.280418]\n",
      "[Epoch 6/50] [Batch 22/235] [D loss: 1.107052, acc: 79.10%] [G loss: 1.339480]\n",
      "[Epoch 6/50] [Batch 23/235] [D loss: 1.135362, acc: 78.52%] [G loss: 1.323016]\n",
      "[Epoch 6/50] [Batch 24/235] [D loss: 1.161230, acc: 76.37%] [G loss: 1.320286]\n",
      "[Epoch 6/50] [Batch 25/235] [D loss: 1.126799, acc: 74.22%] [G loss: 1.334437]\n",
      "[Epoch 6/50] [Batch 26/235] [D loss: 1.119967, acc: 77.15%] [G loss: 1.344611]\n",
      "[Epoch 6/50] [Batch 27/235] [D loss: 1.144128, acc: 77.34%] [G loss: 1.305398]\n",
      "[Epoch 6/50] [Batch 28/235] [D loss: 1.166055, acc: 74.41%] [G loss: 1.251230]\n",
      "[Epoch 6/50] [Batch 29/235] [D loss: 1.158572, acc: 76.95%] [G loss: 1.288164]\n",
      "[Epoch 6/50] [Batch 30/235] [D loss: 1.215619, acc: 74.41%] [G loss: 1.296843]\n",
      "[Epoch 6/50] [Batch 31/235] [D loss: 1.143440, acc: 75.20%] [G loss: 1.330031]\n",
      "[Epoch 6/50] [Batch 32/235] [D loss: 1.126265, acc: 78.52%] [G loss: 1.336142]\n",
      "[Epoch 6/50] [Batch 33/235] [D loss: 1.168266, acc: 74.02%] [G loss: 1.269697]\n",
      "[Epoch 6/50] [Batch 34/235] [D loss: 1.167567, acc: 75.20%] [G loss: 1.330926]\n",
      "[Epoch 6/50] [Batch 35/235] [D loss: 1.126377, acc: 78.52%] [G loss: 1.328770]\n",
      "[Epoch 6/50] [Batch 36/235] [D loss: 1.140095, acc: 75.20%] [G loss: 1.226164]\n",
      "[Epoch 6/50] [Batch 37/235] [D loss: 1.152085, acc: 76.95%] [G loss: 1.327347]\n",
      "[Epoch 6/50] [Batch 38/235] [D loss: 1.133591, acc: 74.61%] [G loss: 1.365063]\n",
      "[Epoch 6/50] [Batch 39/235] [D loss: 1.141036, acc: 75.78%] [G loss: 1.342040]\n",
      "[Epoch 6/50] [Batch 40/235] [D loss: 1.152060, acc: 71.88%] [G loss: 1.323400]\n",
      "[Epoch 6/50] [Batch 41/235] [D loss: 1.132154, acc: 74.22%] [G loss: 1.279305]\n",
      "[Epoch 6/50] [Batch 42/235] [D loss: 1.096237, acc: 77.54%] [G loss: 1.394523]\n",
      "[Epoch 6/50] [Batch 43/235] [D loss: 1.129225, acc: 76.37%] [G loss: 1.281973]\n",
      "[Epoch 6/50] [Batch 44/235] [D loss: 1.153972, acc: 76.17%] [G loss: 1.190891]\n",
      "[Epoch 6/50] [Batch 45/235] [D loss: 1.150650, acc: 77.54%] [G loss: 1.389297]\n",
      "[Epoch 6/50] [Batch 46/235] [D loss: 1.172263, acc: 72.85%] [G loss: 1.225094]\n",
      "[Epoch 6/50] [Batch 47/235] [D loss: 1.129505, acc: 75.00%] [G loss: 1.261514]\n",
      "[Epoch 6/50] [Batch 48/235] [D loss: 1.167182, acc: 72.46%] [G loss: 1.343472]\n",
      "[Epoch 6/50] [Batch 49/235] [D loss: 1.143755, acc: 76.17%] [G loss: 1.265268]\n",
      "[Epoch 6/50] [Batch 50/235] [D loss: 1.157077, acc: 75.20%] [G loss: 1.299034]\n",
      "[Epoch 6/50] [Batch 51/235] [D loss: 1.148329, acc: 75.98%] [G loss: 1.259873]\n",
      "[Epoch 6/50] [Batch 52/235] [D loss: 1.124675, acc: 76.17%] [G loss: 1.336928]\n",
      "[Epoch 6/50] [Batch 53/235] [D loss: 1.135803, acc: 75.39%] [G loss: 1.300048]\n",
      "[Epoch 6/50] [Batch 54/235] [D loss: 1.153502, acc: 74.02%] [G loss: 1.296530]\n",
      "[Epoch 6/50] [Batch 55/235] [D loss: 1.161303, acc: 75.39%] [G loss: 1.346681]\n",
      "[Epoch 6/50] [Batch 56/235] [D loss: 1.131264, acc: 78.12%] [G loss: 1.293730]\n",
      "[Epoch 6/50] [Batch 57/235] [D loss: 1.118043, acc: 76.17%] [G loss: 1.332544]\n",
      "[Epoch 6/50] [Batch 58/235] [D loss: 1.096169, acc: 76.37%] [G loss: 1.294071]\n",
      "[Epoch 6/50] [Batch 59/235] [D loss: 1.145092, acc: 76.95%] [G loss: 1.292461]\n",
      "[Epoch 6/50] [Batch 60/235] [D loss: 1.155164, acc: 77.73%] [G loss: 1.323016]\n",
      "[Epoch 6/50] [Batch 61/235] [D loss: 1.171122, acc: 74.61%] [G loss: 1.158862]\n",
      "[Epoch 6/50] [Batch 62/235] [D loss: 1.160880, acc: 77.54%] [G loss: 1.393962]\n",
      "[Epoch 6/50] [Batch 63/235] [D loss: 1.153011, acc: 77.54%] [G loss: 1.221666]\n",
      "[Epoch 6/50] [Batch 64/235] [D loss: 1.170953, acc: 77.93%] [G loss: 1.190875]\n",
      "[Epoch 6/50] [Batch 65/235] [D loss: 1.167893, acc: 74.22%] [G loss: 1.386627]\n",
      "[Epoch 6/50] [Batch 66/235] [D loss: 1.134676, acc: 73.83%] [G loss: 1.282343]\n",
      "[Epoch 6/50] [Batch 67/235] [D loss: 1.162912, acc: 75.00%] [G loss: 1.261505]\n",
      "[Epoch 6/50] [Batch 68/235] [D loss: 1.151441, acc: 77.93%] [G loss: 1.387753]\n",
      "[Epoch 6/50] [Batch 69/235] [D loss: 1.140469, acc: 75.98%] [G loss: 1.228812]\n",
      "[Epoch 6/50] [Batch 70/235] [D loss: 1.133269, acc: 75.20%] [G loss: 1.248232]\n",
      "[Epoch 6/50] [Batch 71/235] [D loss: 1.166776, acc: 74.41%] [G loss: 1.219785]\n",
      "[Epoch 6/50] [Batch 72/235] [D loss: 1.185242, acc: 74.02%] [G loss: 1.335709]\n",
      "[Epoch 6/50] [Batch 73/235] [D loss: 1.154286, acc: 76.95%] [G loss: 1.248737]\n",
      "[Epoch 6/50] [Batch 74/235] [D loss: 1.144691, acc: 75.59%] [G loss: 1.343307]\n",
      "[Epoch 6/50] [Batch 75/235] [D loss: 1.154106, acc: 77.15%] [G loss: 1.351650]\n",
      "[Epoch 6/50] [Batch 76/235] [D loss: 1.142406, acc: 77.93%] [G loss: 1.274693]\n",
      "[Epoch 6/50] [Batch 77/235] [D loss: 1.161678, acc: 76.37%] [G loss: 1.209734]\n",
      "[Epoch 6/50] [Batch 78/235] [D loss: 1.146808, acc: 75.78%] [G loss: 1.379919]\n",
      "[Epoch 6/50] [Batch 79/235] [D loss: 1.152165, acc: 77.93%] [G loss: 1.250000]\n",
      "[Epoch 6/50] [Batch 80/235] [D loss: 1.121430, acc: 77.54%] [G loss: 1.290705]\n",
      "[Epoch 6/50] [Batch 81/235] [D loss: 1.174493, acc: 75.59%] [G loss: 1.302732]\n",
      "[Epoch 6/50] [Batch 82/235] [D loss: 1.155645, acc: 74.22%] [G loss: 1.332192]\n",
      "[Epoch 6/50] [Batch 83/235] [D loss: 1.140682, acc: 77.15%] [G loss: 1.271129]\n",
      "[Epoch 6/50] [Batch 84/235] [D loss: 1.140130, acc: 76.95%] [G loss: 1.254829]\n",
      "[Epoch 6/50] [Batch 85/235] [D loss: 1.148266, acc: 75.00%] [G loss: 1.342027]\n",
      "[Epoch 6/50] [Batch 86/235] [D loss: 1.144278, acc: 74.22%] [G loss: 1.212107]\n",
      "[Epoch 6/50] [Batch 87/235] [D loss: 1.137744, acc: 77.93%] [G loss: 1.305837]\n",
      "[Epoch 6/50] [Batch 88/235] [D loss: 1.140495, acc: 76.37%] [G loss: 1.328243]\n",
      "[Epoch 6/50] [Batch 89/235] [D loss: 1.194510, acc: 73.44%] [G loss: 1.277185]\n",
      "[Epoch 6/50] [Batch 90/235] [D loss: 1.102283, acc: 78.71%] [G loss: 1.393737]\n",
      "[Epoch 6/50] [Batch 91/235] [D loss: 1.146501, acc: 75.78%] [G loss: 1.221795]\n",
      "[Epoch 6/50] [Batch 92/235] [D loss: 1.147467, acc: 75.98%] [G loss: 1.250767]\n",
      "[Epoch 6/50] [Batch 93/235] [D loss: 1.162745, acc: 74.61%] [G loss: 1.325196]\n",
      "[Epoch 6/50] [Batch 94/235] [D loss: 1.134215, acc: 74.02%] [G loss: 1.348079]\n",
      "[Epoch 6/50] [Batch 95/235] [D loss: 1.122569, acc: 78.32%] [G loss: 1.214391]\n",
      "[Epoch 6/50] [Batch 96/235] [D loss: 1.124581, acc: 74.80%] [G loss: 1.303860]\n",
      "[Epoch 6/50] [Batch 97/235] [D loss: 1.165422, acc: 74.61%] [G loss: 1.266726]\n",
      "[Epoch 6/50] [Batch 98/235] [D loss: 1.152575, acc: 79.30%] [G loss: 1.218551]\n",
      "[Epoch 6/50] [Batch 99/235] [D loss: 1.155935, acc: 76.76%] [G loss: 1.353109]\n",
      "[Epoch 6/50] [Batch 100/235] [D loss: 1.139866, acc: 77.15%] [G loss: 1.230871]\n",
      "[Epoch 6/50] [Batch 101/235] [D loss: 1.111867, acc: 73.83%] [G loss: 1.394636]\n",
      "[Epoch 6/50] [Batch 102/235] [D loss: 1.153138, acc: 75.00%] [G loss: 1.253037]\n",
      "[Epoch 6/50] [Batch 103/235] [D loss: 1.092548, acc: 77.34%] [G loss: 1.276060]\n",
      "[Epoch 6/50] [Batch 104/235] [D loss: 1.167561, acc: 79.88%] [G loss: 1.362829]\n",
      "[Epoch 6/50] [Batch 105/235] [D loss: 1.112508, acc: 74.22%] [G loss: 1.349855]\n",
      "[Epoch 6/50] [Batch 106/235] [D loss: 1.157242, acc: 76.17%] [G loss: 1.385740]\n",
      "[Epoch 6/50] [Batch 107/235] [D loss: 1.135849, acc: 75.00%] [G loss: 1.508655]\n",
      "[Epoch 6/50] [Batch 108/235] [D loss: 1.123971, acc: 77.34%] [G loss: 1.170227]\n",
      "[Epoch 6/50] [Batch 109/235] [D loss: 1.162713, acc: 75.78%] [G loss: 1.250485]\n",
      "[Epoch 6/50] [Batch 110/235] [D loss: 1.124371, acc: 80.66%] [G loss: 1.255986]\n",
      "[Epoch 6/50] [Batch 111/235] [D loss: 1.137746, acc: 75.00%] [G loss: 1.282331]\n",
      "[Epoch 6/50] [Batch 112/235] [D loss: 1.149887, acc: 75.59%] [G loss: 1.208236]\n",
      "[Epoch 6/50] [Batch 113/235] [D loss: 1.140900, acc: 79.30%] [G loss: 1.258242]\n",
      "[Epoch 6/50] [Batch 114/235] [D loss: 1.175341, acc: 75.78%] [G loss: 1.337653]\n",
      "[Epoch 6/50] [Batch 115/235] [D loss: 1.147759, acc: 75.78%] [G loss: 1.293513]\n",
      "[Epoch 6/50] [Batch 116/235] [D loss: 1.159446, acc: 75.20%] [G loss: 1.362520]\n",
      "[Epoch 6/50] [Batch 117/235] [D loss: 1.161219, acc: 75.39%] [G loss: 1.215135]\n",
      "[Epoch 6/50] [Batch 118/235] [D loss: 1.147308, acc: 76.17%] [G loss: 1.265146]\n",
      "[Epoch 6/50] [Batch 119/235] [D loss: 1.116767, acc: 77.34%] [G loss: 1.309774]\n",
      "[Epoch 6/50] [Batch 120/235] [D loss: 1.132296, acc: 77.73%] [G loss: 1.363348]\n",
      "[Epoch 6/50] [Batch 121/235] [D loss: 1.139522, acc: 77.93%] [G loss: 1.213784]\n",
      "[Epoch 6/50] [Batch 122/235] [D loss: 1.137047, acc: 73.83%] [G loss: 1.238122]\n",
      "[Epoch 6/50] [Batch 123/235] [D loss: 1.159674, acc: 72.66%] [G loss: 1.264409]\n",
      "[Epoch 6/50] [Batch 124/235] [D loss: 1.160939, acc: 74.61%] [G loss: 1.267465]\n",
      "[Epoch 6/50] [Batch 125/235] [D loss: 1.193663, acc: 77.54%] [G loss: 1.227963]\n",
      "[Epoch 6/50] [Batch 126/235] [D loss: 1.102916, acc: 80.08%] [G loss: 1.255580]\n",
      "[Epoch 6/50] [Batch 127/235] [D loss: 1.111029, acc: 78.32%] [G loss: 1.208419]\n",
      "[Epoch 6/50] [Batch 128/235] [D loss: 1.134923, acc: 75.39%] [G loss: 1.352191]\n",
      "[Epoch 6/50] [Batch 129/235] [D loss: 1.181627, acc: 73.44%] [G loss: 1.267962]\n",
      "[Epoch 6/50] [Batch 130/235] [D loss: 1.138112, acc: 79.88%] [G loss: 1.204792]\n",
      "[Epoch 6/50] [Batch 131/235] [D loss: 1.153856, acc: 80.66%] [G loss: 1.299448]\n",
      "[Epoch 6/50] [Batch 132/235] [D loss: 1.127213, acc: 77.15%] [G loss: 1.353776]\n",
      "[Epoch 6/50] [Batch 133/235] [D loss: 1.150329, acc: 76.76%] [G loss: 1.305480]\n",
      "[Epoch 6/50] [Batch 134/235] [D loss: 1.163633, acc: 74.61%] [G loss: 1.230566]\n",
      "[Epoch 6/50] [Batch 135/235] [D loss: 1.127423, acc: 78.32%] [G loss: 1.346424]\n",
      "[Epoch 6/50] [Batch 136/235] [D loss: 1.103163, acc: 77.34%] [G loss: 1.286251]\n",
      "[Epoch 6/50] [Batch 137/235] [D loss: 1.154400, acc: 73.24%] [G loss: 1.305519]\n",
      "[Epoch 6/50] [Batch 138/235] [D loss: 1.113959, acc: 77.15%] [G loss: 1.320720]\n",
      "[Epoch 6/50] [Batch 139/235] [D loss: 1.141211, acc: 75.20%] [G loss: 1.353856]\n",
      "[Epoch 6/50] [Batch 140/235] [D loss: 1.139313, acc: 76.56%] [G loss: 1.227562]\n",
      "[Epoch 6/50] [Batch 141/235] [D loss: 1.150808, acc: 73.83%] [G loss: 1.380755]\n",
      "[Epoch 6/50] [Batch 142/235] [D loss: 1.138339, acc: 76.17%] [G loss: 1.270177]\n",
      "[Epoch 6/50] [Batch 143/235] [D loss: 1.130176, acc: 70.70%] [G loss: 1.253871]\n",
      "[Epoch 6/50] [Batch 144/235] [D loss: 1.150474, acc: 76.17%] [G loss: 1.246399]\n",
      "[Epoch 6/50] [Batch 145/235] [D loss: 1.168558, acc: 74.41%] [G loss: 1.350914]\n",
      "[Epoch 6/50] [Batch 146/235] [D loss: 1.194868, acc: 74.80%] [G loss: 1.277225]\n",
      "[Epoch 6/50] [Batch 147/235] [D loss: 1.167651, acc: 75.39%] [G loss: 1.319031]\n",
      "[Epoch 6/50] [Batch 148/235] [D loss: 1.153109, acc: 73.44%] [G loss: 1.386998]\n",
      "[Epoch 6/50] [Batch 149/235] [D loss: 1.153585, acc: 74.02%] [G loss: 1.282757]\n",
      "[Epoch 6/50] [Batch 150/235] [D loss: 1.145337, acc: 75.20%] [G loss: 1.306314]\n",
      "[Epoch 6/50] [Batch 151/235] [D loss: 1.127161, acc: 76.56%] [G loss: 1.320385]\n",
      "[Epoch 6/50] [Batch 152/235] [D loss: 1.112062, acc: 78.71%] [G loss: 1.451456]\n",
      "[Epoch 6/50] [Batch 153/235] [D loss: 1.115042, acc: 77.54%] [G loss: 1.365417]\n",
      "[Epoch 6/50] [Batch 154/235] [D loss: 1.154799, acc: 72.66%] [G loss: 1.342991]\n",
      "[Epoch 6/50] [Batch 155/235] [D loss: 1.163373, acc: 75.39%] [G loss: 1.203460]\n",
      "[Epoch 6/50] [Batch 156/235] [D loss: 1.147454, acc: 76.95%] [G loss: 1.453576]\n",
      "[Epoch 6/50] [Batch 157/235] [D loss: 1.154007, acc: 75.78%] [G loss: 1.278247]\n",
      "[Epoch 6/50] [Batch 158/235] [D loss: 1.134287, acc: 77.54%] [G loss: 1.202674]\n",
      "[Epoch 6/50] [Batch 159/235] [D loss: 1.107162, acc: 77.15%] [G loss: 1.355421]\n",
      "[Epoch 6/50] [Batch 160/235] [D loss: 1.174807, acc: 75.39%] [G loss: 1.351541]\n",
      "[Epoch 6/50] [Batch 161/235] [D loss: 1.133458, acc: 74.61%] [G loss: 1.376106]\n",
      "[Epoch 6/50] [Batch 162/235] [D loss: 1.077322, acc: 76.76%] [G loss: 1.226120]\n",
      "[Epoch 6/50] [Batch 163/235] [D loss: 1.138386, acc: 74.41%] [G loss: 1.231501]\n",
      "[Epoch 6/50] [Batch 164/235] [D loss: 1.143199, acc: 76.56%] [G loss: 1.346794]\n",
      "[Epoch 6/50] [Batch 165/235] [D loss: 1.156477, acc: 75.59%] [G loss: 1.280608]\n",
      "[Epoch 6/50] [Batch 166/235] [D loss: 1.141049, acc: 76.76%] [G loss: 1.330808]\n",
      "[Epoch 6/50] [Batch 167/235] [D loss: 1.140918, acc: 76.37%] [G loss: 1.263961]\n",
      "[Epoch 6/50] [Batch 168/235] [D loss: 1.161846, acc: 75.98%] [G loss: 1.242118]\n",
      "[Epoch 6/50] [Batch 169/235] [D loss: 1.113625, acc: 76.56%] [G loss: 1.308080]\n",
      "[Epoch 6/50] [Batch 170/235] [D loss: 1.125197, acc: 77.34%] [G loss: 1.331975]\n",
      "[Epoch 6/50] [Batch 171/235] [D loss: 1.162426, acc: 75.59%] [G loss: 1.192576]\n",
      "[Epoch 6/50] [Batch 172/235] [D loss: 1.157917, acc: 76.56%] [G loss: 1.228166]\n",
      "[Epoch 6/50] [Batch 173/235] [D loss: 1.143777, acc: 73.24%] [G loss: 1.346307]\n",
      "[Epoch 6/50] [Batch 174/235] [D loss: 1.147331, acc: 77.15%] [G loss: 1.349502]\n",
      "[Epoch 6/50] [Batch 175/235] [D loss: 1.117430, acc: 77.93%] [G loss: 1.346835]\n",
      "[Epoch 6/50] [Batch 176/235] [D loss: 1.163435, acc: 73.83%] [G loss: 1.114844]\n",
      "[Epoch 6/50] [Batch 177/235] [D loss: 1.155247, acc: 76.37%] [G loss: 1.335924]\n",
      "[Epoch 6/50] [Batch 178/235] [D loss: 1.140106, acc: 77.54%] [G loss: 1.316719]\n",
      "[Epoch 6/50] [Batch 179/235] [D loss: 1.148639, acc: 78.32%] [G loss: 1.168448]\n",
      "[Epoch 6/50] [Batch 180/235] [D loss: 1.087308, acc: 80.86%] [G loss: 1.344490]\n",
      "[Epoch 6/50] [Batch 181/235] [D loss: 1.177358, acc: 74.80%] [G loss: 1.369177]\n",
      "[Epoch 6/50] [Batch 182/235] [D loss: 1.156648, acc: 78.91%] [G loss: 1.270761]\n",
      "[Epoch 6/50] [Batch 183/235] [D loss: 1.155434, acc: 78.71%] [G loss: 1.162778]\n",
      "[Epoch 6/50] [Batch 184/235] [D loss: 1.179045, acc: 74.02%] [G loss: 1.330602]\n",
      "[Epoch 6/50] [Batch 185/235] [D loss: 1.120297, acc: 78.12%] [G loss: 1.211969]\n",
      "[Epoch 6/50] [Batch 186/235] [D loss: 1.146709, acc: 75.78%] [G loss: 1.259736]\n",
      "[Epoch 6/50] [Batch 187/235] [D loss: 1.164225, acc: 76.37%] [G loss: 1.282541]\n",
      "[Epoch 6/50] [Batch 188/235] [D loss: 1.145562, acc: 77.15%] [G loss: 1.286059]\n",
      "[Epoch 6/50] [Batch 189/235] [D loss: 1.144189, acc: 75.00%] [G loss: 1.247389]\n",
      "[Epoch 6/50] [Batch 190/235] [D loss: 1.145366, acc: 76.56%] [G loss: 1.249909]\n",
      "[Epoch 6/50] [Batch 191/235] [D loss: 1.150875, acc: 74.41%] [G loss: 1.304360]\n",
      "[Epoch 6/50] [Batch 192/235] [D loss: 1.123218, acc: 76.17%] [G loss: 1.326613]\n",
      "[Epoch 6/50] [Batch 193/235] [D loss: 1.132943, acc: 78.12%] [G loss: 1.217304]\n",
      "[Epoch 6/50] [Batch 194/235] [D loss: 1.162393, acc: 77.15%] [G loss: 1.287985]\n",
      "[Epoch 6/50] [Batch 195/235] [D loss: 1.151687, acc: 76.76%] [G loss: 1.381094]\n",
      "[Epoch 6/50] [Batch 196/235] [D loss: 1.159309, acc: 77.73%] [G loss: 1.277766]\n",
      "[Epoch 6/50] [Batch 197/235] [D loss: 1.141851, acc: 75.59%] [G loss: 1.231866]\n",
      "[Epoch 6/50] [Batch 198/235] [D loss: 1.122264, acc: 77.54%] [G loss: 1.337684]\n",
      "[Epoch 6/50] [Batch 199/235] [D loss: 1.094701, acc: 78.32%] [G loss: 1.256685]\n",
      "[Epoch 6/50] [Batch 200/235] [D loss: 1.152920, acc: 73.44%] [G loss: 1.217409]\n",
      "[Epoch 6/50] [Batch 201/235] [D loss: 1.134234, acc: 74.61%] [G loss: 1.256214]\n",
      "[Epoch 6/50] [Batch 202/235] [D loss: 1.119442, acc: 78.52%] [G loss: 1.437794]\n",
      "[Epoch 6/50] [Batch 203/235] [D loss: 1.181445, acc: 74.02%] [G loss: 1.249569]\n",
      "[Epoch 6/50] [Batch 204/235] [D loss: 1.139580, acc: 77.34%] [G loss: 1.303700]\n",
      "[Epoch 6/50] [Batch 205/235] [D loss: 1.119036, acc: 78.91%] [G loss: 1.358006]\n",
      "[Epoch 6/50] [Batch 206/235] [D loss: 1.120454, acc: 79.10%] [G loss: 1.266014]\n",
      "[Epoch 6/50] [Batch 207/235] [D loss: 1.092940, acc: 77.15%] [G loss: 1.301054]\n",
      "[Epoch 6/50] [Batch 208/235] [D loss: 1.118683, acc: 78.12%] [G loss: 1.234156]\n",
      "[Epoch 6/50] [Batch 209/235] [D loss: 1.138295, acc: 77.93%] [G loss: 1.210011]\n",
      "[Epoch 6/50] [Batch 210/235] [D loss: 1.125045, acc: 74.61%] [G loss: 1.304432]\n",
      "[Epoch 6/50] [Batch 211/235] [D loss: 1.136773, acc: 76.17%] [G loss: 1.316490]\n",
      "[Epoch 6/50] [Batch 212/235] [D loss: 1.148514, acc: 75.98%] [G loss: 1.465172]\n",
      "[Epoch 6/50] [Batch 213/235] [D loss: 1.152828, acc: 77.54%] [G loss: 1.275674]\n",
      "[Epoch 6/50] [Batch 214/235] [D loss: 1.128005, acc: 77.73%] [G loss: 1.192294]\n",
      "[Epoch 6/50] [Batch 215/235] [D loss: 1.121157, acc: 77.54%] [G loss: 1.311444]\n",
      "[Epoch 6/50] [Batch 216/235] [D loss: 1.162256, acc: 74.80%] [G loss: 1.374689]\n",
      "[Epoch 6/50] [Batch 217/235] [D loss: 1.153737, acc: 76.37%] [G loss: 1.199974]\n",
      "[Epoch 6/50] [Batch 218/235] [D loss: 1.117731, acc: 79.88%] [G loss: 1.454236]\n",
      "[Epoch 6/50] [Batch 219/235] [D loss: 1.114602, acc: 74.80%] [G loss: 1.392309]\n",
      "[Epoch 6/50] [Batch 220/235] [D loss: 1.187784, acc: 74.61%] [G loss: 1.346488]\n",
      "[Epoch 6/50] [Batch 221/235] [D loss: 1.136250, acc: 75.39%] [G loss: 1.316643]\n",
      "[Epoch 6/50] [Batch 222/235] [D loss: 1.152642, acc: 77.15%] [G loss: 1.289942]\n",
      "[Epoch 6/50] [Batch 223/235] [D loss: 1.124044, acc: 76.17%] [G loss: 1.269258]\n",
      "[Epoch 6/50] [Batch 224/235] [D loss: 1.131107, acc: 75.00%] [G loss: 1.279943]\n",
      "[Epoch 6/50] [Batch 225/235] [D loss: 1.096078, acc: 77.93%] [G loss: 1.338724]\n",
      "[Epoch 6/50] [Batch 226/235] [D loss: 1.137623, acc: 78.71%] [G loss: 1.244498]\n",
      "[Epoch 6/50] [Batch 227/235] [D loss: 1.117487, acc: 79.49%] [G loss: 1.354801]\n",
      "[Epoch 6/50] [Batch 228/235] [D loss: 1.189801, acc: 77.73%] [G loss: 1.364544]\n",
      "[Epoch 6/50] [Batch 229/235] [D loss: 1.112914, acc: 78.52%] [G loss: 1.233115]\n",
      "[Epoch 6/50] [Batch 230/235] [D loss: 1.129133, acc: 76.37%] [G loss: 1.173082]\n",
      "[Epoch 6/50] [Batch 231/235] [D loss: 1.111672, acc: 77.15%] [G loss: 1.359967]\n",
      "[Epoch 6/50] [Batch 232/235] [D loss: 1.127622, acc: 77.73%] [G loss: 1.440846]\n",
      "[Epoch 6/50] [Batch 233/235] [D loss: 1.143676, acc: 75.98%] [G loss: 1.184044]\n",
      "[Epoch 6/50] [Batch 234/235] [D loss: 1.158743, acc: 77.60%] [G loss: 1.199932]\n",
      "[Epoch 7/50] [Batch 0/235] [D loss: 1.148124, acc: 75.78%] [G loss: 1.216176]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/50] [Batch 1/235] [D loss: 1.157752, acc: 78.91%] [G loss: 1.268564]\n",
      "[Epoch 7/50] [Batch 2/235] [D loss: 1.148605, acc: 78.12%] [G loss: 1.452183]\n",
      "[Epoch 7/50] [Batch 3/235] [D loss: 1.137234, acc: 74.22%] [G loss: 1.229642]\n",
      "[Epoch 7/50] [Batch 4/235] [D loss: 1.138668, acc: 76.56%] [G loss: 1.300382]\n",
      "[Epoch 7/50] [Batch 5/235] [D loss: 1.141763, acc: 75.20%] [G loss: 1.362778]\n",
      "[Epoch 7/50] [Batch 6/235] [D loss: 1.165224, acc: 78.71%] [G loss: 1.200272]\n",
      "[Epoch 7/50] [Batch 7/235] [D loss: 1.100870, acc: 79.30%] [G loss: 1.234319]\n",
      "[Epoch 7/50] [Batch 8/235] [D loss: 1.126956, acc: 75.59%] [G loss: 1.365931]\n",
      "[Epoch 7/50] [Batch 9/235] [D loss: 1.150785, acc: 75.78%] [G loss: 1.355269]\n",
      "[Epoch 7/50] [Batch 10/235] [D loss: 1.162551, acc: 73.83%] [G loss: 1.365686]\n",
      "[Epoch 7/50] [Batch 11/235] [D loss: 1.138811, acc: 77.73%] [G loss: 1.355567]\n",
      "[Epoch 7/50] [Batch 12/235] [D loss: 1.137117, acc: 77.15%] [G loss: 1.175074]\n",
      "[Epoch 7/50] [Batch 13/235] [D loss: 1.105395, acc: 78.12%] [G loss: 1.330446]\n",
      "[Epoch 7/50] [Batch 14/235] [D loss: 1.159282, acc: 78.12%] [G loss: 1.382436]\n",
      "[Epoch 7/50] [Batch 15/235] [D loss: 1.130332, acc: 78.12%] [G loss: 1.306939]\n",
      "[Epoch 7/50] [Batch 16/235] [D loss: 1.121557, acc: 74.80%] [G loss: 1.352262]\n",
      "[Epoch 7/50] [Batch 17/235] [D loss: 1.131148, acc: 77.34%] [G loss: 1.279697]\n",
      "[Epoch 7/50] [Batch 18/235] [D loss: 1.210006, acc: 77.34%] [G loss: 1.181792]\n",
      "[Epoch 7/50] [Batch 19/235] [D loss: 1.114386, acc: 78.91%] [G loss: 1.347924]\n",
      "[Epoch 7/50] [Batch 20/235] [D loss: 1.132077, acc: 76.76%] [G loss: 1.327785]\n",
      "[Epoch 7/50] [Batch 21/235] [D loss: 1.099241, acc: 78.12%] [G loss: 1.238946]\n",
      "[Epoch 7/50] [Batch 22/235] [D loss: 1.158669, acc: 76.76%] [G loss: 1.172332]\n",
      "[Epoch 7/50] [Batch 23/235] [D loss: 1.146156, acc: 78.12%] [G loss: 1.276406]\n",
      "[Epoch 7/50] [Batch 24/235] [D loss: 1.128889, acc: 80.66%] [G loss: 1.282980]\n",
      "[Epoch 7/50] [Batch 25/235] [D loss: 1.145082, acc: 74.41%] [G loss: 1.240656]\n",
      "[Epoch 7/50] [Batch 26/235] [D loss: 1.151762, acc: 76.37%] [G loss: 1.389268]\n",
      "[Epoch 7/50] [Batch 27/235] [D loss: 1.129487, acc: 78.32%] [G loss: 1.352819]\n",
      "[Epoch 7/50] [Batch 28/235] [D loss: 1.124668, acc: 77.15%] [G loss: 1.354102]\n",
      "[Epoch 7/50] [Batch 29/235] [D loss: 1.128855, acc: 76.37%] [G loss: 1.394702]\n",
      "[Epoch 7/50] [Batch 30/235] [D loss: 1.100277, acc: 76.76%] [G loss: 1.238788]\n",
      "[Epoch 7/50] [Batch 31/235] [D loss: 1.118802, acc: 77.15%] [G loss: 1.321085]\n",
      "[Epoch 7/50] [Batch 32/235] [D loss: 1.149633, acc: 78.52%] [G loss: 1.461177]\n",
      "[Epoch 7/50] [Batch 33/235] [D loss: 1.155317, acc: 78.32%] [G loss: 1.160651]\n",
      "[Epoch 7/50] [Batch 34/235] [D loss: 1.104550, acc: 79.10%] [G loss: 1.235930]\n",
      "[Epoch 7/50] [Batch 35/235] [D loss: 1.096695, acc: 76.95%] [G loss: 1.333904]\n",
      "[Epoch 7/50] [Batch 36/235] [D loss: 1.147393, acc: 77.93%] [G loss: 1.360609]\n",
      "[Epoch 7/50] [Batch 37/235] [D loss: 1.142158, acc: 73.83%] [G loss: 1.136031]\n",
      "[Epoch 7/50] [Batch 38/235] [D loss: 1.131510, acc: 79.10%] [G loss: 1.226981]\n",
      "[Epoch 7/50] [Batch 39/235] [D loss: 1.178081, acc: 75.39%] [G loss: 1.350819]\n",
      "[Epoch 7/50] [Batch 40/235] [D loss: 1.137172, acc: 79.10%] [G loss: 1.275802]\n",
      "[Epoch 7/50] [Batch 41/235] [D loss: 1.123510, acc: 77.15%] [G loss: 1.222786]\n",
      "[Epoch 7/50] [Batch 42/235] [D loss: 1.147922, acc: 75.59%] [G loss: 1.230683]\n",
      "[Epoch 7/50] [Batch 43/235] [D loss: 1.161870, acc: 77.54%] [G loss: 1.350943]\n",
      "[Epoch 7/50] [Batch 44/235] [D loss: 1.092204, acc: 75.39%] [G loss: 1.323418]\n",
      "[Epoch 7/50] [Batch 45/235] [D loss: 1.110086, acc: 75.59%] [G loss: 1.261602]\n",
      "[Epoch 7/50] [Batch 46/235] [D loss: 1.135373, acc: 75.20%] [G loss: 1.226453]\n",
      "[Epoch 7/50] [Batch 47/235] [D loss: 1.083269, acc: 75.20%] [G loss: 1.397767]\n",
      "[Epoch 7/50] [Batch 48/235] [D loss: 1.097869, acc: 79.10%] [G loss: 1.381022]\n",
      "[Epoch 7/50] [Batch 49/235] [D loss: 1.120370, acc: 77.34%] [G loss: 1.205592]\n",
      "[Epoch 7/50] [Batch 50/235] [D loss: 1.113735, acc: 79.30%] [G loss: 1.285041]\n",
      "[Epoch 7/50] [Batch 51/235] [D loss: 1.130614, acc: 77.15%] [G loss: 1.258049]\n",
      "[Epoch 7/50] [Batch 52/235] [D loss: 1.125885, acc: 77.34%] [G loss: 1.239427]\n",
      "[Epoch 7/50] [Batch 53/235] [D loss: 1.087433, acc: 78.71%] [G loss: 1.271175]\n",
      "[Epoch 7/50] [Batch 54/235] [D loss: 1.111553, acc: 77.34%] [G loss: 1.328721]\n",
      "[Epoch 7/50] [Batch 55/235] [D loss: 1.165335, acc: 73.05%] [G loss: 1.146740]\n",
      "[Epoch 7/50] [Batch 56/235] [D loss: 1.136753, acc: 76.17%] [G loss: 1.307860]\n",
      "[Epoch 7/50] [Batch 57/235] [D loss: 1.178333, acc: 73.24%] [G loss: 1.355772]\n",
      "[Epoch 7/50] [Batch 58/235] [D loss: 1.154737, acc: 74.80%] [G loss: 1.210513]\n",
      "[Epoch 7/50] [Batch 59/235] [D loss: 1.117370, acc: 77.15%] [G loss: 1.325033]\n",
      "[Epoch 7/50] [Batch 60/235] [D loss: 1.152742, acc: 75.20%] [G loss: 1.389893]\n",
      "[Epoch 7/50] [Batch 61/235] [D loss: 1.124828, acc: 77.34%] [G loss: 1.321447]\n",
      "[Epoch 7/50] [Batch 62/235] [D loss: 1.132902, acc: 78.91%] [G loss: 1.313288]\n",
      "[Epoch 7/50] [Batch 63/235] [D loss: 1.171239, acc: 74.02%] [G loss: 1.359849]\n",
      "[Epoch 7/50] [Batch 64/235] [D loss: 1.106796, acc: 78.91%] [G loss: 1.219432]\n",
      "[Epoch 7/50] [Batch 65/235] [D loss: 1.152722, acc: 75.00%] [G loss: 1.274143]\n",
      "[Epoch 7/50] [Batch 66/235] [D loss: 1.081484, acc: 76.17%] [G loss: 1.380652]\n",
      "[Epoch 7/50] [Batch 67/235] [D loss: 1.102224, acc: 80.66%] [G loss: 1.177303]\n",
      "[Epoch 7/50] [Batch 68/235] [D loss: 1.128153, acc: 74.22%] [G loss: 1.378587]\n",
      "[Epoch 7/50] [Batch 69/235] [D loss: 1.159412, acc: 77.15%] [G loss: 1.252447]\n",
      "[Epoch 7/50] [Batch 70/235] [D loss: 1.092952, acc: 77.54%] [G loss: 1.297666]\n",
      "[Epoch 7/50] [Batch 71/235] [D loss: 1.171687, acc: 75.98%] [G loss: 1.205702]\n",
      "[Epoch 7/50] [Batch 72/235] [D loss: 1.164379, acc: 76.76%] [G loss: 1.380976]\n",
      "[Epoch 7/50] [Batch 73/235] [D loss: 1.077842, acc: 80.08%] [G loss: 1.366008]\n",
      "[Epoch 7/50] [Batch 74/235] [D loss: 1.137137, acc: 77.73%] [G loss: 1.148090]\n",
      "[Epoch 7/50] [Batch 75/235] [D loss: 1.131548, acc: 78.12%] [G loss: 1.364633]\n",
      "[Epoch 7/50] [Batch 76/235] [D loss: 1.130076, acc: 78.71%] [G loss: 1.344064]\n",
      "[Epoch 7/50] [Batch 77/235] [D loss: 1.128824, acc: 74.02%] [G loss: 1.432075]\n",
      "[Epoch 7/50] [Batch 78/235] [D loss: 1.152751, acc: 75.39%] [G loss: 1.378184]\n",
      "[Epoch 7/50] [Batch 79/235] [D loss: 1.150202, acc: 77.15%] [G loss: 1.202367]\n",
      "[Epoch 7/50] [Batch 80/235] [D loss: 1.114146, acc: 77.54%] [G loss: 1.350082]\n",
      "[Epoch 7/50] [Batch 81/235] [D loss: 1.139082, acc: 77.15%] [G loss: 1.338029]\n",
      "[Epoch 7/50] [Batch 82/235] [D loss: 1.141030, acc: 75.20%] [G loss: 1.252283]\n",
      "[Epoch 7/50] [Batch 83/235] [D loss: 1.124155, acc: 78.52%] [G loss: 1.235907]\n",
      "[Epoch 7/50] [Batch 84/235] [D loss: 1.158447, acc: 76.37%] [G loss: 1.180065]\n",
      "[Epoch 7/50] [Batch 85/235] [D loss: 1.107934, acc: 78.32%] [G loss: 1.244100]\n",
      "[Epoch 7/50] [Batch 86/235] [D loss: 1.130602, acc: 74.61%] [G loss: 1.215384]\n",
      "[Epoch 7/50] [Batch 87/235] [D loss: 1.109865, acc: 76.95%] [G loss: 1.304931]\n",
      "[Epoch 7/50] [Batch 88/235] [D loss: 1.108881, acc: 76.76%] [G loss: 1.234179]\n",
      "[Epoch 7/50] [Batch 89/235] [D loss: 1.135306, acc: 77.34%] [G loss: 1.342085]\n",
      "[Epoch 7/50] [Batch 90/235] [D loss: 1.137722, acc: 75.00%] [G loss: 1.253088]\n",
      "[Epoch 7/50] [Batch 91/235] [D loss: 1.168211, acc: 77.34%] [G loss: 1.275235]\n",
      "[Epoch 7/50] [Batch 92/235] [D loss: 1.141187, acc: 74.61%] [G loss: 1.301961]\n",
      "[Epoch 7/50] [Batch 93/235] [D loss: 1.139393, acc: 75.00%] [G loss: 1.227227]\n",
      "[Epoch 7/50] [Batch 94/235] [D loss: 1.145242, acc: 77.73%] [G loss: 1.217876]\n",
      "[Epoch 7/50] [Batch 95/235] [D loss: 1.100861, acc: 75.59%] [G loss: 1.232148]\n",
      "[Epoch 7/50] [Batch 96/235] [D loss: 1.107877, acc: 77.73%] [G loss: 1.338438]\n",
      "[Epoch 7/50] [Batch 97/235] [D loss: 1.143116, acc: 76.37%] [G loss: 1.189517]\n",
      "[Epoch 7/50] [Batch 98/235] [D loss: 1.172038, acc: 75.98%] [G loss: 1.341413]\n",
      "[Epoch 7/50] [Batch 99/235] [D loss: 1.110710, acc: 80.47%] [G loss: 1.396741]\n",
      "[Epoch 7/50] [Batch 100/235] [D loss: 1.141277, acc: 75.20%] [G loss: 1.228333]\n",
      "[Epoch 7/50] [Batch 101/235] [D loss: 1.096023, acc: 76.76%] [G loss: 1.217545]\n",
      "[Epoch 7/50] [Batch 102/235] [D loss: 1.150078, acc: 77.15%] [G loss: 1.252978]\n",
      "[Epoch 7/50] [Batch 103/235] [D loss: 1.167523, acc: 74.22%] [G loss: 1.289318]\n",
      "[Epoch 7/50] [Batch 104/235] [D loss: 1.141596, acc: 72.27%] [G loss: 1.295307]\n",
      "[Epoch 7/50] [Batch 105/235] [D loss: 1.164686, acc: 73.63%] [G loss: 1.329812]\n",
      "[Epoch 7/50] [Batch 106/235] [D loss: 1.125173, acc: 78.32%] [G loss: 1.331124]\n",
      "[Epoch 7/50] [Batch 107/235] [D loss: 1.124408, acc: 76.56%] [G loss: 1.338982]\n",
      "[Epoch 7/50] [Batch 108/235] [D loss: 1.158028, acc: 76.76%] [G loss: 1.211544]\n",
      "[Epoch 7/50] [Batch 109/235] [D loss: 1.139884, acc: 76.37%] [G loss: 1.143031]\n",
      "[Epoch 7/50] [Batch 110/235] [D loss: 1.208107, acc: 73.24%] [G loss: 1.411148]\n",
      "[Epoch 7/50] [Batch 111/235] [D loss: 1.119857, acc: 79.30%] [G loss: 1.266431]\n",
      "[Epoch 7/50] [Batch 112/235] [D loss: 1.142009, acc: 81.25%] [G loss: 1.235646]\n",
      "[Epoch 7/50] [Batch 113/235] [D loss: 1.167770, acc: 73.05%] [G loss: 1.301588]\n",
      "[Epoch 7/50] [Batch 114/235] [D loss: 1.133034, acc: 76.95%] [G loss: 1.214397]\n",
      "[Epoch 7/50] [Batch 115/235] [D loss: 1.123277, acc: 76.56%] [G loss: 1.265068]\n",
      "[Epoch 7/50] [Batch 116/235] [D loss: 1.133549, acc: 80.08%] [G loss: 1.389410]\n",
      "[Epoch 7/50] [Batch 117/235] [D loss: 1.126487, acc: 75.78%] [G loss: 1.331791]\n",
      "[Epoch 7/50] [Batch 118/235] [D loss: 1.146365, acc: 78.12%] [G loss: 1.271959]\n",
      "[Epoch 7/50] [Batch 119/235] [D loss: 1.142480, acc: 77.34%] [G loss: 1.257841]\n",
      "[Epoch 7/50] [Batch 120/235] [D loss: 1.163055, acc: 77.15%] [G loss: 1.278045]\n",
      "[Epoch 7/50] [Batch 121/235] [D loss: 1.103096, acc: 78.91%] [G loss: 1.213717]\n",
      "[Epoch 7/50] [Batch 122/235] [D loss: 1.139165, acc: 74.41%] [G loss: 1.318664]\n",
      "[Epoch 7/50] [Batch 123/235] [D loss: 1.127187, acc: 79.88%] [G loss: 1.200213]\n",
      "[Epoch 7/50] [Batch 124/235] [D loss: 1.099758, acc: 78.91%] [G loss: 1.261673]\n",
      "[Epoch 7/50] [Batch 125/235] [D loss: 1.115795, acc: 75.59%] [G loss: 1.196755]\n",
      "[Epoch 7/50] [Batch 126/235] [D loss: 1.149578, acc: 75.20%] [G loss: 1.412835]\n",
      "[Epoch 7/50] [Batch 127/235] [D loss: 1.107693, acc: 76.56%] [G loss: 1.389905]\n",
      "[Epoch 7/50] [Batch 128/235] [D loss: 1.120327, acc: 76.17%] [G loss: 1.249354]\n",
      "[Epoch 7/50] [Batch 129/235] [D loss: 1.134386, acc: 75.98%] [G loss: 1.271283]\n",
      "[Epoch 7/50] [Batch 130/235] [D loss: 1.153772, acc: 77.15%] [G loss: 1.259411]\n",
      "[Epoch 7/50] [Batch 131/235] [D loss: 1.176997, acc: 73.24%] [G loss: 1.377453]\n",
      "[Epoch 7/50] [Batch 132/235] [D loss: 1.126609, acc: 78.91%] [G loss: 1.313438]\n",
      "[Epoch 7/50] [Batch 133/235] [D loss: 1.188426, acc: 70.31%] [G loss: 1.314501]\n",
      "[Epoch 7/50] [Batch 134/235] [D loss: 1.117208, acc: 78.12%] [G loss: 1.194696]\n",
      "[Epoch 7/50] [Batch 135/235] [D loss: 1.154912, acc: 71.68%] [G loss: 1.345288]\n",
      "[Epoch 7/50] [Batch 136/235] [D loss: 1.147890, acc: 76.76%] [G loss: 1.343119]\n",
      "[Epoch 7/50] [Batch 137/235] [D loss: 1.133976, acc: 78.52%] [G loss: 1.228038]\n",
      "[Epoch 7/50] [Batch 138/235] [D loss: 1.131044, acc: 77.54%] [G loss: 1.339275]\n",
      "[Epoch 7/50] [Batch 139/235] [D loss: 1.149752, acc: 75.00%] [G loss: 1.495108]\n",
      "[Epoch 7/50] [Batch 140/235] [D loss: 1.133979, acc: 78.91%] [G loss: 1.242277]\n",
      "[Epoch 7/50] [Batch 141/235] [D loss: 1.188974, acc: 76.56%] [G loss: 1.255011]\n",
      "[Epoch 7/50] [Batch 142/235] [D loss: 1.144394, acc: 76.56%] [G loss: 1.297157]\n",
      "[Epoch 7/50] [Batch 143/235] [D loss: 1.107431, acc: 76.76%] [G loss: 1.440941]\n",
      "[Epoch 7/50] [Batch 144/235] [D loss: 1.154927, acc: 75.39%] [G loss: 1.347269]\n",
      "[Epoch 7/50] [Batch 145/235] [D loss: 1.124801, acc: 76.95%] [G loss: 1.299304]\n",
      "[Epoch 7/50] [Batch 146/235] [D loss: 1.172031, acc: 76.17%] [G loss: 1.246124]\n",
      "[Epoch 7/50] [Batch 147/235] [D loss: 1.177216, acc: 71.29%] [G loss: 1.438639]\n",
      "[Epoch 7/50] [Batch 148/235] [D loss: 1.133200, acc: 76.37%] [G loss: 1.191604]\n",
      "[Epoch 7/50] [Batch 149/235] [D loss: 1.158104, acc: 77.54%] [G loss: 1.175681]\n",
      "[Epoch 7/50] [Batch 150/235] [D loss: 1.140158, acc: 77.73%] [G loss: 1.336163]\n",
      "[Epoch 7/50] [Batch 151/235] [D loss: 1.150032, acc: 77.34%] [G loss: 1.328985]\n",
      "[Epoch 7/50] [Batch 152/235] [D loss: 1.142845, acc: 73.63%] [G loss: 1.270448]\n",
      "[Epoch 7/50] [Batch 153/235] [D loss: 1.130210, acc: 77.93%] [G loss: 1.185586]\n",
      "[Epoch 7/50] [Batch 154/235] [D loss: 1.106666, acc: 77.73%] [G loss: 1.330149]\n",
      "[Epoch 7/50] [Batch 155/235] [D loss: 1.160205, acc: 77.15%] [G loss: 1.281200]\n",
      "[Epoch 7/50] [Batch 156/235] [D loss: 1.169448, acc: 78.12%] [G loss: 1.276771]\n",
      "[Epoch 7/50] [Batch 157/235] [D loss: 1.194456, acc: 73.44%] [G loss: 1.196740]\n",
      "[Epoch 7/50] [Batch 158/235] [D loss: 1.133816, acc: 77.34%] [G loss: 1.476350]\n",
      "[Epoch 7/50] [Batch 159/235] [D loss: 1.105499, acc: 75.98%] [G loss: 1.248948]\n",
      "[Epoch 7/50] [Batch 160/235] [D loss: 1.195040, acc: 75.20%] [G loss: 1.158807]\n",
      "[Epoch 7/50] [Batch 161/235] [D loss: 1.138089, acc: 76.56%] [G loss: 1.310082]\n",
      "[Epoch 7/50] [Batch 162/235] [D loss: 1.161164, acc: 76.56%] [G loss: 1.415679]\n",
      "[Epoch 7/50] [Batch 163/235] [D loss: 1.160371, acc: 78.52%] [G loss: 1.222568]\n",
      "[Epoch 7/50] [Batch 164/235] [D loss: 1.120700, acc: 75.20%] [G loss: 1.273254]\n",
      "[Epoch 7/50] [Batch 165/235] [D loss: 1.108873, acc: 75.39%] [G loss: 1.443649]\n",
      "[Epoch 7/50] [Batch 166/235] [D loss: 1.138633, acc: 76.95%] [G loss: 1.297591]\n",
      "[Epoch 7/50] [Batch 167/235] [D loss: 1.115676, acc: 75.98%] [G loss: 1.323114]\n",
      "[Epoch 7/50] [Batch 168/235] [D loss: 1.173276, acc: 77.93%] [G loss: 1.259210]\n",
      "[Epoch 7/50] [Batch 169/235] [D loss: 1.160528, acc: 74.80%] [G loss: 1.260509]\n",
      "[Epoch 7/50] [Batch 170/235] [D loss: 1.120660, acc: 80.47%] [G loss: 1.328805]\n",
      "[Epoch 7/50] [Batch 171/235] [D loss: 1.130054, acc: 78.32%] [G loss: 1.318248]\n",
      "[Epoch 7/50] [Batch 172/235] [D loss: 1.157942, acc: 74.41%] [G loss: 1.194422]\n",
      "[Epoch 7/50] [Batch 173/235] [D loss: 1.099375, acc: 78.32%] [G loss: 1.346038]\n",
      "[Epoch 7/50] [Batch 174/235] [D loss: 1.107633, acc: 76.95%] [G loss: 1.336947]\n",
      "[Epoch 7/50] [Batch 175/235] [D loss: 1.189574, acc: 75.00%] [G loss: 1.209089]\n",
      "[Epoch 7/50] [Batch 176/235] [D loss: 1.139363, acc: 77.34%] [G loss: 1.366205]\n",
      "[Epoch 7/50] [Batch 177/235] [D loss: 1.151574, acc: 76.37%] [G loss: 1.223850]\n",
      "[Epoch 7/50] [Batch 178/235] [D loss: 1.146062, acc: 75.78%] [G loss: 1.293391]\n",
      "[Epoch 7/50] [Batch 179/235] [D loss: 1.173522, acc: 76.76%] [G loss: 1.214197]\n",
      "[Epoch 7/50] [Batch 180/235] [D loss: 1.123331, acc: 80.27%] [G loss: 1.282933]\n",
      "[Epoch 7/50] [Batch 181/235] [D loss: 1.158930, acc: 74.61%] [G loss: 1.330777]\n",
      "[Epoch 7/50] [Batch 182/235] [D loss: 1.133053, acc: 76.17%] [G loss: 1.306787]\n",
      "[Epoch 7/50] [Batch 183/235] [D loss: 1.161822, acc: 76.37%] [G loss: 1.344932]\n",
      "[Epoch 7/50] [Batch 184/235] [D loss: 1.128121, acc: 78.91%] [G loss: 1.377950]\n",
      "[Epoch 7/50] [Batch 185/235] [D loss: 1.144621, acc: 76.17%] [G loss: 1.325525]\n",
      "[Epoch 7/50] [Batch 186/235] [D loss: 1.192706, acc: 76.95%] [G loss: 1.249177]\n",
      "[Epoch 7/50] [Batch 187/235] [D loss: 1.120890, acc: 79.69%] [G loss: 1.206789]\n",
      "[Epoch 7/50] [Batch 188/235] [D loss: 1.163735, acc: 75.59%] [G loss: 1.253308]\n",
      "[Epoch 7/50] [Batch 189/235] [D loss: 1.142464, acc: 77.54%] [G loss: 1.326543]\n",
      "[Epoch 7/50] [Batch 190/235] [D loss: 1.127808, acc: 79.10%] [G loss: 1.262797]\n",
      "[Epoch 7/50] [Batch 191/235] [D loss: 1.143708, acc: 76.56%] [G loss: 1.336932]\n",
      "[Epoch 7/50] [Batch 192/235] [D loss: 1.154811, acc: 77.73%] [G loss: 1.298434]\n",
      "[Epoch 7/50] [Batch 193/235] [D loss: 1.150146, acc: 76.17%] [G loss: 1.316971]\n",
      "[Epoch 7/50] [Batch 194/235] [D loss: 1.162888, acc: 75.78%] [G loss: 1.367304]\n",
      "[Epoch 7/50] [Batch 195/235] [D loss: 1.178705, acc: 73.05%] [G loss: 1.201057]\n",
      "[Epoch 7/50] [Batch 196/235] [D loss: 1.121236, acc: 77.34%] [G loss: 1.228436]\n",
      "[Epoch 7/50] [Batch 197/235] [D loss: 1.120631, acc: 79.88%] [G loss: 1.233991]\n",
      "[Epoch 7/50] [Batch 198/235] [D loss: 1.100585, acc: 78.32%] [G loss: 1.208125]\n",
      "[Epoch 7/50] [Batch 199/235] [D loss: 1.190542, acc: 73.63%] [G loss: 1.198380]\n",
      "[Epoch 7/50] [Batch 200/235] [D loss: 1.131974, acc: 76.17%] [G loss: 1.335497]\n",
      "[Epoch 7/50] [Batch 201/235] [D loss: 1.127213, acc: 77.34%] [G loss: 1.274226]\n",
      "[Epoch 7/50] [Batch 202/235] [D loss: 1.163716, acc: 75.39%] [G loss: 1.250291]\n",
      "[Epoch 7/50] [Batch 203/235] [D loss: 1.135285, acc: 78.91%] [G loss: 1.208533]\n",
      "[Epoch 7/50] [Batch 204/235] [D loss: 1.175849, acc: 75.59%] [G loss: 1.296876]\n",
      "[Epoch 7/50] [Batch 205/235] [D loss: 1.135302, acc: 78.52%] [G loss: 1.327490]\n",
      "[Epoch 7/50] [Batch 206/235] [D loss: 1.154279, acc: 74.41%] [G loss: 1.266804]\n",
      "[Epoch 7/50] [Batch 207/235] [D loss: 1.129282, acc: 79.49%] [G loss: 1.246757]\n",
      "[Epoch 7/50] [Batch 208/235] [D loss: 1.182922, acc: 73.63%] [G loss: 1.357346]\n",
      "[Epoch 7/50] [Batch 209/235] [D loss: 1.116328, acc: 76.37%] [G loss: 1.222724]\n",
      "[Epoch 7/50] [Batch 210/235] [D loss: 1.145348, acc: 75.59%] [G loss: 1.278939]\n",
      "[Epoch 7/50] [Batch 211/235] [D loss: 1.147885, acc: 76.76%] [G loss: 1.313427]\n",
      "[Epoch 7/50] [Batch 212/235] [D loss: 1.132548, acc: 77.34%] [G loss: 1.324669]\n",
      "[Epoch 7/50] [Batch 213/235] [D loss: 1.127372, acc: 78.71%] [G loss: 1.335383]\n",
      "[Epoch 7/50] [Batch 214/235] [D loss: 1.140922, acc: 76.17%] [G loss: 1.224108]\n",
      "[Epoch 7/50] [Batch 215/235] [D loss: 1.155814, acc: 73.83%] [G loss: 1.371521]\n",
      "[Epoch 7/50] [Batch 216/235] [D loss: 1.165858, acc: 75.59%] [G loss: 1.315510]\n",
      "[Epoch 7/50] [Batch 217/235] [D loss: 1.120484, acc: 76.95%] [G loss: 1.180443]\n",
      "[Epoch 7/50] [Batch 218/235] [D loss: 1.119656, acc: 77.15%] [G loss: 1.268592]\n",
      "[Epoch 7/50] [Batch 219/235] [D loss: 1.149612, acc: 74.41%] [G loss: 1.340667]\n",
      "[Epoch 7/50] [Batch 220/235] [D loss: 1.151256, acc: 77.15%] [G loss: 1.201396]\n",
      "[Epoch 7/50] [Batch 221/235] [D loss: 1.179917, acc: 75.78%] [G loss: 1.304688]\n",
      "[Epoch 7/50] [Batch 222/235] [D loss: 1.172938, acc: 74.22%] [G loss: 1.228865]\n",
      "[Epoch 7/50] [Batch 223/235] [D loss: 1.186817, acc: 79.30%] [G loss: 1.306361]\n",
      "[Epoch 7/50] [Batch 224/235] [D loss: 1.146401, acc: 76.95%] [G loss: 1.197078]\n",
      "[Epoch 7/50] [Batch 225/235] [D loss: 1.175336, acc: 79.69%] [G loss: 1.187474]\n",
      "[Epoch 7/50] [Batch 226/235] [D loss: 1.146780, acc: 75.00%] [G loss: 1.251837]\n",
      "[Epoch 7/50] [Batch 227/235] [D loss: 1.139558, acc: 76.95%] [G loss: 1.265062]\n",
      "[Epoch 7/50] [Batch 228/235] [D loss: 1.135588, acc: 74.80%] [G loss: 1.268883]\n",
      "[Epoch 7/50] [Batch 229/235] [D loss: 1.149780, acc: 76.37%] [G loss: 1.305685]\n",
      "[Epoch 7/50] [Batch 230/235] [D loss: 1.139947, acc: 75.78%] [G loss: 1.344113]\n",
      "[Epoch 7/50] [Batch 231/235] [D loss: 1.106999, acc: 77.34%] [G loss: 1.332287]\n",
      "[Epoch 7/50] [Batch 232/235] [D loss: 1.133610, acc: 79.10%] [G loss: 1.274006]\n",
      "[Epoch 7/50] [Batch 233/235] [D loss: 1.139550, acc: 76.37%] [G loss: 1.323553]\n",
      "[Epoch 7/50] [Batch 234/235] [D loss: 1.134615, acc: 80.21%] [G loss: 1.209846]\n",
      "[Epoch 8/50] [Batch 0/235] [D loss: 1.137109, acc: 73.83%] [G loss: 1.475581]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/50] [Batch 1/235] [D loss: 1.167729, acc: 74.41%] [G loss: 1.087658]\n",
      "[Epoch 8/50] [Batch 2/235] [D loss: 1.165549, acc: 75.20%] [G loss: 1.312310]\n",
      "[Epoch 8/50] [Batch 3/235] [D loss: 1.147374, acc: 78.71%] [G loss: 1.412153]\n",
      "[Epoch 8/50] [Batch 4/235] [D loss: 1.127043, acc: 77.15%] [G loss: 1.365811]\n",
      "[Epoch 8/50] [Batch 5/235] [D loss: 1.135854, acc: 74.02%] [G loss: 1.251012]\n",
      "[Epoch 8/50] [Batch 6/235] [D loss: 1.130057, acc: 72.85%] [G loss: 1.397421]\n",
      "[Epoch 8/50] [Batch 7/235] [D loss: 1.143178, acc: 74.61%] [G loss: 1.363111]\n",
      "[Epoch 8/50] [Batch 8/235] [D loss: 1.087496, acc: 78.12%] [G loss: 1.245400]\n",
      "[Epoch 8/50] [Batch 9/235] [D loss: 1.109805, acc: 77.73%] [G loss: 1.259159]\n",
      "[Epoch 8/50] [Batch 10/235] [D loss: 1.126150, acc: 76.56%] [G loss: 1.388049]\n",
      "[Epoch 8/50] [Batch 11/235] [D loss: 1.121012, acc: 77.15%] [G loss: 1.286540]\n",
      "[Epoch 8/50] [Batch 12/235] [D loss: 1.119504, acc: 76.95%] [G loss: 1.396374]\n",
      "[Epoch 8/50] [Batch 13/235] [D loss: 1.199650, acc: 75.39%] [G loss: 1.204623]\n",
      "[Epoch 8/50] [Batch 14/235] [D loss: 1.116527, acc: 75.98%] [G loss: 1.272943]\n",
      "[Epoch 8/50] [Batch 15/235] [D loss: 1.155536, acc: 74.41%] [G loss: 1.337224]\n",
      "[Epoch 8/50] [Batch 16/235] [D loss: 1.123633, acc: 77.34%] [G loss: 1.293937]\n",
      "[Epoch 8/50] [Batch 17/235] [D loss: 1.164783, acc: 75.00%] [G loss: 1.199924]\n",
      "[Epoch 8/50] [Batch 18/235] [D loss: 1.117142, acc: 78.52%] [G loss: 1.293968]\n",
      "[Epoch 8/50] [Batch 19/235] [D loss: 1.189705, acc: 73.05%] [G loss: 1.423076]\n",
      "[Epoch 8/50] [Batch 20/235] [D loss: 1.114794, acc: 77.34%] [G loss: 1.211321]\n",
      "[Epoch 8/50] [Batch 21/235] [D loss: 1.143827, acc: 72.85%] [G loss: 1.349554]\n",
      "[Epoch 8/50] [Batch 22/235] [D loss: 1.135628, acc: 75.98%] [G loss: 1.326665]\n",
      "[Epoch 8/50] [Batch 23/235] [D loss: 1.155484, acc: 77.15%] [G loss: 1.314755]\n",
      "[Epoch 8/50] [Batch 24/235] [D loss: 1.121389, acc: 78.32%] [G loss: 1.315142]\n",
      "[Epoch 8/50] [Batch 25/235] [D loss: 1.116472, acc: 79.10%] [G loss: 1.192371]\n",
      "[Epoch 8/50] [Batch 26/235] [D loss: 1.105348, acc: 77.54%] [G loss: 1.230108]\n",
      "[Epoch 8/50] [Batch 27/235] [D loss: 1.122194, acc: 78.52%] [G loss: 1.354321]\n",
      "[Epoch 8/50] [Batch 28/235] [D loss: 1.098973, acc: 77.73%] [G loss: 1.274984]\n",
      "[Epoch 8/50] [Batch 29/235] [D loss: 1.166414, acc: 73.24%] [G loss: 1.286629]\n",
      "[Epoch 8/50] [Batch 30/235] [D loss: 1.152888, acc: 75.98%] [G loss: 1.298639]\n",
      "[Epoch 8/50] [Batch 31/235] [D loss: 1.125569, acc: 75.20%] [G loss: 1.351118]\n",
      "[Epoch 8/50] [Batch 32/235] [D loss: 1.153177, acc: 74.80%] [G loss: 1.202893]\n",
      "[Epoch 8/50] [Batch 33/235] [D loss: 1.128530, acc: 76.56%] [G loss: 1.370899]\n",
      "[Epoch 8/50] [Batch 34/235] [D loss: 1.123427, acc: 77.73%] [G loss: 1.242189]\n",
      "[Epoch 8/50] [Batch 35/235] [D loss: 1.131258, acc: 78.12%] [G loss: 1.366729]\n",
      "[Epoch 8/50] [Batch 36/235] [D loss: 1.202230, acc: 75.78%] [G loss: 1.336659]\n",
      "[Epoch 8/50] [Batch 37/235] [D loss: 1.119790, acc: 80.27%] [G loss: 1.193880]\n",
      "[Epoch 8/50] [Batch 38/235] [D loss: 1.153625, acc: 76.76%] [G loss: 1.206785]\n",
      "[Epoch 8/50] [Batch 39/235] [D loss: 1.129845, acc: 79.88%] [G loss: 1.265907]\n",
      "[Epoch 8/50] [Batch 40/235] [D loss: 1.087569, acc: 75.59%] [G loss: 1.266461]\n",
      "[Epoch 8/50] [Batch 41/235] [D loss: 1.157533, acc: 76.17%] [G loss: 1.215951]\n",
      "[Epoch 8/50] [Batch 42/235] [D loss: 1.174789, acc: 72.85%] [G loss: 1.217091]\n",
      "[Epoch 8/50] [Batch 43/235] [D loss: 1.131560, acc: 75.78%] [G loss: 1.229239]\n",
      "[Epoch 8/50] [Batch 44/235] [D loss: 1.085949, acc: 79.30%] [G loss: 1.210379]\n",
      "[Epoch 8/50] [Batch 45/235] [D loss: 1.109822, acc: 77.54%] [G loss: 1.238160]\n",
      "[Epoch 8/50] [Batch 46/235] [D loss: 1.146142, acc: 74.61%] [G loss: 1.338982]\n",
      "[Epoch 8/50] [Batch 47/235] [D loss: 1.116338, acc: 77.93%] [G loss: 1.323772]\n",
      "[Epoch 8/50] [Batch 48/235] [D loss: 1.153150, acc: 75.00%] [G loss: 1.156082]\n",
      "[Epoch 8/50] [Batch 49/235] [D loss: 1.161486, acc: 76.17%] [G loss: 1.324331]\n",
      "[Epoch 8/50] [Batch 50/235] [D loss: 1.153212, acc: 74.41%] [G loss: 1.241479]\n",
      "[Epoch 8/50] [Batch 51/235] [D loss: 1.164803, acc: 79.10%] [G loss: 1.351544]\n",
      "[Epoch 8/50] [Batch 52/235] [D loss: 1.149673, acc: 76.37%] [G loss: 1.256869]\n",
      "[Epoch 8/50] [Batch 53/235] [D loss: 1.131143, acc: 80.47%] [G loss: 1.230646]\n",
      "[Epoch 8/50] [Batch 54/235] [D loss: 1.139306, acc: 79.10%] [G loss: 1.100304]\n",
      "[Epoch 8/50] [Batch 55/235] [D loss: 1.147349, acc: 74.61%] [G loss: 1.298581]\n",
      "[Epoch 8/50] [Batch 56/235] [D loss: 1.186789, acc: 75.59%] [G loss: 1.439389]\n",
      "[Epoch 8/50] [Batch 57/235] [D loss: 1.151720, acc: 76.37%] [G loss: 1.263015]\n",
      "[Epoch 8/50] [Batch 58/235] [D loss: 1.124058, acc: 75.98%] [G loss: 1.244410]\n",
      "[Epoch 8/50] [Batch 59/235] [D loss: 1.096272, acc: 81.45%] [G loss: 1.217506]\n",
      "[Epoch 8/50] [Batch 60/235] [D loss: 1.083783, acc: 80.47%] [G loss: 1.238756]\n",
      "[Epoch 8/50] [Batch 61/235] [D loss: 1.151085, acc: 76.17%] [G loss: 1.316553]\n",
      "[Epoch 8/50] [Batch 62/235] [D loss: 1.111780, acc: 77.73%] [G loss: 1.269724]\n",
      "[Epoch 8/50] [Batch 63/235] [D loss: 1.150239, acc: 76.56%] [G loss: 1.312164]\n",
      "[Epoch 8/50] [Batch 64/235] [D loss: 1.132284, acc: 79.49%] [G loss: 1.216498]\n",
      "[Epoch 8/50] [Batch 65/235] [D loss: 1.099297, acc: 78.71%] [G loss: 1.312851]\n",
      "[Epoch 8/50] [Batch 66/235] [D loss: 1.166413, acc: 75.00%] [G loss: 1.298105]\n",
      "[Epoch 8/50] [Batch 67/235] [D loss: 1.174960, acc: 78.71%] [G loss: 1.203942]\n",
      "[Epoch 8/50] [Batch 68/235] [D loss: 1.147189, acc: 79.69%] [G loss: 1.257704]\n",
      "[Epoch 8/50] [Batch 69/235] [D loss: 1.153665, acc: 78.12%] [G loss: 1.287782]\n",
      "[Epoch 8/50] [Batch 70/235] [D loss: 1.124322, acc: 75.59%] [G loss: 1.199336]\n",
      "[Epoch 8/50] [Batch 71/235] [D loss: 1.141843, acc: 77.93%] [G loss: 1.215165]\n",
      "[Epoch 8/50] [Batch 72/235] [D loss: 1.152420, acc: 78.12%] [G loss: 1.344941]\n",
      "[Epoch 8/50] [Batch 73/235] [D loss: 1.151006, acc: 79.49%] [G loss: 1.323122]\n",
      "[Epoch 8/50] [Batch 74/235] [D loss: 1.123923, acc: 78.52%] [G loss: 1.223093]\n",
      "[Epoch 8/50] [Batch 75/235] [D loss: 1.190683, acc: 80.66%] [G loss: 1.253434]\n",
      "[Epoch 8/50] [Batch 76/235] [D loss: 1.132140, acc: 76.95%] [G loss: 1.336567]\n",
      "[Epoch 8/50] [Batch 77/235] [D loss: 1.130849, acc: 79.49%] [G loss: 1.308484]\n",
      "[Epoch 8/50] [Batch 78/235] [D loss: 1.157113, acc: 75.20%] [G loss: 1.265074]\n",
      "[Epoch 8/50] [Batch 79/235] [D loss: 1.186942, acc: 77.73%] [G loss: 1.295416]\n",
      "[Epoch 8/50] [Batch 80/235] [D loss: 1.101489, acc: 76.56%] [G loss: 1.294839]\n",
      "[Epoch 8/50] [Batch 81/235] [D loss: 1.149851, acc: 76.56%] [G loss: 1.289653]\n",
      "[Epoch 8/50] [Batch 82/235] [D loss: 1.123591, acc: 77.54%] [G loss: 1.238914]\n",
      "[Epoch 8/50] [Batch 83/235] [D loss: 1.135174, acc: 78.52%] [G loss: 1.340357]\n",
      "[Epoch 8/50] [Batch 84/235] [D loss: 1.128260, acc: 80.08%] [G loss: 1.366307]\n",
      "[Epoch 8/50] [Batch 85/235] [D loss: 1.121852, acc: 75.78%] [G loss: 1.241722]\n",
      "[Epoch 8/50] [Batch 86/235] [D loss: 1.197135, acc: 75.20%] [G loss: 1.203885]\n",
      "[Epoch 8/50] [Batch 87/235] [D loss: 1.153256, acc: 75.20%] [G loss: 1.249855]\n",
      "[Epoch 8/50] [Batch 88/235] [D loss: 1.145502, acc: 77.93%] [G loss: 1.239701]\n",
      "[Epoch 8/50] [Batch 89/235] [D loss: 1.096208, acc: 78.91%] [G loss: 1.303694]\n",
      "[Epoch 8/50] [Batch 90/235] [D loss: 1.170373, acc: 76.17%] [G loss: 1.297806]\n",
      "[Epoch 8/50] [Batch 91/235] [D loss: 1.152305, acc: 75.78%] [G loss: 1.318343]\n",
      "[Epoch 8/50] [Batch 92/235] [D loss: 1.157555, acc: 75.59%] [G loss: 1.210129]\n",
      "[Epoch 8/50] [Batch 93/235] [D loss: 1.164292, acc: 75.78%] [G loss: 1.201772]\n",
      "[Epoch 8/50] [Batch 94/235] [D loss: 1.126611, acc: 77.34%] [G loss: 1.229077]\n",
      "[Epoch 8/50] [Batch 95/235] [D loss: 1.104944, acc: 78.12%] [G loss: 1.383732]\n",
      "[Epoch 8/50] [Batch 96/235] [D loss: 1.167873, acc: 76.17%] [G loss: 1.271668]\n",
      "[Epoch 8/50] [Batch 97/235] [D loss: 1.116932, acc: 79.49%] [G loss: 1.246609]\n",
      "[Epoch 8/50] [Batch 98/235] [D loss: 1.124485, acc: 78.12%] [G loss: 1.309530]\n",
      "[Epoch 8/50] [Batch 99/235] [D loss: 1.127947, acc: 75.78%] [G loss: 1.251251]\n",
      "[Epoch 8/50] [Batch 100/235] [D loss: 1.116112, acc: 80.66%] [G loss: 1.249364]\n",
      "[Epoch 8/50] [Batch 101/235] [D loss: 1.121406, acc: 78.52%] [G loss: 1.254779]\n",
      "[Epoch 8/50] [Batch 102/235] [D loss: 1.153522, acc: 77.34%] [G loss: 1.257732]\n",
      "[Epoch 8/50] [Batch 103/235] [D loss: 1.162675, acc: 78.52%] [G loss: 1.418831]\n",
      "[Epoch 8/50] [Batch 104/235] [D loss: 1.170122, acc: 76.37%] [G loss: 1.122601]\n",
      "[Epoch 8/50] [Batch 105/235] [D loss: 1.145283, acc: 77.54%] [G loss: 1.299487]\n",
      "[Epoch 8/50] [Batch 106/235] [D loss: 1.127958, acc: 79.10%] [G loss: 1.297343]\n",
      "[Epoch 8/50] [Batch 107/235] [D loss: 1.135299, acc: 78.12%] [G loss: 1.212389]\n",
      "[Epoch 8/50] [Batch 108/235] [D loss: 1.134665, acc: 77.73%] [G loss: 1.293739]\n",
      "[Epoch 8/50] [Batch 109/235] [D loss: 1.135544, acc: 78.71%] [G loss: 1.288342]\n",
      "[Epoch 8/50] [Batch 110/235] [D loss: 1.140917, acc: 75.59%] [G loss: 1.292519]\n",
      "[Epoch 8/50] [Batch 111/235] [D loss: 1.151165, acc: 77.93%] [G loss: 1.192548]\n",
      "[Epoch 8/50] [Batch 112/235] [D loss: 1.145928, acc: 76.17%] [G loss: 1.242769]\n",
      "[Epoch 8/50] [Batch 113/235] [D loss: 1.154649, acc: 78.12%] [G loss: 1.348081]\n",
      "[Epoch 8/50] [Batch 114/235] [D loss: 1.166767, acc: 75.39%] [G loss: 1.127041]\n",
      "[Epoch 8/50] [Batch 115/235] [D loss: 1.137925, acc: 75.98%] [G loss: 1.354322]\n",
      "[Epoch 8/50] [Batch 116/235] [D loss: 1.183270, acc: 75.98%] [G loss: 1.469941]\n",
      "[Epoch 8/50] [Batch 117/235] [D loss: 1.126001, acc: 78.52%] [G loss: 1.243085]\n",
      "[Epoch 8/50] [Batch 118/235] [D loss: 1.167346, acc: 76.95%] [G loss: 1.143709]\n",
      "[Epoch 8/50] [Batch 119/235] [D loss: 1.170186, acc: 78.32%] [G loss: 1.270235]\n",
      "[Epoch 8/50] [Batch 120/235] [D loss: 1.137540, acc: 79.49%] [G loss: 1.236820]\n",
      "[Epoch 8/50] [Batch 121/235] [D loss: 1.108361, acc: 78.32%] [G loss: 1.272529]\n",
      "[Epoch 8/50] [Batch 122/235] [D loss: 1.113589, acc: 76.17%] [G loss: 1.258983]\n",
      "[Epoch 8/50] [Batch 123/235] [D loss: 1.119167, acc: 76.76%] [G loss: 1.320544]\n",
      "[Epoch 8/50] [Batch 124/235] [D loss: 1.106919, acc: 78.52%] [G loss: 1.217335]\n",
      "[Epoch 8/50] [Batch 125/235] [D loss: 1.116929, acc: 81.25%] [G loss: 1.325981]\n",
      "[Epoch 8/50] [Batch 126/235] [D loss: 1.104693, acc: 83.01%] [G loss: 1.371556]\n",
      "[Epoch 8/50] [Batch 127/235] [D loss: 1.139001, acc: 78.91%] [G loss: 1.136461]\n",
      "[Epoch 8/50] [Batch 128/235] [D loss: 1.148637, acc: 79.88%] [G loss: 1.298244]\n",
      "[Epoch 8/50] [Batch 129/235] [D loss: 1.103448, acc: 79.10%] [G loss: 1.263345]\n",
      "[Epoch 8/50] [Batch 130/235] [D loss: 1.143583, acc: 78.91%] [G loss: 1.192913]\n",
      "[Epoch 8/50] [Batch 131/235] [D loss: 1.115556, acc: 76.17%] [G loss: 1.291829]\n",
      "[Epoch 8/50] [Batch 132/235] [D loss: 1.125929, acc: 79.88%] [G loss: 1.395855]\n",
      "[Epoch 8/50] [Batch 133/235] [D loss: 1.117033, acc: 77.54%] [G loss: 1.335332]\n",
      "[Epoch 8/50] [Batch 134/235] [D loss: 1.136991, acc: 77.93%] [G loss: 1.305700]\n",
      "[Epoch 8/50] [Batch 135/235] [D loss: 1.173716, acc: 79.69%] [G loss: 1.251657]\n",
      "[Epoch 8/50] [Batch 136/235] [D loss: 1.147884, acc: 74.41%] [G loss: 1.289449]\n",
      "[Epoch 8/50] [Batch 137/235] [D loss: 1.130624, acc: 82.23%] [G loss: 1.221009]\n",
      "[Epoch 8/50] [Batch 138/235] [D loss: 1.094253, acc: 78.91%] [G loss: 1.221049]\n",
      "[Epoch 8/50] [Batch 139/235] [D loss: 1.143642, acc: 79.10%] [G loss: 1.250964]\n",
      "[Epoch 8/50] [Batch 140/235] [D loss: 1.164199, acc: 77.15%] [G loss: 1.312010]\n",
      "[Epoch 8/50] [Batch 141/235] [D loss: 1.157210, acc: 79.49%] [G loss: 1.204904]\n",
      "[Epoch 8/50] [Batch 142/235] [D loss: 1.096417, acc: 79.49%] [G loss: 1.289550]\n",
      "[Epoch 8/50] [Batch 143/235] [D loss: 1.117714, acc: 75.98%] [G loss: 1.173841]\n",
      "[Epoch 8/50] [Batch 144/235] [D loss: 1.146469, acc: 80.66%] [G loss: 1.328503]\n",
      "[Epoch 8/50] [Batch 145/235] [D loss: 1.164054, acc: 77.73%] [G loss: 1.308329]\n",
      "[Epoch 8/50] [Batch 146/235] [D loss: 1.149264, acc: 78.71%] [G loss: 1.261689]\n",
      "[Epoch 8/50] [Batch 147/235] [D loss: 1.141614, acc: 78.71%] [G loss: 1.254490]\n",
      "[Epoch 8/50] [Batch 148/235] [D loss: 1.107631, acc: 79.69%] [G loss: 1.319365]\n",
      "[Epoch 8/50] [Batch 149/235] [D loss: 1.106615, acc: 76.37%] [G loss: 1.244089]\n",
      "[Epoch 8/50] [Batch 150/235] [D loss: 1.121545, acc: 80.27%] [G loss: 1.207494]\n",
      "[Epoch 8/50] [Batch 151/235] [D loss: 1.142799, acc: 77.34%] [G loss: 1.281384]\n",
      "[Epoch 8/50] [Batch 152/235] [D loss: 1.106416, acc: 80.66%] [G loss: 1.266703]\n",
      "[Epoch 8/50] [Batch 153/235] [D loss: 1.105030, acc: 81.64%] [G loss: 1.278745]\n",
      "[Epoch 8/50] [Batch 154/235] [D loss: 1.150994, acc: 80.66%] [G loss: 1.141773]\n",
      "[Epoch 8/50] [Batch 155/235] [D loss: 1.122596, acc: 81.05%] [G loss: 1.281100]\n",
      "[Epoch 8/50] [Batch 156/235] [D loss: 1.122215, acc: 81.84%] [G loss: 1.209458]\n",
      "[Epoch 8/50] [Batch 157/235] [D loss: 1.123110, acc: 78.91%] [G loss: 1.336030]\n",
      "[Epoch 8/50] [Batch 158/235] [D loss: 1.153431, acc: 77.15%] [G loss: 1.217869]\n",
      "[Epoch 8/50] [Batch 159/235] [D loss: 1.137080, acc: 78.71%] [G loss: 1.255084]\n",
      "[Epoch 8/50] [Batch 160/235] [D loss: 1.151896, acc: 76.56%] [G loss: 1.306510]\n",
      "[Epoch 8/50] [Batch 161/235] [D loss: 1.127969, acc: 80.47%] [G loss: 1.334169]\n",
      "[Epoch 8/50] [Batch 162/235] [D loss: 1.097620, acc: 78.52%] [G loss: 1.306587]\n",
      "[Epoch 8/50] [Batch 163/235] [D loss: 1.150050, acc: 79.49%] [G loss: 1.156341]\n",
      "[Epoch 8/50] [Batch 164/235] [D loss: 1.146209, acc: 77.73%] [G loss: 1.310069]\n",
      "[Epoch 8/50] [Batch 165/235] [D loss: 1.130945, acc: 80.27%] [G loss: 1.304767]\n",
      "[Epoch 8/50] [Batch 166/235] [D loss: 1.176939, acc: 80.66%] [G loss: 1.243085]\n",
      "[Epoch 8/50] [Batch 167/235] [D loss: 1.157231, acc: 81.05%] [G loss: 1.238434]\n",
      "[Epoch 8/50] [Batch 168/235] [D loss: 1.096187, acc: 79.69%] [G loss: 1.412868]\n",
      "[Epoch 8/50] [Batch 169/235] [D loss: 1.132819, acc: 80.08%] [G loss: 1.342758]\n",
      "[Epoch 8/50] [Batch 170/235] [D loss: 1.175067, acc: 78.32%] [G loss: 1.283542]\n",
      "[Epoch 8/50] [Batch 171/235] [D loss: 1.081321, acc: 81.64%] [G loss: 1.278469]\n",
      "[Epoch 8/50] [Batch 172/235] [D loss: 1.103685, acc: 80.66%] [G loss: 1.276156]\n",
      "[Epoch 8/50] [Batch 173/235] [D loss: 1.104431, acc: 78.91%] [G loss: 1.251664]\n",
      "[Epoch 8/50] [Batch 174/235] [D loss: 1.111657, acc: 79.49%] [G loss: 1.270909]\n",
      "[Epoch 8/50] [Batch 175/235] [D loss: 1.116596, acc: 82.62%] [G loss: 1.305076]\n",
      "[Epoch 8/50] [Batch 176/235] [D loss: 1.110768, acc: 79.49%] [G loss: 1.263141]\n",
      "[Epoch 8/50] [Batch 177/235] [D loss: 1.118767, acc: 79.30%] [G loss: 1.239455]\n",
      "[Epoch 8/50] [Batch 178/235] [D loss: 1.126328, acc: 82.81%] [G loss: 1.262333]\n",
      "[Epoch 8/50] [Batch 179/235] [D loss: 1.161424, acc: 80.27%] [G loss: 1.295815]\n",
      "[Epoch 8/50] [Batch 180/235] [D loss: 1.119117, acc: 79.88%] [G loss: 1.206739]\n",
      "[Epoch 8/50] [Batch 181/235] [D loss: 1.166384, acc: 78.32%] [G loss: 1.425244]\n",
      "[Epoch 8/50] [Batch 182/235] [D loss: 1.149630, acc: 77.15%] [G loss: 1.312532]\n",
      "[Epoch 8/50] [Batch 183/235] [D loss: 1.132259, acc: 80.08%] [G loss: 1.216408]\n",
      "[Epoch 8/50] [Batch 184/235] [D loss: 1.127578, acc: 79.30%] [G loss: 1.400907]\n",
      "[Epoch 8/50] [Batch 185/235] [D loss: 1.186556, acc: 77.34%] [G loss: 1.183250]\n",
      "[Epoch 8/50] [Batch 186/235] [D loss: 1.138038, acc: 81.84%] [G loss: 1.388071]\n",
      "[Epoch 8/50] [Batch 187/235] [D loss: 1.111005, acc: 82.03%] [G loss: 1.310571]\n",
      "[Epoch 8/50] [Batch 188/235] [D loss: 1.137827, acc: 80.66%] [G loss: 1.198909]\n",
      "[Epoch 8/50] [Batch 189/235] [D loss: 1.125053, acc: 82.23%] [G loss: 1.246533]\n",
      "[Epoch 8/50] [Batch 190/235] [D loss: 1.122989, acc: 80.27%] [G loss: 1.329671]\n",
      "[Epoch 8/50] [Batch 191/235] [D loss: 1.153643, acc: 78.91%] [G loss: 1.253202]\n",
      "[Epoch 8/50] [Batch 192/235] [D loss: 1.127577, acc: 78.12%] [G loss: 1.201755]\n",
      "[Epoch 8/50] [Batch 193/235] [D loss: 1.173014, acc: 78.32%] [G loss: 1.243106]\n",
      "[Epoch 8/50] [Batch 194/235] [D loss: 1.135154, acc: 80.27%] [G loss: 1.263097]\n",
      "[Epoch 8/50] [Batch 195/235] [D loss: 1.174146, acc: 75.39%] [G loss: 1.296928]\n",
      "[Epoch 8/50] [Batch 196/235] [D loss: 1.120062, acc: 79.69%] [G loss: 1.274859]\n",
      "[Epoch 8/50] [Batch 197/235] [D loss: 1.125739, acc: 81.25%] [G loss: 1.312108]\n",
      "[Epoch 8/50] [Batch 198/235] [D loss: 1.151550, acc: 82.62%] [G loss: 1.341002]\n",
      "[Epoch 8/50] [Batch 199/235] [D loss: 1.120738, acc: 77.54%] [G loss: 1.274360]\n",
      "[Epoch 8/50] [Batch 200/235] [D loss: 1.160976, acc: 79.30%] [G loss: 1.345480]\n",
      "[Epoch 8/50] [Batch 201/235] [D loss: 1.127520, acc: 82.03%] [G loss: 1.224737]\n",
      "[Epoch 8/50] [Batch 202/235] [D loss: 1.136240, acc: 78.71%] [G loss: 1.257216]\n",
      "[Epoch 8/50] [Batch 203/235] [D loss: 1.130134, acc: 78.12%] [G loss: 1.284279]\n",
      "[Epoch 8/50] [Batch 204/235] [D loss: 1.180878, acc: 80.66%] [G loss: 1.434978]\n",
      "[Epoch 8/50] [Batch 205/235] [D loss: 1.087984, acc: 80.66%] [G loss: 1.276815]\n",
      "[Epoch 8/50] [Batch 206/235] [D loss: 1.112761, acc: 76.95%] [G loss: 1.225029]\n",
      "[Epoch 8/50] [Batch 207/235] [D loss: 1.140164, acc: 80.27%] [G loss: 1.331736]\n",
      "[Epoch 8/50] [Batch 208/235] [D loss: 1.117445, acc: 82.42%] [G loss: 1.175133]\n",
      "[Epoch 8/50] [Batch 209/235] [D loss: 1.144823, acc: 79.69%] [G loss: 1.435940]\n",
      "[Epoch 8/50] [Batch 210/235] [D loss: 1.102233, acc: 79.30%] [G loss: 1.291240]\n",
      "[Epoch 8/50] [Batch 211/235] [D loss: 1.100755, acc: 79.88%] [G loss: 1.268865]\n",
      "[Epoch 8/50] [Batch 212/235] [D loss: 1.110400, acc: 79.69%] [G loss: 1.243082]\n",
      "[Epoch 8/50] [Batch 213/235] [D loss: 1.133238, acc: 78.71%] [G loss: 1.260021]\n",
      "[Epoch 8/50] [Batch 214/235] [D loss: 1.109713, acc: 81.05%] [G loss: 1.196209]\n",
      "[Epoch 8/50] [Batch 215/235] [D loss: 1.109669, acc: 81.45%] [G loss: 1.122265]\n",
      "[Epoch 8/50] [Batch 216/235] [D loss: 1.127879, acc: 80.86%] [G loss: 1.257668]\n",
      "[Epoch 8/50] [Batch 217/235] [D loss: 1.106163, acc: 83.20%] [G loss: 1.271364]\n",
      "[Epoch 8/50] [Batch 218/235] [D loss: 1.096293, acc: 81.25%] [G loss: 1.352810]\n",
      "[Epoch 8/50] [Batch 219/235] [D loss: 1.153080, acc: 79.69%] [G loss: 1.182976]\n",
      "[Epoch 8/50] [Batch 220/235] [D loss: 1.137649, acc: 83.01%] [G loss: 1.327350]\n",
      "[Epoch 8/50] [Batch 221/235] [D loss: 1.106404, acc: 81.45%] [G loss: 1.259911]\n",
      "[Epoch 8/50] [Batch 222/235] [D loss: 1.115701, acc: 76.95%] [G loss: 1.274909]\n",
      "[Epoch 8/50] [Batch 223/235] [D loss: 1.127286, acc: 80.66%] [G loss: 1.265532]\n",
      "[Epoch 8/50] [Batch 224/235] [D loss: 1.138778, acc: 79.49%] [G loss: 1.310056]\n",
      "[Epoch 8/50] [Batch 225/235] [D loss: 1.139320, acc: 80.27%] [G loss: 1.330370]\n",
      "[Epoch 8/50] [Batch 226/235] [D loss: 1.120439, acc: 82.62%] [G loss: 1.234813]\n",
      "[Epoch 8/50] [Batch 227/235] [D loss: 1.130826, acc: 81.25%] [G loss: 1.132748]\n",
      "[Epoch 8/50] [Batch 228/235] [D loss: 1.109934, acc: 82.03%] [G loss: 1.210592]\n",
      "[Epoch 8/50] [Batch 229/235] [D loss: 1.159268, acc: 78.91%] [G loss: 1.297676]\n",
      "[Epoch 8/50] [Batch 230/235] [D loss: 1.089180, acc: 79.49%] [G loss: 1.261602]\n",
      "[Epoch 8/50] [Batch 231/235] [D loss: 1.118292, acc: 81.64%] [G loss: 1.199753]\n",
      "[Epoch 8/50] [Batch 232/235] [D loss: 1.171159, acc: 80.66%] [G loss: 1.246989]\n",
      "[Epoch 8/50] [Batch 233/235] [D loss: 1.134740, acc: 76.95%] [G loss: 1.234933]\n",
      "[Epoch 8/50] [Batch 234/235] [D loss: 1.188883, acc: 80.73%] [G loss: 1.311054]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/50] [Batch 0/235] [D loss: 1.124529, acc: 81.25%] [G loss: 1.165262]\n",
      "[Epoch 9/50] [Batch 1/235] [D loss: 1.113547, acc: 83.01%] [G loss: 1.186132]\n",
      "[Epoch 9/50] [Batch 2/235] [D loss: 1.095641, acc: 79.88%] [G loss: 1.266986]\n",
      "[Epoch 9/50] [Batch 3/235] [D loss: 1.101267, acc: 81.45%] [G loss: 1.271020]\n",
      "[Epoch 9/50] [Batch 4/235] [D loss: 1.105148, acc: 79.10%] [G loss: 1.240276]\n",
      "[Epoch 9/50] [Batch 5/235] [D loss: 1.140908, acc: 79.30%] [G loss: 1.155365]\n",
      "[Epoch 9/50] [Batch 6/235] [D loss: 1.117457, acc: 79.88%] [G loss: 1.245690]\n",
      "[Epoch 9/50] [Batch 7/235] [D loss: 1.154331, acc: 79.10%] [G loss: 1.141962]\n",
      "[Epoch 9/50] [Batch 8/235] [D loss: 1.100668, acc: 81.84%] [G loss: 1.218046]\n",
      "[Epoch 9/50] [Batch 9/235] [D loss: 1.061677, acc: 83.40%] [G loss: 1.334958]\n",
      "[Epoch 9/50] [Batch 10/235] [D loss: 1.103132, acc: 84.77%] [G loss: 1.381827]\n",
      "[Epoch 9/50] [Batch 11/235] [D loss: 1.143745, acc: 83.59%] [G loss: 1.133978]\n",
      "[Epoch 9/50] [Batch 12/235] [D loss: 1.143761, acc: 80.66%] [G loss: 1.086054]\n",
      "[Epoch 9/50] [Batch 13/235] [D loss: 1.092151, acc: 80.66%] [G loss: 1.301091]\n",
      "[Epoch 9/50] [Batch 14/235] [D loss: 1.090095, acc: 79.88%] [G loss: 1.407243]\n",
      "[Epoch 9/50] [Batch 15/235] [D loss: 1.103164, acc: 79.69%] [G loss: 1.183306]\n",
      "[Epoch 9/50] [Batch 16/235] [D loss: 1.166578, acc: 78.71%] [G loss: 1.173330]\n",
      "[Epoch 9/50] [Batch 17/235] [D loss: 1.120271, acc: 77.73%] [G loss: 1.256119]\n",
      "[Epoch 9/50] [Batch 18/235] [D loss: 1.144931, acc: 79.88%] [G loss: 1.242930]\n",
      "[Epoch 9/50] [Batch 19/235] [D loss: 1.127377, acc: 81.45%] [G loss: 1.258142]\n",
      "[Epoch 9/50] [Batch 20/235] [D loss: 1.152677, acc: 79.30%] [G loss: 1.295311]\n",
      "[Epoch 9/50] [Batch 21/235] [D loss: 1.143620, acc: 81.25%] [G loss: 1.200072]\n",
      "[Epoch 9/50] [Batch 22/235] [D loss: 1.129876, acc: 77.54%] [G loss: 1.262403]\n",
      "[Epoch 9/50] [Batch 23/235] [D loss: 1.155028, acc: 78.52%] [G loss: 1.295948]\n",
      "[Epoch 9/50] [Batch 24/235] [D loss: 1.211810, acc: 80.08%] [G loss: 1.230590]\n",
      "[Epoch 9/50] [Batch 25/235] [D loss: 1.152289, acc: 79.69%] [G loss: 1.245000]\n",
      "[Epoch 9/50] [Batch 26/235] [D loss: 1.159886, acc: 81.25%] [G loss: 1.270324]\n",
      "[Epoch 9/50] [Batch 27/235] [D loss: 1.109065, acc: 83.79%] [G loss: 1.163859]\n",
      "[Epoch 9/50] [Batch 28/235] [D loss: 1.158210, acc: 82.81%] [G loss: 1.233722]\n",
      "[Epoch 9/50] [Batch 29/235] [D loss: 1.117159, acc: 84.38%] [G loss: 1.196509]\n",
      "[Epoch 9/50] [Batch 30/235] [D loss: 1.096989, acc: 81.64%] [G loss: 1.195578]\n",
      "[Epoch 9/50] [Batch 31/235] [D loss: 1.154540, acc: 83.01%] [G loss: 1.183313]\n",
      "[Epoch 9/50] [Batch 32/235] [D loss: 1.101948, acc: 80.27%] [G loss: 1.259066]\n",
      "[Epoch 9/50] [Batch 33/235] [D loss: 1.104866, acc: 81.45%] [G loss: 1.155700]\n",
      "[Epoch 9/50] [Batch 34/235] [D loss: 1.150275, acc: 78.91%] [G loss: 1.293542]\n",
      "[Epoch 9/50] [Batch 35/235] [D loss: 1.140838, acc: 81.05%] [G loss: 1.252481]\n",
      "[Epoch 9/50] [Batch 36/235] [D loss: 1.171832, acc: 80.08%] [G loss: 1.314846]\n",
      "[Epoch 9/50] [Batch 37/235] [D loss: 1.118531, acc: 79.69%] [G loss: 1.236543]\n",
      "[Epoch 9/50] [Batch 38/235] [D loss: 1.144048, acc: 81.25%] [G loss: 1.249849]\n",
      "[Epoch 9/50] [Batch 39/235] [D loss: 1.143016, acc: 82.42%] [G loss: 1.297720]\n",
      "[Epoch 9/50] [Batch 40/235] [D loss: 1.152279, acc: 83.40%] [G loss: 1.203739]\n",
      "[Epoch 9/50] [Batch 41/235] [D loss: 1.122763, acc: 79.88%] [G loss: 1.237000]\n",
      "[Epoch 9/50] [Batch 42/235] [D loss: 1.144148, acc: 76.95%] [G loss: 1.245130]\n",
      "[Epoch 9/50] [Batch 43/235] [D loss: 1.089608, acc: 82.23%] [G loss: 1.182879]\n",
      "[Epoch 9/50] [Batch 44/235] [D loss: 1.118713, acc: 78.91%] [G loss: 1.218372]\n",
      "[Epoch 9/50] [Batch 45/235] [D loss: 1.123373, acc: 80.47%] [G loss: 1.316728]\n",
      "[Epoch 9/50] [Batch 46/235] [D loss: 1.130267, acc: 82.62%] [G loss: 1.137008]\n",
      "[Epoch 9/50] [Batch 47/235] [D loss: 1.134368, acc: 83.20%] [G loss: 1.263670]\n",
      "[Epoch 9/50] [Batch 48/235] [D loss: 1.106101, acc: 81.25%] [G loss: 1.344742]\n",
      "[Epoch 9/50] [Batch 49/235] [D loss: 1.138468, acc: 81.45%] [G loss: 1.264374]\n",
      "[Epoch 9/50] [Batch 50/235] [D loss: 1.098787, acc: 82.81%] [G loss: 1.236038]\n",
      "[Epoch 9/50] [Batch 51/235] [D loss: 1.145051, acc: 80.47%] [G loss: 1.146289]\n",
      "[Epoch 9/50] [Batch 52/235] [D loss: 1.073967, acc: 83.40%] [G loss: 1.342732]\n",
      "[Epoch 9/50] [Batch 53/235] [D loss: 1.094860, acc: 79.30%] [G loss: 1.314954]\n",
      "[Epoch 9/50] [Batch 54/235] [D loss: 1.105507, acc: 83.20%] [G loss: 1.169734]\n",
      "[Epoch 9/50] [Batch 55/235] [D loss: 1.106652, acc: 79.69%] [G loss: 1.360492]\n",
      "[Epoch 9/50] [Batch 56/235] [D loss: 1.122456, acc: 82.62%] [G loss: 1.195043]\n",
      "[Epoch 9/50] [Batch 57/235] [D loss: 1.139849, acc: 77.73%] [G loss: 1.259838]\n",
      "[Epoch 9/50] [Batch 58/235] [D loss: 1.155298, acc: 78.32%] [G loss: 1.191151]\n",
      "[Epoch 9/50] [Batch 59/235] [D loss: 1.085563, acc: 86.33%] [G loss: 1.168746]\n",
      "[Epoch 9/50] [Batch 60/235] [D loss: 1.138316, acc: 82.42%] [G loss: 1.409315]\n",
      "[Epoch 9/50] [Batch 61/235] [D loss: 1.062693, acc: 81.45%] [G loss: 1.236272]\n",
      "[Epoch 9/50] [Batch 62/235] [D loss: 1.121807, acc: 79.30%] [G loss: 1.244669]\n",
      "[Epoch 9/50] [Batch 63/235] [D loss: 1.138784, acc: 80.27%] [G loss: 1.196205]\n",
      "[Epoch 9/50] [Batch 64/235] [D loss: 1.095969, acc: 80.66%] [G loss: 1.286870]\n",
      "[Epoch 9/50] [Batch 65/235] [D loss: 1.103501, acc: 80.08%] [G loss: 1.329261]\n",
      "[Epoch 9/50] [Batch 66/235] [D loss: 1.107784, acc: 82.62%] [G loss: 1.193445]\n",
      "[Epoch 9/50] [Batch 67/235] [D loss: 1.081487, acc: 83.59%] [G loss: 1.170116]\n",
      "[Epoch 9/50] [Batch 68/235] [D loss: 1.120567, acc: 81.84%] [G loss: 1.188401]\n",
      "[Epoch 9/50] [Batch 69/235] [D loss: 1.120425, acc: 81.84%] [G loss: 1.270846]\n",
      "[Epoch 9/50] [Batch 70/235] [D loss: 1.109452, acc: 84.38%] [G loss: 1.161730]\n",
      "[Epoch 9/50] [Batch 71/235] [D loss: 1.120735, acc: 81.84%] [G loss: 1.197971]\n",
      "[Epoch 9/50] [Batch 72/235] [D loss: 1.100719, acc: 83.79%] [G loss: 1.292226]\n",
      "[Epoch 9/50] [Batch 73/235] [D loss: 1.115837, acc: 80.27%] [G loss: 1.290864]\n",
      "[Epoch 9/50] [Batch 74/235] [D loss: 1.083787, acc: 81.05%] [G loss: 1.240340]\n",
      "[Epoch 9/50] [Batch 75/235] [D loss: 1.091101, acc: 82.62%] [G loss: 1.297241]\n",
      "[Epoch 9/50] [Batch 76/235] [D loss: 1.110880, acc: 80.47%] [G loss: 1.410089]\n",
      "[Epoch 9/50] [Batch 77/235] [D loss: 1.135401, acc: 84.57%] [G loss: 1.132558]\n",
      "[Epoch 9/50] [Batch 78/235] [D loss: 1.155970, acc: 79.88%] [G loss: 1.247784]\n",
      "[Epoch 9/50] [Batch 79/235] [D loss: 1.152477, acc: 82.23%] [G loss: 1.312023]\n",
      "[Epoch 9/50] [Batch 80/235] [D loss: 1.083568, acc: 80.27%] [G loss: 1.339725]\n",
      "[Epoch 9/50] [Batch 81/235] [D loss: 1.167228, acc: 81.64%] [G loss: 1.227828]\n",
      "[Epoch 9/50] [Batch 82/235] [D loss: 1.131084, acc: 79.49%] [G loss: 1.318519]\n",
      "[Epoch 9/50] [Batch 83/235] [D loss: 1.090460, acc: 80.66%] [G loss: 1.258320]\n",
      "[Epoch 9/50] [Batch 84/235] [D loss: 1.123249, acc: 81.45%] [G loss: 1.348242]\n",
      "[Epoch 9/50] [Batch 85/235] [D loss: 1.098389, acc: 83.59%] [G loss: 1.267574]\n",
      "[Epoch 9/50] [Batch 86/235] [D loss: 1.146062, acc: 81.05%] [G loss: 1.118453]\n",
      "[Epoch 9/50] [Batch 87/235] [D loss: 1.134469, acc: 82.81%] [G loss: 1.316791]\n",
      "[Epoch 9/50] [Batch 88/235] [D loss: 1.135065, acc: 83.79%] [G loss: 1.272636]\n",
      "[Epoch 9/50] [Batch 89/235] [D loss: 1.141102, acc: 80.86%] [G loss: 1.320752]\n",
      "[Epoch 9/50] [Batch 90/235] [D loss: 1.170769, acc: 80.47%] [G loss: 1.198395]\n",
      "[Epoch 9/50] [Batch 91/235] [D loss: 1.110250, acc: 82.42%] [G loss: 1.248701]\n",
      "[Epoch 9/50] [Batch 92/235] [D loss: 1.135973, acc: 82.23%] [G loss: 1.333390]\n",
      "[Epoch 9/50] [Batch 93/235] [D loss: 1.138152, acc: 80.47%] [G loss: 1.273466]\n",
      "[Epoch 9/50] [Batch 94/235] [D loss: 1.131778, acc: 81.45%] [G loss: 1.333953]\n",
      "[Epoch 9/50] [Batch 95/235] [D loss: 1.115044, acc: 80.27%] [G loss: 1.158568]\n",
      "[Epoch 9/50] [Batch 96/235] [D loss: 1.128474, acc: 82.03%] [G loss: 1.176269]\n",
      "[Epoch 9/50] [Batch 97/235] [D loss: 1.145693, acc: 84.38%] [G loss: 1.249048]\n",
      "[Epoch 9/50] [Batch 98/235] [D loss: 1.139009, acc: 82.23%] [G loss: 1.289559]\n",
      "[Epoch 9/50] [Batch 99/235] [D loss: 1.118424, acc: 81.45%] [G loss: 1.188595]\n",
      "[Epoch 9/50] [Batch 100/235] [D loss: 1.115436, acc: 82.42%] [G loss: 1.253535]\n",
      "[Epoch 9/50] [Batch 101/235] [D loss: 1.145622, acc: 84.57%] [G loss: 1.286924]\n",
      "[Epoch 9/50] [Batch 102/235] [D loss: 1.104930, acc: 81.25%] [G loss: 1.344194]\n",
      "[Epoch 9/50] [Batch 103/235] [D loss: 1.157645, acc: 82.23%] [G loss: 1.307221]\n",
      "[Epoch 9/50] [Batch 104/235] [D loss: 1.150137, acc: 83.20%] [G loss: 1.071211]\n",
      "[Epoch 9/50] [Batch 105/235] [D loss: 1.094657, acc: 84.77%] [G loss: 1.175842]\n",
      "[Epoch 9/50] [Batch 106/235] [D loss: 1.137393, acc: 82.62%] [G loss: 1.307544]\n",
      "[Epoch 9/50] [Batch 107/235] [D loss: 1.104087, acc: 83.98%] [G loss: 1.189707]\n",
      "[Epoch 9/50] [Batch 108/235] [D loss: 1.143053, acc: 81.05%] [G loss: 1.261899]\n",
      "[Epoch 9/50] [Batch 109/235] [D loss: 1.119664, acc: 84.38%] [G loss: 1.268597]\n",
      "[Epoch 9/50] [Batch 110/235] [D loss: 1.092435, acc: 81.84%] [G loss: 1.282240]\n",
      "[Epoch 9/50] [Batch 111/235] [D loss: 1.108178, acc: 80.27%] [G loss: 1.124865]\n",
      "[Epoch 9/50] [Batch 112/235] [D loss: 1.112804, acc: 83.20%] [G loss: 1.138966]\n",
      "[Epoch 9/50] [Batch 113/235] [D loss: 1.106614, acc: 82.81%] [G loss: 1.188372]\n",
      "[Epoch 9/50] [Batch 114/235] [D loss: 1.124859, acc: 81.05%] [G loss: 1.318227]\n",
      "[Epoch 9/50] [Batch 115/235] [D loss: 1.144457, acc: 80.86%] [G loss: 1.131533]\n",
      "[Epoch 9/50] [Batch 116/235] [D loss: 1.145508, acc: 76.37%] [G loss: 1.161623]\n",
      "[Epoch 9/50] [Batch 117/235] [D loss: 1.098624, acc: 83.79%] [G loss: 1.290166]\n",
      "[Epoch 9/50] [Batch 118/235] [D loss: 1.100132, acc: 83.59%] [G loss: 1.371486]\n",
      "[Epoch 9/50] [Batch 119/235] [D loss: 1.142308, acc: 79.49%] [G loss: 1.296452]\n",
      "[Epoch 9/50] [Batch 120/235] [D loss: 1.081578, acc: 82.42%] [G loss: 1.145142]\n",
      "[Epoch 9/50] [Batch 121/235] [D loss: 1.116650, acc: 81.25%] [G loss: 1.157303]\n",
      "[Epoch 9/50] [Batch 122/235] [D loss: 1.083792, acc: 82.23%] [G loss: 1.450558]\n",
      "[Epoch 9/50] [Batch 123/235] [D loss: 1.141368, acc: 82.03%] [G loss: 1.239814]\n",
      "[Epoch 9/50] [Batch 124/235] [D loss: 1.109242, acc: 81.84%] [G loss: 1.221742]\n",
      "[Epoch 9/50] [Batch 125/235] [D loss: 1.115137, acc: 83.40%] [G loss: 1.184247]\n",
      "[Epoch 9/50] [Batch 126/235] [D loss: 1.117681, acc: 82.42%] [G loss: 1.243454]\n",
      "[Epoch 9/50] [Batch 127/235] [D loss: 1.090560, acc: 82.62%] [G loss: 1.208577]\n",
      "[Epoch 9/50] [Batch 128/235] [D loss: 1.125751, acc: 83.79%] [G loss: 1.223719]\n",
      "[Epoch 9/50] [Batch 129/235] [D loss: 1.113634, acc: 83.01%] [G loss: 1.243056]\n",
      "[Epoch 9/50] [Batch 130/235] [D loss: 1.147178, acc: 80.47%] [G loss: 1.278076]\n",
      "[Epoch 9/50] [Batch 131/235] [D loss: 1.123055, acc: 86.52%] [G loss: 1.245535]\n",
      "[Epoch 9/50] [Batch 132/235] [D loss: 1.137096, acc: 79.69%] [G loss: 1.313536]\n",
      "[Epoch 9/50] [Batch 133/235] [D loss: 1.150185, acc: 83.79%] [G loss: 1.296642]\n",
      "[Epoch 9/50] [Batch 134/235] [D loss: 1.136791, acc: 79.49%] [G loss: 1.312692]\n",
      "[Epoch 9/50] [Batch 135/235] [D loss: 1.127383, acc: 81.45%] [G loss: 1.159801]\n",
      "[Epoch 9/50] [Batch 136/235] [D loss: 1.131372, acc: 81.84%] [G loss: 1.158191]\n",
      "[Epoch 9/50] [Batch 137/235] [D loss: 1.104538, acc: 82.62%] [G loss: 1.308520]\n",
      "[Epoch 9/50] [Batch 138/235] [D loss: 1.123489, acc: 83.01%] [G loss: 1.185147]\n",
      "[Epoch 9/50] [Batch 139/235] [D loss: 1.081089, acc: 83.59%] [G loss: 1.250933]\n",
      "[Epoch 9/50] [Batch 140/235] [D loss: 1.093332, acc: 82.81%] [G loss: 1.227082]\n",
      "[Epoch 9/50] [Batch 141/235] [D loss: 1.084522, acc: 82.03%] [G loss: 1.306933]\n",
      "[Epoch 9/50] [Batch 142/235] [D loss: 1.133937, acc: 80.66%] [G loss: 1.251377]\n",
      "[Epoch 9/50] [Batch 143/235] [D loss: 1.075616, acc: 81.84%] [G loss: 1.148589]\n",
      "[Epoch 9/50] [Batch 144/235] [D loss: 1.117727, acc: 82.23%] [G loss: 1.242399]\n",
      "[Epoch 9/50] [Batch 145/235] [D loss: 1.111915, acc: 81.25%] [G loss: 1.374202]\n",
      "[Epoch 9/50] [Batch 146/235] [D loss: 1.081961, acc: 81.25%] [G loss: 1.238441]\n",
      "[Epoch 9/50] [Batch 147/235] [D loss: 1.068089, acc: 83.20%] [G loss: 1.297159]\n",
      "[Epoch 9/50] [Batch 148/235] [D loss: 1.111593, acc: 84.38%] [G loss: 1.275486]\n",
      "[Epoch 9/50] [Batch 149/235] [D loss: 1.150807, acc: 80.86%] [G loss: 1.163049]\n",
      "[Epoch 9/50] [Batch 150/235] [D loss: 1.159552, acc: 83.40%] [G loss: 1.225369]\n",
      "[Epoch 9/50] [Batch 151/235] [D loss: 1.088064, acc: 83.40%] [G loss: 1.291605]\n",
      "[Epoch 9/50] [Batch 152/235] [D loss: 1.130562, acc: 82.42%] [G loss: 1.339044]\n",
      "[Epoch 9/50] [Batch 153/235] [D loss: 1.128200, acc: 81.64%] [G loss: 1.266365]\n",
      "[Epoch 9/50] [Batch 154/235] [D loss: 1.127577, acc: 82.42%] [G loss: 1.382667]\n",
      "[Epoch 9/50] [Batch 155/235] [D loss: 1.130203, acc: 81.05%] [G loss: 1.198049]\n",
      "[Epoch 9/50] [Batch 156/235] [D loss: 1.129473, acc: 82.81%] [G loss: 1.222165]\n",
      "[Epoch 9/50] [Batch 157/235] [D loss: 1.122911, acc: 82.42%] [G loss: 1.479312]\n",
      "[Epoch 9/50] [Batch 158/235] [D loss: 1.107105, acc: 81.45%] [G loss: 1.159659]\n",
      "[Epoch 9/50] [Batch 159/235] [D loss: 1.125921, acc: 77.93%] [G loss: 1.172268]\n",
      "[Epoch 9/50] [Batch 160/235] [D loss: 1.086919, acc: 82.23%] [G loss: 1.319725]\n",
      "[Epoch 9/50] [Batch 161/235] [D loss: 1.119517, acc: 77.73%] [G loss: 1.238684]\n",
      "[Epoch 9/50] [Batch 162/235] [D loss: 1.087107, acc: 81.05%] [G loss: 1.276731]\n",
      "[Epoch 9/50] [Batch 163/235] [D loss: 1.102079, acc: 82.03%] [G loss: 1.213227]\n",
      "[Epoch 9/50] [Batch 164/235] [D loss: 1.102505, acc: 83.01%] [G loss: 1.306556]\n",
      "[Epoch 9/50] [Batch 165/235] [D loss: 1.129726, acc: 83.01%] [G loss: 1.215348]\n",
      "[Epoch 9/50] [Batch 166/235] [D loss: 1.115595, acc: 80.86%] [G loss: 1.210611]\n",
      "[Epoch 9/50] [Batch 167/235] [D loss: 1.091944, acc: 81.05%] [G loss: 1.242301]\n",
      "[Epoch 9/50] [Batch 168/235] [D loss: 1.122903, acc: 82.62%] [G loss: 1.336050]\n",
      "[Epoch 9/50] [Batch 169/235] [D loss: 1.136383, acc: 83.20%] [G loss: 1.178880]\n",
      "[Epoch 9/50] [Batch 170/235] [D loss: 1.115096, acc: 82.42%] [G loss: 1.166260]\n",
      "[Epoch 9/50] [Batch 171/235] [D loss: 1.145284, acc: 79.10%] [G loss: 1.247433]\n",
      "[Epoch 9/50] [Batch 172/235] [D loss: 1.118282, acc: 84.77%] [G loss: 1.359349]\n",
      "[Epoch 9/50] [Batch 173/235] [D loss: 1.112625, acc: 81.84%] [G loss: 1.268608]\n",
      "[Epoch 9/50] [Batch 174/235] [D loss: 1.105817, acc: 82.81%] [G loss: 1.217531]\n",
      "[Epoch 9/50] [Batch 175/235] [D loss: 1.115575, acc: 82.03%] [G loss: 1.151422]\n",
      "[Epoch 9/50] [Batch 176/235] [D loss: 1.121473, acc: 83.59%] [G loss: 1.323974]\n",
      "[Epoch 9/50] [Batch 177/235] [D loss: 1.139348, acc: 81.05%] [G loss: 1.327306]\n",
      "[Epoch 9/50] [Batch 178/235] [D loss: 1.125445, acc: 84.77%] [G loss: 1.194750]\n",
      "[Epoch 9/50] [Batch 179/235] [D loss: 1.089595, acc: 83.59%] [G loss: 1.326119]\n",
      "[Epoch 9/50] [Batch 180/235] [D loss: 1.108503, acc: 83.79%] [G loss: 1.267069]\n",
      "[Epoch 9/50] [Batch 181/235] [D loss: 1.118267, acc: 79.88%] [G loss: 1.242482]\n",
      "[Epoch 9/50] [Batch 182/235] [D loss: 1.108766, acc: 84.18%] [G loss: 1.271156]\n",
      "[Epoch 9/50] [Batch 183/235] [D loss: 1.127731, acc: 85.35%] [G loss: 1.297732]\n",
      "[Epoch 9/50] [Batch 184/235] [D loss: 1.078368, acc: 81.64%] [G loss: 1.290966]\n",
      "[Epoch 9/50] [Batch 185/235] [D loss: 1.086213, acc: 81.45%] [G loss: 1.292270]\n",
      "[Epoch 9/50] [Batch 186/235] [D loss: 1.137405, acc: 79.88%] [G loss: 1.195233]\n",
      "[Epoch 9/50] [Batch 187/235] [D loss: 1.123713, acc: 85.74%] [G loss: 1.134237]\n",
      "[Epoch 9/50] [Batch 188/235] [D loss: 1.143508, acc: 83.20%] [G loss: 1.263271]\n",
      "[Epoch 9/50] [Batch 189/235] [D loss: 1.186827, acc: 82.03%] [G loss: 1.484868]\n",
      "[Epoch 9/50] [Batch 190/235] [D loss: 1.098309, acc: 83.01%] [G loss: 1.088728]\n",
      "[Epoch 9/50] [Batch 191/235] [D loss: 1.123631, acc: 83.59%] [G loss: 1.139036]\n",
      "[Epoch 9/50] [Batch 192/235] [D loss: 1.117458, acc: 84.38%] [G loss: 1.396601]\n",
      "[Epoch 9/50] [Batch 193/235] [D loss: 1.066931, acc: 83.40%] [G loss: 1.239539]\n",
      "[Epoch 9/50] [Batch 194/235] [D loss: 1.080386, acc: 83.40%] [G loss: 1.258900]\n",
      "[Epoch 9/50] [Batch 195/235] [D loss: 1.103431, acc: 83.01%] [G loss: 1.153404]\n",
      "[Epoch 9/50] [Batch 196/235] [D loss: 1.089445, acc: 81.45%] [G loss: 1.230854]\n",
      "[Epoch 9/50] [Batch 197/235] [D loss: 1.127877, acc: 82.81%] [G loss: 1.159184]\n",
      "[Epoch 9/50] [Batch 198/235] [D loss: 1.106010, acc: 84.77%] [G loss: 1.345551]\n",
      "[Epoch 9/50] [Batch 199/235] [D loss: 1.144699, acc: 80.27%] [G loss: 1.358489]\n",
      "[Epoch 9/50] [Batch 200/235] [D loss: 1.106805, acc: 84.38%] [G loss: 1.173594]\n",
      "[Epoch 9/50] [Batch 201/235] [D loss: 1.133581, acc: 82.42%] [G loss: 1.158135]\n",
      "[Epoch 9/50] [Batch 202/235] [D loss: 1.139507, acc: 80.66%] [G loss: 1.261743]\n",
      "[Epoch 9/50] [Batch 203/235] [D loss: 1.107517, acc: 81.05%] [G loss: 1.150704]\n",
      "[Epoch 9/50] [Batch 204/235] [D loss: 1.138529, acc: 81.25%] [G loss: 1.315302]\n",
      "[Epoch 9/50] [Batch 205/235] [D loss: 1.114079, acc: 81.45%] [G loss: 1.256811]\n",
      "[Epoch 9/50] [Batch 206/235] [D loss: 1.115306, acc: 83.20%] [G loss: 1.252455]\n",
      "[Epoch 9/50] [Batch 207/235] [D loss: 1.166800, acc: 81.05%] [G loss: 1.085836]\n",
      "[Epoch 9/50] [Batch 208/235] [D loss: 1.075109, acc: 82.42%] [G loss: 1.179124]\n",
      "[Epoch 9/50] [Batch 209/235] [D loss: 1.130601, acc: 83.59%] [G loss: 1.440294]\n",
      "[Epoch 9/50] [Batch 210/235] [D loss: 1.144272, acc: 82.03%] [G loss: 1.330369]\n",
      "[Epoch 9/50] [Batch 211/235] [D loss: 1.100599, acc: 84.77%] [G loss: 1.107680]\n",
      "[Epoch 9/50] [Batch 212/235] [D loss: 1.092086, acc: 82.23%] [G loss: 1.174662]\n",
      "[Epoch 9/50] [Batch 213/235] [D loss: 1.130969, acc: 80.27%] [G loss: 1.284062]\n",
      "[Epoch 9/50] [Batch 214/235] [D loss: 1.178550, acc: 80.47%] [G loss: 1.235980]\n",
      "[Epoch 9/50] [Batch 215/235] [D loss: 1.160259, acc: 83.98%] [G loss: 1.176901]\n",
      "[Epoch 9/50] [Batch 216/235] [D loss: 1.138638, acc: 82.03%] [G loss: 1.240469]\n",
      "[Epoch 9/50] [Batch 217/235] [D loss: 1.135729, acc: 80.66%] [G loss: 1.221701]\n",
      "[Epoch 9/50] [Batch 218/235] [D loss: 1.120810, acc: 80.47%] [G loss: 1.205066]\n",
      "[Epoch 9/50] [Batch 219/235] [D loss: 1.151094, acc: 82.23%] [G loss: 1.090539]\n",
      "[Epoch 9/50] [Batch 220/235] [D loss: 1.109737, acc: 82.03%] [G loss: 1.226588]\n",
      "[Epoch 9/50] [Batch 221/235] [D loss: 1.131511, acc: 82.81%] [G loss: 1.202331]\n",
      "[Epoch 9/50] [Batch 222/235] [D loss: 1.109222, acc: 81.84%] [G loss: 1.307599]\n",
      "[Epoch 9/50] [Batch 223/235] [D loss: 1.118769, acc: 83.40%] [G loss: 1.278049]\n",
      "[Epoch 9/50] [Batch 224/235] [D loss: 1.089952, acc: 83.79%] [G loss: 1.145556]\n",
      "[Epoch 9/50] [Batch 225/235] [D loss: 1.113116, acc: 84.57%] [G loss: 1.261237]\n",
      "[Epoch 9/50] [Batch 226/235] [D loss: 1.176863, acc: 78.91%] [G loss: 1.277104]\n",
      "[Epoch 9/50] [Batch 227/235] [D loss: 1.140281, acc: 78.71%] [G loss: 1.287051]\n",
      "[Epoch 9/50] [Batch 228/235] [D loss: 1.083368, acc: 82.81%] [G loss: 1.173571]\n",
      "[Epoch 9/50] [Batch 229/235] [D loss: 1.075428, acc: 82.03%] [G loss: 1.146345]\n",
      "[Epoch 9/50] [Batch 230/235] [D loss: 1.135922, acc: 82.62%] [G loss: 1.286150]\n",
      "[Epoch 9/50] [Batch 231/235] [D loss: 1.149734, acc: 83.01%] [G loss: 1.204157]\n",
      "[Epoch 9/50] [Batch 232/235] [D loss: 1.092687, acc: 83.59%] [G loss: 1.319447]\n",
      "[Epoch 9/50] [Batch 233/235] [D loss: 1.111203, acc: 84.18%] [G loss: 1.202592]\n",
      "[Epoch 9/50] [Batch 234/235] [D loss: 1.170588, acc: 76.04%] [G loss: 1.128883]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/50] [Batch 0/235] [D loss: 1.128204, acc: 82.03%] [G loss: 1.278601]\n",
      "[Epoch 10/50] [Batch 1/235] [D loss: 1.127359, acc: 81.45%] [G loss: 1.164536]\n",
      "[Epoch 10/50] [Batch 2/235] [D loss: 1.124558, acc: 84.77%] [G loss: 1.307227]\n",
      "[Epoch 10/50] [Batch 3/235] [D loss: 1.132620, acc: 81.45%] [G loss: 1.394431]\n",
      "[Epoch 10/50] [Batch 4/235] [D loss: 1.107018, acc: 82.62%] [G loss: 1.213032]\n",
      "[Epoch 10/50] [Batch 5/235] [D loss: 1.105624, acc: 80.66%] [G loss: 1.220829]\n",
      "[Epoch 10/50] [Batch 6/235] [D loss: 1.106762, acc: 85.35%] [G loss: 1.252492]\n",
      "[Epoch 10/50] [Batch 7/235] [D loss: 1.132113, acc: 84.18%] [G loss: 1.283740]\n",
      "[Epoch 10/50] [Batch 8/235] [D loss: 1.108882, acc: 79.88%] [G loss: 1.205051]\n",
      "[Epoch 10/50] [Batch 9/235] [D loss: 1.121126, acc: 84.77%] [G loss: 1.271979]\n",
      "[Epoch 10/50] [Batch 10/235] [D loss: 1.118359, acc: 81.84%] [G loss: 1.321152]\n",
      "[Epoch 10/50] [Batch 11/235] [D loss: 1.143162, acc: 79.69%] [G loss: 1.215371]\n",
      "[Epoch 10/50] [Batch 12/235] [D loss: 1.118150, acc: 79.88%] [G loss: 1.325006]\n",
      "[Epoch 10/50] [Batch 13/235] [D loss: 1.133027, acc: 81.84%] [G loss: 1.156950]\n",
      "[Epoch 10/50] [Batch 14/235] [D loss: 1.062516, acc: 83.20%] [G loss: 1.360998]\n",
      "[Epoch 10/50] [Batch 15/235] [D loss: 1.134056, acc: 78.32%] [G loss: 1.186089]\n",
      "[Epoch 10/50] [Batch 16/235] [D loss: 1.122516, acc: 83.98%] [G loss: 1.225077]\n",
      "[Epoch 10/50] [Batch 17/235] [D loss: 1.153783, acc: 82.42%] [G loss: 1.286353]\n",
      "[Epoch 10/50] [Batch 18/235] [D loss: 1.167264, acc: 84.18%] [G loss: 1.102914]\n",
      "[Epoch 10/50] [Batch 19/235] [D loss: 1.124654, acc: 82.03%] [G loss: 1.349520]\n",
      "[Epoch 10/50] [Batch 20/235] [D loss: 1.125830, acc: 82.23%] [G loss: 1.352543]\n",
      "[Epoch 10/50] [Batch 21/235] [D loss: 1.150181, acc: 82.03%] [G loss: 1.087551]\n",
      "[Epoch 10/50] [Batch 22/235] [D loss: 1.126783, acc: 82.42%] [G loss: 1.198197]\n",
      "[Epoch 10/50] [Batch 23/235] [D loss: 1.133768, acc: 82.62%] [G loss: 1.221842]\n",
      "[Epoch 10/50] [Batch 24/235] [D loss: 1.147251, acc: 82.23%] [G loss: 1.471113]\n",
      "[Epoch 10/50] [Batch 25/235] [D loss: 1.110022, acc: 81.25%] [G loss: 1.186652]\n",
      "[Epoch 10/50] [Batch 26/235] [D loss: 1.115506, acc: 80.66%] [G loss: 1.159945]\n",
      "[Epoch 10/50] [Batch 27/235] [D loss: 1.150804, acc: 79.49%] [G loss: 1.191906]\n",
      "[Epoch 10/50] [Batch 28/235] [D loss: 1.181961, acc: 80.66%] [G loss: 1.277479]\n",
      "[Epoch 10/50] [Batch 29/235] [D loss: 1.113618, acc: 81.84%] [G loss: 1.303238]\n",
      "[Epoch 10/50] [Batch 30/235] [D loss: 1.131941, acc: 80.47%] [G loss: 1.183984]\n",
      "[Epoch 10/50] [Batch 31/235] [D loss: 1.048213, acc: 84.18%] [G loss: 1.163374]\n",
      "[Epoch 10/50] [Batch 32/235] [D loss: 1.118414, acc: 85.16%] [G loss: 1.286240]\n",
      "[Epoch 10/50] [Batch 33/235] [D loss: 1.128169, acc: 83.01%] [G loss: 1.267820]\n",
      "[Epoch 10/50] [Batch 34/235] [D loss: 1.138404, acc: 81.25%] [G loss: 1.214272]\n",
      "[Epoch 10/50] [Batch 35/235] [D loss: 1.123186, acc: 80.27%] [G loss: 1.246462]\n",
      "[Epoch 10/50] [Batch 36/235] [D loss: 1.134185, acc: 83.20%] [G loss: 1.229522]\n",
      "[Epoch 10/50] [Batch 37/235] [D loss: 1.097134, acc: 84.96%] [G loss: 1.161829]\n",
      "[Epoch 10/50] [Batch 38/235] [D loss: 1.095255, acc: 83.01%] [G loss: 1.292681]\n",
      "[Epoch 10/50] [Batch 39/235] [D loss: 1.159488, acc: 81.45%] [G loss: 1.290220]\n",
      "[Epoch 10/50] [Batch 40/235] [D loss: 1.108536, acc: 82.42%] [G loss: 1.254503]\n",
      "[Epoch 10/50] [Batch 41/235] [D loss: 1.092873, acc: 85.35%] [G loss: 1.146731]\n",
      "[Epoch 10/50] [Batch 42/235] [D loss: 1.131496, acc: 81.05%] [G loss: 1.261163]\n",
      "[Epoch 10/50] [Batch 43/235] [D loss: 1.108845, acc: 83.01%] [G loss: 1.221895]\n",
      "[Epoch 10/50] [Batch 44/235] [D loss: 1.047732, acc: 84.96%] [G loss: 1.190949]\n",
      "[Epoch 10/50] [Batch 45/235] [D loss: 1.127291, acc: 83.20%] [G loss: 1.190134]\n",
      "[Epoch 10/50] [Batch 46/235] [D loss: 1.072550, acc: 84.18%] [G loss: 1.180085]\n",
      "[Epoch 10/50] [Batch 47/235] [D loss: 1.119713, acc: 85.16%] [G loss: 1.238999]\n",
      "[Epoch 10/50] [Batch 48/235] [D loss: 1.163847, acc: 82.42%] [G loss: 1.321079]\n",
      "[Epoch 10/50] [Batch 49/235] [D loss: 1.088869, acc: 82.03%] [G loss: 1.249109]\n",
      "[Epoch 10/50] [Batch 50/235] [D loss: 1.097241, acc: 83.79%] [G loss: 1.266174]\n",
      "[Epoch 10/50] [Batch 51/235] [D loss: 1.078876, acc: 82.03%] [G loss: 1.180555]\n",
      "[Epoch 10/50] [Batch 52/235] [D loss: 1.118847, acc: 82.03%] [G loss: 1.295489]\n",
      "[Epoch 10/50] [Batch 53/235] [D loss: 1.102294, acc: 84.38%] [G loss: 1.232753]\n",
      "[Epoch 10/50] [Batch 54/235] [D loss: 1.140407, acc: 83.01%] [G loss: 1.207781]\n",
      "[Epoch 10/50] [Batch 55/235] [D loss: 1.116336, acc: 82.62%] [G loss: 1.228979]\n",
      "[Epoch 10/50] [Batch 56/235] [D loss: 1.129464, acc: 81.05%] [G loss: 1.270275]\n",
      "[Epoch 10/50] [Batch 57/235] [D loss: 1.108651, acc: 86.52%] [G loss: 1.247801]\n",
      "[Epoch 10/50] [Batch 58/235] [D loss: 1.065012, acc: 84.18%] [G loss: 1.241994]\n",
      "[Epoch 10/50] [Batch 59/235] [D loss: 1.107802, acc: 82.62%] [G loss: 1.241570]\n",
      "[Epoch 10/50] [Batch 60/235] [D loss: 1.120569, acc: 82.03%] [G loss: 1.236672]\n",
      "[Epoch 10/50] [Batch 61/235] [D loss: 1.136619, acc: 83.79%] [G loss: 1.292918]\n",
      "[Epoch 10/50] [Batch 62/235] [D loss: 1.104434, acc: 82.42%] [G loss: 1.152394]\n",
      "[Epoch 10/50] [Batch 63/235] [D loss: 1.101877, acc: 83.20%] [G loss: 1.227086]\n",
      "[Epoch 10/50] [Batch 64/235] [D loss: 1.148713, acc: 83.59%] [G loss: 1.308077]\n",
      "[Epoch 10/50] [Batch 65/235] [D loss: 1.167505, acc: 84.38%] [G loss: 1.296434]\n",
      "[Epoch 10/50] [Batch 66/235] [D loss: 1.117265, acc: 83.59%] [G loss: 1.202931]\n",
      "[Epoch 10/50] [Batch 67/235] [D loss: 1.065920, acc: 84.57%] [G loss: 1.287241]\n",
      "[Epoch 10/50] [Batch 68/235] [D loss: 1.092239, acc: 83.20%] [G loss: 1.149087]\n",
      "[Epoch 10/50] [Batch 69/235] [D loss: 1.069190, acc: 85.16%] [G loss: 1.248765]\n",
      "[Epoch 10/50] [Batch 70/235] [D loss: 1.148482, acc: 80.47%] [G loss: 1.182108]\n",
      "[Epoch 10/50] [Batch 71/235] [D loss: 1.160940, acc: 83.59%] [G loss: 1.300221]\n",
      "[Epoch 10/50] [Batch 72/235] [D loss: 1.105759, acc: 82.23%] [G loss: 1.226223]\n",
      "[Epoch 10/50] [Batch 73/235] [D loss: 1.137090, acc: 83.01%] [G loss: 1.101739]\n",
      "[Epoch 10/50] [Batch 74/235] [D loss: 1.167666, acc: 83.40%] [G loss: 1.267389]\n",
      "[Epoch 10/50] [Batch 75/235] [D loss: 1.090475, acc: 84.96%] [G loss: 1.298687]\n",
      "[Epoch 10/50] [Batch 76/235] [D loss: 1.136517, acc: 83.01%] [G loss: 1.221649]\n",
      "[Epoch 10/50] [Batch 77/235] [D loss: 1.090556, acc: 84.18%] [G loss: 1.261109]\n",
      "[Epoch 10/50] [Batch 78/235] [D loss: 1.106348, acc: 83.40%] [G loss: 1.199969]\n",
      "[Epoch 10/50] [Batch 79/235] [D loss: 1.092002, acc: 82.42%] [G loss: 1.292204]\n",
      "[Epoch 10/50] [Batch 80/235] [D loss: 1.180233, acc: 83.01%] [G loss: 1.260669]\n",
      "[Epoch 10/50] [Batch 81/235] [D loss: 1.142498, acc: 83.01%] [G loss: 1.207057]\n",
      "[Epoch 10/50] [Batch 82/235] [D loss: 1.106305, acc: 83.20%] [G loss: 1.185719]\n",
      "[Epoch 10/50] [Batch 83/235] [D loss: 1.111266, acc: 85.35%] [G loss: 1.142736]\n",
      "[Epoch 10/50] [Batch 84/235] [D loss: 1.086969, acc: 81.64%] [G loss: 1.304107]\n",
      "[Epoch 10/50] [Batch 85/235] [D loss: 1.130960, acc: 83.59%] [G loss: 1.211550]\n",
      "[Epoch 10/50] [Batch 86/235] [D loss: 1.097567, acc: 81.64%] [G loss: 1.249652]\n",
      "[Epoch 10/50] [Batch 87/235] [D loss: 1.129757, acc: 81.64%] [G loss: 1.242959]\n",
      "[Epoch 10/50] [Batch 88/235] [D loss: 1.120209, acc: 84.57%] [G loss: 1.248809]\n",
      "[Epoch 10/50] [Batch 89/235] [D loss: 1.134297, acc: 83.40%] [G loss: 1.192533]\n",
      "[Epoch 10/50] [Batch 90/235] [D loss: 1.104471, acc: 83.79%] [G loss: 1.282914]\n",
      "[Epoch 10/50] [Batch 91/235] [D loss: 1.125463, acc: 82.81%] [G loss: 1.168563]\n",
      "[Epoch 10/50] [Batch 92/235] [D loss: 1.113494, acc: 83.20%] [G loss: 1.316185]\n",
      "[Epoch 10/50] [Batch 93/235] [D loss: 1.129401, acc: 83.40%] [G loss: 1.286194]\n",
      "[Epoch 10/50] [Batch 94/235] [D loss: 1.127849, acc: 81.64%] [G loss: 1.294623]\n",
      "[Epoch 10/50] [Batch 95/235] [D loss: 1.152319, acc: 82.81%] [G loss: 1.293026]\n",
      "[Epoch 10/50] [Batch 96/235] [D loss: 1.122804, acc: 81.84%] [G loss: 1.241330]\n",
      "[Epoch 10/50] [Batch 97/235] [D loss: 1.134502, acc: 80.47%] [G loss: 1.207052]\n",
      "[Epoch 10/50] [Batch 98/235] [D loss: 1.060016, acc: 85.55%] [G loss: 1.356564]\n",
      "[Epoch 10/50] [Batch 99/235] [D loss: 1.081227, acc: 82.81%] [G loss: 1.215955]\n",
      "[Epoch 10/50] [Batch 100/235] [D loss: 1.122420, acc: 82.03%] [G loss: 1.161153]\n",
      "[Epoch 10/50] [Batch 101/235] [D loss: 1.122016, acc: 85.16%] [G loss: 1.225309]\n",
      "[Epoch 10/50] [Batch 102/235] [D loss: 1.107453, acc: 82.81%] [G loss: 1.310888]\n",
      "[Epoch 10/50] [Batch 103/235] [D loss: 1.087826, acc: 80.86%] [G loss: 1.419711]\n",
      "[Epoch 10/50] [Batch 104/235] [D loss: 1.095212, acc: 85.16%] [G loss: 1.210745]\n",
      "[Epoch 10/50] [Batch 105/235] [D loss: 1.123870, acc: 83.40%] [G loss: 1.269796]\n",
      "[Epoch 10/50] [Batch 106/235] [D loss: 1.128058, acc: 82.42%] [G loss: 1.257103]\n",
      "[Epoch 10/50] [Batch 107/235] [D loss: 1.108369, acc: 83.01%] [G loss: 1.198655]\n",
      "[Epoch 10/50] [Batch 108/235] [D loss: 1.148637, acc: 81.84%] [G loss: 1.333143]\n",
      "[Epoch 10/50] [Batch 109/235] [D loss: 1.109743, acc: 82.03%] [G loss: 1.209363]\n",
      "[Epoch 10/50] [Batch 110/235] [D loss: 1.112375, acc: 83.01%] [G loss: 1.201127]\n",
      "[Epoch 10/50] [Batch 111/235] [D loss: 1.098714, acc: 83.98%] [G loss: 1.222331]\n",
      "[Epoch 10/50] [Batch 112/235] [D loss: 1.087595, acc: 81.05%] [G loss: 1.323880]\n",
      "[Epoch 10/50] [Batch 113/235] [D loss: 1.119287, acc: 87.50%] [G loss: 1.411493]\n",
      "[Epoch 10/50] [Batch 114/235] [D loss: 1.078669, acc: 82.81%] [G loss: 1.176839]\n",
      "[Epoch 10/50] [Batch 115/235] [D loss: 1.136858, acc: 86.33%] [G loss: 1.212059]\n",
      "[Epoch 10/50] [Batch 116/235] [D loss: 1.121131, acc: 84.57%] [G loss: 1.223524]\n",
      "[Epoch 10/50] [Batch 117/235] [D loss: 1.130514, acc: 84.57%] [G loss: 1.243417]\n",
      "[Epoch 10/50] [Batch 118/235] [D loss: 1.065133, acc: 82.62%] [G loss: 1.295319]\n",
      "[Epoch 10/50] [Batch 119/235] [D loss: 1.126441, acc: 88.87%] [G loss: 1.209775]\n",
      "[Epoch 10/50] [Batch 120/235] [D loss: 1.090372, acc: 82.23%] [G loss: 1.299751]\n",
      "[Epoch 10/50] [Batch 121/235] [D loss: 1.088970, acc: 85.35%] [G loss: 1.254637]\n",
      "[Epoch 10/50] [Batch 122/235] [D loss: 1.094947, acc: 84.38%] [G loss: 1.161646]\n",
      "[Epoch 10/50] [Batch 123/235] [D loss: 1.155040, acc: 86.33%] [G loss: 1.105729]\n",
      "[Epoch 10/50] [Batch 124/235] [D loss: 1.158313, acc: 81.64%] [G loss: 1.133499]\n",
      "[Epoch 10/50] [Batch 125/235] [D loss: 1.091945, acc: 80.47%] [G loss: 1.287123]\n",
      "[Epoch 10/50] [Batch 126/235] [D loss: 1.048753, acc: 83.01%] [G loss: 1.315983]\n",
      "[Epoch 10/50] [Batch 127/235] [D loss: 1.162616, acc: 83.59%] [G loss: 1.170249]\n",
      "[Epoch 10/50] [Batch 128/235] [D loss: 1.105874, acc: 81.84%] [G loss: 1.269916]\n",
      "[Epoch 10/50] [Batch 129/235] [D loss: 1.084646, acc: 85.74%] [G loss: 1.291655]\n",
      "[Epoch 10/50] [Batch 130/235] [D loss: 1.092613, acc: 86.72%] [G loss: 1.201391]\n",
      "[Epoch 10/50] [Batch 131/235] [D loss: 1.080953, acc: 83.79%] [G loss: 1.354581]\n",
      "[Epoch 10/50] [Batch 132/235] [D loss: 1.129149, acc: 86.33%] [G loss: 1.236998]\n",
      "[Epoch 10/50] [Batch 133/235] [D loss: 1.122109, acc: 85.74%] [G loss: 1.144547]\n",
      "[Epoch 10/50] [Batch 134/235] [D loss: 1.192143, acc: 80.86%] [G loss: 1.297262]\n",
      "[Epoch 10/50] [Batch 135/235] [D loss: 1.139323, acc: 81.45%] [G loss: 1.148753]\n",
      "[Epoch 10/50] [Batch 136/235] [D loss: 1.102346, acc: 82.81%] [G loss: 1.265924]\n",
      "[Epoch 10/50] [Batch 137/235] [D loss: 1.098046, acc: 83.79%] [G loss: 1.234728]\n",
      "[Epoch 10/50] [Batch 138/235] [D loss: 1.115037, acc: 85.16%] [G loss: 1.289464]\n",
      "[Epoch 10/50] [Batch 139/235] [D loss: 1.159724, acc: 82.62%] [G loss: 1.101255]\n",
      "[Epoch 10/50] [Batch 140/235] [D loss: 1.090380, acc: 83.01%] [G loss: 1.130038]\n",
      "[Epoch 10/50] [Batch 141/235] [D loss: 1.134570, acc: 82.42%] [G loss: 1.335451]\n",
      "[Epoch 10/50] [Batch 142/235] [D loss: 1.102435, acc: 85.16%] [G loss: 1.203839]\n",
      "[Epoch 10/50] [Batch 143/235] [D loss: 1.160841, acc: 83.20%] [G loss: 1.370277]\n",
      "[Epoch 10/50] [Batch 144/235] [D loss: 1.069075, acc: 84.77%] [G loss: 1.323191]\n",
      "[Epoch 10/50] [Batch 145/235] [D loss: 1.138638, acc: 83.98%] [G loss: 1.177372]\n",
      "[Epoch 10/50] [Batch 146/235] [D loss: 1.087378, acc: 84.38%] [G loss: 1.178184]\n",
      "[Epoch 10/50] [Batch 147/235] [D loss: 1.112599, acc: 80.27%] [G loss: 1.181672]\n",
      "[Epoch 10/50] [Batch 148/235] [D loss: 1.121817, acc: 81.45%] [G loss: 1.259773]\n",
      "[Epoch 10/50] [Batch 149/235] [D loss: 1.141345, acc: 83.59%] [G loss: 1.212476]\n",
      "[Epoch 10/50] [Batch 150/235] [D loss: 1.112509, acc: 81.84%] [G loss: 1.121968]\n",
      "[Epoch 10/50] [Batch 151/235] [D loss: 1.129539, acc: 85.55%] [G loss: 1.235181]\n",
      "[Epoch 10/50] [Batch 152/235] [D loss: 1.091225, acc: 82.81%] [G loss: 1.225794]\n",
      "[Epoch 10/50] [Batch 153/235] [D loss: 1.131600, acc: 80.86%] [G loss: 1.170140]\n",
      "[Epoch 10/50] [Batch 154/235] [D loss: 1.109107, acc: 81.25%] [G loss: 1.224453]\n",
      "[Epoch 10/50] [Batch 155/235] [D loss: 1.075524, acc: 83.59%] [G loss: 1.148657]\n",
      "[Epoch 10/50] [Batch 156/235] [D loss: 1.142238, acc: 83.20%] [G loss: 1.164275]\n",
      "[Epoch 10/50] [Batch 157/235] [D loss: 1.117052, acc: 83.01%] [G loss: 1.281322]\n",
      "[Epoch 10/50] [Batch 158/235] [D loss: 1.112566, acc: 83.79%] [G loss: 1.248281]\n",
      "[Epoch 10/50] [Batch 159/235] [D loss: 1.144555, acc: 82.23%] [G loss: 1.281673]\n",
      "[Epoch 10/50] [Batch 160/235] [D loss: 1.123087, acc: 86.91%] [G loss: 1.264415]\n",
      "[Epoch 10/50] [Batch 161/235] [D loss: 1.131911, acc: 83.98%] [G loss: 1.170596]\n",
      "[Epoch 10/50] [Batch 162/235] [D loss: 1.143296, acc: 83.01%] [G loss: 1.129946]\n",
      "[Epoch 10/50] [Batch 163/235] [D loss: 1.123721, acc: 84.77%] [G loss: 1.123727]\n",
      "[Epoch 10/50] [Batch 164/235] [D loss: 1.134925, acc: 85.74%] [G loss: 1.395579]\n",
      "[Epoch 10/50] [Batch 165/235] [D loss: 1.070222, acc: 84.18%] [G loss: 1.147816]\n",
      "[Epoch 10/50] [Batch 166/235] [D loss: 1.102053, acc: 83.79%] [G loss: 1.212989]\n",
      "[Epoch 10/50] [Batch 167/235] [D loss: 1.104488, acc: 85.94%] [G loss: 1.320367]\n",
      "[Epoch 10/50] [Batch 168/235] [D loss: 1.123992, acc: 82.03%] [G loss: 1.208611]\n",
      "[Epoch 10/50] [Batch 169/235] [D loss: 1.114044, acc: 80.47%] [G loss: 1.194551]\n",
      "[Epoch 10/50] [Batch 170/235] [D loss: 1.151767, acc: 83.40%] [G loss: 1.132510]\n",
      "[Epoch 10/50] [Batch 171/235] [D loss: 1.155945, acc: 83.59%] [G loss: 1.131645]\n",
      "[Epoch 10/50] [Batch 172/235] [D loss: 1.143021, acc: 81.45%] [G loss: 1.285045]\n",
      "[Epoch 10/50] [Batch 173/235] [D loss: 1.103463, acc: 85.16%] [G loss: 1.262087]\n",
      "[Epoch 10/50] [Batch 174/235] [D loss: 1.111123, acc: 79.88%] [G loss: 1.224282]\n",
      "[Epoch 10/50] [Batch 175/235] [D loss: 1.139144, acc: 84.38%] [G loss: 1.191412]\n",
      "[Epoch 10/50] [Batch 176/235] [D loss: 1.110807, acc: 84.77%] [G loss: 1.150021]\n",
      "[Epoch 10/50] [Batch 177/235] [D loss: 1.105139, acc: 83.01%] [G loss: 1.299482]\n",
      "[Epoch 10/50] [Batch 178/235] [D loss: 1.110828, acc: 84.18%] [G loss: 1.204099]\n",
      "[Epoch 10/50] [Batch 179/235] [D loss: 1.088056, acc: 84.96%] [G loss: 1.192191]\n",
      "[Epoch 10/50] [Batch 180/235] [D loss: 1.114106, acc: 84.96%] [G loss: 1.166262]\n",
      "[Epoch 10/50] [Batch 181/235] [D loss: 1.088198, acc: 83.01%] [G loss: 1.219434]\n",
      "[Epoch 10/50] [Batch 182/235] [D loss: 1.114969, acc: 84.96%] [G loss: 1.131486]\n",
      "[Epoch 10/50] [Batch 183/235] [D loss: 1.110879, acc: 82.23%] [G loss: 1.222087]\n",
      "[Epoch 10/50] [Batch 184/235] [D loss: 1.102235, acc: 82.03%] [G loss: 1.348795]\n",
      "[Epoch 10/50] [Batch 185/235] [D loss: 1.140257, acc: 81.84%] [G loss: 1.196395]\n",
      "[Epoch 10/50] [Batch 186/235] [D loss: 1.142881, acc: 82.81%] [G loss: 1.179170]\n",
      "[Epoch 10/50] [Batch 187/235] [D loss: 1.134340, acc: 82.62%] [G loss: 1.200027]\n",
      "[Epoch 10/50] [Batch 188/235] [D loss: 1.110464, acc: 83.98%] [G loss: 1.222161]\n",
      "[Epoch 10/50] [Batch 189/235] [D loss: 1.092401, acc: 83.98%] [G loss: 1.260733]\n",
      "[Epoch 10/50] [Batch 190/235] [D loss: 1.107779, acc: 81.64%] [G loss: 1.187714]\n",
      "[Epoch 10/50] [Batch 191/235] [D loss: 1.084667, acc: 83.98%] [G loss: 1.213272]\n",
      "[Epoch 10/50] [Batch 192/235] [D loss: 1.090335, acc: 83.40%] [G loss: 1.250861]\n",
      "[Epoch 10/50] [Batch 193/235] [D loss: 1.116236, acc: 84.77%] [G loss: 1.135470]\n",
      "[Epoch 10/50] [Batch 194/235] [D loss: 1.106553, acc: 82.42%] [G loss: 1.171262]\n",
      "[Epoch 10/50] [Batch 195/235] [D loss: 1.151895, acc: 83.59%] [G loss: 1.183103]\n",
      "[Epoch 10/50] [Batch 196/235] [D loss: 1.175252, acc: 83.59%] [G loss: 1.179577]\n",
      "[Epoch 10/50] [Batch 197/235] [D loss: 1.117934, acc: 81.25%] [G loss: 1.166531]\n",
      "[Epoch 10/50] [Batch 198/235] [D loss: 1.151655, acc: 84.18%] [G loss: 1.061309]\n",
      "[Epoch 10/50] [Batch 199/235] [D loss: 1.145998, acc: 83.01%] [G loss: 1.301433]\n",
      "[Epoch 10/50] [Batch 200/235] [D loss: 1.098537, acc: 83.79%] [G loss: 1.272147]\n",
      "[Epoch 10/50] [Batch 201/235] [D loss: 1.106008, acc: 84.38%] [G loss: 1.311082]\n",
      "[Epoch 10/50] [Batch 202/235] [D loss: 1.119308, acc: 84.77%] [G loss: 1.315117]\n",
      "[Epoch 10/50] [Batch 203/235] [D loss: 1.083893, acc: 80.08%] [G loss: 1.250592]\n",
      "[Epoch 10/50] [Batch 204/235] [D loss: 1.134867, acc: 82.62%] [G loss: 1.160688]\n",
      "[Epoch 10/50] [Batch 205/235] [D loss: 1.082052, acc: 84.57%] [G loss: 1.278125]\n",
      "[Epoch 10/50] [Batch 206/235] [D loss: 1.117327, acc: 82.81%] [G loss: 1.170090]\n",
      "[Epoch 10/50] [Batch 207/235] [D loss: 1.108988, acc: 82.81%] [G loss: 1.181186]\n",
      "[Epoch 10/50] [Batch 208/235] [D loss: 1.100450, acc: 85.16%] [G loss: 1.117982]\n",
      "[Epoch 10/50] [Batch 209/235] [D loss: 1.142839, acc: 84.38%] [G loss: 1.233652]\n",
      "[Epoch 10/50] [Batch 210/235] [D loss: 1.110833, acc: 83.40%] [G loss: 1.376259]\n",
      "[Epoch 10/50] [Batch 211/235] [D loss: 1.145959, acc: 83.20%] [G loss: 1.123477]\n",
      "[Epoch 10/50] [Batch 212/235] [D loss: 1.135783, acc: 82.42%] [G loss: 1.299852]\n",
      "[Epoch 10/50] [Batch 213/235] [D loss: 1.165539, acc: 82.62%] [G loss: 1.330283]\n",
      "[Epoch 10/50] [Batch 214/235] [D loss: 1.120553, acc: 82.42%] [G loss: 1.264085]\n",
      "[Epoch 10/50] [Batch 215/235] [D loss: 1.097964, acc: 81.84%] [G loss: 1.154380]\n",
      "[Epoch 10/50] [Batch 216/235] [D loss: 1.105093, acc: 82.03%] [G loss: 1.264593]\n",
      "[Epoch 10/50] [Batch 217/235] [D loss: 1.095723, acc: 85.35%] [G loss: 1.244086]\n",
      "[Epoch 10/50] [Batch 218/235] [D loss: 1.154711, acc: 80.86%] [G loss: 1.180066]\n",
      "[Epoch 10/50] [Batch 219/235] [D loss: 1.114653, acc: 84.38%] [G loss: 1.273219]\n",
      "[Epoch 10/50] [Batch 220/235] [D loss: 1.084103, acc: 80.66%] [G loss: 1.333549]\n",
      "[Epoch 10/50] [Batch 221/235] [D loss: 1.168306, acc: 83.79%] [G loss: 1.096882]\n",
      "[Epoch 10/50] [Batch 222/235] [D loss: 1.142949, acc: 83.01%] [G loss: 1.305825]\n",
      "[Epoch 10/50] [Batch 223/235] [D loss: 1.108934, acc: 83.20%] [G loss: 1.245463]\n",
      "[Epoch 10/50] [Batch 224/235] [D loss: 1.112051, acc: 84.57%] [G loss: 1.193497]\n",
      "[Epoch 10/50] [Batch 225/235] [D loss: 1.059427, acc: 85.16%] [G loss: 1.253789]\n",
      "[Epoch 10/50] [Batch 226/235] [D loss: 1.134414, acc: 82.03%] [G loss: 1.307510]\n",
      "[Epoch 10/50] [Batch 227/235] [D loss: 1.123268, acc: 83.98%] [G loss: 1.138864]\n",
      "[Epoch 10/50] [Batch 228/235] [D loss: 1.079824, acc: 84.18%] [G loss: 1.245166]\n",
      "[Epoch 10/50] [Batch 229/235] [D loss: 1.110840, acc: 83.98%] [G loss: 1.311179]\n",
      "[Epoch 10/50] [Batch 230/235] [D loss: 1.123037, acc: 82.42%] [G loss: 1.251463]\n",
      "[Epoch 10/50] [Batch 231/235] [D loss: 1.117378, acc: 84.38%] [G loss: 1.178014]\n",
      "[Epoch 10/50] [Batch 232/235] [D loss: 1.160372, acc: 83.79%] [G loss: 1.323380]\n",
      "[Epoch 10/50] [Batch 233/235] [D loss: 1.136426, acc: 83.98%] [G loss: 1.272796]\n",
      "[Epoch 10/50] [Batch 234/235] [D loss: 1.221817, acc: 86.46%] [G loss: 1.284956]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/50] [Batch 0/235] [D loss: 1.141996, acc: 82.42%] [G loss: 1.108068]\n",
      "[Epoch 11/50] [Batch 1/235] [D loss: 1.104740, acc: 85.35%] [G loss: 1.078124]\n",
      "[Epoch 11/50] [Batch 2/235] [D loss: 1.104372, acc: 83.40%] [G loss: 1.294921]\n",
      "[Epoch 11/50] [Batch 3/235] [D loss: 1.091099, acc: 83.59%] [G loss: 1.429430]\n",
      "[Epoch 11/50] [Batch 4/235] [D loss: 1.127053, acc: 81.84%] [G loss: 1.133854]\n",
      "[Epoch 11/50] [Batch 5/235] [D loss: 1.128607, acc: 84.96%] [G loss: 1.256637]\n",
      "[Epoch 11/50] [Batch 6/235] [D loss: 1.135302, acc: 84.38%] [G loss: 1.368242]\n",
      "[Epoch 11/50] [Batch 7/235] [D loss: 1.098781, acc: 83.59%] [G loss: 1.335501]\n",
      "[Epoch 11/50] [Batch 8/235] [D loss: 1.106276, acc: 85.16%] [G loss: 1.320568]\n",
      "[Epoch 11/50] [Batch 9/235] [D loss: 1.173341, acc: 81.05%] [G loss: 1.074597]\n",
      "[Epoch 11/50] [Batch 10/235] [D loss: 1.091335, acc: 82.42%] [G loss: 1.213333]\n",
      "[Epoch 11/50] [Batch 11/235] [D loss: 1.127005, acc: 85.35%] [G loss: 1.331519]\n",
      "[Epoch 11/50] [Batch 12/235] [D loss: 1.146719, acc: 82.23%] [G loss: 1.268371]\n",
      "[Epoch 11/50] [Batch 13/235] [D loss: 1.109377, acc: 81.05%] [G loss: 1.116945]\n",
      "[Epoch 11/50] [Batch 14/235] [D loss: 1.143907, acc: 83.20%] [G loss: 1.124390]\n",
      "[Epoch 11/50] [Batch 15/235] [D loss: 1.150324, acc: 82.03%] [G loss: 1.292141]\n",
      "[Epoch 11/50] [Batch 16/235] [D loss: 1.107154, acc: 83.01%] [G loss: 1.431832]\n",
      "[Epoch 11/50] [Batch 17/235] [D loss: 1.065957, acc: 83.98%] [G loss: 1.282413]\n",
      "[Epoch 11/50] [Batch 18/235] [D loss: 1.093837, acc: 83.79%] [G loss: 1.214298]\n",
      "[Epoch 11/50] [Batch 19/235] [D loss: 1.116585, acc: 85.55%] [G loss: 1.234459]\n",
      "[Epoch 11/50] [Batch 20/235] [D loss: 1.083283, acc: 83.40%] [G loss: 1.234342]\n",
      "[Epoch 11/50] [Batch 21/235] [D loss: 1.081696, acc: 85.74%] [G loss: 1.201080]\n",
      "[Epoch 11/50] [Batch 22/235] [D loss: 1.124717, acc: 83.59%] [G loss: 1.197887]\n",
      "[Epoch 11/50] [Batch 23/235] [D loss: 1.156064, acc: 82.23%] [G loss: 1.228280]\n",
      "[Epoch 11/50] [Batch 24/235] [D loss: 1.088782, acc: 82.62%] [G loss: 1.166330]\n",
      "[Epoch 11/50] [Batch 25/235] [D loss: 1.077907, acc: 80.86%] [G loss: 1.212566]\n",
      "[Epoch 11/50] [Batch 26/235] [D loss: 1.099383, acc: 82.62%] [G loss: 1.246142]\n",
      "[Epoch 11/50] [Batch 27/235] [D loss: 1.094240, acc: 84.38%] [G loss: 1.307767]\n",
      "[Epoch 11/50] [Batch 28/235] [D loss: 1.123082, acc: 81.64%] [G loss: 1.206630]\n",
      "[Epoch 11/50] [Batch 29/235] [D loss: 1.096648, acc: 85.35%] [G loss: 1.217687]\n",
      "[Epoch 11/50] [Batch 30/235] [D loss: 1.152110, acc: 85.35%] [G loss: 1.157409]\n",
      "[Epoch 11/50] [Batch 31/235] [D loss: 1.103018, acc: 80.66%] [G loss: 1.407130]\n",
      "[Epoch 11/50] [Batch 32/235] [D loss: 1.114749, acc: 84.77%] [G loss: 1.236951]\n",
      "[Epoch 11/50] [Batch 33/235] [D loss: 1.091436, acc: 84.18%] [G loss: 1.159002]\n",
      "[Epoch 11/50] [Batch 34/235] [D loss: 1.133224, acc: 84.96%] [G loss: 1.151227]\n",
      "[Epoch 11/50] [Batch 35/235] [D loss: 1.164671, acc: 81.45%] [G loss: 1.219137]\n",
      "[Epoch 11/50] [Batch 36/235] [D loss: 1.087050, acc: 84.38%] [G loss: 1.102519]\n",
      "[Epoch 11/50] [Batch 37/235] [D loss: 1.116914, acc: 83.59%] [G loss: 1.208917]\n",
      "[Epoch 11/50] [Batch 38/235] [D loss: 1.134244, acc: 81.45%] [G loss: 1.261018]\n",
      "[Epoch 11/50] [Batch 39/235] [D loss: 1.118580, acc: 84.18%] [G loss: 1.289871]\n",
      "[Epoch 11/50] [Batch 40/235] [D loss: 1.133645, acc: 86.33%] [G loss: 1.044081]\n",
      "[Epoch 11/50] [Batch 41/235] [D loss: 1.112145, acc: 83.40%] [G loss: 1.278049]\n",
      "[Epoch 11/50] [Batch 42/235] [D loss: 1.098697, acc: 84.38%] [G loss: 1.216749]\n",
      "[Epoch 11/50] [Batch 43/235] [D loss: 1.134465, acc: 81.45%] [G loss: 1.241863]\n",
      "[Epoch 11/50] [Batch 44/235] [D loss: 1.130626, acc: 82.23%] [G loss: 1.191027]\n",
      "[Epoch 11/50] [Batch 45/235] [D loss: 1.111620, acc: 83.40%] [G loss: 1.215534]\n",
      "[Epoch 11/50] [Batch 46/235] [D loss: 1.122858, acc: 83.01%] [G loss: 1.250981]\n",
      "[Epoch 11/50] [Batch 47/235] [D loss: 1.138944, acc: 83.98%] [G loss: 1.116278]\n",
      "[Epoch 11/50] [Batch 48/235] [D loss: 1.155335, acc: 85.16%] [G loss: 1.218430]\n",
      "[Epoch 11/50] [Batch 49/235] [D loss: 1.133330, acc: 83.01%] [G loss: 1.330870]\n",
      "[Epoch 11/50] [Batch 50/235] [D loss: 1.138301, acc: 82.62%] [G loss: 1.217612]\n",
      "[Epoch 11/50] [Batch 51/235] [D loss: 1.136680, acc: 83.01%] [G loss: 1.135240]\n",
      "[Epoch 11/50] [Batch 52/235] [D loss: 1.120885, acc: 85.35%] [G loss: 1.260697]\n",
      "[Epoch 11/50] [Batch 53/235] [D loss: 1.101058, acc: 87.70%] [G loss: 1.192828]\n",
      "[Epoch 11/50] [Batch 54/235] [D loss: 1.120408, acc: 84.57%] [G loss: 1.221055]\n",
      "[Epoch 11/50] [Batch 55/235] [D loss: 1.100260, acc: 86.13%] [G loss: 1.252149]\n",
      "[Epoch 11/50] [Batch 56/235] [D loss: 1.139581, acc: 84.57%] [G loss: 1.343554]\n",
      "[Epoch 11/50] [Batch 57/235] [D loss: 1.107416, acc: 83.01%] [G loss: 1.183447]\n",
      "[Epoch 11/50] [Batch 58/235] [D loss: 1.102968, acc: 84.38%] [G loss: 1.175375]\n",
      "[Epoch 11/50] [Batch 59/235] [D loss: 1.110732, acc: 85.35%] [G loss: 1.183402]\n",
      "[Epoch 11/50] [Batch 60/235] [D loss: 1.097564, acc: 81.64%] [G loss: 1.143542]\n",
      "[Epoch 11/50] [Batch 61/235] [D loss: 1.085938, acc: 84.96%] [G loss: 1.214454]\n",
      "[Epoch 11/50] [Batch 62/235] [D loss: 1.095071, acc: 81.05%] [G loss: 1.182407]\n",
      "[Epoch 11/50] [Batch 63/235] [D loss: 1.136242, acc: 84.57%] [G loss: 1.256123]\n",
      "[Epoch 11/50] [Batch 64/235] [D loss: 1.173205, acc: 82.23%] [G loss: 1.260272]\n",
      "[Epoch 11/50] [Batch 65/235] [D loss: 1.115925, acc: 84.38%] [G loss: 1.226228]\n",
      "[Epoch 11/50] [Batch 66/235] [D loss: 1.101381, acc: 81.05%] [G loss: 1.262203]\n",
      "[Epoch 11/50] [Batch 67/235] [D loss: 1.099131, acc: 81.64%] [G loss: 1.230763]\n",
      "[Epoch 11/50] [Batch 68/235] [D loss: 1.092406, acc: 83.98%] [G loss: 1.152578]\n",
      "[Epoch 11/50] [Batch 69/235] [D loss: 1.117700, acc: 80.86%] [G loss: 1.271032]\n",
      "[Epoch 11/50] [Batch 70/235] [D loss: 1.083455, acc: 81.25%] [G loss: 1.197120]\n",
      "[Epoch 11/50] [Batch 71/235] [D loss: 1.140217, acc: 80.86%] [G loss: 1.268834]\n",
      "[Epoch 11/50] [Batch 72/235] [D loss: 1.065037, acc: 83.40%] [G loss: 1.104930]\n",
      "[Epoch 11/50] [Batch 73/235] [D loss: 1.120257, acc: 84.57%] [G loss: 1.069821]\n",
      "[Epoch 11/50] [Batch 74/235] [D loss: 1.103729, acc: 84.38%] [G loss: 1.199104]\n",
      "[Epoch 11/50] [Batch 75/235] [D loss: 1.087511, acc: 83.79%] [G loss: 1.155654]\n",
      "[Epoch 11/50] [Batch 76/235] [D loss: 1.176122, acc: 83.59%] [G loss: 1.204211]\n",
      "[Epoch 11/50] [Batch 77/235] [D loss: 1.064788, acc: 84.18%] [G loss: 1.217736]\n",
      "[Epoch 11/50] [Batch 78/235] [D loss: 1.101106, acc: 85.35%] [G loss: 1.142160]\n",
      "[Epoch 11/50] [Batch 79/235] [D loss: 1.111686, acc: 84.77%] [G loss: 1.129929]\n",
      "[Epoch 11/50] [Batch 80/235] [D loss: 1.138154, acc: 80.86%] [G loss: 1.287250]\n",
      "[Epoch 11/50] [Batch 81/235] [D loss: 1.106201, acc: 84.96%] [G loss: 1.377987]\n",
      "[Epoch 11/50] [Batch 82/235] [D loss: 1.112316, acc: 82.42%] [G loss: 1.149492]\n",
      "[Epoch 11/50] [Batch 83/235] [D loss: 1.135797, acc: 85.16%] [G loss: 1.082468]\n",
      "[Epoch 11/50] [Batch 84/235] [D loss: 1.124296, acc: 84.18%] [G loss: 1.212983]\n",
      "[Epoch 11/50] [Batch 85/235] [D loss: 1.120307, acc: 84.38%] [G loss: 1.308784]\n",
      "[Epoch 11/50] [Batch 86/235] [D loss: 1.093532, acc: 86.52%] [G loss: 1.241146]\n",
      "[Epoch 11/50] [Batch 87/235] [D loss: 1.112818, acc: 84.57%] [G loss: 1.271937]\n",
      "[Epoch 11/50] [Batch 88/235] [D loss: 1.110442, acc: 83.59%] [G loss: 1.258804]\n",
      "[Epoch 11/50] [Batch 89/235] [D loss: 1.106475, acc: 83.40%] [G loss: 1.293815]\n",
      "[Epoch 11/50] [Batch 90/235] [D loss: 1.141837, acc: 81.05%] [G loss: 1.196765]\n",
      "[Epoch 11/50] [Batch 91/235] [D loss: 1.110279, acc: 83.01%] [G loss: 1.164037]\n",
      "[Epoch 11/50] [Batch 92/235] [D loss: 1.152488, acc: 84.57%] [G loss: 1.200739]\n",
      "[Epoch 11/50] [Batch 93/235] [D loss: 1.129608, acc: 82.81%] [G loss: 1.124986]\n",
      "[Epoch 11/50] [Batch 94/235] [D loss: 1.079235, acc: 84.18%] [G loss: 1.237975]\n",
      "[Epoch 11/50] [Batch 95/235] [D loss: 1.099755, acc: 85.74%] [G loss: 1.231005]\n",
      "[Epoch 11/50] [Batch 96/235] [D loss: 1.096522, acc: 84.18%] [G loss: 1.129255]\n",
      "[Epoch 11/50] [Batch 97/235] [D loss: 1.109906, acc: 84.38%] [G loss: 1.144056]\n",
      "[Epoch 11/50] [Batch 98/235] [D loss: 1.132359, acc: 81.84%] [G loss: 1.280376]\n",
      "[Epoch 11/50] [Batch 99/235] [D loss: 1.115891, acc: 84.38%] [G loss: 1.280232]\n",
      "[Epoch 11/50] [Batch 100/235] [D loss: 1.117676, acc: 83.79%] [G loss: 1.272725]\n",
      "[Epoch 11/50] [Batch 101/235] [D loss: 1.095973, acc: 84.77%] [G loss: 1.178759]\n",
      "[Epoch 11/50] [Batch 102/235] [D loss: 1.136374, acc: 82.42%] [G loss: 1.210819]\n",
      "[Epoch 11/50] [Batch 103/235] [D loss: 1.071768, acc: 82.03%] [G loss: 1.259901]\n",
      "[Epoch 11/50] [Batch 104/235] [D loss: 1.119541, acc: 83.98%] [G loss: 1.270226]\n",
      "[Epoch 11/50] [Batch 105/235] [D loss: 1.151858, acc: 83.79%] [G loss: 1.176335]\n",
      "[Epoch 11/50] [Batch 106/235] [D loss: 1.103082, acc: 83.40%] [G loss: 1.265911]\n",
      "[Epoch 11/50] [Batch 107/235] [D loss: 1.115589, acc: 82.03%] [G loss: 1.255568]\n",
      "[Epoch 11/50] [Batch 108/235] [D loss: 1.080065, acc: 86.91%] [G loss: 1.164443]\n",
      "[Epoch 11/50] [Batch 109/235] [D loss: 1.114338, acc: 84.77%] [G loss: 1.100022]\n",
      "[Epoch 11/50] [Batch 110/235] [D loss: 1.113710, acc: 83.98%] [G loss: 1.420876]\n",
      "[Epoch 11/50] [Batch 111/235] [D loss: 1.105538, acc: 84.38%] [G loss: 1.261816]\n",
      "[Epoch 11/50] [Batch 112/235] [D loss: 1.091723, acc: 83.01%] [G loss: 1.350920]\n",
      "[Epoch 11/50] [Batch 113/235] [D loss: 1.088832, acc: 83.98%] [G loss: 1.142680]\n",
      "[Epoch 11/50] [Batch 114/235] [D loss: 1.111131, acc: 83.40%] [G loss: 1.143037]\n",
      "[Epoch 11/50] [Batch 115/235] [D loss: 1.092290, acc: 83.79%] [G loss: 1.201863]\n",
      "[Epoch 11/50] [Batch 116/235] [D loss: 1.125671, acc: 84.38%] [G loss: 1.240276]\n",
      "[Epoch 11/50] [Batch 117/235] [D loss: 1.120529, acc: 85.74%] [G loss: 1.189850]\n",
      "[Epoch 11/50] [Batch 118/235] [D loss: 1.122620, acc: 84.38%] [G loss: 1.106676]\n",
      "[Epoch 11/50] [Batch 119/235] [D loss: 1.154112, acc: 83.59%] [G loss: 1.235333]\n",
      "[Epoch 11/50] [Batch 120/235] [D loss: 1.114623, acc: 84.57%] [G loss: 1.417870]\n",
      "[Epoch 11/50] [Batch 121/235] [D loss: 1.088263, acc: 83.20%] [G loss: 1.246292]\n",
      "[Epoch 11/50] [Batch 122/235] [D loss: 1.113164, acc: 83.40%] [G loss: 1.145104]\n",
      "[Epoch 11/50] [Batch 123/235] [D loss: 1.096791, acc: 85.35%] [G loss: 1.179029]\n",
      "[Epoch 11/50] [Batch 124/235] [D loss: 1.095778, acc: 85.94%] [G loss: 1.182714]\n",
      "[Epoch 11/50] [Batch 125/235] [D loss: 1.142093, acc: 86.13%] [G loss: 1.224883]\n",
      "[Epoch 11/50] [Batch 126/235] [D loss: 1.095543, acc: 82.42%] [G loss: 1.210097]\n",
      "[Epoch 11/50] [Batch 127/235] [D loss: 1.122186, acc: 83.59%] [G loss: 1.311727]\n",
      "[Epoch 11/50] [Batch 128/235] [D loss: 1.151367, acc: 83.20%] [G loss: 1.230852]\n",
      "[Epoch 11/50] [Batch 129/235] [D loss: 1.148609, acc: 83.40%] [G loss: 1.045683]\n",
      "[Epoch 11/50] [Batch 130/235] [D loss: 1.090619, acc: 84.57%] [G loss: 1.198655]\n",
      "[Epoch 11/50] [Batch 131/235] [D loss: 1.169452, acc: 83.59%] [G loss: 1.397064]\n",
      "[Epoch 11/50] [Batch 132/235] [D loss: 1.072132, acc: 81.64%] [G loss: 1.178802]\n",
      "[Epoch 11/50] [Batch 133/235] [D loss: 1.156177, acc: 81.25%] [G loss: 1.206653]\n",
      "[Epoch 11/50] [Batch 134/235] [D loss: 1.159409, acc: 83.59%] [G loss: 1.228638]\n",
      "[Epoch 11/50] [Batch 135/235] [D loss: 1.119368, acc: 84.77%] [G loss: 1.065724]\n",
      "[Epoch 11/50] [Batch 136/235] [D loss: 1.100294, acc: 84.38%] [G loss: 1.289068]\n",
      "[Epoch 11/50] [Batch 137/235] [D loss: 1.137005, acc: 87.11%] [G loss: 1.303710]\n",
      "[Epoch 11/50] [Batch 138/235] [D loss: 1.115324, acc: 84.96%] [G loss: 1.164266]\n",
      "[Epoch 11/50] [Batch 139/235] [D loss: 1.116595, acc: 85.55%] [G loss: 1.239113]\n",
      "[Epoch 11/50] [Batch 140/235] [D loss: 1.166022, acc: 82.62%] [G loss: 1.323749]\n",
      "[Epoch 11/50] [Batch 141/235] [D loss: 1.169963, acc: 80.47%] [G loss: 1.307473]\n",
      "[Epoch 11/50] [Batch 142/235] [D loss: 1.095519, acc: 85.35%] [G loss: 1.237615]\n",
      "[Epoch 11/50] [Batch 143/235] [D loss: 1.090018, acc: 84.96%] [G loss: 1.071368]\n",
      "[Epoch 11/50] [Batch 144/235] [D loss: 1.133812, acc: 84.77%] [G loss: 1.200842]\n",
      "[Epoch 11/50] [Batch 145/235] [D loss: 1.159129, acc: 82.23%] [G loss: 1.319650]\n",
      "[Epoch 11/50] [Batch 146/235] [D loss: 1.111321, acc: 85.16%] [G loss: 1.139925]\n",
      "[Epoch 11/50] [Batch 147/235] [D loss: 1.125247, acc: 85.74%] [G loss: 1.171604]\n",
      "[Epoch 11/50] [Batch 148/235] [D loss: 1.118068, acc: 83.59%] [G loss: 1.409674]\n",
      "[Epoch 11/50] [Batch 149/235] [D loss: 1.125049, acc: 85.74%] [G loss: 1.098133]\n",
      "[Epoch 11/50] [Batch 150/235] [D loss: 1.077968, acc: 84.18%] [G loss: 1.163138]\n",
      "[Epoch 11/50] [Batch 151/235] [D loss: 1.159611, acc: 82.62%] [G loss: 1.152031]\n",
      "[Epoch 11/50] [Batch 152/235] [D loss: 1.090388, acc: 86.33%] [G loss: 1.279786]\n",
      "[Epoch 11/50] [Batch 153/235] [D loss: 1.104419, acc: 85.35%] [G loss: 1.211926]\n",
      "[Epoch 11/50] [Batch 154/235] [D loss: 1.108752, acc: 85.74%] [G loss: 1.128350]\n",
      "[Epoch 11/50] [Batch 155/235] [D loss: 1.139130, acc: 84.18%] [G loss: 1.206797]\n",
      "[Epoch 11/50] [Batch 156/235] [D loss: 1.125066, acc: 83.40%] [G loss: 1.166804]\n",
      "[Epoch 11/50] [Batch 157/235] [D loss: 1.123899, acc: 84.77%] [G loss: 1.162178]\n",
      "[Epoch 11/50] [Batch 158/235] [D loss: 1.107228, acc: 81.25%] [G loss: 1.277726]\n",
      "[Epoch 11/50] [Batch 159/235] [D loss: 1.095306, acc: 84.38%] [G loss: 1.218939]\n",
      "[Epoch 11/50] [Batch 160/235] [D loss: 1.119782, acc: 84.96%] [G loss: 1.266566]\n",
      "[Epoch 11/50] [Batch 161/235] [D loss: 1.119307, acc: 81.05%] [G loss: 1.200084]\n",
      "[Epoch 11/50] [Batch 162/235] [D loss: 1.056245, acc: 87.11%] [G loss: 1.284265]\n",
      "[Epoch 11/50] [Batch 163/235] [D loss: 1.103281, acc: 82.81%] [G loss: 1.232965]\n",
      "[Epoch 11/50] [Batch 164/235] [D loss: 1.090970, acc: 86.13%] [G loss: 1.355607]\n",
      "[Epoch 11/50] [Batch 165/235] [D loss: 1.127517, acc: 82.81%] [G loss: 1.291186]\n",
      "[Epoch 11/50] [Batch 166/235] [D loss: 1.098781, acc: 85.35%] [G loss: 1.372813]\n",
      "[Epoch 11/50] [Batch 167/235] [D loss: 1.086202, acc: 84.77%] [G loss: 1.229387]\n",
      "[Epoch 11/50] [Batch 168/235] [D loss: 1.155603, acc: 83.20%] [G loss: 1.248904]\n",
      "[Epoch 11/50] [Batch 169/235] [D loss: 1.157482, acc: 84.57%] [G loss: 1.288930]\n",
      "[Epoch 11/50] [Batch 170/235] [D loss: 1.061281, acc: 83.40%] [G loss: 1.208796]\n",
      "[Epoch 11/50] [Batch 171/235] [D loss: 1.134278, acc: 80.66%] [G loss: 1.263633]\n",
      "[Epoch 11/50] [Batch 172/235] [D loss: 1.161830, acc: 84.57%] [G loss: 1.170247]\n",
      "[Epoch 11/50] [Batch 173/235] [D loss: 1.129686, acc: 82.81%] [G loss: 1.342114]\n",
      "[Epoch 11/50] [Batch 174/235] [D loss: 1.155045, acc: 84.77%] [G loss: 1.207806]\n",
      "[Epoch 11/50] [Batch 175/235] [D loss: 1.099495, acc: 86.33%] [G loss: 1.160689]\n",
      "[Epoch 11/50] [Batch 176/235] [D loss: 1.104499, acc: 84.96%] [G loss: 1.293326]\n",
      "[Epoch 11/50] [Batch 177/235] [D loss: 1.152955, acc: 82.62%] [G loss: 1.143899]\n",
      "[Epoch 11/50] [Batch 178/235] [D loss: 1.129804, acc: 83.01%] [G loss: 1.149006]\n",
      "[Epoch 11/50] [Batch 179/235] [D loss: 1.145200, acc: 84.57%] [G loss: 1.255262]\n",
      "[Epoch 11/50] [Batch 180/235] [D loss: 1.114701, acc: 84.38%] [G loss: 1.256824]\n",
      "[Epoch 11/50] [Batch 181/235] [D loss: 1.118082, acc: 82.42%] [G loss: 1.229317]\n",
      "[Epoch 11/50] [Batch 182/235] [D loss: 1.158136, acc: 81.84%] [G loss: 1.090468]\n",
      "[Epoch 11/50] [Batch 183/235] [D loss: 1.081622, acc: 85.35%] [G loss: 1.211180]\n",
      "[Epoch 11/50] [Batch 184/235] [D loss: 1.088851, acc: 84.57%] [G loss: 1.244874]\n",
      "[Epoch 11/50] [Batch 185/235] [D loss: 1.129993, acc: 84.18%] [G loss: 1.276532]\n",
      "[Epoch 11/50] [Batch 186/235] [D loss: 1.114697, acc: 83.20%] [G loss: 1.221451]\n",
      "[Epoch 11/50] [Batch 187/235] [D loss: 1.114696, acc: 83.40%] [G loss: 1.357025]\n",
      "[Epoch 11/50] [Batch 188/235] [D loss: 1.088707, acc: 83.59%] [G loss: 1.324108]\n",
      "[Epoch 11/50] [Batch 189/235] [D loss: 1.105958, acc: 85.16%] [G loss: 1.173350]\n",
      "[Epoch 11/50] [Batch 190/235] [D loss: 1.130133, acc: 83.20%] [G loss: 1.175672]\n",
      "[Epoch 11/50] [Batch 191/235] [D loss: 1.102592, acc: 83.98%] [G loss: 1.274797]\n",
      "[Epoch 11/50] [Batch 192/235] [D loss: 1.112329, acc: 85.74%] [G loss: 1.293700]\n",
      "[Epoch 11/50] [Batch 193/235] [D loss: 1.076431, acc: 86.72%] [G loss: 1.164408]\n",
      "[Epoch 11/50] [Batch 194/235] [D loss: 1.129865, acc: 83.01%] [G loss: 1.128752]\n",
      "[Epoch 11/50] [Batch 195/235] [D loss: 1.114240, acc: 85.16%] [G loss: 1.243633]\n",
      "[Epoch 11/50] [Batch 196/235] [D loss: 1.101731, acc: 84.38%] [G loss: 1.195993]\n",
      "[Epoch 11/50] [Batch 197/235] [D loss: 1.096177, acc: 83.79%] [G loss: 1.124672]\n",
      "[Epoch 11/50] [Batch 198/235] [D loss: 1.074728, acc: 85.35%] [G loss: 1.178004]\n",
      "[Epoch 11/50] [Batch 199/235] [D loss: 1.073782, acc: 84.18%] [G loss: 1.291372]\n",
      "[Epoch 11/50] [Batch 200/235] [D loss: 1.164299, acc: 84.96%] [G loss: 1.162814]\n",
      "[Epoch 11/50] [Batch 201/235] [D loss: 1.109717, acc: 84.96%] [G loss: 1.248832]\n",
      "[Epoch 11/50] [Batch 202/235] [D loss: 1.177694, acc: 82.81%] [G loss: 1.236104]\n",
      "[Epoch 11/50] [Batch 203/235] [D loss: 1.130594, acc: 84.18%] [G loss: 1.326750]\n",
      "[Epoch 11/50] [Batch 204/235] [D loss: 1.143068, acc: 83.01%] [G loss: 1.334686]\n",
      "[Epoch 11/50] [Batch 205/235] [D loss: 1.091449, acc: 86.13%] [G loss: 1.135207]\n",
      "[Epoch 11/50] [Batch 206/235] [D loss: 1.139634, acc: 83.01%] [G loss: 1.098891]\n",
      "[Epoch 11/50] [Batch 207/235] [D loss: 1.117282, acc: 85.94%] [G loss: 1.295255]\n",
      "[Epoch 11/50] [Batch 208/235] [D loss: 1.108944, acc: 83.01%] [G loss: 1.385448]\n",
      "[Epoch 11/50] [Batch 209/235] [D loss: 1.114458, acc: 83.79%] [G loss: 1.236097]\n",
      "[Epoch 11/50] [Batch 210/235] [D loss: 1.105703, acc: 83.40%] [G loss: 1.170042]\n",
      "[Epoch 11/50] [Batch 211/235] [D loss: 1.078455, acc: 83.01%] [G loss: 1.359039]\n",
      "[Epoch 11/50] [Batch 212/235] [D loss: 1.116319, acc: 84.57%] [G loss: 1.175469]\n",
      "[Epoch 11/50] [Batch 213/235] [D loss: 1.090982, acc: 82.62%] [G loss: 1.228276]\n",
      "[Epoch 11/50] [Batch 214/235] [D loss: 1.112315, acc: 84.18%] [G loss: 1.284897]\n",
      "[Epoch 11/50] [Batch 215/235] [D loss: 1.108702, acc: 86.72%] [G loss: 1.288241]\n",
      "[Epoch 11/50] [Batch 216/235] [D loss: 1.098289, acc: 82.23%] [G loss: 1.167005]\n",
      "[Epoch 11/50] [Batch 217/235] [D loss: 1.118914, acc: 83.59%] [G loss: 1.149318]\n",
      "[Epoch 11/50] [Batch 218/235] [D loss: 1.105384, acc: 85.74%] [G loss: 1.274405]\n",
      "[Epoch 11/50] [Batch 219/235] [D loss: 1.148890, acc: 84.77%] [G loss: 1.269828]\n",
      "[Epoch 11/50] [Batch 220/235] [D loss: 1.121782, acc: 84.77%] [G loss: 1.246851]\n",
      "[Epoch 11/50] [Batch 221/235] [D loss: 1.133628, acc: 83.40%] [G loss: 1.198923]\n",
      "[Epoch 11/50] [Batch 222/235] [D loss: 1.129769, acc: 82.23%] [G loss: 1.241004]\n",
      "[Epoch 11/50] [Batch 223/235] [D loss: 1.126397, acc: 82.03%] [G loss: 1.301545]\n",
      "[Epoch 11/50] [Batch 224/235] [D loss: 1.108796, acc: 83.98%] [G loss: 1.201138]\n",
      "[Epoch 11/50] [Batch 225/235] [D loss: 1.066638, acc: 85.94%] [G loss: 1.171453]\n",
      "[Epoch 11/50] [Batch 226/235] [D loss: 1.086093, acc: 84.77%] [G loss: 1.147973]\n",
      "[Epoch 11/50] [Batch 227/235] [D loss: 1.151531, acc: 84.77%] [G loss: 1.278760]\n",
      "[Epoch 11/50] [Batch 228/235] [D loss: 1.069263, acc: 82.42%] [G loss: 1.241286]\n",
      "[Epoch 11/50] [Batch 229/235] [D loss: 1.074159, acc: 87.30%] [G loss: 1.196716]\n",
      "[Epoch 11/50] [Batch 230/235] [D loss: 1.120148, acc: 84.18%] [G loss: 1.151582]\n",
      "[Epoch 11/50] [Batch 231/235] [D loss: 1.061608, acc: 86.52%] [G loss: 1.197845]\n",
      "[Epoch 11/50] [Batch 232/235] [D loss: 1.094016, acc: 84.18%] [G loss: 1.252109]\n",
      "[Epoch 11/50] [Batch 233/235] [D loss: 1.102015, acc: 85.94%] [G loss: 1.147201]\n",
      "[Epoch 11/50] [Batch 234/235] [D loss: 1.161168, acc: 80.21%] [G loss: 1.211021]\n",
      "[Epoch 12/50] [Batch 0/235] [D loss: 1.124982, acc: 84.18%] [G loss: 1.122134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/50] [Batch 1/235] [D loss: 1.106492, acc: 85.35%] [G loss: 1.117539]\n",
      "[Epoch 12/50] [Batch 2/235] [D loss: 1.145050, acc: 83.40%] [G loss: 1.298417]\n",
      "[Epoch 12/50] [Batch 3/235] [D loss: 1.087171, acc: 83.79%] [G loss: 1.384347]\n",
      "[Epoch 12/50] [Batch 4/235] [D loss: 1.100555, acc: 83.98%] [G loss: 1.331138]\n",
      "[Epoch 12/50] [Batch 5/235] [D loss: 1.103475, acc: 87.50%] [G loss: 1.151132]\n",
      "[Epoch 12/50] [Batch 6/235] [D loss: 1.103907, acc: 85.94%] [G loss: 1.149661]\n",
      "[Epoch 12/50] [Batch 7/235] [D loss: 1.073364, acc: 84.38%] [G loss: 1.077037]\n",
      "[Epoch 12/50] [Batch 8/235] [D loss: 1.052517, acc: 87.89%] [G loss: 1.277031]\n",
      "[Epoch 12/50] [Batch 9/235] [D loss: 1.136103, acc: 85.16%] [G loss: 1.269809]\n",
      "[Epoch 12/50] [Batch 10/235] [D loss: 1.113579, acc: 80.66%] [G loss: 1.096061]\n",
      "[Epoch 12/50] [Batch 11/235] [D loss: 1.066440, acc: 85.94%] [G loss: 1.129113]\n",
      "[Epoch 12/50] [Batch 12/235] [D loss: 1.118637, acc: 85.55%] [G loss: 1.214103]\n",
      "[Epoch 12/50] [Batch 13/235] [D loss: 1.089318, acc: 85.94%] [G loss: 1.272897]\n",
      "[Epoch 12/50] [Batch 14/235] [D loss: 1.083378, acc: 82.23%] [G loss: 1.242579]\n",
      "[Epoch 12/50] [Batch 15/235] [D loss: 1.095717, acc: 85.94%] [G loss: 1.199514]\n",
      "[Epoch 12/50] [Batch 16/235] [D loss: 1.116624, acc: 86.13%] [G loss: 1.260723]\n",
      "[Epoch 12/50] [Batch 17/235] [D loss: 1.134660, acc: 83.79%] [G loss: 1.146127]\n",
      "[Epoch 12/50] [Batch 18/235] [D loss: 1.098987, acc: 83.59%] [G loss: 1.211655]\n",
      "[Epoch 12/50] [Batch 19/235] [D loss: 1.143013, acc: 83.79%] [G loss: 1.258903]\n",
      "[Epoch 12/50] [Batch 20/235] [D loss: 1.092047, acc: 83.98%] [G loss: 1.160186]\n",
      "[Epoch 12/50] [Batch 21/235] [D loss: 1.086356, acc: 84.96%] [G loss: 1.219299]\n",
      "[Epoch 12/50] [Batch 22/235] [D loss: 1.084610, acc: 84.77%] [G loss: 1.239535]\n",
      "[Epoch 12/50] [Batch 23/235] [D loss: 1.142281, acc: 83.59%] [G loss: 1.131294]\n",
      "[Epoch 12/50] [Batch 24/235] [D loss: 1.158660, acc: 85.55%] [G loss: 1.083373]\n",
      "[Epoch 12/50] [Batch 25/235] [D loss: 1.076959, acc: 86.33%] [G loss: 1.278000]\n",
      "[Epoch 12/50] [Batch 26/235] [D loss: 1.103460, acc: 83.01%] [G loss: 1.336731]\n",
      "[Epoch 12/50] [Batch 27/235] [D loss: 1.102459, acc: 82.03%] [G loss: 1.155593]\n",
      "[Epoch 12/50] [Batch 28/235] [D loss: 1.145420, acc: 82.81%] [G loss: 1.122097]\n",
      "[Epoch 12/50] [Batch 29/235] [D loss: 1.104336, acc: 85.74%] [G loss: 1.267338]\n",
      "[Epoch 12/50] [Batch 30/235] [D loss: 1.102293, acc: 83.59%] [G loss: 1.371361]\n",
      "[Epoch 12/50] [Batch 31/235] [D loss: 1.074215, acc: 85.35%] [G loss: 1.220135]\n",
      "[Epoch 12/50] [Batch 32/235] [D loss: 1.176436, acc: 83.40%] [G loss: 1.059444]\n",
      "[Epoch 12/50] [Batch 33/235] [D loss: 1.093831, acc: 85.55%] [G loss: 1.158784]\n",
      "[Epoch 12/50] [Batch 34/235] [D loss: 1.114833, acc: 85.16%] [G loss: 1.383450]\n",
      "[Epoch 12/50] [Batch 35/235] [D loss: 1.149647, acc: 87.11%] [G loss: 1.189935]\n",
      "[Epoch 12/50] [Batch 36/235] [D loss: 1.147698, acc: 86.13%] [G loss: 1.165909]\n",
      "[Epoch 12/50] [Batch 37/235] [D loss: 1.102928, acc: 85.74%] [G loss: 1.242916]\n",
      "[Epoch 12/50] [Batch 38/235] [D loss: 1.124849, acc: 83.98%] [G loss: 1.228724]\n",
      "[Epoch 12/50] [Batch 39/235] [D loss: 1.141751, acc: 82.81%] [G loss: 1.205114]\n",
      "[Epoch 12/50] [Batch 40/235] [D loss: 1.091274, acc: 82.81%] [G loss: 1.253258]\n",
      "[Epoch 12/50] [Batch 41/235] [D loss: 1.059907, acc: 84.18%] [G loss: 1.208151]\n",
      "[Epoch 12/50] [Batch 42/235] [D loss: 1.139172, acc: 82.23%] [G loss: 1.209029]\n",
      "[Epoch 12/50] [Batch 43/235] [D loss: 1.162014, acc: 82.62%] [G loss: 1.249459]\n",
      "[Epoch 12/50] [Batch 44/235] [D loss: 1.154830, acc: 83.40%] [G loss: 1.327589]\n",
      "[Epoch 12/50] [Batch 45/235] [D loss: 1.138211, acc: 86.33%] [G loss: 1.233445]\n",
      "[Epoch 12/50] [Batch 46/235] [D loss: 1.099968, acc: 83.01%] [G loss: 1.203934]\n",
      "[Epoch 12/50] [Batch 47/235] [D loss: 1.166789, acc: 85.55%] [G loss: 1.193326]\n",
      "[Epoch 12/50] [Batch 48/235] [D loss: 1.124398, acc: 85.16%] [G loss: 1.290445]\n",
      "[Epoch 12/50] [Batch 49/235] [D loss: 1.078851, acc: 84.96%] [G loss: 1.197985]\n",
      "[Epoch 12/50] [Batch 50/235] [D loss: 1.157973, acc: 81.84%] [G loss: 1.106310]\n",
      "[Epoch 12/50] [Batch 51/235] [D loss: 1.157113, acc: 82.62%] [G loss: 1.332341]\n",
      "[Epoch 12/50] [Batch 52/235] [D loss: 1.139584, acc: 84.57%] [G loss: 1.238825]\n",
      "[Epoch 12/50] [Batch 53/235] [D loss: 1.117069, acc: 83.40%] [G loss: 1.098243]\n",
      "[Epoch 12/50] [Batch 54/235] [D loss: 1.136150, acc: 82.62%] [G loss: 1.183546]\n",
      "[Epoch 12/50] [Batch 55/235] [D loss: 1.110508, acc: 83.98%] [G loss: 1.305421]\n",
      "[Epoch 12/50] [Batch 56/235] [D loss: 1.109537, acc: 83.01%] [G loss: 1.352733]\n",
      "[Epoch 12/50] [Batch 57/235] [D loss: 1.118835, acc: 86.13%] [G loss: 1.129111]\n",
      "[Epoch 12/50] [Batch 58/235] [D loss: 1.112937, acc: 86.52%] [G loss: 1.164883]\n",
      "[Epoch 12/50] [Batch 59/235] [D loss: 1.099457, acc: 84.77%] [G loss: 1.319384]\n",
      "[Epoch 12/50] [Batch 60/235] [D loss: 1.086210, acc: 85.35%] [G loss: 1.193672]\n",
      "[Epoch 12/50] [Batch 61/235] [D loss: 1.134987, acc: 82.42%] [G loss: 1.178432]\n",
      "[Epoch 12/50] [Batch 62/235] [D loss: 1.110118, acc: 83.20%] [G loss: 1.442393]\n",
      "[Epoch 12/50] [Batch 63/235] [D loss: 1.079430, acc: 87.11%] [G loss: 1.248829]\n",
      "[Epoch 12/50] [Batch 64/235] [D loss: 1.144009, acc: 82.03%] [G loss: 1.211590]\n",
      "[Epoch 12/50] [Batch 65/235] [D loss: 1.145728, acc: 83.59%] [G loss: 1.333549]\n",
      "[Epoch 12/50] [Batch 66/235] [D loss: 1.178993, acc: 83.01%] [G loss: 1.361255]\n",
      "[Epoch 12/50] [Batch 67/235] [D loss: 1.170788, acc: 84.18%] [G loss: 1.082232]\n",
      "[Epoch 12/50] [Batch 68/235] [D loss: 1.129492, acc: 82.42%] [G loss: 1.146092]\n",
      "[Epoch 12/50] [Batch 69/235] [D loss: 1.135111, acc: 85.55%] [G loss: 1.290541]\n",
      "[Epoch 12/50] [Batch 70/235] [D loss: 1.094148, acc: 85.35%] [G loss: 1.245591]\n",
      "[Epoch 12/50] [Batch 71/235] [D loss: 1.136939, acc: 83.40%] [G loss: 1.199531]\n",
      "[Epoch 12/50] [Batch 72/235] [D loss: 1.143937, acc: 84.18%] [G loss: 1.012084]\n",
      "[Epoch 12/50] [Batch 73/235] [D loss: 1.114573, acc: 82.42%] [G loss: 1.273156]\n",
      "[Epoch 12/50] [Batch 74/235] [D loss: 1.110446, acc: 85.16%] [G loss: 1.243232]\n",
      "[Epoch 12/50] [Batch 75/235] [D loss: 1.112224, acc: 82.42%] [G loss: 1.277511]\n",
      "[Epoch 12/50] [Batch 76/235] [D loss: 1.117911, acc: 84.77%] [G loss: 1.180312]\n",
      "[Epoch 12/50] [Batch 77/235] [D loss: 1.143171, acc: 81.05%] [G loss: 1.291373]\n",
      "[Epoch 12/50] [Batch 78/235] [D loss: 1.113572, acc: 83.40%] [G loss: 1.371118]\n",
      "[Epoch 12/50] [Batch 79/235] [D loss: 1.118182, acc: 84.96%] [G loss: 1.228393]\n",
      "[Epoch 12/50] [Batch 80/235] [D loss: 1.155732, acc: 81.64%] [G loss: 1.224550]\n",
      "[Epoch 12/50] [Batch 81/235] [D loss: 1.098516, acc: 83.40%] [G loss: 1.329851]\n",
      "[Epoch 12/50] [Batch 82/235] [D loss: 1.074125, acc: 84.96%] [G loss: 1.214355]\n",
      "[Epoch 12/50] [Batch 83/235] [D loss: 1.051398, acc: 85.16%] [G loss: 1.235883]\n",
      "[Epoch 12/50] [Batch 84/235] [D loss: 1.103296, acc: 85.35%] [G loss: 1.136118]\n",
      "[Epoch 12/50] [Batch 85/235] [D loss: 1.109653, acc: 85.55%] [G loss: 1.071635]\n",
      "[Epoch 12/50] [Batch 86/235] [D loss: 1.072808, acc: 84.96%] [G loss: 1.258038]\n",
      "[Epoch 12/50] [Batch 87/235] [D loss: 1.127228, acc: 84.38%] [G loss: 1.201087]\n",
      "[Epoch 12/50] [Batch 88/235] [D loss: 1.115602, acc: 83.59%] [G loss: 1.165064]\n",
      "[Epoch 12/50] [Batch 89/235] [D loss: 1.097566, acc: 84.96%] [G loss: 1.139197]\n",
      "[Epoch 12/50] [Batch 90/235] [D loss: 1.132184, acc: 84.57%] [G loss: 1.114045]\n",
      "[Epoch 12/50] [Batch 91/235] [D loss: 1.084933, acc: 83.98%] [G loss: 1.126287]\n",
      "[Epoch 12/50] [Batch 92/235] [D loss: 1.141882, acc: 81.45%] [G loss: 1.160867]\n",
      "[Epoch 12/50] [Batch 93/235] [D loss: 1.132538, acc: 87.30%] [G loss: 1.223176]\n",
      "[Epoch 12/50] [Batch 94/235] [D loss: 1.104339, acc: 83.01%] [G loss: 1.204556]\n",
      "[Epoch 12/50] [Batch 95/235] [D loss: 1.097735, acc: 86.33%] [G loss: 1.101205]\n",
      "[Epoch 12/50] [Batch 96/235] [D loss: 1.106113, acc: 84.18%] [G loss: 1.277732]\n",
      "[Epoch 12/50] [Batch 97/235] [D loss: 1.119709, acc: 86.52%] [G loss: 1.206580]\n",
      "[Epoch 12/50] [Batch 98/235] [D loss: 1.119648, acc: 82.81%] [G loss: 1.187457]\n",
      "[Epoch 12/50] [Batch 99/235] [D loss: 1.152454, acc: 82.62%] [G loss: 1.226102]\n",
      "[Epoch 12/50] [Batch 100/235] [D loss: 1.105200, acc: 84.57%] [G loss: 1.219251]\n",
      "[Epoch 12/50] [Batch 101/235] [D loss: 1.122139, acc: 82.42%] [G loss: 1.144064]\n",
      "[Epoch 12/50] [Batch 102/235] [D loss: 1.095364, acc: 84.96%] [G loss: 1.095076]\n",
      "[Epoch 12/50] [Batch 103/235] [D loss: 1.087393, acc: 84.77%] [G loss: 1.098826]\n",
      "[Epoch 12/50] [Batch 104/235] [D loss: 1.087810, acc: 83.98%] [G loss: 1.201929]\n",
      "[Epoch 12/50] [Batch 105/235] [D loss: 1.125331, acc: 84.18%] [G loss: 1.207614]\n",
      "[Epoch 12/50] [Batch 106/235] [D loss: 1.083446, acc: 85.35%] [G loss: 1.192623]\n",
      "[Epoch 12/50] [Batch 107/235] [D loss: 1.132242, acc: 85.94%] [G loss: 1.160166]\n",
      "[Epoch 12/50] [Batch 108/235] [D loss: 1.120144, acc: 84.77%] [G loss: 1.142737]\n",
      "[Epoch 12/50] [Batch 109/235] [D loss: 1.153692, acc: 82.81%] [G loss: 1.317094]\n",
      "[Epoch 12/50] [Batch 110/235] [D loss: 1.111788, acc: 84.18%] [G loss: 1.223599]\n",
      "[Epoch 12/50] [Batch 111/235] [D loss: 1.142950, acc: 84.18%] [G loss: 1.115063]\n",
      "[Epoch 12/50] [Batch 112/235] [D loss: 1.088009, acc: 81.84%] [G loss: 1.201092]\n",
      "[Epoch 12/50] [Batch 113/235] [D loss: 1.127217, acc: 84.96%] [G loss: 1.299613]\n",
      "[Epoch 12/50] [Batch 114/235] [D loss: 1.101701, acc: 87.89%] [G loss: 1.246122]\n",
      "[Epoch 12/50] [Batch 115/235] [D loss: 1.134557, acc: 82.81%] [G loss: 1.079792]\n",
      "[Epoch 12/50] [Batch 116/235] [D loss: 1.121476, acc: 85.74%] [G loss: 1.072991]\n",
      "[Epoch 12/50] [Batch 117/235] [D loss: 1.147462, acc: 85.35%] [G loss: 1.326141]\n",
      "[Epoch 12/50] [Batch 118/235] [D loss: 1.102453, acc: 85.74%] [G loss: 1.159817]\n",
      "[Epoch 12/50] [Batch 119/235] [D loss: 1.082459, acc: 84.18%] [G loss: 1.249522]\n",
      "[Epoch 12/50] [Batch 120/235] [D loss: 1.124034, acc: 85.74%] [G loss: 1.192736]\n",
      "[Epoch 12/50] [Batch 121/235] [D loss: 1.119501, acc: 82.23%] [G loss: 1.272433]\n",
      "[Epoch 12/50] [Batch 122/235] [D loss: 1.121973, acc: 82.03%] [G loss: 1.291060]\n",
      "[Epoch 12/50] [Batch 123/235] [D loss: 1.073236, acc: 85.74%] [G loss: 1.210116]\n",
      "[Epoch 12/50] [Batch 124/235] [D loss: 1.117123, acc: 83.98%] [G loss: 1.221954]\n",
      "[Epoch 12/50] [Batch 125/235] [D loss: 1.124353, acc: 85.16%] [G loss: 1.071427]\n",
      "[Epoch 12/50] [Batch 126/235] [D loss: 1.139062, acc: 81.64%] [G loss: 1.216405]\n",
      "[Epoch 12/50] [Batch 127/235] [D loss: 1.100059, acc: 85.55%] [G loss: 1.373426]\n",
      "[Epoch 12/50] [Batch 128/235] [D loss: 1.100322, acc: 83.40%] [G loss: 1.222616]\n",
      "[Epoch 12/50] [Batch 129/235] [D loss: 1.119947, acc: 86.52%] [G loss: 1.018767]\n",
      "[Epoch 12/50] [Batch 130/235] [D loss: 1.087165, acc: 85.35%] [G loss: 1.234590]\n",
      "[Epoch 12/50] [Batch 131/235] [D loss: 1.135336, acc: 84.38%] [G loss: 1.268619]\n",
      "[Epoch 12/50] [Batch 132/235] [D loss: 1.165677, acc: 82.03%] [G loss: 1.153653]\n",
      "[Epoch 12/50] [Batch 133/235] [D loss: 1.108460, acc: 84.96%] [G loss: 1.231113]\n",
      "[Epoch 12/50] [Batch 134/235] [D loss: 1.175112, acc: 83.79%] [G loss: 1.120889]\n",
      "[Epoch 12/50] [Batch 135/235] [D loss: 1.159749, acc: 83.20%] [G loss: 1.395998]\n",
      "[Epoch 12/50] [Batch 136/235] [D loss: 1.122601, acc: 81.45%] [G loss: 1.311382]\n",
      "[Epoch 12/50] [Batch 137/235] [D loss: 1.080735, acc: 84.77%] [G loss: 1.170844]\n",
      "[Epoch 12/50] [Batch 138/235] [D loss: 1.121192, acc: 84.38%] [G loss: 1.166348]\n",
      "[Epoch 12/50] [Batch 139/235] [D loss: 1.098073, acc: 83.20%] [G loss: 1.156573]\n",
      "[Epoch 12/50] [Batch 140/235] [D loss: 1.156708, acc: 85.94%] [G loss: 1.220614]\n",
      "[Epoch 12/50] [Batch 141/235] [D loss: 1.102653, acc: 83.40%] [G loss: 1.179789]\n",
      "[Epoch 12/50] [Batch 142/235] [D loss: 1.085881, acc: 83.98%] [G loss: 1.084395]\n",
      "[Epoch 12/50] [Batch 143/235] [D loss: 1.105565, acc: 85.35%] [G loss: 1.207558]\n",
      "[Epoch 12/50] [Batch 144/235] [D loss: 1.120086, acc: 84.57%] [G loss: 1.382797]\n",
      "[Epoch 12/50] [Batch 145/235] [D loss: 1.119151, acc: 86.33%] [G loss: 1.228718]\n",
      "[Epoch 12/50] [Batch 146/235] [D loss: 1.097380, acc: 84.96%] [G loss: 1.073349]\n",
      "[Epoch 12/50] [Batch 147/235] [D loss: 1.123885, acc: 84.38%] [G loss: 1.153252]\n",
      "[Epoch 12/50] [Batch 148/235] [D loss: 1.136001, acc: 82.42%] [G loss: 1.363714]\n",
      "[Epoch 12/50] [Batch 149/235] [D loss: 1.086709, acc: 83.59%] [G loss: 1.332960]\n",
      "[Epoch 12/50] [Batch 150/235] [D loss: 1.150379, acc: 86.91%] [G loss: 1.097584]\n",
      "[Epoch 12/50] [Batch 151/235] [D loss: 1.109340, acc: 84.57%] [G loss: 1.354985]\n",
      "[Epoch 12/50] [Batch 152/235] [D loss: 1.103530, acc: 83.79%] [G loss: 1.357739]\n",
      "[Epoch 12/50] [Batch 153/235] [D loss: 1.114545, acc: 84.38%] [G loss: 1.202204]\n",
      "[Epoch 12/50] [Batch 154/235] [D loss: 1.088118, acc: 85.35%] [G loss: 1.162214]\n",
      "[Epoch 12/50] [Batch 155/235] [D loss: 1.193407, acc: 82.42%] [G loss: 1.212623]\n",
      "[Epoch 12/50] [Batch 156/235] [D loss: 1.108584, acc: 84.77%] [G loss: 1.127820]\n",
      "[Epoch 12/50] [Batch 157/235] [D loss: 1.095200, acc: 84.96%] [G loss: 1.118421]\n",
      "[Epoch 12/50] [Batch 158/235] [D loss: 1.116663, acc: 84.18%] [G loss: 1.190565]\n",
      "[Epoch 12/50] [Batch 159/235] [D loss: 1.165845, acc: 85.16%] [G loss: 1.216137]\n",
      "[Epoch 12/50] [Batch 160/235] [D loss: 1.127569, acc: 83.98%] [G loss: 1.138437]\n",
      "[Epoch 12/50] [Batch 161/235] [D loss: 1.124260, acc: 85.55%] [G loss: 1.169831]\n",
      "[Epoch 12/50] [Batch 162/235] [D loss: 1.097964, acc: 86.72%] [G loss: 1.220948]\n",
      "[Epoch 12/50] [Batch 163/235] [D loss: 1.147145, acc: 84.96%] [G loss: 1.248147]\n",
      "[Epoch 12/50] [Batch 164/235] [D loss: 1.101268, acc: 80.47%] [G loss: 1.292558]\n",
      "[Epoch 12/50] [Batch 165/235] [D loss: 1.110630, acc: 83.59%] [G loss: 1.148513]\n",
      "[Epoch 12/50] [Batch 166/235] [D loss: 1.171753, acc: 85.35%] [G loss: 1.102144]\n",
      "[Epoch 12/50] [Batch 167/235] [D loss: 1.155784, acc: 83.98%] [G loss: 1.171249]\n",
      "[Epoch 12/50] [Batch 168/235] [D loss: 1.073645, acc: 85.16%] [G loss: 1.223105]\n",
      "[Epoch 12/50] [Batch 169/235] [D loss: 1.116119, acc: 88.09%] [G loss: 1.251511]\n",
      "[Epoch 12/50] [Batch 170/235] [D loss: 1.123919, acc: 83.20%] [G loss: 1.161368]\n",
      "[Epoch 12/50] [Batch 171/235] [D loss: 1.158928, acc: 84.57%] [G loss: 1.175372]\n",
      "[Epoch 12/50] [Batch 172/235] [D loss: 1.137061, acc: 82.81%] [G loss: 1.146055]\n",
      "[Epoch 12/50] [Batch 173/235] [D loss: 1.110737, acc: 84.18%] [G loss: 1.180815]\n",
      "[Epoch 12/50] [Batch 174/235] [D loss: 1.121632, acc: 85.74%] [G loss: 1.181369]\n",
      "[Epoch 12/50] [Batch 175/235] [D loss: 1.087120, acc: 83.98%] [G loss: 1.248370]\n",
      "[Epoch 12/50] [Batch 176/235] [D loss: 1.138727, acc: 83.98%] [G loss: 1.145577]\n",
      "[Epoch 12/50] [Batch 177/235] [D loss: 1.154975, acc: 85.35%] [G loss: 1.177964]\n",
      "[Epoch 12/50] [Batch 178/235] [D loss: 1.107893, acc: 85.55%] [G loss: 1.332499]\n",
      "[Epoch 12/50] [Batch 179/235] [D loss: 1.137325, acc: 81.45%] [G loss: 1.341687]\n",
      "[Epoch 12/50] [Batch 180/235] [D loss: 1.149593, acc: 84.57%] [G loss: 1.184863]\n",
      "[Epoch 12/50] [Batch 181/235] [D loss: 1.092969, acc: 88.09%] [G loss: 1.312009]\n",
      "[Epoch 12/50] [Batch 182/235] [D loss: 1.117329, acc: 84.96%] [G loss: 1.158742]\n",
      "[Epoch 12/50] [Batch 183/235] [D loss: 1.104438, acc: 83.98%] [G loss: 1.185745]\n",
      "[Epoch 12/50] [Batch 184/235] [D loss: 1.110933, acc: 84.77%] [G loss: 1.332050]\n",
      "[Epoch 12/50] [Batch 185/235] [D loss: 1.110143, acc: 83.01%] [G loss: 1.229797]\n",
      "[Epoch 12/50] [Batch 186/235] [D loss: 1.086204, acc: 85.55%] [G loss: 1.186417]\n",
      "[Epoch 12/50] [Batch 187/235] [D loss: 1.178832, acc: 82.81%] [G loss: 1.203382]\n",
      "[Epoch 12/50] [Batch 188/235] [D loss: 1.163259, acc: 80.86%] [G loss: 1.150845]\n",
      "[Epoch 12/50] [Batch 189/235] [D loss: 1.152851, acc: 83.20%] [G loss: 1.120620]\n",
      "[Epoch 12/50] [Batch 190/235] [D loss: 1.092576, acc: 85.94%] [G loss: 1.226669]\n",
      "[Epoch 12/50] [Batch 191/235] [D loss: 1.111045, acc: 84.57%] [G loss: 1.361079]\n",
      "[Epoch 12/50] [Batch 192/235] [D loss: 1.141403, acc: 85.35%] [G loss: 1.254628]\n",
      "[Epoch 12/50] [Batch 193/235] [D loss: 1.125628, acc: 84.57%] [G loss: 1.144972]\n",
      "[Epoch 12/50] [Batch 194/235] [D loss: 1.146546, acc: 81.25%] [G loss: 1.228041]\n",
      "[Epoch 12/50] [Batch 195/235] [D loss: 1.073595, acc: 84.38%] [G loss: 1.210930]\n",
      "[Epoch 12/50] [Batch 196/235] [D loss: 1.067576, acc: 85.35%] [G loss: 1.239586]\n",
      "[Epoch 12/50] [Batch 197/235] [D loss: 1.094851, acc: 83.59%] [G loss: 1.210088]\n",
      "[Epoch 12/50] [Batch 198/235] [D loss: 1.109906, acc: 86.91%] [G loss: 1.238275]\n",
      "[Epoch 12/50] [Batch 199/235] [D loss: 1.093339, acc: 84.38%] [G loss: 1.185030]\n",
      "[Epoch 12/50] [Batch 200/235] [D loss: 1.098922, acc: 85.55%] [G loss: 1.226899]\n",
      "[Epoch 12/50] [Batch 201/235] [D loss: 1.097754, acc: 86.13%] [G loss: 1.388695]\n",
      "[Epoch 12/50] [Batch 202/235] [D loss: 1.150982, acc: 85.55%] [G loss: 1.153590]\n",
      "[Epoch 12/50] [Batch 203/235] [D loss: 1.082399, acc: 83.20%] [G loss: 1.360320]\n",
      "[Epoch 12/50] [Batch 204/235] [D loss: 1.114272, acc: 83.20%] [G loss: 1.217861]\n",
      "[Epoch 12/50] [Batch 205/235] [D loss: 1.135007, acc: 82.42%] [G loss: 1.216608]\n",
      "[Epoch 12/50] [Batch 206/235] [D loss: 1.112874, acc: 86.72%] [G loss: 1.328299]\n",
      "[Epoch 12/50] [Batch 207/235] [D loss: 1.130366, acc: 84.57%] [G loss: 1.229535]\n",
      "[Epoch 12/50] [Batch 208/235] [D loss: 1.138086, acc: 80.86%] [G loss: 1.148993]\n",
      "[Epoch 12/50] [Batch 209/235] [D loss: 1.102361, acc: 81.25%] [G loss: 1.302583]\n",
      "[Epoch 12/50] [Batch 210/235] [D loss: 1.133881, acc: 83.59%] [G loss: 1.246634]\n",
      "[Epoch 12/50] [Batch 211/235] [D loss: 1.100461, acc: 83.79%] [G loss: 1.165458]\n",
      "[Epoch 12/50] [Batch 212/235] [D loss: 1.130692, acc: 83.40%] [G loss: 1.126836]\n",
      "[Epoch 12/50] [Batch 213/235] [D loss: 1.084849, acc: 83.59%] [G loss: 1.306187]\n",
      "[Epoch 12/50] [Batch 214/235] [D loss: 1.117937, acc: 85.16%] [G loss: 1.234937]\n",
      "[Epoch 12/50] [Batch 215/235] [D loss: 1.094885, acc: 83.20%] [G loss: 1.189844]\n",
      "[Epoch 12/50] [Batch 216/235] [D loss: 1.136917, acc: 84.38%] [G loss: 1.186068]\n",
      "[Epoch 12/50] [Batch 217/235] [D loss: 1.112775, acc: 83.20%] [G loss: 1.146670]\n",
      "[Epoch 12/50] [Batch 218/235] [D loss: 1.169109, acc: 83.20%] [G loss: 1.163399]\n",
      "[Epoch 12/50] [Batch 219/235] [D loss: 1.135580, acc: 83.40%] [G loss: 1.282202]\n",
      "[Epoch 12/50] [Batch 220/235] [D loss: 1.083636, acc: 83.79%] [G loss: 1.238810]\n",
      "[Epoch 12/50] [Batch 221/235] [D loss: 1.128073, acc: 85.55%] [G loss: 1.064452]\n",
      "[Epoch 12/50] [Batch 222/235] [D loss: 1.116080, acc: 83.20%] [G loss: 1.261192]\n",
      "[Epoch 12/50] [Batch 223/235] [D loss: 1.155277, acc: 86.13%] [G loss: 1.380285]\n",
      "[Epoch 12/50] [Batch 224/235] [D loss: 1.157186, acc: 87.11%] [G loss: 1.148848]\n",
      "[Epoch 12/50] [Batch 225/235] [D loss: 1.066721, acc: 83.40%] [G loss: 1.211113]\n",
      "[Epoch 12/50] [Batch 226/235] [D loss: 1.090352, acc: 84.38%] [G loss: 1.169597]\n",
      "[Epoch 12/50] [Batch 227/235] [D loss: 1.118939, acc: 83.79%] [G loss: 1.380047]\n",
      "[Epoch 12/50] [Batch 228/235] [D loss: 1.093636, acc: 83.98%] [G loss: 1.044685]\n",
      "[Epoch 12/50] [Batch 229/235] [D loss: 1.111136, acc: 82.42%] [G loss: 1.110474]\n",
      "[Epoch 12/50] [Batch 230/235] [D loss: 1.071693, acc: 87.89%] [G loss: 1.208928]\n",
      "[Epoch 12/50] [Batch 231/235] [D loss: 1.088241, acc: 83.79%] [G loss: 1.242201]\n",
      "[Epoch 12/50] [Batch 232/235] [D loss: 1.130929, acc: 82.62%] [G loss: 1.204729]\n",
      "[Epoch 12/50] [Batch 233/235] [D loss: 1.136434, acc: 83.98%] [G loss: 1.189685]\n",
      "[Epoch 12/50] [Batch 234/235] [D loss: 1.169133, acc: 85.94%] [G loss: 1.181107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/50] [Batch 0/235] [D loss: 1.112612, acc: 83.40%] [G loss: 1.257316]\n",
      "[Epoch 13/50] [Batch 1/235] [D loss: 1.073960, acc: 85.94%] [G loss: 1.212746]\n",
      "[Epoch 13/50] [Batch 2/235] [D loss: 1.090915, acc: 86.13%] [G loss: 1.198545]\n",
      "[Epoch 13/50] [Batch 3/235] [D loss: 1.131363, acc: 85.35%] [G loss: 1.136914]\n",
      "[Epoch 13/50] [Batch 4/235] [D loss: 1.135679, acc: 84.77%] [G loss: 1.230807]\n",
      "[Epoch 13/50] [Batch 5/235] [D loss: 1.096168, acc: 81.84%] [G loss: 1.197797]\n",
      "[Epoch 13/50] [Batch 6/235] [D loss: 1.142229, acc: 81.84%] [G loss: 1.223027]\n",
      "[Epoch 13/50] [Batch 7/235] [D loss: 1.134098, acc: 83.40%] [G loss: 1.199498]\n",
      "[Epoch 13/50] [Batch 8/235] [D loss: 1.125533, acc: 84.77%] [G loss: 1.315428]\n",
      "[Epoch 13/50] [Batch 9/235] [D loss: 1.087870, acc: 84.77%] [G loss: 1.282388]\n",
      "[Epoch 13/50] [Batch 10/235] [D loss: 1.168594, acc: 84.38%] [G loss: 1.117227]\n",
      "[Epoch 13/50] [Batch 11/235] [D loss: 1.106131, acc: 84.38%] [G loss: 1.379728]\n",
      "[Epoch 13/50] [Batch 12/235] [D loss: 1.176172, acc: 83.40%] [G loss: 1.290175]\n",
      "[Epoch 13/50] [Batch 13/235] [D loss: 1.149926, acc: 83.20%] [G loss: 1.126289]\n",
      "[Epoch 13/50] [Batch 14/235] [D loss: 1.114652, acc: 83.01%] [G loss: 1.112200]\n",
      "[Epoch 13/50] [Batch 15/235] [D loss: 1.132521, acc: 85.16%] [G loss: 1.320493]\n",
      "[Epoch 13/50] [Batch 16/235] [D loss: 1.138824, acc: 83.40%] [G loss: 1.290327]\n",
      "[Epoch 13/50] [Batch 17/235] [D loss: 1.096539, acc: 84.96%] [G loss: 1.137003]\n",
      "[Epoch 13/50] [Batch 18/235] [D loss: 1.116719, acc: 86.13%] [G loss: 1.224296]\n",
      "[Epoch 13/50] [Batch 19/235] [D loss: 1.103056, acc: 85.94%] [G loss: 1.283709]\n",
      "[Epoch 13/50] [Batch 20/235] [D loss: 1.121208, acc: 85.55%] [G loss: 1.102924]\n",
      "[Epoch 13/50] [Batch 21/235] [D loss: 1.108883, acc: 83.01%] [G loss: 1.206169]\n",
      "[Epoch 13/50] [Batch 22/235] [D loss: 1.135079, acc: 82.42%] [G loss: 1.334235]\n",
      "[Epoch 13/50] [Batch 23/235] [D loss: 1.185349, acc: 84.18%] [G loss: 1.288219]\n",
      "[Epoch 13/50] [Batch 24/235] [D loss: 1.129387, acc: 81.64%] [G loss: 1.119759]\n",
      "[Epoch 13/50] [Batch 25/235] [D loss: 1.132260, acc: 84.77%] [G loss: 1.122388]\n",
      "[Epoch 13/50] [Batch 26/235] [D loss: 1.144691, acc: 85.35%] [G loss: 1.309363]\n",
      "[Epoch 13/50] [Batch 27/235] [D loss: 1.151980, acc: 87.11%] [G loss: 1.096904]\n",
      "[Epoch 13/50] [Batch 28/235] [D loss: 1.130899, acc: 85.74%] [G loss: 1.252549]\n",
      "[Epoch 13/50] [Batch 29/235] [D loss: 1.142256, acc: 83.59%] [G loss: 1.283558]\n",
      "[Epoch 13/50] [Batch 30/235] [D loss: 1.097637, acc: 83.01%] [G loss: 1.306240]\n",
      "[Epoch 13/50] [Batch 31/235] [D loss: 1.123068, acc: 83.40%] [G loss: 1.117841]\n",
      "[Epoch 13/50] [Batch 32/235] [D loss: 1.196033, acc: 83.01%] [G loss: 1.321776]\n",
      "[Epoch 13/50] [Batch 33/235] [D loss: 1.053669, acc: 84.57%] [G loss: 1.205513]\n",
      "[Epoch 13/50] [Batch 34/235] [D loss: 1.079176, acc: 85.35%] [G loss: 1.171081]\n",
      "[Epoch 13/50] [Batch 35/235] [D loss: 1.134914, acc: 84.38%] [G loss: 1.139179]\n",
      "[Epoch 13/50] [Batch 36/235] [D loss: 1.125386, acc: 82.23%] [G loss: 1.164285]\n",
      "[Epoch 13/50] [Batch 37/235] [D loss: 1.124062, acc: 85.55%] [G loss: 1.243197]\n",
      "[Epoch 13/50] [Batch 38/235] [D loss: 1.115476, acc: 87.30%] [G loss: 1.197105]\n",
      "[Epoch 13/50] [Batch 39/235] [D loss: 1.172105, acc: 86.13%] [G loss: 1.251678]\n",
      "[Epoch 13/50] [Batch 40/235] [D loss: 1.126811, acc: 82.42%] [G loss: 1.116490]\n",
      "[Epoch 13/50] [Batch 41/235] [D loss: 1.104337, acc: 84.57%] [G loss: 1.085473]\n",
      "[Epoch 13/50] [Batch 42/235] [D loss: 1.114678, acc: 85.55%] [G loss: 1.146221]\n",
      "[Epoch 13/50] [Batch 43/235] [D loss: 1.079950, acc: 84.18%] [G loss: 1.256785]\n",
      "[Epoch 13/50] [Batch 44/235] [D loss: 1.113588, acc: 84.38%] [G loss: 1.214848]\n",
      "[Epoch 13/50] [Batch 45/235] [D loss: 1.116422, acc: 84.96%] [G loss: 1.329365]\n",
      "[Epoch 13/50] [Batch 46/235] [D loss: 1.101206, acc: 84.96%] [G loss: 1.214513]\n",
      "[Epoch 13/50] [Batch 47/235] [D loss: 1.158322, acc: 85.16%] [G loss: 1.228779]\n",
      "[Epoch 13/50] [Batch 48/235] [D loss: 1.081045, acc: 84.96%] [G loss: 1.117004]\n",
      "[Epoch 13/50] [Batch 49/235] [D loss: 1.064242, acc: 83.98%] [G loss: 1.155320]\n",
      "[Epoch 13/50] [Batch 50/235] [D loss: 1.137060, acc: 83.79%] [G loss: 1.195869]\n",
      "[Epoch 13/50] [Batch 51/235] [D loss: 1.157334, acc: 83.01%] [G loss: 1.242578]\n",
      "[Epoch 13/50] [Batch 52/235] [D loss: 1.078006, acc: 83.40%] [G loss: 1.230923]\n",
      "[Epoch 13/50] [Batch 53/235] [D loss: 1.108709, acc: 85.74%] [G loss: 1.130948]\n",
      "[Epoch 13/50] [Batch 54/235] [D loss: 1.099011, acc: 85.94%] [G loss: 1.245656]\n",
      "[Epoch 13/50] [Batch 55/235] [D loss: 1.068533, acc: 84.57%] [G loss: 1.233432]\n",
      "[Epoch 13/50] [Batch 56/235] [D loss: 1.077028, acc: 83.01%] [G loss: 1.311621]\n",
      "[Epoch 13/50] [Batch 57/235] [D loss: 1.106015, acc: 86.91%] [G loss: 1.251883]\n",
      "[Epoch 13/50] [Batch 58/235] [D loss: 1.108083, acc: 83.20%] [G loss: 1.298084]\n",
      "[Epoch 13/50] [Batch 59/235] [D loss: 1.129399, acc: 84.96%] [G loss: 1.139239]\n",
      "[Epoch 13/50] [Batch 60/235] [D loss: 1.122715, acc: 85.35%] [G loss: 1.209502]\n",
      "[Epoch 13/50] [Batch 61/235] [D loss: 1.066463, acc: 85.16%] [G loss: 1.252351]\n",
      "[Epoch 13/50] [Batch 62/235] [D loss: 1.124246, acc: 83.98%] [G loss: 1.259012]\n",
      "[Epoch 13/50] [Batch 63/235] [D loss: 1.140064, acc: 86.33%] [G loss: 1.285551]\n",
      "[Epoch 13/50] [Batch 64/235] [D loss: 1.164242, acc: 86.91%] [G loss: 1.130880]\n",
      "[Epoch 13/50] [Batch 65/235] [D loss: 1.146948, acc: 84.57%] [G loss: 1.176539]\n",
      "[Epoch 13/50] [Batch 66/235] [D loss: 1.160434, acc: 84.96%] [G loss: 1.175018]\n",
      "[Epoch 13/50] [Batch 67/235] [D loss: 1.109191, acc: 84.18%] [G loss: 1.205371]\n",
      "[Epoch 13/50] [Batch 68/235] [D loss: 1.134320, acc: 85.16%] [G loss: 1.180933]\n",
      "[Epoch 13/50] [Batch 69/235] [D loss: 1.098946, acc: 84.38%] [G loss: 1.282864]\n",
      "[Epoch 13/50] [Batch 70/235] [D loss: 1.142101, acc: 86.52%] [G loss: 1.162332]\n",
      "[Epoch 13/50] [Batch 71/235] [D loss: 1.098701, acc: 81.05%] [G loss: 1.292788]\n",
      "[Epoch 13/50] [Batch 72/235] [D loss: 1.104785, acc: 83.59%] [G loss: 1.225156]\n",
      "[Epoch 13/50] [Batch 73/235] [D loss: 1.106387, acc: 83.01%] [G loss: 1.335642]\n",
      "[Epoch 13/50] [Batch 74/235] [D loss: 1.142025, acc: 86.33%] [G loss: 1.125502]\n",
      "[Epoch 13/50] [Batch 75/235] [D loss: 1.108208, acc: 84.77%] [G loss: 1.219840]\n",
      "[Epoch 13/50] [Batch 76/235] [D loss: 1.128428, acc: 83.01%] [G loss: 1.261930]\n",
      "[Epoch 13/50] [Batch 77/235] [D loss: 1.079517, acc: 83.20%] [G loss: 1.231690]\n",
      "[Epoch 13/50] [Batch 78/235] [D loss: 1.162805, acc: 84.38%] [G loss: 1.128791]\n",
      "[Epoch 13/50] [Batch 79/235] [D loss: 1.120124, acc: 84.18%] [G loss: 1.287142]\n",
      "[Epoch 13/50] [Batch 80/235] [D loss: 1.157910, acc: 81.84%] [G loss: 1.195213]\n",
      "[Epoch 13/50] [Batch 81/235] [D loss: 1.120113, acc: 82.42%] [G loss: 1.203823]\n",
      "[Epoch 13/50] [Batch 82/235] [D loss: 1.113623, acc: 84.18%] [G loss: 1.231346]\n",
      "[Epoch 13/50] [Batch 83/235] [D loss: 1.115746, acc: 82.62%] [G loss: 1.056992]\n",
      "[Epoch 13/50] [Batch 84/235] [D loss: 1.095968, acc: 87.50%] [G loss: 1.187261]\n",
      "[Epoch 13/50] [Batch 85/235] [D loss: 1.089397, acc: 87.70%] [G loss: 1.202907]\n",
      "[Epoch 13/50] [Batch 86/235] [D loss: 1.116056, acc: 82.81%] [G loss: 1.205782]\n",
      "[Epoch 13/50] [Batch 87/235] [D loss: 1.099787, acc: 82.81%] [G loss: 1.122479]\n",
      "[Epoch 13/50] [Batch 88/235] [D loss: 1.118853, acc: 84.57%] [G loss: 1.108757]\n",
      "[Epoch 13/50] [Batch 89/235] [D loss: 1.129461, acc: 83.40%] [G loss: 1.183035]\n",
      "[Epoch 13/50] [Batch 90/235] [D loss: 1.123517, acc: 83.59%] [G loss: 1.246615]\n",
      "[Epoch 13/50] [Batch 91/235] [D loss: 1.107836, acc: 85.16%] [G loss: 1.129126]\n",
      "[Epoch 13/50] [Batch 92/235] [D loss: 1.168522, acc: 82.81%] [G loss: 1.169839]\n",
      "[Epoch 13/50] [Batch 93/235] [D loss: 1.108206, acc: 83.59%] [G loss: 1.145942]\n",
      "[Epoch 13/50] [Batch 94/235] [D loss: 1.120699, acc: 87.11%] [G loss: 1.183543]\n",
      "[Epoch 13/50] [Batch 95/235] [D loss: 1.116705, acc: 83.59%] [G loss: 1.289873]\n",
      "[Epoch 13/50] [Batch 96/235] [D loss: 1.131569, acc: 83.79%] [G loss: 1.190605]\n",
      "[Epoch 13/50] [Batch 97/235] [D loss: 1.111724, acc: 83.98%] [G loss: 1.222943]\n",
      "[Epoch 13/50] [Batch 98/235] [D loss: 1.112757, acc: 87.30%] [G loss: 1.181631]\n",
      "[Epoch 13/50] [Batch 99/235] [D loss: 1.136183, acc: 85.74%] [G loss: 1.274988]\n",
      "[Epoch 13/50] [Batch 100/235] [D loss: 1.123263, acc: 83.20%] [G loss: 1.116334]\n",
      "[Epoch 13/50] [Batch 101/235] [D loss: 1.130162, acc: 84.18%] [G loss: 1.195970]\n",
      "[Epoch 13/50] [Batch 102/235] [D loss: 1.115474, acc: 84.38%] [G loss: 1.266407]\n",
      "[Epoch 13/50] [Batch 103/235] [D loss: 1.107614, acc: 85.55%] [G loss: 1.248777]\n",
      "[Epoch 13/50] [Batch 104/235] [D loss: 1.114584, acc: 86.13%] [G loss: 1.244275]\n",
      "[Epoch 13/50] [Batch 105/235] [D loss: 1.086093, acc: 84.77%] [G loss: 1.133678]\n",
      "[Epoch 13/50] [Batch 106/235] [D loss: 1.123012, acc: 85.74%] [G loss: 1.372444]\n",
      "[Epoch 13/50] [Batch 107/235] [D loss: 1.104672, acc: 83.98%] [G loss: 1.089750]\n",
      "[Epoch 13/50] [Batch 108/235] [D loss: 1.170058, acc: 85.94%] [G loss: 1.050966]\n",
      "[Epoch 13/50] [Batch 109/235] [D loss: 1.105579, acc: 84.38%] [G loss: 1.222121]\n",
      "[Epoch 13/50] [Batch 110/235] [D loss: 1.111355, acc: 85.74%] [G loss: 1.180454]\n",
      "[Epoch 13/50] [Batch 111/235] [D loss: 1.135344, acc: 85.35%] [G loss: 1.179492]\n",
      "[Epoch 13/50] [Batch 112/235] [D loss: 1.089608, acc: 86.72%] [G loss: 1.258821]\n",
      "[Epoch 13/50] [Batch 113/235] [D loss: 1.100413, acc: 85.55%] [G loss: 1.192169]\n",
      "[Epoch 13/50] [Batch 114/235] [D loss: 1.134689, acc: 84.57%] [G loss: 1.197137]\n",
      "[Epoch 13/50] [Batch 115/235] [D loss: 1.173669, acc: 80.66%] [G loss: 1.217786]\n",
      "[Epoch 13/50] [Batch 116/235] [D loss: 1.124006, acc: 82.81%] [G loss: 1.159375]\n",
      "[Epoch 13/50] [Batch 117/235] [D loss: 1.113207, acc: 87.11%] [G loss: 1.211815]\n",
      "[Epoch 13/50] [Batch 118/235] [D loss: 1.150811, acc: 84.96%] [G loss: 0.997410]\n",
      "[Epoch 13/50] [Batch 119/235] [D loss: 1.158231, acc: 84.57%] [G loss: 1.209978]\n",
      "[Epoch 13/50] [Batch 120/235] [D loss: 1.102429, acc: 84.38%] [G loss: 1.303794]\n",
      "[Epoch 13/50] [Batch 121/235] [D loss: 1.162746, acc: 82.62%] [G loss: 1.274361]\n",
      "[Epoch 13/50] [Batch 122/235] [D loss: 1.066608, acc: 86.52%] [G loss: 1.285080]\n",
      "[Epoch 13/50] [Batch 123/235] [D loss: 1.103105, acc: 85.55%] [G loss: 1.131176]\n",
      "[Epoch 13/50] [Batch 124/235] [D loss: 1.114323, acc: 85.16%] [G loss: 1.263782]\n",
      "[Epoch 13/50] [Batch 125/235] [D loss: 1.123071, acc: 84.96%] [G loss: 1.181111]\n",
      "[Epoch 13/50] [Batch 126/235] [D loss: 1.127272, acc: 84.38%] [G loss: 1.160028]\n",
      "[Epoch 13/50] [Batch 127/235] [D loss: 1.104710, acc: 84.57%] [G loss: 1.301099]\n",
      "[Epoch 13/50] [Batch 128/235] [D loss: 1.088120, acc: 82.42%] [G loss: 1.179931]\n",
      "[Epoch 13/50] [Batch 129/235] [D loss: 1.102469, acc: 82.81%] [G loss: 1.292963]\n",
      "[Epoch 13/50] [Batch 130/235] [D loss: 1.093814, acc: 83.98%] [G loss: 1.147205]\n",
      "[Epoch 13/50] [Batch 131/235] [D loss: 1.038126, acc: 85.35%] [G loss: 1.284671]\n",
      "[Epoch 13/50] [Batch 132/235] [D loss: 1.103833, acc: 84.38%] [G loss: 1.252621]\n",
      "[Epoch 13/50] [Batch 133/235] [D loss: 1.142550, acc: 86.52%] [G loss: 1.141771]\n",
      "[Epoch 13/50] [Batch 134/235] [D loss: 1.116231, acc: 82.42%] [G loss: 1.194147]\n",
      "[Epoch 13/50] [Batch 135/235] [D loss: 1.136087, acc: 84.77%] [G loss: 1.307333]\n",
      "[Epoch 13/50] [Batch 136/235] [D loss: 1.116999, acc: 84.57%] [G loss: 1.132329]\n",
      "[Epoch 13/50] [Batch 137/235] [D loss: 1.075445, acc: 87.30%] [G loss: 1.107521]\n",
      "[Epoch 13/50] [Batch 138/235] [D loss: 1.125980, acc: 83.59%] [G loss: 1.122011]\n",
      "[Epoch 13/50] [Batch 139/235] [D loss: 1.098768, acc: 84.96%] [G loss: 1.314207]\n",
      "[Epoch 13/50] [Batch 140/235] [D loss: 1.083923, acc: 87.11%] [G loss: 1.246452]\n",
      "[Epoch 13/50] [Batch 141/235] [D loss: 1.102494, acc: 83.98%] [G loss: 1.204858]\n",
      "[Epoch 13/50] [Batch 142/235] [D loss: 1.123087, acc: 85.35%] [G loss: 1.219736]\n",
      "[Epoch 13/50] [Batch 143/235] [D loss: 1.151808, acc: 86.13%] [G loss: 1.278193]\n",
      "[Epoch 13/50] [Batch 144/235] [D loss: 1.124403, acc: 84.38%] [G loss: 1.110916]\n",
      "[Epoch 13/50] [Batch 145/235] [D loss: 1.145307, acc: 86.13%] [G loss: 1.141256]\n",
      "[Epoch 13/50] [Batch 146/235] [D loss: 1.108159, acc: 84.77%] [G loss: 1.357119]\n",
      "[Epoch 13/50] [Batch 147/235] [D loss: 1.147640, acc: 85.55%] [G loss: 1.270185]\n",
      "[Epoch 13/50] [Batch 148/235] [D loss: 1.098701, acc: 86.33%] [G loss: 1.208666]\n",
      "[Epoch 13/50] [Batch 149/235] [D loss: 1.118354, acc: 83.79%] [G loss: 1.322399]\n",
      "[Epoch 13/50] [Batch 150/235] [D loss: 1.110805, acc: 84.96%] [G loss: 1.266263]\n",
      "[Epoch 13/50] [Batch 151/235] [D loss: 1.123055, acc: 81.05%] [G loss: 1.118428]\n",
      "[Epoch 13/50] [Batch 152/235] [D loss: 1.122664, acc: 85.55%] [G loss: 1.189368]\n",
      "[Epoch 13/50] [Batch 153/235] [D loss: 1.150259, acc: 85.35%] [G loss: 1.307901]\n",
      "[Epoch 13/50] [Batch 154/235] [D loss: 1.127278, acc: 86.52%] [G loss: 1.409189]\n",
      "[Epoch 13/50] [Batch 155/235] [D loss: 1.095814, acc: 84.18%] [G loss: 1.179288]\n",
      "[Epoch 13/50] [Batch 156/235] [D loss: 1.099696, acc: 83.79%] [G loss: 1.183872]\n",
      "[Epoch 13/50] [Batch 157/235] [D loss: 1.127721, acc: 84.38%] [G loss: 1.331607]\n",
      "[Epoch 13/50] [Batch 158/235] [D loss: 1.087260, acc: 85.35%] [G loss: 1.162439]\n",
      "[Epoch 13/50] [Batch 159/235] [D loss: 1.095816, acc: 85.55%] [G loss: 1.113499]\n",
      "[Epoch 13/50] [Batch 160/235] [D loss: 1.171360, acc: 82.23%] [G loss: 1.434663]\n",
      "[Epoch 13/50] [Batch 161/235] [D loss: 1.188801, acc: 83.98%] [G loss: 1.255353]\n",
      "[Epoch 13/50] [Batch 162/235] [D loss: 1.075662, acc: 85.55%] [G loss: 1.081973]\n",
      "[Epoch 13/50] [Batch 163/235] [D loss: 1.125109, acc: 86.72%] [G loss: 1.094309]\n",
      "[Epoch 13/50] [Batch 164/235] [D loss: 1.118048, acc: 84.18%] [G loss: 1.210088]\n",
      "[Epoch 13/50] [Batch 165/235] [D loss: 1.147006, acc: 81.84%] [G loss: 1.223222]\n",
      "[Epoch 13/50] [Batch 166/235] [D loss: 1.115538, acc: 84.57%] [G loss: 1.163445]\n",
      "[Epoch 13/50] [Batch 167/235] [D loss: 1.098040, acc: 83.98%] [G loss: 1.348580]\n",
      "[Epoch 13/50] [Batch 168/235] [D loss: 1.128219, acc: 86.13%] [G loss: 1.195783]\n",
      "[Epoch 13/50] [Batch 169/235] [D loss: 1.136798, acc: 84.77%] [G loss: 1.103249]\n",
      "[Epoch 13/50] [Batch 170/235] [D loss: 1.092293, acc: 84.38%] [G loss: 1.105613]\n",
      "[Epoch 13/50] [Batch 171/235] [D loss: 1.058010, acc: 82.42%] [G loss: 1.200243]\n",
      "[Epoch 13/50] [Batch 172/235] [D loss: 1.182353, acc: 83.79%] [G loss: 1.085906]\n",
      "[Epoch 13/50] [Batch 173/235] [D loss: 1.147390, acc: 87.70%] [G loss: 1.320305]\n",
      "[Epoch 13/50] [Batch 174/235] [D loss: 1.127734, acc: 84.77%] [G loss: 1.264924]\n",
      "[Epoch 13/50] [Batch 175/235] [D loss: 1.132602, acc: 86.91%] [G loss: 1.051396]\n",
      "[Epoch 13/50] [Batch 176/235] [D loss: 1.080214, acc: 85.35%] [G loss: 1.276549]\n",
      "[Epoch 13/50] [Batch 177/235] [D loss: 1.156025, acc: 84.38%] [G loss: 1.266350]\n",
      "[Epoch 13/50] [Batch 178/235] [D loss: 1.144359, acc: 85.16%] [G loss: 1.117433]\n",
      "[Epoch 13/50] [Batch 179/235] [D loss: 1.133812, acc: 85.35%] [G loss: 1.143138]\n",
      "[Epoch 13/50] [Batch 180/235] [D loss: 1.106429, acc: 83.79%] [G loss: 1.204389]\n",
      "[Epoch 13/50] [Batch 181/235] [D loss: 1.087133, acc: 84.18%] [G loss: 1.162446]\n",
      "[Epoch 13/50] [Batch 182/235] [D loss: 1.109035, acc: 83.98%] [G loss: 1.248081]\n",
      "[Epoch 13/50] [Batch 183/235] [D loss: 1.099142, acc: 86.13%] [G loss: 1.230652]\n",
      "[Epoch 13/50] [Batch 184/235] [D loss: 1.116203, acc: 83.98%] [G loss: 1.237203]\n",
      "[Epoch 13/50] [Batch 185/235] [D loss: 1.162620, acc: 84.38%] [G loss: 1.134220]\n",
      "[Epoch 13/50] [Batch 186/235] [D loss: 1.134057, acc: 82.81%] [G loss: 1.212469]\n",
      "[Epoch 13/50] [Batch 187/235] [D loss: 1.115570, acc: 84.57%] [G loss: 1.310980]\n",
      "[Epoch 13/50] [Batch 188/235] [D loss: 1.111598, acc: 83.20%] [G loss: 1.226867]\n",
      "[Epoch 13/50] [Batch 189/235] [D loss: 1.122976, acc: 86.33%] [G loss: 1.308037]\n",
      "[Epoch 13/50] [Batch 190/235] [D loss: 1.105423, acc: 84.77%] [G loss: 1.299490]\n",
      "[Epoch 13/50] [Batch 191/235] [D loss: 1.129480, acc: 85.74%] [G loss: 1.312064]\n",
      "[Epoch 13/50] [Batch 192/235] [D loss: 1.098768, acc: 83.59%] [G loss: 1.228324]\n",
      "[Epoch 13/50] [Batch 193/235] [D loss: 1.112050, acc: 84.57%] [G loss: 1.215905]\n",
      "[Epoch 13/50] [Batch 194/235] [D loss: 1.111838, acc: 83.98%] [G loss: 1.337983]\n",
      "[Epoch 13/50] [Batch 195/235] [D loss: 1.131352, acc: 86.33%] [G loss: 1.195642]\n",
      "[Epoch 13/50] [Batch 196/235] [D loss: 1.109205, acc: 87.50%] [G loss: 1.147373]\n",
      "[Epoch 13/50] [Batch 197/235] [D loss: 1.128939, acc: 83.59%] [G loss: 1.251879]\n",
      "[Epoch 13/50] [Batch 198/235] [D loss: 1.186177, acc: 82.42%] [G loss: 1.320683]\n",
      "[Epoch 13/50] [Batch 199/235] [D loss: 1.142449, acc: 88.09%] [G loss: 1.089715]\n",
      "[Epoch 13/50] [Batch 200/235] [D loss: 1.113762, acc: 83.98%] [G loss: 1.210614]\n",
      "[Epoch 13/50] [Batch 201/235] [D loss: 1.102226, acc: 83.20%] [G loss: 1.215271]\n",
      "[Epoch 13/50] [Batch 202/235] [D loss: 1.145232, acc: 83.40%] [G loss: 1.207297]\n",
      "[Epoch 13/50] [Batch 203/235] [D loss: 1.096906, acc: 86.13%] [G loss: 1.261279]\n",
      "[Epoch 13/50] [Batch 204/235] [D loss: 1.129881, acc: 84.38%] [G loss: 1.267215]\n",
      "[Epoch 13/50] [Batch 205/235] [D loss: 1.135789, acc: 83.79%] [G loss: 1.270819]\n",
      "[Epoch 13/50] [Batch 206/235] [D loss: 1.116804, acc: 84.96%] [G loss: 1.169643]\n",
      "[Epoch 13/50] [Batch 207/235] [D loss: 1.144713, acc: 84.38%] [G loss: 1.248771]\n",
      "[Epoch 13/50] [Batch 208/235] [D loss: 1.080563, acc: 84.57%] [G loss: 1.335009]\n",
      "[Epoch 13/50] [Batch 209/235] [D loss: 1.098168, acc: 84.96%] [G loss: 1.180984]\n",
      "[Epoch 13/50] [Batch 210/235] [D loss: 1.115239, acc: 83.40%] [G loss: 1.111766]\n",
      "[Epoch 13/50] [Batch 211/235] [D loss: 1.141938, acc: 84.38%] [G loss: 1.229736]\n",
      "[Epoch 13/50] [Batch 212/235] [D loss: 1.093424, acc: 86.52%] [G loss: 1.317563]\n",
      "[Epoch 13/50] [Batch 213/235] [D loss: 1.124963, acc: 84.77%] [G loss: 1.207648]\n",
      "[Epoch 13/50] [Batch 214/235] [D loss: 1.147557, acc: 84.57%] [G loss: 1.042090]\n",
      "[Epoch 13/50] [Batch 215/235] [D loss: 1.071355, acc: 84.96%] [G loss: 1.213967]\n",
      "[Epoch 13/50] [Batch 216/235] [D loss: 1.129162, acc: 83.98%] [G loss: 1.155739]\n",
      "[Epoch 13/50] [Batch 217/235] [D loss: 1.138496, acc: 84.57%] [G loss: 1.199499]\n",
      "[Epoch 13/50] [Batch 218/235] [D loss: 1.107332, acc: 84.38%] [G loss: 1.106400]\n",
      "[Epoch 13/50] [Batch 219/235] [D loss: 1.086746, acc: 87.50%] [G loss: 1.279548]\n",
      "[Epoch 13/50] [Batch 220/235] [D loss: 1.068026, acc: 85.55%] [G loss: 1.292596]\n",
      "[Epoch 13/50] [Batch 221/235] [D loss: 1.089653, acc: 84.57%] [G loss: 1.151116]\n",
      "[Epoch 13/50] [Batch 222/235] [D loss: 1.114089, acc: 87.30%] [G loss: 1.340243]\n",
      "[Epoch 13/50] [Batch 223/235] [D loss: 1.146954, acc: 86.13%] [G loss: 1.196919]\n",
      "[Epoch 13/50] [Batch 224/235] [D loss: 1.126072, acc: 84.77%] [G loss: 1.224552]\n",
      "[Epoch 13/50] [Batch 225/235] [D loss: 1.104060, acc: 84.77%] [G loss: 1.292483]\n",
      "[Epoch 13/50] [Batch 226/235] [D loss: 1.155848, acc: 85.55%] [G loss: 1.125393]\n",
      "[Epoch 13/50] [Batch 227/235] [D loss: 1.138098, acc: 85.55%] [G loss: 1.310533]\n",
      "[Epoch 13/50] [Batch 228/235] [D loss: 1.106687, acc: 86.33%] [G loss: 1.167618]\n",
      "[Epoch 13/50] [Batch 229/235] [D loss: 1.119119, acc: 86.13%] [G loss: 1.260183]\n",
      "[Epoch 13/50] [Batch 230/235] [D loss: 1.081424, acc: 86.13%] [G loss: 1.297980]\n",
      "[Epoch 13/50] [Batch 231/235] [D loss: 1.123299, acc: 82.81%] [G loss: 1.297740]\n",
      "[Epoch 13/50] [Batch 232/235] [D loss: 1.136538, acc: 82.62%] [G loss: 1.153560]\n",
      "[Epoch 13/50] [Batch 233/235] [D loss: 1.092115, acc: 84.96%] [G loss: 1.209775]\n",
      "[Epoch 13/50] [Batch 234/235] [D loss: 1.124169, acc: 86.46%] [G loss: 1.231176]\n",
      "[Epoch 14/50] [Batch 0/235] [D loss: 1.103417, acc: 87.30%] [G loss: 1.223229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/50] [Batch 1/235] [D loss: 1.110955, acc: 85.74%] [G loss: 1.160820]\n",
      "[Epoch 14/50] [Batch 2/235] [D loss: 1.121898, acc: 84.77%] [G loss: 1.252294]\n",
      "[Epoch 14/50] [Batch 3/235] [D loss: 1.141230, acc: 86.52%] [G loss: 1.130774]\n",
      "[Epoch 14/50] [Batch 4/235] [D loss: 1.095058, acc: 85.35%] [G loss: 1.274947]\n",
      "[Epoch 14/50] [Batch 5/235] [D loss: 1.164693, acc: 83.79%] [G loss: 1.243295]\n",
      "[Epoch 14/50] [Batch 6/235] [D loss: 1.121401, acc: 83.98%] [G loss: 1.284768]\n",
      "[Epoch 14/50] [Batch 7/235] [D loss: 1.094606, acc: 85.55%] [G loss: 1.315454]\n",
      "[Epoch 14/50] [Batch 8/235] [D loss: 1.099804, acc: 83.98%] [G loss: 1.247760]\n",
      "[Epoch 14/50] [Batch 9/235] [D loss: 1.127710, acc: 84.77%] [G loss: 1.265387]\n",
      "[Epoch 14/50] [Batch 10/235] [D loss: 1.182216, acc: 83.40%] [G loss: 1.108889]\n",
      "[Epoch 14/50] [Batch 11/235] [D loss: 1.138598, acc: 83.40%] [G loss: 1.181813]\n",
      "[Epoch 14/50] [Batch 12/235] [D loss: 1.125628, acc: 85.35%] [G loss: 1.351507]\n",
      "[Epoch 14/50] [Batch 13/235] [D loss: 1.141189, acc: 81.45%] [G loss: 1.261529]\n",
      "[Epoch 14/50] [Batch 14/235] [D loss: 1.132241, acc: 85.74%] [G loss: 1.209177]\n",
      "[Epoch 14/50] [Batch 15/235] [D loss: 1.134600, acc: 85.16%] [G loss: 1.076781]\n",
      "[Epoch 14/50] [Batch 16/235] [D loss: 1.107094, acc: 86.13%] [G loss: 1.223094]\n",
      "[Epoch 14/50] [Batch 17/235] [D loss: 1.122840, acc: 83.98%] [G loss: 1.286950]\n",
      "[Epoch 14/50] [Batch 18/235] [D loss: 1.061223, acc: 84.57%] [G loss: 1.289295]\n",
      "[Epoch 14/50] [Batch 19/235] [D loss: 1.124292, acc: 84.57%] [G loss: 1.154881]\n",
      "[Epoch 14/50] [Batch 20/235] [D loss: 1.247668, acc: 83.98%] [G loss: 1.226788]\n",
      "[Epoch 14/50] [Batch 21/235] [D loss: 1.209573, acc: 82.23%] [G loss: 1.270443]\n",
      "[Epoch 14/50] [Batch 22/235] [D loss: 1.120625, acc: 81.64%] [G loss: 1.183978]\n",
      "[Epoch 14/50] [Batch 23/235] [D loss: 1.060814, acc: 85.94%] [G loss: 1.211376]\n",
      "[Epoch 14/50] [Batch 24/235] [D loss: 1.117394, acc: 86.33%] [G loss: 1.231447]\n",
      "[Epoch 14/50] [Batch 25/235] [D loss: 1.097304, acc: 86.52%] [G loss: 1.327819]\n",
      "[Epoch 14/50] [Batch 26/235] [D loss: 1.086614, acc: 84.77%] [G loss: 1.196752]\n",
      "[Epoch 14/50] [Batch 27/235] [D loss: 1.104953, acc: 83.98%] [G loss: 1.193454]\n",
      "[Epoch 14/50] [Batch 28/235] [D loss: 1.106085, acc: 81.64%] [G loss: 1.211898]\n",
      "[Epoch 14/50] [Batch 29/235] [D loss: 1.109196, acc: 84.38%] [G loss: 1.223033]\n",
      "[Epoch 14/50] [Batch 30/235] [D loss: 1.111225, acc: 84.38%] [G loss: 1.196479]\n",
      "[Epoch 14/50] [Batch 31/235] [D loss: 1.107331, acc: 83.98%] [G loss: 1.134726]\n",
      "[Epoch 14/50] [Batch 32/235] [D loss: 1.144291, acc: 83.20%] [G loss: 1.186574]\n",
      "[Epoch 14/50] [Batch 33/235] [D loss: 1.110693, acc: 85.55%] [G loss: 1.164868]\n",
      "[Epoch 14/50] [Batch 34/235] [D loss: 1.075792, acc: 85.74%] [G loss: 1.209425]\n",
      "[Epoch 14/50] [Batch 35/235] [D loss: 1.142835, acc: 85.16%] [G loss: 1.253147]\n",
      "[Epoch 14/50] [Batch 36/235] [D loss: 1.105364, acc: 83.98%] [G loss: 1.189436]\n",
      "[Epoch 14/50] [Batch 37/235] [D loss: 1.154707, acc: 86.72%] [G loss: 1.107397]\n",
      "[Epoch 14/50] [Batch 38/235] [D loss: 1.127650, acc: 85.35%] [G loss: 1.326570]\n",
      "[Epoch 14/50] [Batch 39/235] [D loss: 1.073479, acc: 83.79%] [G loss: 1.278371]\n",
      "[Epoch 14/50] [Batch 40/235] [D loss: 1.147994, acc: 82.03%] [G loss: 1.077565]\n",
      "[Epoch 14/50] [Batch 41/235] [D loss: 1.099163, acc: 84.38%] [G loss: 1.155174]\n",
      "[Epoch 14/50] [Batch 42/235] [D loss: 1.131118, acc: 81.45%] [G loss: 1.102237]\n",
      "[Epoch 14/50] [Batch 43/235] [D loss: 1.192983, acc: 85.16%] [G loss: 1.179565]\n",
      "[Epoch 14/50] [Batch 44/235] [D loss: 1.111755, acc: 82.81%] [G loss: 1.170877]\n",
      "[Epoch 14/50] [Batch 45/235] [D loss: 1.092001, acc: 83.59%] [G loss: 1.138782]\n",
      "[Epoch 14/50] [Batch 46/235] [D loss: 1.133410, acc: 82.42%] [G loss: 1.131375]\n",
      "[Epoch 14/50] [Batch 47/235] [D loss: 1.131585, acc: 81.05%] [G loss: 1.286354]\n",
      "[Epoch 14/50] [Batch 48/235] [D loss: 1.083429, acc: 83.01%] [G loss: 1.298571]\n",
      "[Epoch 14/50] [Batch 49/235] [D loss: 1.152847, acc: 82.42%] [G loss: 1.225337]\n",
      "[Epoch 14/50] [Batch 50/235] [D loss: 1.071922, acc: 83.59%] [G loss: 1.307663]\n",
      "[Epoch 14/50] [Batch 51/235] [D loss: 1.103059, acc: 84.38%] [G loss: 1.230887]\n",
      "[Epoch 14/50] [Batch 52/235] [D loss: 1.095379, acc: 85.94%] [G loss: 1.285454]\n",
      "[Epoch 14/50] [Batch 53/235] [D loss: 1.100393, acc: 84.38%] [G loss: 1.203319]\n",
      "[Epoch 14/50] [Batch 54/235] [D loss: 1.117497, acc: 83.59%] [G loss: 1.187564]\n",
      "[Epoch 14/50] [Batch 55/235] [D loss: 1.113546, acc: 85.55%] [G loss: 1.306806]\n",
      "[Epoch 14/50] [Batch 56/235] [D loss: 1.124346, acc: 83.40%] [G loss: 1.323739]\n",
      "[Epoch 14/50] [Batch 57/235] [D loss: 1.138145, acc: 82.81%] [G loss: 1.175142]\n",
      "[Epoch 14/50] [Batch 58/235] [D loss: 1.135376, acc: 84.18%] [G loss: 1.125655]\n",
      "[Epoch 14/50] [Batch 59/235] [D loss: 1.178368, acc: 86.91%] [G loss: 1.120886]\n",
      "[Epoch 14/50] [Batch 60/235] [D loss: 1.056550, acc: 88.09%] [G loss: 1.358962]\n",
      "[Epoch 14/50] [Batch 61/235] [D loss: 1.151206, acc: 83.40%] [G loss: 1.197885]\n",
      "[Epoch 14/50] [Batch 62/235] [D loss: 1.124837, acc: 83.79%] [G loss: 1.205083]\n",
      "[Epoch 14/50] [Batch 63/235] [D loss: 1.143727, acc: 82.42%] [G loss: 1.074349]\n",
      "[Epoch 14/50] [Batch 64/235] [D loss: 1.120908, acc: 85.55%] [G loss: 1.149252]\n",
      "[Epoch 14/50] [Batch 65/235] [D loss: 1.068724, acc: 88.28%] [G loss: 1.314973]\n",
      "[Epoch 14/50] [Batch 66/235] [D loss: 1.088487, acc: 84.57%] [G loss: 1.299217]\n",
      "[Epoch 14/50] [Batch 67/235] [D loss: 1.106004, acc: 84.77%] [G loss: 1.204738]\n",
      "[Epoch 14/50] [Batch 68/235] [D loss: 1.143466, acc: 84.77%] [G loss: 1.145405]\n",
      "[Epoch 14/50] [Batch 69/235] [D loss: 1.142734, acc: 85.94%] [G loss: 1.277938]\n",
      "[Epoch 14/50] [Batch 70/235] [D loss: 1.100204, acc: 85.74%] [G loss: 1.281377]\n",
      "[Epoch 14/50] [Batch 71/235] [D loss: 1.096861, acc: 86.33%] [G loss: 1.207938]\n",
      "[Epoch 14/50] [Batch 72/235] [D loss: 1.115637, acc: 81.64%] [G loss: 1.184068]\n",
      "[Epoch 14/50] [Batch 73/235] [D loss: 1.143559, acc: 85.16%] [G loss: 1.176028]\n",
      "[Epoch 14/50] [Batch 74/235] [D loss: 1.117675, acc: 87.11%] [G loss: 1.246602]\n",
      "[Epoch 14/50] [Batch 75/235] [D loss: 1.062702, acc: 84.38%] [G loss: 1.134617]\n",
      "[Epoch 14/50] [Batch 76/235] [D loss: 1.067715, acc: 87.11%] [G loss: 1.109325]\n",
      "[Epoch 14/50] [Batch 77/235] [D loss: 1.131098, acc: 84.77%] [G loss: 1.290241]\n",
      "[Epoch 14/50] [Batch 78/235] [D loss: 1.100027, acc: 85.74%] [G loss: 1.146315]\n",
      "[Epoch 14/50] [Batch 79/235] [D loss: 1.069282, acc: 85.55%] [G loss: 1.161452]\n",
      "[Epoch 14/50] [Batch 80/235] [D loss: 1.137396, acc: 84.38%] [G loss: 1.154922]\n",
      "[Epoch 14/50] [Batch 81/235] [D loss: 1.068897, acc: 85.74%] [G loss: 1.145894]\n",
      "[Epoch 14/50] [Batch 82/235] [D loss: 1.133065, acc: 83.98%] [G loss: 1.140952]\n",
      "[Epoch 14/50] [Batch 83/235] [D loss: 1.192333, acc: 81.45%] [G loss: 1.137877]\n",
      "[Epoch 14/50] [Batch 84/235] [D loss: 1.069516, acc: 85.35%] [G loss: 1.186062]\n",
      "[Epoch 14/50] [Batch 85/235] [D loss: 1.094846, acc: 84.38%] [G loss: 1.272020]\n",
      "[Epoch 14/50] [Batch 86/235] [D loss: 1.063918, acc: 86.91%] [G loss: 1.186507]\n",
      "[Epoch 14/50] [Batch 87/235] [D loss: 1.108899, acc: 85.55%] [G loss: 1.254430]\n",
      "[Epoch 14/50] [Batch 88/235] [D loss: 1.116330, acc: 84.96%] [G loss: 1.250988]\n",
      "[Epoch 14/50] [Batch 89/235] [D loss: 1.143337, acc: 86.72%] [G loss: 1.138024]\n",
      "[Epoch 14/50] [Batch 90/235] [D loss: 1.142098, acc: 83.98%] [G loss: 1.144973]\n",
      "[Epoch 14/50] [Batch 91/235] [D loss: 1.147160, acc: 84.38%] [G loss: 1.238066]\n",
      "[Epoch 14/50] [Batch 92/235] [D loss: 1.135136, acc: 83.20%] [G loss: 1.253047]\n",
      "[Epoch 14/50] [Batch 93/235] [D loss: 1.127891, acc: 85.74%] [G loss: 1.168095]\n",
      "[Epoch 14/50] [Batch 94/235] [D loss: 1.093535, acc: 86.91%] [G loss: 1.258160]\n",
      "[Epoch 14/50] [Batch 95/235] [D loss: 1.185153, acc: 86.91%] [G loss: 1.152613]\n",
      "[Epoch 14/50] [Batch 96/235] [D loss: 1.156533, acc: 84.96%] [G loss: 1.273721]\n",
      "[Epoch 14/50] [Batch 97/235] [D loss: 1.159788, acc: 85.35%] [G loss: 1.177321]\n",
      "[Epoch 14/50] [Batch 98/235] [D loss: 1.173105, acc: 83.98%] [G loss: 1.195768]\n",
      "[Epoch 14/50] [Batch 99/235] [D loss: 1.121209, acc: 85.55%] [G loss: 1.299191]\n",
      "[Epoch 14/50] [Batch 100/235] [D loss: 1.120169, acc: 85.94%] [G loss: 1.241880]\n",
      "[Epoch 14/50] [Batch 101/235] [D loss: 1.113655, acc: 85.16%] [G loss: 1.229234]\n",
      "[Epoch 14/50] [Batch 102/235] [D loss: 1.149671, acc: 82.03%] [G loss: 1.214419]\n",
      "[Epoch 14/50] [Batch 103/235] [D loss: 1.097552, acc: 83.01%] [G loss: 1.313639]\n",
      "[Epoch 14/50] [Batch 104/235] [D loss: 1.099135, acc: 85.16%] [G loss: 1.223186]\n",
      "[Epoch 14/50] [Batch 105/235] [D loss: 1.101105, acc: 84.96%] [G loss: 1.213209]\n",
      "[Epoch 14/50] [Batch 106/235] [D loss: 1.128736, acc: 85.55%] [G loss: 1.238245]\n",
      "[Epoch 14/50] [Batch 107/235] [D loss: 1.076186, acc: 84.96%] [G loss: 1.303396]\n",
      "[Epoch 14/50] [Batch 108/235] [D loss: 1.113901, acc: 83.20%] [G loss: 1.203878]\n",
      "[Epoch 14/50] [Batch 109/235] [D loss: 1.126225, acc: 85.16%] [G loss: 1.292171]\n",
      "[Epoch 14/50] [Batch 110/235] [D loss: 1.123644, acc: 84.18%] [G loss: 1.187711]\n",
      "[Epoch 14/50] [Batch 111/235] [D loss: 1.147316, acc: 84.96%] [G loss: 1.150608]\n",
      "[Epoch 14/50] [Batch 112/235] [D loss: 1.118097, acc: 83.59%] [G loss: 1.228200]\n",
      "[Epoch 14/50] [Batch 113/235] [D loss: 1.135816, acc: 83.98%] [G loss: 1.241869]\n",
      "[Epoch 14/50] [Batch 114/235] [D loss: 1.103690, acc: 86.33%] [G loss: 1.251010]\n",
      "[Epoch 14/50] [Batch 115/235] [D loss: 1.071684, acc: 84.57%] [G loss: 1.133654]\n",
      "[Epoch 14/50] [Batch 116/235] [D loss: 1.063401, acc: 87.30%] [G loss: 1.137996]\n",
      "[Epoch 14/50] [Batch 117/235] [D loss: 1.104146, acc: 87.30%] [G loss: 1.108027]\n",
      "[Epoch 14/50] [Batch 118/235] [D loss: 1.146399, acc: 83.20%] [G loss: 1.211117]\n",
      "[Epoch 14/50] [Batch 119/235] [D loss: 1.102311, acc: 83.20%] [G loss: 1.155041]\n",
      "[Epoch 14/50] [Batch 120/235] [D loss: 1.091847, acc: 84.96%] [G loss: 1.188679]\n",
      "[Epoch 14/50] [Batch 121/235] [D loss: 1.113578, acc: 88.09%] [G loss: 1.238783]\n",
      "[Epoch 14/50] [Batch 122/235] [D loss: 1.126862, acc: 85.16%] [G loss: 1.191912]\n",
      "[Epoch 14/50] [Batch 123/235] [D loss: 1.145209, acc: 86.91%] [G loss: 1.147370]\n",
      "[Epoch 14/50] [Batch 124/235] [D loss: 1.087614, acc: 85.55%] [G loss: 1.222751]\n",
      "[Epoch 14/50] [Batch 125/235] [D loss: 1.126744, acc: 84.38%] [G loss: 1.241731]\n",
      "[Epoch 14/50] [Batch 126/235] [D loss: 1.117603, acc: 85.16%] [G loss: 1.262424]\n",
      "[Epoch 14/50] [Batch 127/235] [D loss: 1.054421, acc: 86.13%] [G loss: 1.060325]\n",
      "[Epoch 14/50] [Batch 128/235] [D loss: 1.147372, acc: 85.74%] [G loss: 1.213312]\n",
      "[Epoch 14/50] [Batch 129/235] [D loss: 1.175465, acc: 86.91%] [G loss: 1.274397]\n",
      "[Epoch 14/50] [Batch 130/235] [D loss: 1.188671, acc: 87.70%] [G loss: 1.259722]\n",
      "[Epoch 14/50] [Batch 131/235] [D loss: 1.125014, acc: 83.20%] [G loss: 1.097155]\n",
      "[Epoch 14/50] [Batch 132/235] [D loss: 1.063096, acc: 85.55%] [G loss: 1.198303]\n",
      "[Epoch 14/50] [Batch 133/235] [D loss: 1.123891, acc: 85.94%] [G loss: 1.245143]\n",
      "[Epoch 14/50] [Batch 134/235] [D loss: 1.082518, acc: 83.98%] [G loss: 1.329157]\n",
      "[Epoch 14/50] [Batch 135/235] [D loss: 1.117801, acc: 87.89%] [G loss: 1.164208]\n",
      "[Epoch 14/50] [Batch 136/235] [D loss: 1.185460, acc: 83.20%] [G loss: 1.303094]\n",
      "[Epoch 14/50] [Batch 137/235] [D loss: 1.126719, acc: 84.18%] [G loss: 1.155610]\n",
      "[Epoch 14/50] [Batch 138/235] [D loss: 1.079956, acc: 86.13%] [G loss: 1.178244]\n",
      "[Epoch 14/50] [Batch 139/235] [D loss: 1.107936, acc: 85.74%] [G loss: 1.175513]\n",
      "[Epoch 14/50] [Batch 140/235] [D loss: 1.150546, acc: 85.16%] [G loss: 1.229349]\n",
      "[Epoch 14/50] [Batch 141/235] [D loss: 1.152617, acc: 82.62%] [G loss: 0.988418]\n",
      "[Epoch 14/50] [Batch 142/235] [D loss: 1.084338, acc: 87.11%] [G loss: 1.087489]\n",
      "[Epoch 14/50] [Batch 143/235] [D loss: 1.131934, acc: 84.96%] [G loss: 1.132128]\n",
      "[Epoch 14/50] [Batch 144/235] [D loss: 1.078421, acc: 84.96%] [G loss: 1.103978]\n",
      "[Epoch 14/50] [Batch 145/235] [D loss: 1.154275, acc: 83.01%] [G loss: 1.332070]\n",
      "[Epoch 14/50] [Batch 146/235] [D loss: 1.078802, acc: 85.55%] [G loss: 1.272895]\n",
      "[Epoch 14/50] [Batch 147/235] [D loss: 1.119018, acc: 84.57%] [G loss: 1.315353]\n",
      "[Epoch 14/50] [Batch 148/235] [D loss: 1.205418, acc: 83.98%] [G loss: 1.152596]\n",
      "[Epoch 14/50] [Batch 149/235] [D loss: 1.128623, acc: 84.57%] [G loss: 1.231574]\n",
      "[Epoch 14/50] [Batch 150/235] [D loss: 1.152361, acc: 83.98%] [G loss: 1.286072]\n",
      "[Epoch 14/50] [Batch 151/235] [D loss: 1.101279, acc: 85.16%] [G loss: 1.230871]\n",
      "[Epoch 14/50] [Batch 152/235] [D loss: 1.118475, acc: 86.33%] [G loss: 1.081948]\n",
      "[Epoch 14/50] [Batch 153/235] [D loss: 1.105543, acc: 86.91%] [G loss: 1.188858]\n",
      "[Epoch 14/50] [Batch 154/235] [D loss: 1.160963, acc: 82.62%] [G loss: 1.354312]\n",
      "[Epoch 14/50] [Batch 155/235] [D loss: 1.086569, acc: 83.98%] [G loss: 1.185832]\n",
      "[Epoch 14/50] [Batch 156/235] [D loss: 1.098042, acc: 83.59%] [G loss: 1.155202]\n",
      "[Epoch 14/50] [Batch 157/235] [D loss: 1.101786, acc: 88.48%] [G loss: 1.199739]\n",
      "[Epoch 14/50] [Batch 158/235] [D loss: 1.151771, acc: 86.33%] [G loss: 1.128532]\n",
      "[Epoch 14/50] [Batch 159/235] [D loss: 1.116363, acc: 84.38%] [G loss: 1.279239]\n",
      "[Epoch 14/50] [Batch 160/235] [D loss: 1.144445, acc: 84.77%] [G loss: 1.210224]\n",
      "[Epoch 14/50] [Batch 161/235] [D loss: 1.122476, acc: 85.16%] [G loss: 1.276410]\n",
      "[Epoch 14/50] [Batch 162/235] [D loss: 1.126052, acc: 84.77%] [G loss: 1.292000]\n",
      "[Epoch 14/50] [Batch 163/235] [D loss: 1.113915, acc: 85.35%] [G loss: 1.111638]\n",
      "[Epoch 14/50] [Batch 164/235] [D loss: 1.085060, acc: 84.96%] [G loss: 1.297224]\n",
      "[Epoch 14/50] [Batch 165/235] [D loss: 1.081294, acc: 83.20%] [G loss: 1.150417]\n",
      "[Epoch 14/50] [Batch 166/235] [D loss: 1.212734, acc: 81.25%] [G loss: 1.036798]\n",
      "[Epoch 14/50] [Batch 167/235] [D loss: 1.114690, acc: 83.59%] [G loss: 1.314218]\n",
      "[Epoch 14/50] [Batch 168/235] [D loss: 1.070974, acc: 84.57%] [G loss: 1.288720]\n",
      "[Epoch 14/50] [Batch 169/235] [D loss: 1.116699, acc: 84.18%] [G loss: 1.195627]\n",
      "[Epoch 14/50] [Batch 170/235] [D loss: 1.137314, acc: 84.38%] [G loss: 1.132201]\n",
      "[Epoch 14/50] [Batch 171/235] [D loss: 1.127517, acc: 86.91%] [G loss: 1.205033]\n",
      "[Epoch 14/50] [Batch 172/235] [D loss: 1.166742, acc: 85.35%] [G loss: 1.325970]\n",
      "[Epoch 14/50] [Batch 173/235] [D loss: 1.166453, acc: 83.20%] [G loss: 1.283532]\n",
      "[Epoch 14/50] [Batch 174/235] [D loss: 1.135499, acc: 81.84%] [G loss: 1.107581]\n",
      "[Epoch 14/50] [Batch 175/235] [D loss: 1.115371, acc: 84.18%] [G loss: 1.164845]\n",
      "[Epoch 14/50] [Batch 176/235] [D loss: 1.062024, acc: 84.57%] [G loss: 1.206834]\n",
      "[Epoch 14/50] [Batch 177/235] [D loss: 1.136926, acc: 85.55%] [G loss: 1.359074]\n",
      "[Epoch 14/50] [Batch 178/235] [D loss: 1.144776, acc: 87.30%] [G loss: 1.205261]\n",
      "[Epoch 14/50] [Batch 179/235] [D loss: 1.134347, acc: 81.05%] [G loss: 1.315478]\n",
      "[Epoch 14/50] [Batch 180/235] [D loss: 1.140519, acc: 86.33%] [G loss: 1.166455]\n",
      "[Epoch 14/50] [Batch 181/235] [D loss: 1.109958, acc: 85.94%] [G loss: 1.343263]\n",
      "[Epoch 14/50] [Batch 182/235] [D loss: 1.147310, acc: 85.55%] [G loss: 1.168452]\n",
      "[Epoch 14/50] [Batch 183/235] [D loss: 1.172996, acc: 86.91%] [G loss: 1.108990]\n",
      "[Epoch 14/50] [Batch 184/235] [D loss: 1.099555, acc: 83.01%] [G loss: 1.290615]\n",
      "[Epoch 14/50] [Batch 185/235] [D loss: 1.162579, acc: 84.18%] [G loss: 1.275375]\n",
      "[Epoch 14/50] [Batch 186/235] [D loss: 1.136221, acc: 84.38%] [G loss: 1.076187]\n",
      "[Epoch 14/50] [Batch 187/235] [D loss: 1.120343, acc: 86.13%] [G loss: 1.150908]\n",
      "[Epoch 14/50] [Batch 188/235] [D loss: 1.149009, acc: 85.94%] [G loss: 1.293691]\n",
      "[Epoch 14/50] [Batch 189/235] [D loss: 1.142344, acc: 85.94%] [G loss: 1.256708]\n",
      "[Epoch 14/50] [Batch 190/235] [D loss: 1.124656, acc: 87.30%] [G loss: 1.132149]\n",
      "[Epoch 14/50] [Batch 191/235] [D loss: 1.080339, acc: 86.52%] [G loss: 1.183243]\n",
      "[Epoch 14/50] [Batch 192/235] [D loss: 1.162629, acc: 85.35%] [G loss: 1.191725]\n",
      "[Epoch 14/50] [Batch 193/235] [D loss: 1.095610, acc: 87.50%] [G loss: 1.119728]\n",
      "[Epoch 14/50] [Batch 194/235] [D loss: 1.118070, acc: 85.16%] [G loss: 1.122319]\n",
      "[Epoch 14/50] [Batch 195/235] [D loss: 1.135943, acc: 85.16%] [G loss: 1.418326]\n",
      "[Epoch 14/50] [Batch 196/235] [D loss: 1.112783, acc: 86.72%] [G loss: 1.328597]\n",
      "[Epoch 14/50] [Batch 197/235] [D loss: 1.088780, acc: 85.16%] [G loss: 1.140034]\n",
      "[Epoch 14/50] [Batch 198/235] [D loss: 1.141174, acc: 83.20%] [G loss: 1.136635]\n",
      "[Epoch 14/50] [Batch 199/235] [D loss: 1.094125, acc: 85.55%] [G loss: 1.132117]\n",
      "[Epoch 14/50] [Batch 200/235] [D loss: 1.154581, acc: 86.72%] [G loss: 1.212759]\n",
      "[Epoch 14/50] [Batch 201/235] [D loss: 1.110545, acc: 85.55%] [G loss: 1.253183]\n",
      "[Epoch 14/50] [Batch 202/235] [D loss: 1.119153, acc: 85.35%] [G loss: 1.242315]\n",
      "[Epoch 14/50] [Batch 203/235] [D loss: 1.122801, acc: 86.52%] [G loss: 1.232015]\n",
      "[Epoch 14/50] [Batch 204/235] [D loss: 1.109503, acc: 85.16%] [G loss: 1.142185]\n",
      "[Epoch 14/50] [Batch 205/235] [D loss: 1.122510, acc: 84.18%] [G loss: 1.176760]\n",
      "[Epoch 14/50] [Batch 206/235] [D loss: 1.115283, acc: 86.72%] [G loss: 1.087591]\n",
      "[Epoch 14/50] [Batch 207/235] [D loss: 1.096533, acc: 84.38%] [G loss: 1.240166]\n",
      "[Epoch 14/50] [Batch 208/235] [D loss: 1.077435, acc: 87.11%] [G loss: 1.266712]\n",
      "[Epoch 14/50] [Batch 209/235] [D loss: 1.159615, acc: 85.94%] [G loss: 1.107690]\n",
      "[Epoch 14/50] [Batch 210/235] [D loss: 1.095373, acc: 85.35%] [G loss: 1.194853]\n",
      "[Epoch 14/50] [Batch 211/235] [D loss: 1.098600, acc: 86.33%] [G loss: 1.202498]\n",
      "[Epoch 14/50] [Batch 212/235] [D loss: 1.141801, acc: 83.20%] [G loss: 1.225356]\n",
      "[Epoch 14/50] [Batch 213/235] [D loss: 1.130527, acc: 84.57%] [G loss: 1.247517]\n",
      "[Epoch 14/50] [Batch 214/235] [D loss: 1.122711, acc: 84.96%] [G loss: 1.202318]\n",
      "[Epoch 14/50] [Batch 215/235] [D loss: 1.148576, acc: 84.77%] [G loss: 1.273889]\n",
      "[Epoch 14/50] [Batch 216/235] [D loss: 1.140206, acc: 81.84%] [G loss: 1.274395]\n",
      "[Epoch 14/50] [Batch 217/235] [D loss: 1.145500, acc: 84.57%] [G loss: 1.090990]\n",
      "[Epoch 14/50] [Batch 218/235] [D loss: 1.163101, acc: 86.13%] [G loss: 1.223334]\n",
      "[Epoch 14/50] [Batch 219/235] [D loss: 1.134380, acc: 83.79%] [G loss: 1.137193]\n",
      "[Epoch 14/50] [Batch 220/235] [D loss: 1.149706, acc: 84.38%] [G loss: 1.150975]\n",
      "[Epoch 14/50] [Batch 221/235] [D loss: 1.133777, acc: 86.13%] [G loss: 1.103080]\n",
      "[Epoch 14/50] [Batch 222/235] [D loss: 1.134711, acc: 84.18%] [G loss: 1.265873]\n",
      "[Epoch 14/50] [Batch 223/235] [D loss: 1.109376, acc: 84.96%] [G loss: 1.263283]\n",
      "[Epoch 14/50] [Batch 224/235] [D loss: 1.099526, acc: 86.33%] [G loss: 1.140841]\n",
      "[Epoch 14/50] [Batch 225/235] [D loss: 1.071729, acc: 84.96%] [G loss: 1.158735]\n",
      "[Epoch 14/50] [Batch 226/235] [D loss: 1.120811, acc: 83.98%] [G loss: 1.182696]\n",
      "[Epoch 14/50] [Batch 227/235] [D loss: 1.112265, acc: 83.98%] [G loss: 1.286753]\n",
      "[Epoch 14/50] [Batch 228/235] [D loss: 1.087735, acc: 84.38%] [G loss: 1.314697]\n",
      "[Epoch 14/50] [Batch 229/235] [D loss: 1.156704, acc: 86.52%] [G loss: 1.241466]\n",
      "[Epoch 14/50] [Batch 230/235] [D loss: 1.086505, acc: 83.79%] [G loss: 1.129101]\n",
      "[Epoch 14/50] [Batch 231/235] [D loss: 1.143069, acc: 85.94%] [G loss: 1.107134]\n",
      "[Epoch 14/50] [Batch 232/235] [D loss: 1.138455, acc: 86.13%] [G loss: 1.189045]\n",
      "[Epoch 14/50] [Batch 233/235] [D loss: 1.125191, acc: 86.33%] [G loss: 1.287088]\n",
      "[Epoch 14/50] [Batch 234/235] [D loss: 1.138048, acc: 84.38%] [G loss: 1.294820]\n",
      "[Epoch 15/50] [Batch 0/235] [D loss: 1.090606, acc: 85.74%] [G loss: 1.231943]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/50] [Batch 1/235] [D loss: 1.111271, acc: 86.13%] [G loss: 1.201507]\n",
      "[Epoch 15/50] [Batch 2/235] [D loss: 1.165800, acc: 82.03%] [G loss: 1.276807]\n",
      "[Epoch 15/50] [Batch 3/235] [D loss: 1.127192, acc: 83.40%] [G loss: 1.241570]\n",
      "[Epoch 15/50] [Batch 4/235] [D loss: 1.103871, acc: 85.35%] [G loss: 1.088036]\n",
      "[Epoch 15/50] [Batch 5/235] [D loss: 1.159471, acc: 83.40%] [G loss: 1.181207]\n",
      "[Epoch 15/50] [Batch 6/235] [D loss: 1.080045, acc: 86.33%] [G loss: 1.201950]\n",
      "[Epoch 15/50] [Batch 7/235] [D loss: 1.152679, acc: 84.38%] [G loss: 1.271359]\n",
      "[Epoch 15/50] [Batch 8/235] [D loss: 1.115542, acc: 83.59%] [G loss: 1.147821]\n",
      "[Epoch 15/50] [Batch 9/235] [D loss: 1.148017, acc: 86.13%] [G loss: 1.202394]\n",
      "[Epoch 15/50] [Batch 10/235] [D loss: 1.157625, acc: 83.01%] [G loss: 1.185506]\n",
      "[Epoch 15/50] [Batch 11/235] [D loss: 1.106483, acc: 86.52%] [G loss: 1.239036]\n",
      "[Epoch 15/50] [Batch 12/235] [D loss: 1.129091, acc: 84.77%] [G loss: 1.328552]\n",
      "[Epoch 15/50] [Batch 13/235] [D loss: 1.111317, acc: 85.94%] [G loss: 1.153810]\n",
      "[Epoch 15/50] [Batch 14/235] [D loss: 1.101779, acc: 85.55%] [G loss: 1.080335]\n",
      "[Epoch 15/50] [Batch 15/235] [D loss: 1.099204, acc: 83.98%] [G loss: 1.150392]\n",
      "[Epoch 15/50] [Batch 16/235] [D loss: 1.116809, acc: 85.55%] [G loss: 1.133669]\n",
      "[Epoch 15/50] [Batch 17/235] [D loss: 1.152694, acc: 83.01%] [G loss: 1.275604]\n",
      "[Epoch 15/50] [Batch 18/235] [D loss: 1.112108, acc: 87.11%] [G loss: 1.199526]\n",
      "[Epoch 15/50] [Batch 19/235] [D loss: 1.148915, acc: 87.70%] [G loss: 1.233178]\n",
      "[Epoch 15/50] [Batch 20/235] [D loss: 1.102816, acc: 86.72%] [G loss: 1.113162]\n",
      "[Epoch 15/50] [Batch 21/235] [D loss: 1.114116, acc: 83.40%] [G loss: 1.249774]\n",
      "[Epoch 15/50] [Batch 22/235] [D loss: 1.147550, acc: 84.38%] [G loss: 1.077051]\n",
      "[Epoch 15/50] [Batch 23/235] [D loss: 1.123167, acc: 84.57%] [G loss: 1.220104]\n",
      "[Epoch 15/50] [Batch 24/235] [D loss: 1.128392, acc: 83.59%] [G loss: 1.137503]\n",
      "[Epoch 15/50] [Batch 25/235] [D loss: 1.133457, acc: 84.96%] [G loss: 1.079504]\n",
      "[Epoch 15/50] [Batch 26/235] [D loss: 1.100101, acc: 85.16%] [G loss: 1.213257]\n",
      "[Epoch 15/50] [Batch 27/235] [D loss: 1.137293, acc: 84.57%] [G loss: 1.251090]\n",
      "[Epoch 15/50] [Batch 28/235] [D loss: 1.080580, acc: 85.35%] [G loss: 1.090132]\n",
      "[Epoch 15/50] [Batch 29/235] [D loss: 1.168989, acc: 86.91%] [G loss: 1.091947]\n",
      "[Epoch 15/50] [Batch 30/235] [D loss: 1.122715, acc: 83.20%] [G loss: 1.233511]\n",
      "[Epoch 15/50] [Batch 31/235] [D loss: 1.111350, acc: 86.13%] [G loss: 1.123255]\n",
      "[Epoch 15/50] [Batch 32/235] [D loss: 1.110363, acc: 84.96%] [G loss: 1.181926]\n",
      "[Epoch 15/50] [Batch 33/235] [D loss: 1.142356, acc: 85.74%] [G loss: 1.238513]\n",
      "[Epoch 15/50] [Batch 34/235] [D loss: 1.113035, acc: 86.91%] [G loss: 1.223513]\n",
      "[Epoch 15/50] [Batch 35/235] [D loss: 1.102849, acc: 86.13%] [G loss: 1.187977]\n",
      "[Epoch 15/50] [Batch 36/235] [D loss: 1.134061, acc: 84.38%] [G loss: 1.360053]\n",
      "[Epoch 15/50] [Batch 37/235] [D loss: 1.062166, acc: 84.77%] [G loss: 1.242603]\n",
      "[Epoch 15/50] [Batch 38/235] [D loss: 1.102112, acc: 86.72%] [G loss: 1.208531]\n",
      "[Epoch 15/50] [Batch 39/235] [D loss: 1.181442, acc: 84.96%] [G loss: 1.127269]\n",
      "[Epoch 15/50] [Batch 40/235] [D loss: 1.092858, acc: 82.62%] [G loss: 1.083864]\n",
      "[Epoch 15/50] [Batch 41/235] [D loss: 1.140122, acc: 84.77%] [G loss: 1.153286]\n",
      "[Epoch 15/50] [Batch 42/235] [D loss: 1.087254, acc: 87.30%] [G loss: 1.278414]\n",
      "[Epoch 15/50] [Batch 43/235] [D loss: 1.130255, acc: 83.98%] [G loss: 1.268235]\n",
      "[Epoch 15/50] [Batch 44/235] [D loss: 1.137367, acc: 85.74%] [G loss: 1.257332]\n",
      "[Epoch 15/50] [Batch 45/235] [D loss: 1.127272, acc: 87.30%] [G loss: 1.145648]\n",
      "[Epoch 15/50] [Batch 46/235] [D loss: 1.112899, acc: 81.45%] [G loss: 1.108186]\n",
      "[Epoch 15/50] [Batch 47/235] [D loss: 1.139281, acc: 87.30%] [G loss: 1.146457]\n",
      "[Epoch 15/50] [Batch 48/235] [D loss: 1.133069, acc: 83.98%] [G loss: 1.141202]\n",
      "[Epoch 15/50] [Batch 49/235] [D loss: 1.114014, acc: 86.33%] [G loss: 1.176995]\n",
      "[Epoch 15/50] [Batch 50/235] [D loss: 1.113928, acc: 85.55%] [G loss: 1.227024]\n",
      "[Epoch 15/50] [Batch 51/235] [D loss: 1.139127, acc: 85.94%] [G loss: 1.107393]\n",
      "[Epoch 15/50] [Batch 52/235] [D loss: 1.146357, acc: 85.16%] [G loss: 1.072487]\n",
      "[Epoch 15/50] [Batch 53/235] [D loss: 1.060873, acc: 88.67%] [G loss: 1.273788]\n",
      "[Epoch 15/50] [Batch 54/235] [D loss: 1.122981, acc: 85.94%] [G loss: 1.285297]\n",
      "[Epoch 15/50] [Batch 55/235] [D loss: 1.096065, acc: 85.94%] [G loss: 1.263533]\n",
      "[Epoch 15/50] [Batch 56/235] [D loss: 1.090475, acc: 86.33%] [G loss: 1.220877]\n",
      "[Epoch 15/50] [Batch 57/235] [D loss: 1.062332, acc: 87.11%] [G loss: 1.166761]\n",
      "[Epoch 15/50] [Batch 58/235] [D loss: 1.125861, acc: 84.38%] [G loss: 1.163320]\n",
      "[Epoch 15/50] [Batch 59/235] [D loss: 1.121261, acc: 85.55%] [G loss: 1.362397]\n",
      "[Epoch 15/50] [Batch 60/235] [D loss: 1.112245, acc: 86.72%] [G loss: 1.156701]\n",
      "[Epoch 15/50] [Batch 61/235] [D loss: 1.126192, acc: 86.13%] [G loss: 1.071821]\n",
      "[Epoch 15/50] [Batch 62/235] [D loss: 1.051392, acc: 88.28%] [G loss: 1.205450]\n",
      "[Epoch 15/50] [Batch 63/235] [D loss: 1.080493, acc: 85.55%] [G loss: 1.204050]\n",
      "[Epoch 15/50] [Batch 64/235] [D loss: 1.086221, acc: 85.74%] [G loss: 1.171240]\n",
      "[Epoch 15/50] [Batch 65/235] [D loss: 1.130685, acc: 85.35%] [G loss: 1.124850]\n",
      "[Epoch 15/50] [Batch 66/235] [D loss: 1.128631, acc: 84.57%] [G loss: 1.297161]\n",
      "[Epoch 15/50] [Batch 67/235] [D loss: 1.140083, acc: 86.13%] [G loss: 1.222873]\n",
      "[Epoch 15/50] [Batch 68/235] [D loss: 1.122609, acc: 83.20%] [G loss: 1.191062]\n",
      "[Epoch 15/50] [Batch 69/235] [D loss: 1.127399, acc: 85.35%] [G loss: 1.158814]\n",
      "[Epoch 15/50] [Batch 70/235] [D loss: 1.079094, acc: 84.96%] [G loss: 1.407676]\n",
      "[Epoch 15/50] [Batch 71/235] [D loss: 1.099889, acc: 87.30%] [G loss: 1.342590]\n",
      "[Epoch 15/50] [Batch 72/235] [D loss: 1.204600, acc: 83.79%] [G loss: 1.090601]\n",
      "[Epoch 15/50] [Batch 73/235] [D loss: 1.088886, acc: 86.33%] [G loss: 1.083922]\n",
      "[Epoch 15/50] [Batch 74/235] [D loss: 1.111351, acc: 85.35%] [G loss: 1.220117]\n",
      "[Epoch 15/50] [Batch 75/235] [D loss: 1.092672, acc: 84.38%] [G loss: 1.228372]\n",
      "[Epoch 15/50] [Batch 76/235] [D loss: 1.160837, acc: 84.18%] [G loss: 1.265079]\n",
      "[Epoch 15/50] [Batch 77/235] [D loss: 1.121909, acc: 83.20%] [G loss: 1.127165]\n",
      "[Epoch 15/50] [Batch 78/235] [D loss: 1.133370, acc: 82.81%] [G loss: 1.028236]\n",
      "[Epoch 15/50] [Batch 79/235] [D loss: 1.129112, acc: 85.74%] [G loss: 1.298044]\n",
      "[Epoch 15/50] [Batch 80/235] [D loss: 1.132922, acc: 85.16%] [G loss: 1.207077]\n",
      "[Epoch 15/50] [Batch 81/235] [D loss: 1.118859, acc: 82.42%] [G loss: 1.176102]\n",
      "[Epoch 15/50] [Batch 82/235] [D loss: 1.139553, acc: 83.20%] [G loss: 1.093740]\n",
      "[Epoch 15/50] [Batch 83/235] [D loss: 1.167774, acc: 87.70%] [G loss: 1.206760]\n",
      "[Epoch 15/50] [Batch 84/235] [D loss: 1.120839, acc: 87.30%] [G loss: 1.236871]\n",
      "[Epoch 15/50] [Batch 85/235] [D loss: 1.105482, acc: 86.13%] [G loss: 1.104016]\n",
      "[Epoch 15/50] [Batch 86/235] [D loss: 1.101571, acc: 86.13%] [G loss: 1.309828]\n",
      "[Epoch 15/50] [Batch 87/235] [D loss: 1.105895, acc: 86.33%] [G loss: 1.155346]\n",
      "[Epoch 15/50] [Batch 88/235] [D loss: 1.136943, acc: 84.77%] [G loss: 1.173440]\n",
      "[Epoch 15/50] [Batch 89/235] [D loss: 1.089365, acc: 85.16%] [G loss: 1.193492]\n",
      "[Epoch 15/50] [Batch 90/235] [D loss: 1.098069, acc: 87.89%] [G loss: 1.176473]\n",
      "[Epoch 15/50] [Batch 91/235] [D loss: 1.171694, acc: 85.74%] [G loss: 1.287686]\n",
      "[Epoch 15/50] [Batch 92/235] [D loss: 1.125894, acc: 86.13%] [G loss: 1.227599]\n",
      "[Epoch 15/50] [Batch 93/235] [D loss: 1.102099, acc: 85.94%] [G loss: 1.141321]\n",
      "[Epoch 15/50] [Batch 94/235] [D loss: 1.141313, acc: 84.96%] [G loss: 1.258506]\n",
      "[Epoch 15/50] [Batch 95/235] [D loss: 1.132291, acc: 84.96%] [G loss: 1.132394]\n",
      "[Epoch 15/50] [Batch 96/235] [D loss: 1.150321, acc: 83.01%] [G loss: 1.074386]\n",
      "[Epoch 15/50] [Batch 97/235] [D loss: 1.167544, acc: 83.98%] [G loss: 1.340512]\n",
      "[Epoch 15/50] [Batch 98/235] [D loss: 1.053274, acc: 86.72%] [G loss: 1.157386]\n",
      "[Epoch 15/50] [Batch 99/235] [D loss: 1.069959, acc: 83.98%] [G loss: 1.187910]\n",
      "[Epoch 15/50] [Batch 100/235] [D loss: 1.115184, acc: 88.09%] [G loss: 1.106494]\n",
      "[Epoch 15/50] [Batch 101/235] [D loss: 1.135108, acc: 84.77%] [G loss: 1.202344]\n",
      "[Epoch 15/50] [Batch 102/235] [D loss: 1.090315, acc: 88.67%] [G loss: 1.269467]\n",
      "[Epoch 15/50] [Batch 103/235] [D loss: 1.111409, acc: 84.18%] [G loss: 1.171592]\n",
      "[Epoch 15/50] [Batch 104/235] [D loss: 1.125379, acc: 85.35%] [G loss: 1.140298]\n",
      "[Epoch 15/50] [Batch 105/235] [D loss: 1.098729, acc: 84.77%] [G loss: 1.209938]\n",
      "[Epoch 15/50] [Batch 106/235] [D loss: 1.122033, acc: 86.52%] [G loss: 1.141199]\n",
      "[Epoch 15/50] [Batch 107/235] [D loss: 1.113424, acc: 87.70%] [G loss: 1.296011]\n",
      "[Epoch 15/50] [Batch 108/235] [D loss: 1.101102, acc: 85.35%] [G loss: 1.165192]\n",
      "[Epoch 15/50] [Batch 109/235] [D loss: 1.103620, acc: 82.42%] [G loss: 1.155442]\n",
      "[Epoch 15/50] [Batch 110/235] [D loss: 1.195237, acc: 86.13%] [G loss: 1.133662]\n",
      "[Epoch 15/50] [Batch 111/235] [D loss: 1.091252, acc: 84.77%] [G loss: 1.278097]\n",
      "[Epoch 15/50] [Batch 112/235] [D loss: 1.139642, acc: 85.55%] [G loss: 1.264097]\n",
      "[Epoch 15/50] [Batch 113/235] [D loss: 1.117269, acc: 84.18%] [G loss: 1.245068]\n",
      "[Epoch 15/50] [Batch 114/235] [D loss: 1.092216, acc: 85.94%] [G loss: 1.185999]\n",
      "[Epoch 15/50] [Batch 115/235] [D loss: 1.113559, acc: 86.13%] [G loss: 1.180184]\n",
      "[Epoch 15/50] [Batch 116/235] [D loss: 1.148740, acc: 83.98%] [G loss: 1.132009]\n",
      "[Epoch 15/50] [Batch 117/235] [D loss: 1.089805, acc: 85.55%] [G loss: 1.217569]\n",
      "[Epoch 15/50] [Batch 118/235] [D loss: 1.129961, acc: 88.09%] [G loss: 1.235364]\n",
      "[Epoch 15/50] [Batch 119/235] [D loss: 1.144885, acc: 83.40%] [G loss: 1.189960]\n",
      "[Epoch 15/50] [Batch 120/235] [D loss: 1.085403, acc: 86.72%] [G loss: 1.148115]\n",
      "[Epoch 15/50] [Batch 121/235] [D loss: 1.119741, acc: 86.91%] [G loss: 1.234580]\n",
      "[Epoch 15/50] [Batch 122/235] [D loss: 1.055040, acc: 85.94%] [G loss: 1.282585]\n",
      "[Epoch 15/50] [Batch 123/235] [D loss: 1.134352, acc: 82.62%] [G loss: 1.259908]\n",
      "[Epoch 15/50] [Batch 124/235] [D loss: 1.117527, acc: 84.57%] [G loss: 1.160879]\n",
      "[Epoch 15/50] [Batch 125/235] [D loss: 1.128102, acc: 86.72%] [G loss: 1.058115]\n",
      "[Epoch 15/50] [Batch 126/235] [D loss: 1.112521, acc: 83.98%] [G loss: 1.208126]\n",
      "[Epoch 15/50] [Batch 127/235] [D loss: 1.127272, acc: 85.74%] [G loss: 1.128415]\n",
      "[Epoch 15/50] [Batch 128/235] [D loss: 1.171702, acc: 84.77%] [G loss: 1.215259]\n",
      "[Epoch 15/50] [Batch 129/235] [D loss: 1.111120, acc: 87.30%] [G loss: 1.232120]\n",
      "[Epoch 15/50] [Batch 130/235] [D loss: 1.152757, acc: 84.18%] [G loss: 1.162909]\n",
      "[Epoch 15/50] [Batch 131/235] [D loss: 1.149211, acc: 85.55%] [G loss: 1.157961]\n",
      "[Epoch 15/50] [Batch 132/235] [D loss: 1.137258, acc: 83.79%] [G loss: 1.095532]\n",
      "[Epoch 15/50] [Batch 133/235] [D loss: 1.152937, acc: 83.79%] [G loss: 1.150445]\n",
      "[Epoch 15/50] [Batch 134/235] [D loss: 1.119833, acc: 83.01%] [G loss: 1.340654]\n",
      "[Epoch 15/50] [Batch 135/235] [D loss: 1.125728, acc: 84.77%] [G loss: 1.148324]\n",
      "[Epoch 15/50] [Batch 136/235] [D loss: 1.083368, acc: 84.18%] [G loss: 1.152618]\n",
      "[Epoch 15/50] [Batch 137/235] [D loss: 1.142632, acc: 85.94%] [G loss: 1.196811]\n",
      "[Epoch 15/50] [Batch 138/235] [D loss: 1.098108, acc: 86.13%] [G loss: 1.073755]\n",
      "[Epoch 15/50] [Batch 139/235] [D loss: 1.137028, acc: 84.38%] [G loss: 1.215110]\n",
      "[Epoch 15/50] [Batch 140/235] [D loss: 1.114429, acc: 84.18%] [G loss: 1.266422]\n",
      "[Epoch 15/50] [Batch 141/235] [D loss: 1.096844, acc: 85.55%] [G loss: 1.148072]\n",
      "[Epoch 15/50] [Batch 142/235] [D loss: 1.079339, acc: 84.57%] [G loss: 1.258762]\n",
      "[Epoch 15/50] [Batch 143/235] [D loss: 1.109934, acc: 87.70%] [G loss: 1.189013]\n",
      "[Epoch 15/50] [Batch 144/235] [D loss: 1.141215, acc: 83.40%] [G loss: 1.070796]\n",
      "[Epoch 15/50] [Batch 145/235] [D loss: 1.181562, acc: 86.72%] [G loss: 1.071530]\n",
      "[Epoch 15/50] [Batch 146/235] [D loss: 1.101180, acc: 84.57%] [G loss: 1.186156]\n",
      "[Epoch 15/50] [Batch 147/235] [D loss: 1.080677, acc: 83.40%] [G loss: 1.200986]\n",
      "[Epoch 15/50] [Batch 148/235] [D loss: 1.089791, acc: 87.30%] [G loss: 1.171450]\n",
      "[Epoch 15/50] [Batch 149/235] [D loss: 1.098899, acc: 84.18%] [G loss: 1.189919]\n",
      "[Epoch 15/50] [Batch 150/235] [D loss: 1.126644, acc: 83.98%] [G loss: 1.133052]\n",
      "[Epoch 15/50] [Batch 151/235] [D loss: 1.116620, acc: 86.52%] [G loss: 1.310266]\n",
      "[Epoch 15/50] [Batch 152/235] [D loss: 1.068454, acc: 87.11%] [G loss: 1.140907]\n",
      "[Epoch 15/50] [Batch 153/235] [D loss: 1.125465, acc: 84.96%] [G loss: 1.139833]\n",
      "[Epoch 15/50] [Batch 154/235] [D loss: 1.112808, acc: 84.38%] [G loss: 1.142620]\n",
      "[Epoch 15/50] [Batch 155/235] [D loss: 1.137188, acc: 85.16%] [G loss: 1.260119]\n",
      "[Epoch 15/50] [Batch 156/235] [D loss: 1.080533, acc: 87.11%] [G loss: 1.264272]\n",
      "[Epoch 15/50] [Batch 157/235] [D loss: 1.083965, acc: 88.09%] [G loss: 1.071561]\n",
      "[Epoch 15/50] [Batch 158/235] [D loss: 1.138624, acc: 85.35%] [G loss: 1.079017]\n",
      "[Epoch 15/50] [Batch 159/235] [D loss: 1.147012, acc: 85.16%] [G loss: 1.194499]\n",
      "[Epoch 15/50] [Batch 160/235] [D loss: 1.118773, acc: 83.79%] [G loss: 1.315178]\n",
      "[Epoch 15/50] [Batch 161/235] [D loss: 1.122065, acc: 83.79%] [G loss: 1.133426]\n",
      "[Epoch 15/50] [Batch 162/235] [D loss: 1.096073, acc: 86.91%] [G loss: 1.133050]\n",
      "[Epoch 15/50] [Batch 163/235] [D loss: 1.130559, acc: 86.72%] [G loss: 1.067124]\n",
      "[Epoch 15/50] [Batch 164/235] [D loss: 1.131497, acc: 86.13%] [G loss: 1.176126]\n",
      "[Epoch 15/50] [Batch 165/235] [D loss: 1.096994, acc: 87.30%] [G loss: 1.398133]\n",
      "[Epoch 15/50] [Batch 166/235] [D loss: 1.087943, acc: 87.50%] [G loss: 1.123449]\n",
      "[Epoch 15/50] [Batch 167/235] [D loss: 1.084095, acc: 88.28%] [G loss: 1.247704]\n",
      "[Epoch 15/50] [Batch 168/235] [D loss: 1.111838, acc: 83.79%] [G loss: 1.221732]\n",
      "[Epoch 15/50] [Batch 169/235] [D loss: 1.170390, acc: 82.03%] [G loss: 1.296727]\n",
      "[Epoch 15/50] [Batch 170/235] [D loss: 1.131570, acc: 85.35%] [G loss: 1.120703]\n",
      "[Epoch 15/50] [Batch 171/235] [D loss: 1.148870, acc: 85.35%] [G loss: 1.078619]\n",
      "[Epoch 15/50] [Batch 172/235] [D loss: 1.142001, acc: 83.79%] [G loss: 1.277029]\n",
      "[Epoch 15/50] [Batch 173/235] [D loss: 1.119328, acc: 88.28%] [G loss: 1.188226]\n",
      "[Epoch 15/50] [Batch 174/235] [D loss: 1.098031, acc: 83.98%] [G loss: 1.189235]\n",
      "[Epoch 15/50] [Batch 175/235] [D loss: 1.124797, acc: 84.38%] [G loss: 1.209083]\n",
      "[Epoch 15/50] [Batch 176/235] [D loss: 1.089581, acc: 88.28%] [G loss: 1.179027]\n",
      "[Epoch 15/50] [Batch 177/235] [D loss: 1.100991, acc: 84.18%] [G loss: 1.057859]\n",
      "[Epoch 15/50] [Batch 178/235] [D loss: 1.123772, acc: 83.98%] [G loss: 1.378577]\n",
      "[Epoch 15/50] [Batch 179/235] [D loss: 1.094706, acc: 84.77%] [G loss: 1.164206]\n",
      "[Epoch 15/50] [Batch 180/235] [D loss: 1.146994, acc: 82.81%] [G loss: 1.254707]\n",
      "[Epoch 15/50] [Batch 181/235] [D loss: 1.083121, acc: 85.55%] [G loss: 1.144089]\n",
      "[Epoch 15/50] [Batch 182/235] [D loss: 1.155054, acc: 86.52%] [G loss: 1.146455]\n",
      "[Epoch 15/50] [Batch 183/235] [D loss: 1.089952, acc: 86.13%] [G loss: 1.389799]\n",
      "[Epoch 15/50] [Batch 184/235] [D loss: 1.055876, acc: 85.35%] [G loss: 1.259584]\n",
      "[Epoch 15/50] [Batch 185/235] [D loss: 1.084559, acc: 86.52%] [G loss: 1.121411]\n",
      "[Epoch 15/50] [Batch 186/235] [D loss: 1.084314, acc: 86.91%] [G loss: 1.201025]\n",
      "[Epoch 15/50] [Batch 187/235] [D loss: 1.105562, acc: 84.77%] [G loss: 1.133199]\n",
      "[Epoch 15/50] [Batch 188/235] [D loss: 1.054802, acc: 83.79%] [G loss: 1.159746]\n",
      "[Epoch 15/50] [Batch 189/235] [D loss: 1.090572, acc: 86.13%] [G loss: 1.174734]\n",
      "[Epoch 15/50] [Batch 190/235] [D loss: 1.077621, acc: 84.57%] [G loss: 1.075197]\n",
      "[Epoch 15/50] [Batch 191/235] [D loss: 1.136080, acc: 86.72%] [G loss: 1.216766]\n",
      "[Epoch 15/50] [Batch 192/235] [D loss: 1.127932, acc: 87.30%] [G loss: 1.232106]\n",
      "[Epoch 15/50] [Batch 193/235] [D loss: 1.148504, acc: 85.55%] [G loss: 1.157231]\n",
      "[Epoch 15/50] [Batch 194/235] [D loss: 1.121351, acc: 86.91%] [G loss: 1.249296]\n",
      "[Epoch 15/50] [Batch 195/235] [D loss: 1.142815, acc: 85.55%] [G loss: 1.309331]\n",
      "[Epoch 15/50] [Batch 196/235] [D loss: 1.115816, acc: 87.30%] [G loss: 1.241815]\n",
      "[Epoch 15/50] [Batch 197/235] [D loss: 1.151477, acc: 83.98%] [G loss: 1.066673]\n",
      "[Epoch 15/50] [Batch 198/235] [D loss: 1.159450, acc: 83.79%] [G loss: 1.048427]\n",
      "[Epoch 15/50] [Batch 199/235] [D loss: 1.106256, acc: 86.13%] [G loss: 1.153843]\n",
      "[Epoch 15/50] [Batch 200/235] [D loss: 1.167215, acc: 83.98%] [G loss: 1.201492]\n",
      "[Epoch 15/50] [Batch 201/235] [D loss: 1.106615, acc: 85.55%] [G loss: 1.191210]\n",
      "[Epoch 15/50] [Batch 202/235] [D loss: 1.163751, acc: 83.40%] [G loss: 1.104631]\n",
      "[Epoch 15/50] [Batch 203/235] [D loss: 1.126961, acc: 83.98%] [G loss: 1.177644]\n",
      "[Epoch 15/50] [Batch 204/235] [D loss: 1.093360, acc: 84.57%] [G loss: 1.252687]\n",
      "[Epoch 15/50] [Batch 205/235] [D loss: 1.122156, acc: 83.79%] [G loss: 1.255871]\n",
      "[Epoch 15/50] [Batch 206/235] [D loss: 1.132705, acc: 88.48%] [G loss: 1.242813]\n",
      "[Epoch 15/50] [Batch 207/235] [D loss: 1.082955, acc: 87.30%] [G loss: 1.144063]\n",
      "[Epoch 15/50] [Batch 208/235] [D loss: 1.144328, acc: 82.81%] [G loss: 1.224451]\n",
      "[Epoch 15/50] [Batch 209/235] [D loss: 1.065781, acc: 85.55%] [G loss: 1.226743]\n",
      "[Epoch 15/50] [Batch 210/235] [D loss: 1.094184, acc: 83.98%] [G loss: 1.201175]\n",
      "[Epoch 15/50] [Batch 211/235] [D loss: 1.116314, acc: 86.52%] [G loss: 1.163903]\n",
      "[Epoch 15/50] [Batch 212/235] [D loss: 1.082115, acc: 81.64%] [G loss: 1.246774]\n",
      "[Epoch 15/50] [Batch 213/235] [D loss: 1.106073, acc: 84.77%] [G loss: 1.200900]\n",
      "[Epoch 15/50] [Batch 214/235] [D loss: 1.138113, acc: 83.40%] [G loss: 1.323801]\n",
      "[Epoch 15/50] [Batch 215/235] [D loss: 1.130604, acc: 82.62%] [G loss: 1.130090]\n",
      "[Epoch 15/50] [Batch 216/235] [D loss: 1.105336, acc: 85.55%] [G loss: 1.143392]\n",
      "[Epoch 15/50] [Batch 217/235] [D loss: 1.182389, acc: 81.45%] [G loss: 1.306856]\n",
      "[Epoch 15/50] [Batch 218/235] [D loss: 1.121262, acc: 82.23%] [G loss: 1.295111]\n",
      "[Epoch 15/50] [Batch 219/235] [D loss: 1.062071, acc: 84.18%] [G loss: 1.278887]\n",
      "[Epoch 15/50] [Batch 220/235] [D loss: 1.126729, acc: 84.96%] [G loss: 1.135849]\n",
      "[Epoch 15/50] [Batch 221/235] [D loss: 1.154445, acc: 85.35%] [G loss: 1.130170]\n",
      "[Epoch 15/50] [Batch 222/235] [D loss: 1.137183, acc: 84.77%] [G loss: 1.133312]\n",
      "[Epoch 15/50] [Batch 223/235] [D loss: 1.124936, acc: 86.13%] [G loss: 1.185099]\n",
      "[Epoch 15/50] [Batch 224/235] [D loss: 1.119651, acc: 88.48%] [G loss: 1.174922]\n",
      "[Epoch 15/50] [Batch 225/235] [D loss: 1.101524, acc: 83.98%] [G loss: 1.199151]\n",
      "[Epoch 15/50] [Batch 226/235] [D loss: 1.103719, acc: 84.18%] [G loss: 1.074471]\n",
      "[Epoch 15/50] [Batch 227/235] [D loss: 1.127135, acc: 86.13%] [G loss: 1.163633]\n",
      "[Epoch 15/50] [Batch 228/235] [D loss: 1.124039, acc: 84.77%] [G loss: 1.247250]\n",
      "[Epoch 15/50] [Batch 229/235] [D loss: 1.128599, acc: 86.13%] [G loss: 1.153210]\n",
      "[Epoch 15/50] [Batch 230/235] [D loss: 1.081454, acc: 84.38%] [G loss: 1.214580]\n",
      "[Epoch 15/50] [Batch 231/235] [D loss: 1.142097, acc: 84.18%] [G loss: 1.228204]\n",
      "[Epoch 15/50] [Batch 232/235] [D loss: 1.119554, acc: 84.38%] [G loss: 1.143489]\n",
      "[Epoch 15/50] [Batch 233/235] [D loss: 1.162238, acc: 84.57%] [G loss: 1.190452]\n",
      "[Epoch 15/50] [Batch 234/235] [D loss: 1.163949, acc: 81.25%] [G loss: 1.133310]\n",
      "[Epoch 16/50] [Batch 0/235] [D loss: 1.172623, acc: 85.35%] [G loss: 1.230253]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/50] [Batch 1/235] [D loss: 1.120562, acc: 84.77%] [G loss: 1.162282]\n",
      "[Epoch 16/50] [Batch 2/235] [D loss: 1.092721, acc: 86.52%] [G loss: 1.150699]\n",
      "[Epoch 16/50] [Batch 3/235] [D loss: 1.156506, acc: 84.77%] [G loss: 1.218830]\n",
      "[Epoch 16/50] [Batch 4/235] [D loss: 1.121321, acc: 84.57%] [G loss: 1.294737]\n",
      "[Epoch 16/50] [Batch 5/235] [D loss: 1.057012, acc: 85.74%] [G loss: 1.182490]\n",
      "[Epoch 16/50] [Batch 6/235] [D loss: 1.119642, acc: 83.79%] [G loss: 1.114660]\n",
      "[Epoch 16/50] [Batch 7/235] [D loss: 1.138197, acc: 86.72%] [G loss: 1.098037]\n",
      "[Epoch 16/50] [Batch 8/235] [D loss: 1.092808, acc: 84.38%] [G loss: 1.176925]\n",
      "[Epoch 16/50] [Batch 9/235] [D loss: 1.172785, acc: 82.03%] [G loss: 1.355586]\n",
      "[Epoch 16/50] [Batch 10/235] [D loss: 1.104284, acc: 85.55%] [G loss: 1.190546]\n",
      "[Epoch 16/50] [Batch 11/235] [D loss: 1.196539, acc: 84.57%] [G loss: 1.271296]\n",
      "[Epoch 16/50] [Batch 12/235] [D loss: 1.136360, acc: 84.57%] [G loss: 1.153201]\n",
      "[Epoch 16/50] [Batch 13/235] [D loss: 1.160245, acc: 84.96%] [G loss: 1.070913]\n",
      "[Epoch 16/50] [Batch 14/235] [D loss: 1.173312, acc: 80.66%] [G loss: 1.293169]\n",
      "[Epoch 16/50] [Batch 15/235] [D loss: 1.160585, acc: 86.13%] [G loss: 1.160347]\n",
      "[Epoch 16/50] [Batch 16/235] [D loss: 1.187753, acc: 83.20%] [G loss: 1.043977]\n",
      "[Epoch 16/50] [Batch 17/235] [D loss: 1.052601, acc: 86.33%] [G loss: 1.191563]\n",
      "[Epoch 16/50] [Batch 18/235] [D loss: 1.154794, acc: 83.40%] [G loss: 1.295439]\n",
      "[Epoch 16/50] [Batch 19/235] [D loss: 1.124344, acc: 85.94%] [G loss: 1.281143]\n",
      "[Epoch 16/50] [Batch 20/235] [D loss: 1.149944, acc: 84.77%] [G loss: 1.142993]\n",
      "[Epoch 16/50] [Batch 21/235] [D loss: 1.144550, acc: 86.72%] [G loss: 1.196028]\n",
      "[Epoch 16/50] [Batch 22/235] [D loss: 1.113508, acc: 84.57%] [G loss: 1.180828]\n",
      "[Epoch 16/50] [Batch 23/235] [D loss: 1.131169, acc: 86.13%] [G loss: 1.173740]\n",
      "[Epoch 16/50] [Batch 24/235] [D loss: 1.127649, acc: 81.45%] [G loss: 1.245405]\n",
      "[Epoch 16/50] [Batch 25/235] [D loss: 1.120706, acc: 86.13%] [G loss: 1.166641]\n",
      "[Epoch 16/50] [Batch 26/235] [D loss: 1.111310, acc: 84.38%] [G loss: 1.098196]\n",
      "[Epoch 16/50] [Batch 27/235] [D loss: 1.105269, acc: 86.13%] [G loss: 1.151154]\n",
      "[Epoch 16/50] [Batch 28/235] [D loss: 1.126094, acc: 84.57%] [G loss: 1.215981]\n",
      "[Epoch 16/50] [Batch 29/235] [D loss: 1.114985, acc: 86.33%] [G loss: 1.186465]\n",
      "[Epoch 16/50] [Batch 30/235] [D loss: 1.123304, acc: 86.52%] [G loss: 1.221610]\n",
      "[Epoch 16/50] [Batch 31/235] [D loss: 1.085024, acc: 86.72%] [G loss: 1.184604]\n",
      "[Epoch 16/50] [Batch 32/235] [D loss: 1.140350, acc: 86.13%] [G loss: 1.250327]\n",
      "[Epoch 16/50] [Batch 33/235] [D loss: 1.123279, acc: 86.91%] [G loss: 1.179813]\n",
      "[Epoch 16/50] [Batch 34/235] [D loss: 1.083433, acc: 84.38%] [G loss: 1.104158]\n",
      "[Epoch 16/50] [Batch 35/235] [D loss: 1.075174, acc: 86.13%] [G loss: 1.170828]\n",
      "[Epoch 16/50] [Batch 36/235] [D loss: 1.097929, acc: 84.38%] [G loss: 1.254694]\n",
      "[Epoch 16/50] [Batch 37/235] [D loss: 1.100833, acc: 84.96%] [G loss: 1.217990]\n",
      "[Epoch 16/50] [Batch 38/235] [D loss: 1.112505, acc: 85.94%] [G loss: 1.179065]\n",
      "[Epoch 16/50] [Batch 39/235] [D loss: 1.123888, acc: 86.13%] [G loss: 1.127132]\n",
      "[Epoch 16/50] [Batch 40/235] [D loss: 1.072276, acc: 85.94%] [G loss: 1.182665]\n",
      "[Epoch 16/50] [Batch 41/235] [D loss: 1.099865, acc: 87.50%] [G loss: 1.186422]\n",
      "[Epoch 16/50] [Batch 42/235] [D loss: 1.063261, acc: 86.13%] [G loss: 1.224613]\n",
      "[Epoch 16/50] [Batch 43/235] [D loss: 1.122034, acc: 84.18%] [G loss: 1.200028]\n",
      "[Epoch 16/50] [Batch 44/235] [D loss: 1.074789, acc: 85.94%] [G loss: 1.137928]\n",
      "[Epoch 16/50] [Batch 45/235] [D loss: 1.112002, acc: 86.33%] [G loss: 1.109784]\n",
      "[Epoch 16/50] [Batch 46/235] [D loss: 1.141407, acc: 85.94%] [G loss: 1.086496]\n",
      "[Epoch 16/50] [Batch 47/235] [D loss: 1.167389, acc: 84.38%] [G loss: 1.234477]\n",
      "[Epoch 16/50] [Batch 48/235] [D loss: 1.156740, acc: 84.18%] [G loss: 1.274270]\n",
      "[Epoch 16/50] [Batch 49/235] [D loss: 1.168177, acc: 86.13%] [G loss: 1.121127]\n",
      "[Epoch 16/50] [Batch 50/235] [D loss: 1.114943, acc: 86.52%] [G loss: 1.165965]\n",
      "[Epoch 16/50] [Batch 51/235] [D loss: 1.081822, acc: 84.96%] [G loss: 1.227141]\n",
      "[Epoch 16/50] [Batch 52/235] [D loss: 1.131175, acc: 85.16%] [G loss: 1.256597]\n",
      "[Epoch 16/50] [Batch 53/235] [D loss: 1.095330, acc: 86.52%] [G loss: 1.194437]\n",
      "[Epoch 16/50] [Batch 54/235] [D loss: 1.151610, acc: 84.18%] [G loss: 1.101457]\n",
      "[Epoch 16/50] [Batch 55/235] [D loss: 1.126871, acc: 86.13%] [G loss: 1.209534]\n",
      "[Epoch 16/50] [Batch 56/235] [D loss: 1.139131, acc: 86.33%] [G loss: 1.236998]\n",
      "[Epoch 16/50] [Batch 57/235] [D loss: 1.128714, acc: 86.13%] [G loss: 1.188686]\n",
      "[Epoch 16/50] [Batch 58/235] [D loss: 1.149399, acc: 82.42%] [G loss: 1.273608]\n",
      "[Epoch 16/50] [Batch 59/235] [D loss: 1.114558, acc: 86.33%] [G loss: 1.257331]\n",
      "[Epoch 16/50] [Batch 60/235] [D loss: 1.126055, acc: 84.77%] [G loss: 1.281811]\n",
      "[Epoch 16/50] [Batch 61/235] [D loss: 1.120509, acc: 86.13%] [G loss: 1.268667]\n",
      "[Epoch 16/50] [Batch 62/235] [D loss: 1.065338, acc: 85.55%] [G loss: 1.073401]\n",
      "[Epoch 16/50] [Batch 63/235] [D loss: 1.066291, acc: 85.74%] [G loss: 1.189938]\n",
      "[Epoch 16/50] [Batch 64/235] [D loss: 1.106890, acc: 87.30%] [G loss: 1.230744]\n",
      "[Epoch 16/50] [Batch 65/235] [D loss: 1.086557, acc: 85.74%] [G loss: 1.150526]\n",
      "[Epoch 16/50] [Batch 66/235] [D loss: 1.220372, acc: 83.20%] [G loss: 1.106949]\n",
      "[Epoch 16/50] [Batch 67/235] [D loss: 1.160540, acc: 85.74%] [G loss: 1.286066]\n",
      "[Epoch 16/50] [Batch 68/235] [D loss: 1.087106, acc: 86.33%] [G loss: 1.212205]\n",
      "[Epoch 16/50] [Batch 69/235] [D loss: 1.084098, acc: 86.52%] [G loss: 1.170268]\n",
      "[Epoch 16/50] [Batch 70/235] [D loss: 1.093628, acc: 88.09%] [G loss: 1.263778]\n",
      "[Epoch 16/50] [Batch 71/235] [D loss: 1.114393, acc: 82.62%] [G loss: 1.243154]\n",
      "[Epoch 16/50] [Batch 72/235] [D loss: 1.087019, acc: 88.28%] [G loss: 1.150894]\n",
      "[Epoch 16/50] [Batch 73/235] [D loss: 1.108670, acc: 83.59%] [G loss: 1.150109]\n",
      "[Epoch 16/50] [Batch 74/235] [D loss: 1.145712, acc: 85.74%] [G loss: 1.372697]\n",
      "[Epoch 16/50] [Batch 75/235] [D loss: 1.117829, acc: 86.33%] [G loss: 1.117758]\n",
      "[Epoch 16/50] [Batch 76/235] [D loss: 1.101418, acc: 85.94%] [G loss: 1.197567]\n",
      "[Epoch 16/50] [Batch 77/235] [D loss: 1.122723, acc: 86.13%] [G loss: 1.282962]\n",
      "[Epoch 16/50] [Batch 78/235] [D loss: 1.171819, acc: 84.57%] [G loss: 1.130971]\n",
      "[Epoch 16/50] [Batch 79/235] [D loss: 1.138489, acc: 88.48%] [G loss: 1.183429]\n",
      "[Epoch 16/50] [Batch 80/235] [D loss: 1.072964, acc: 88.28%] [G loss: 1.156005]\n",
      "[Epoch 16/50] [Batch 81/235] [D loss: 1.086286, acc: 86.52%] [G loss: 1.204318]\n",
      "[Epoch 16/50] [Batch 82/235] [D loss: 1.068452, acc: 86.72%] [G loss: 1.296708]\n",
      "[Epoch 16/50] [Batch 83/235] [D loss: 1.120660, acc: 87.11%] [G loss: 1.133031]\n",
      "[Epoch 16/50] [Batch 84/235] [D loss: 1.107893, acc: 86.72%] [G loss: 1.158155]\n",
      "[Epoch 16/50] [Batch 85/235] [D loss: 1.137555, acc: 83.20%] [G loss: 1.214154]\n",
      "[Epoch 16/50] [Batch 86/235] [D loss: 1.089547, acc: 87.50%] [G loss: 1.174009]\n",
      "[Epoch 16/50] [Batch 87/235] [D loss: 1.115023, acc: 84.77%] [G loss: 1.225828]\n",
      "[Epoch 16/50] [Batch 88/235] [D loss: 1.152918, acc: 85.16%] [G loss: 1.300824]\n",
      "[Epoch 16/50] [Batch 89/235] [D loss: 1.099367, acc: 87.11%] [G loss: 1.183270]\n",
      "[Epoch 16/50] [Batch 90/235] [D loss: 1.198199, acc: 85.35%] [G loss: 1.212286]\n",
      "[Epoch 16/50] [Batch 91/235] [D loss: 1.131591, acc: 83.79%] [G loss: 1.213956]\n",
      "[Epoch 16/50] [Batch 92/235] [D loss: 1.128354, acc: 86.72%] [G loss: 1.119280]\n",
      "[Epoch 16/50] [Batch 93/235] [D loss: 1.109807, acc: 84.96%] [G loss: 1.242562]\n",
      "[Epoch 16/50] [Batch 94/235] [D loss: 1.154715, acc: 86.33%] [G loss: 1.268850]\n",
      "[Epoch 16/50] [Batch 95/235] [D loss: 1.124263, acc: 85.16%] [G loss: 1.260267]\n",
      "[Epoch 16/50] [Batch 96/235] [D loss: 1.114394, acc: 84.18%] [G loss: 1.255255]\n",
      "[Epoch 16/50] [Batch 97/235] [D loss: 1.121906, acc: 85.94%] [G loss: 1.078230]\n",
      "[Epoch 16/50] [Batch 98/235] [D loss: 1.151514, acc: 88.67%] [G loss: 1.159790]\n",
      "[Epoch 16/50] [Batch 99/235] [D loss: 1.107228, acc: 85.35%] [G loss: 1.164478]\n",
      "[Epoch 16/50] [Batch 100/235] [D loss: 1.119571, acc: 87.50%] [G loss: 1.160608]\n",
      "[Epoch 16/50] [Batch 101/235] [D loss: 1.072917, acc: 87.70%] [G loss: 1.129776]\n",
      "[Epoch 16/50] [Batch 102/235] [D loss: 1.133924, acc: 87.30%] [G loss: 1.180100]\n",
      "[Epoch 16/50] [Batch 103/235] [D loss: 1.113304, acc: 86.52%] [G loss: 1.201087]\n",
      "[Epoch 16/50] [Batch 104/235] [D loss: 1.103755, acc: 86.72%] [G loss: 1.157517]\n",
      "[Epoch 16/50] [Batch 105/235] [D loss: 1.130490, acc: 83.40%] [G loss: 1.190863]\n",
      "[Epoch 16/50] [Batch 106/235] [D loss: 1.104740, acc: 83.79%] [G loss: 1.194738]\n",
      "[Epoch 16/50] [Batch 107/235] [D loss: 1.142170, acc: 85.16%] [G loss: 1.263342]\n",
      "[Epoch 16/50] [Batch 108/235] [D loss: 1.174147, acc: 83.01%] [G loss: 1.226031]\n",
      "[Epoch 16/50] [Batch 109/235] [D loss: 1.174726, acc: 85.94%] [G loss: 1.218983]\n",
      "[Epoch 16/50] [Batch 110/235] [D loss: 1.084517, acc: 86.52%] [G loss: 1.112033]\n",
      "[Epoch 16/50] [Batch 111/235] [D loss: 1.157495, acc: 82.42%] [G loss: 1.189247]\n",
      "[Epoch 16/50] [Batch 112/235] [D loss: 1.112834, acc: 84.96%] [G loss: 1.143588]\n",
      "[Epoch 16/50] [Batch 113/235] [D loss: 1.178480, acc: 84.38%] [G loss: 1.218003]\n",
      "[Epoch 16/50] [Batch 114/235] [D loss: 1.141893, acc: 83.98%] [G loss: 1.205129]\n",
      "[Epoch 16/50] [Batch 115/235] [D loss: 1.141528, acc: 86.13%] [G loss: 1.294563]\n",
      "[Epoch 16/50] [Batch 116/235] [D loss: 1.071432, acc: 88.87%] [G loss: 1.240702]\n",
      "[Epoch 16/50] [Batch 117/235] [D loss: 1.108242, acc: 88.67%] [G loss: 1.113911]\n",
      "[Epoch 16/50] [Batch 118/235] [D loss: 1.099850, acc: 85.94%] [G loss: 1.247900]\n",
      "[Epoch 16/50] [Batch 119/235] [D loss: 1.099552, acc: 87.70%] [G loss: 1.327755]\n",
      "[Epoch 16/50] [Batch 120/235] [D loss: 1.077369, acc: 86.13%] [G loss: 1.214396]\n",
      "[Epoch 16/50] [Batch 121/235] [D loss: 1.104963, acc: 85.16%] [G loss: 1.130810]\n",
      "[Epoch 16/50] [Batch 122/235] [D loss: 1.169317, acc: 86.52%] [G loss: 1.171815]\n",
      "[Epoch 16/50] [Batch 123/235] [D loss: 1.108557, acc: 83.20%] [G loss: 1.328063]\n",
      "[Epoch 16/50] [Batch 124/235] [D loss: 1.128818, acc: 84.38%] [G loss: 1.094609]\n",
      "[Epoch 16/50] [Batch 125/235] [D loss: 1.133525, acc: 86.13%] [G loss: 1.094319]\n",
      "[Epoch 16/50] [Batch 126/235] [D loss: 1.151822, acc: 83.98%] [G loss: 1.187379]\n",
      "[Epoch 16/50] [Batch 127/235] [D loss: 1.122518, acc: 83.98%] [G loss: 1.090064]\n",
      "[Epoch 16/50] [Batch 128/235] [D loss: 1.154652, acc: 86.13%] [G loss: 1.097328]\n",
      "[Epoch 16/50] [Batch 129/235] [D loss: 1.090355, acc: 86.13%] [G loss: 1.135697]\n",
      "[Epoch 16/50] [Batch 130/235] [D loss: 1.178857, acc: 84.38%] [G loss: 1.212201]\n",
      "[Epoch 16/50] [Batch 131/235] [D loss: 1.100488, acc: 84.96%] [G loss: 1.209028]\n",
      "[Epoch 16/50] [Batch 132/235] [D loss: 1.134950, acc: 83.20%] [G loss: 1.132728]\n",
      "[Epoch 16/50] [Batch 133/235] [D loss: 1.125775, acc: 85.16%] [G loss: 1.204564]\n",
      "[Epoch 16/50] [Batch 134/235] [D loss: 1.117641, acc: 86.52%] [G loss: 1.174241]\n",
      "[Epoch 16/50] [Batch 135/235] [D loss: 1.111168, acc: 83.79%] [G loss: 1.059507]\n",
      "[Epoch 16/50] [Batch 136/235] [D loss: 1.077576, acc: 86.52%] [G loss: 1.393130]\n",
      "[Epoch 16/50] [Batch 137/235] [D loss: 1.128108, acc: 84.57%] [G loss: 1.167029]\n",
      "[Epoch 16/50] [Batch 138/235] [D loss: 1.151367, acc: 84.96%] [G loss: 1.197108]\n",
      "[Epoch 16/50] [Batch 139/235] [D loss: 1.141166, acc: 83.40%] [G loss: 1.232813]\n",
      "[Epoch 16/50] [Batch 140/235] [D loss: 1.111340, acc: 86.33%] [G loss: 1.048645]\n",
      "[Epoch 16/50] [Batch 141/235] [D loss: 1.148814, acc: 85.35%] [G loss: 1.132294]\n",
      "[Epoch 16/50] [Batch 142/235] [D loss: 1.127113, acc: 84.96%] [G loss: 1.216465]\n",
      "[Epoch 16/50] [Batch 143/235] [D loss: 1.116715, acc: 85.74%] [G loss: 1.229400]\n",
      "[Epoch 16/50] [Batch 144/235] [D loss: 1.084682, acc: 85.35%] [G loss: 1.209200]\n",
      "[Epoch 16/50] [Batch 145/235] [D loss: 1.101160, acc: 87.89%] [G loss: 1.232713]\n",
      "[Epoch 16/50] [Batch 146/235] [D loss: 1.150359, acc: 81.84%] [G loss: 1.187027]\n",
      "[Epoch 16/50] [Batch 147/235] [D loss: 1.112373, acc: 90.04%] [G loss: 1.218831]\n",
      "[Epoch 16/50] [Batch 148/235] [D loss: 1.140982, acc: 83.01%] [G loss: 1.157194]\n",
      "[Epoch 16/50] [Batch 149/235] [D loss: 1.158291, acc: 85.55%] [G loss: 1.090145]\n",
      "[Epoch 16/50] [Batch 150/235] [D loss: 1.091214, acc: 84.38%] [G loss: 1.270970]\n",
      "[Epoch 16/50] [Batch 151/235] [D loss: 1.093462, acc: 84.18%] [G loss: 1.167842]\n",
      "[Epoch 16/50] [Batch 152/235] [D loss: 1.123803, acc: 84.77%] [G loss: 1.160348]\n",
      "[Epoch 16/50] [Batch 153/235] [D loss: 1.116651, acc: 86.52%] [G loss: 1.188351]\n",
      "[Epoch 16/50] [Batch 154/235] [D loss: 1.073070, acc: 87.70%] [G loss: 1.132666]\n",
      "[Epoch 16/50] [Batch 155/235] [D loss: 1.110321, acc: 86.72%] [G loss: 1.165929]\n",
      "[Epoch 16/50] [Batch 156/235] [D loss: 1.161454, acc: 86.52%] [G loss: 1.177454]\n",
      "[Epoch 16/50] [Batch 157/235] [D loss: 1.120389, acc: 84.38%] [G loss: 1.220059]\n",
      "[Epoch 16/50] [Batch 158/235] [D loss: 1.069630, acc: 85.94%] [G loss: 1.244387]\n",
      "[Epoch 16/50] [Batch 159/235] [D loss: 1.070078, acc: 84.77%] [G loss: 1.137061]\n",
      "[Epoch 16/50] [Batch 160/235] [D loss: 1.155661, acc: 81.84%] [G loss: 1.150386]\n",
      "[Epoch 16/50] [Batch 161/235] [D loss: 1.081249, acc: 89.26%] [G loss: 1.107681]\n",
      "[Epoch 16/50] [Batch 162/235] [D loss: 1.123640, acc: 87.50%] [G loss: 1.147551]\n",
      "[Epoch 16/50] [Batch 163/235] [D loss: 1.103526, acc: 84.18%] [G loss: 1.212451]\n",
      "[Epoch 16/50] [Batch 164/235] [D loss: 1.175398, acc: 83.79%] [G loss: 1.306145]\n",
      "[Epoch 16/50] [Batch 165/235] [D loss: 1.120750, acc: 84.77%] [G loss: 1.164215]\n",
      "[Epoch 16/50] [Batch 166/235] [D loss: 1.160673, acc: 86.33%] [G loss: 1.080423]\n",
      "[Epoch 16/50] [Batch 167/235] [D loss: 1.135132, acc: 84.96%] [G loss: 1.220114]\n",
      "[Epoch 16/50] [Batch 168/235] [D loss: 1.091565, acc: 87.11%] [G loss: 1.147522]\n",
      "[Epoch 16/50] [Batch 169/235] [D loss: 1.134506, acc: 84.77%] [G loss: 1.173891]\n",
      "[Epoch 16/50] [Batch 170/235] [D loss: 1.161512, acc: 82.81%] [G loss: 1.275876]\n",
      "[Epoch 16/50] [Batch 171/235] [D loss: 1.127987, acc: 83.40%] [G loss: 1.111533]\n",
      "[Epoch 16/50] [Batch 172/235] [D loss: 1.090342, acc: 87.30%] [G loss: 1.134055]\n",
      "[Epoch 16/50] [Batch 173/235] [D loss: 1.200615, acc: 83.20%] [G loss: 1.343687]\n",
      "[Epoch 16/50] [Batch 174/235] [D loss: 1.130143, acc: 85.74%] [G loss: 1.170258]\n",
      "[Epoch 16/50] [Batch 175/235] [D loss: 1.128334, acc: 86.33%] [G loss: 1.111700]\n",
      "[Epoch 16/50] [Batch 176/235] [D loss: 1.131865, acc: 85.94%] [G loss: 1.319185]\n",
      "[Epoch 16/50] [Batch 177/235] [D loss: 1.146301, acc: 84.57%] [G loss: 1.190920]\n",
      "[Epoch 16/50] [Batch 178/235] [D loss: 1.104265, acc: 88.48%] [G loss: 1.149049]\n",
      "[Epoch 16/50] [Batch 179/235] [D loss: 1.082337, acc: 86.52%] [G loss: 1.131532]\n",
      "[Epoch 16/50] [Batch 180/235] [D loss: 1.162011, acc: 86.72%] [G loss: 1.189837]\n",
      "[Epoch 16/50] [Batch 181/235] [D loss: 1.164105, acc: 83.79%] [G loss: 1.317314]\n",
      "[Epoch 16/50] [Batch 182/235] [D loss: 1.109309, acc: 84.77%] [G loss: 1.219109]\n",
      "[Epoch 16/50] [Batch 183/235] [D loss: 1.141288, acc: 81.45%] [G loss: 1.156790]\n",
      "[Epoch 16/50] [Batch 184/235] [D loss: 1.096618, acc: 84.96%] [G loss: 1.228002]\n",
      "[Epoch 16/50] [Batch 185/235] [D loss: 1.136992, acc: 85.55%] [G loss: 1.162313]\n",
      "[Epoch 16/50] [Batch 186/235] [D loss: 1.126665, acc: 85.35%] [G loss: 1.122006]\n",
      "[Epoch 16/50] [Batch 187/235] [D loss: 1.125064, acc: 83.79%] [G loss: 1.176735]\n",
      "[Epoch 16/50] [Batch 188/235] [D loss: 1.112488, acc: 85.16%] [G loss: 1.134467]\n",
      "[Epoch 16/50] [Batch 189/235] [D loss: 1.148051, acc: 85.94%] [G loss: 1.126237]\n",
      "[Epoch 16/50] [Batch 190/235] [D loss: 1.165361, acc: 86.33%] [G loss: 1.145123]\n",
      "[Epoch 16/50] [Batch 191/235] [D loss: 1.095120, acc: 88.48%] [G loss: 1.311647]\n",
      "[Epoch 16/50] [Batch 192/235] [D loss: 1.156761, acc: 86.33%] [G loss: 1.235544]\n",
      "[Epoch 16/50] [Batch 193/235] [D loss: 1.148725, acc: 86.13%] [G loss: 1.122711]\n",
      "[Epoch 16/50] [Batch 194/235] [D loss: 1.062038, acc: 85.16%] [G loss: 1.109246]\n",
      "[Epoch 16/50] [Batch 195/235] [D loss: 1.085818, acc: 86.72%] [G loss: 1.221258]\n",
      "[Epoch 16/50] [Batch 196/235] [D loss: 1.137808, acc: 84.77%] [G loss: 1.262321]\n",
      "[Epoch 16/50] [Batch 197/235] [D loss: 1.084457, acc: 83.98%] [G loss: 1.086843]\n",
      "[Epoch 16/50] [Batch 198/235] [D loss: 1.088923, acc: 84.57%] [G loss: 1.127603]\n",
      "[Epoch 16/50] [Batch 199/235] [D loss: 1.074502, acc: 84.38%] [G loss: 1.249523]\n",
      "[Epoch 16/50] [Batch 200/235] [D loss: 1.091333, acc: 86.91%] [G loss: 1.125534]\n",
      "[Epoch 16/50] [Batch 201/235] [D loss: 1.138944, acc: 86.52%] [G loss: 1.307174]\n",
      "[Epoch 16/50] [Batch 202/235] [D loss: 1.070483, acc: 86.72%] [G loss: 1.184951]\n",
      "[Epoch 16/50] [Batch 203/235] [D loss: 1.074492, acc: 87.70%] [G loss: 1.133643]\n",
      "[Epoch 16/50] [Batch 204/235] [D loss: 1.120374, acc: 84.57%] [G loss: 1.193498]\n",
      "[Epoch 16/50] [Batch 205/235] [D loss: 1.162308, acc: 87.11%] [G loss: 1.120917]\n",
      "[Epoch 16/50] [Batch 206/235] [D loss: 1.102636, acc: 87.30%] [G loss: 1.274462]\n",
      "[Epoch 16/50] [Batch 207/235] [D loss: 1.092990, acc: 84.18%] [G loss: 1.188946]\n",
      "[Epoch 16/50] [Batch 208/235] [D loss: 1.075588, acc: 84.38%] [G loss: 1.151917]\n",
      "[Epoch 16/50] [Batch 209/235] [D loss: 1.154218, acc: 87.11%] [G loss: 1.143907]\n",
      "[Epoch 16/50] [Batch 210/235] [D loss: 1.132784, acc: 85.94%] [G loss: 1.056182]\n",
      "[Epoch 16/50] [Batch 211/235] [D loss: 1.114634, acc: 85.16%] [G loss: 1.289817]\n",
      "[Epoch 16/50] [Batch 212/235] [D loss: 1.123143, acc: 85.74%] [G loss: 1.095486]\n",
      "[Epoch 16/50] [Batch 213/235] [D loss: 1.132892, acc: 86.52%] [G loss: 1.115273]\n",
      "[Epoch 16/50] [Batch 214/235] [D loss: 1.122783, acc: 83.20%] [G loss: 1.147617]\n",
      "[Epoch 16/50] [Batch 215/235] [D loss: 1.114146, acc: 85.16%] [G loss: 1.275061]\n",
      "[Epoch 16/50] [Batch 216/235] [D loss: 1.147295, acc: 84.18%] [G loss: 1.273164]\n",
      "[Epoch 16/50] [Batch 217/235] [D loss: 1.140545, acc: 84.77%] [G loss: 1.164686]\n",
      "[Epoch 16/50] [Batch 218/235] [D loss: 1.104384, acc: 86.13%] [G loss: 1.127370]\n",
      "[Epoch 16/50] [Batch 219/235] [D loss: 1.086187, acc: 86.72%] [G loss: 1.142872]\n",
      "[Epoch 16/50] [Batch 220/235] [D loss: 1.118034, acc: 84.18%] [G loss: 1.192340]\n",
      "[Epoch 16/50] [Batch 221/235] [D loss: 1.119111, acc: 83.98%] [G loss: 1.322143]\n",
      "[Epoch 16/50] [Batch 222/235] [D loss: 1.135670, acc: 86.52%] [G loss: 1.234551]\n",
      "[Epoch 16/50] [Batch 223/235] [D loss: 1.111295, acc: 81.45%] [G loss: 1.301898]\n",
      "[Epoch 16/50] [Batch 224/235] [D loss: 1.124757, acc: 84.77%] [G loss: 1.144225]\n",
      "[Epoch 16/50] [Batch 225/235] [D loss: 1.090089, acc: 85.55%] [G loss: 1.166049]\n",
      "[Epoch 16/50] [Batch 226/235] [D loss: 1.121996, acc: 84.38%] [G loss: 1.140268]\n",
      "[Epoch 16/50] [Batch 227/235] [D loss: 1.099293, acc: 84.57%] [G loss: 1.137676]\n",
      "[Epoch 16/50] [Batch 228/235] [D loss: 1.108991, acc: 85.16%] [G loss: 1.186658]\n",
      "[Epoch 16/50] [Batch 229/235] [D loss: 1.097398, acc: 85.16%] [G loss: 1.099605]\n",
      "[Epoch 16/50] [Batch 230/235] [D loss: 1.127837, acc: 86.52%] [G loss: 1.267179]\n",
      "[Epoch 16/50] [Batch 231/235] [D loss: 1.151196, acc: 80.66%] [G loss: 1.198792]\n",
      "[Epoch 16/50] [Batch 232/235] [D loss: 1.088323, acc: 84.96%] [G loss: 1.192493]\n",
      "[Epoch 16/50] [Batch 233/235] [D loss: 1.077185, acc: 88.28%] [G loss: 1.109167]\n",
      "[Epoch 16/50] [Batch 234/235] [D loss: 1.048834, acc: 88.54%] [G loss: 1.046106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/50] [Batch 0/235] [D loss: 1.089645, acc: 82.81%] [G loss: 1.161296]\n",
      "[Epoch 17/50] [Batch 1/235] [D loss: 1.146851, acc: 81.64%] [G loss: 1.145574]\n",
      "[Epoch 17/50] [Batch 2/235] [D loss: 1.125959, acc: 81.45%] [G loss: 1.359841]\n",
      "[Epoch 17/50] [Batch 3/235] [D loss: 1.129366, acc: 84.38%] [G loss: 1.245072]\n",
      "[Epoch 17/50] [Batch 4/235] [D loss: 1.192281, acc: 84.18%] [G loss: 1.066347]\n",
      "[Epoch 17/50] [Batch 5/235] [D loss: 1.106035, acc: 84.18%] [G loss: 1.247633]\n",
      "[Epoch 17/50] [Batch 6/235] [D loss: 1.122439, acc: 86.91%] [G loss: 1.215345]\n",
      "[Epoch 17/50] [Batch 7/235] [D loss: 1.126276, acc: 84.77%] [G loss: 1.098641]\n",
      "[Epoch 17/50] [Batch 8/235] [D loss: 1.130964, acc: 84.38%] [G loss: 1.179119]\n",
      "[Epoch 17/50] [Batch 9/235] [D loss: 1.108695, acc: 85.35%] [G loss: 1.144945]\n",
      "[Epoch 17/50] [Batch 10/235] [D loss: 1.160754, acc: 87.30%] [G loss: 1.278375]\n",
      "[Epoch 17/50] [Batch 11/235] [D loss: 1.126827, acc: 84.96%] [G loss: 1.115966]\n",
      "[Epoch 17/50] [Batch 12/235] [D loss: 1.121319, acc: 85.35%] [G loss: 1.209740]\n",
      "[Epoch 17/50] [Batch 13/235] [D loss: 1.148498, acc: 85.35%] [G loss: 1.131120]\n",
      "[Epoch 17/50] [Batch 14/235] [D loss: 1.177360, acc: 88.48%] [G loss: 1.229901]\n",
      "[Epoch 17/50] [Batch 15/235] [D loss: 1.157795, acc: 84.96%] [G loss: 1.167603]\n",
      "[Epoch 17/50] [Batch 16/235] [D loss: 1.082545, acc: 85.94%] [G loss: 1.109273]\n",
      "[Epoch 17/50] [Batch 17/235] [D loss: 1.068385, acc: 85.35%] [G loss: 1.208586]\n",
      "[Epoch 17/50] [Batch 18/235] [D loss: 1.087121, acc: 84.57%] [G loss: 1.100751]\n",
      "[Epoch 17/50] [Batch 19/235] [D loss: 1.130544, acc: 88.48%] [G loss: 1.224865]\n",
      "[Epoch 17/50] [Batch 20/235] [D loss: 1.163089, acc: 83.01%] [G loss: 1.295272]\n",
      "[Epoch 17/50] [Batch 21/235] [D loss: 1.077578, acc: 86.13%] [G loss: 1.170081]\n",
      "[Epoch 17/50] [Batch 22/235] [D loss: 1.147646, acc: 86.33%] [G loss: 1.117191]\n",
      "[Epoch 17/50] [Batch 23/235] [D loss: 1.167591, acc: 83.40%] [G loss: 1.255469]\n",
      "[Epoch 17/50] [Batch 24/235] [D loss: 1.099866, acc: 85.74%] [G loss: 1.329815]\n",
      "[Epoch 17/50] [Batch 25/235] [D loss: 1.108279, acc: 86.91%] [G loss: 1.098134]\n",
      "[Epoch 17/50] [Batch 26/235] [D loss: 1.133030, acc: 86.13%] [G loss: 1.113862]\n",
      "[Epoch 17/50] [Batch 27/235] [D loss: 1.111305, acc: 85.94%] [G loss: 1.202217]\n",
      "[Epoch 17/50] [Batch 28/235] [D loss: 1.135530, acc: 85.35%] [G loss: 1.247845]\n",
      "[Epoch 17/50] [Batch 29/235] [D loss: 1.110427, acc: 86.33%] [G loss: 1.257101]\n",
      "[Epoch 17/50] [Batch 30/235] [D loss: 1.098098, acc: 83.20%] [G loss: 1.229839]\n",
      "[Epoch 17/50] [Batch 31/235] [D loss: 1.121081, acc: 86.33%] [G loss: 1.155393]\n",
      "[Epoch 17/50] [Batch 32/235] [D loss: 1.096250, acc: 87.50%] [G loss: 1.223702]\n",
      "[Epoch 17/50] [Batch 33/235] [D loss: 1.143636, acc: 83.40%] [G loss: 1.058950]\n",
      "[Epoch 17/50] [Batch 34/235] [D loss: 1.165695, acc: 85.35%] [G loss: 1.082191]\n",
      "[Epoch 17/50] [Batch 35/235] [D loss: 1.054068, acc: 84.38%] [G loss: 1.242112]\n",
      "[Epoch 17/50] [Batch 36/235] [D loss: 1.124350, acc: 86.33%] [G loss: 1.189083]\n",
      "[Epoch 17/50] [Batch 37/235] [D loss: 1.097000, acc: 88.67%] [G loss: 1.135586]\n",
      "[Epoch 17/50] [Batch 38/235] [D loss: 1.197033, acc: 84.57%] [G loss: 1.218445]\n",
      "[Epoch 17/50] [Batch 39/235] [D loss: 1.082456, acc: 85.35%] [G loss: 1.207755]\n",
      "[Epoch 17/50] [Batch 40/235] [D loss: 1.113137, acc: 84.77%] [G loss: 1.376131]\n",
      "[Epoch 17/50] [Batch 41/235] [D loss: 1.068108, acc: 84.18%] [G loss: 1.130358]\n",
      "[Epoch 17/50] [Batch 42/235] [D loss: 1.108369, acc: 84.96%] [G loss: 1.149359]\n",
      "[Epoch 17/50] [Batch 43/235] [D loss: 1.147886, acc: 83.20%] [G loss: 1.242944]\n",
      "[Epoch 17/50] [Batch 44/235] [D loss: 1.119395, acc: 85.16%] [G loss: 1.170687]\n",
      "[Epoch 17/50] [Batch 45/235] [D loss: 1.099360, acc: 85.94%] [G loss: 1.246353]\n",
      "[Epoch 17/50] [Batch 46/235] [D loss: 1.107085, acc: 85.94%] [G loss: 1.288228]\n",
      "[Epoch 17/50] [Batch 47/235] [D loss: 1.065996, acc: 86.72%] [G loss: 1.189291]\n",
      "[Epoch 17/50] [Batch 48/235] [D loss: 1.124907, acc: 84.77%] [G loss: 1.174636]\n",
      "[Epoch 17/50] [Batch 49/235] [D loss: 1.133489, acc: 85.94%] [G loss: 1.256157]\n",
      "[Epoch 17/50] [Batch 50/235] [D loss: 1.144659, acc: 83.79%] [G loss: 1.263288]\n",
      "[Epoch 17/50] [Batch 51/235] [D loss: 1.086716, acc: 87.70%] [G loss: 1.188766]\n",
      "[Epoch 17/50] [Batch 52/235] [D loss: 1.116009, acc: 86.91%] [G loss: 1.102080]\n",
      "[Epoch 17/50] [Batch 53/235] [D loss: 1.109976, acc: 84.38%] [G loss: 1.121007]\n",
      "[Epoch 17/50] [Batch 54/235] [D loss: 1.054303, acc: 88.09%] [G loss: 1.227227]\n",
      "[Epoch 17/50] [Batch 55/235] [D loss: 1.092098, acc: 84.96%] [G loss: 1.301957]\n",
      "[Epoch 17/50] [Batch 56/235] [D loss: 1.063826, acc: 87.30%] [G loss: 1.149001]\n",
      "[Epoch 17/50] [Batch 57/235] [D loss: 1.120273, acc: 84.18%] [G loss: 1.191453]\n",
      "[Epoch 17/50] [Batch 58/235] [D loss: 1.144402, acc: 83.01%] [G loss: 1.108386]\n",
      "[Epoch 17/50] [Batch 59/235] [D loss: 1.137172, acc: 83.20%] [G loss: 1.147696]\n",
      "[Epoch 17/50] [Batch 60/235] [D loss: 1.153016, acc: 85.94%] [G loss: 1.226681]\n",
      "[Epoch 17/50] [Batch 61/235] [D loss: 1.154185, acc: 85.55%] [G loss: 1.105011]\n",
      "[Epoch 17/50] [Batch 62/235] [D loss: 1.189105, acc: 84.96%] [G loss: 1.124855]\n",
      "[Epoch 17/50] [Batch 63/235] [D loss: 1.147125, acc: 84.57%] [G loss: 1.007484]\n",
      "[Epoch 17/50] [Batch 64/235] [D loss: 1.119187, acc: 84.18%] [G loss: 1.209465]\n",
      "[Epoch 17/50] [Batch 65/235] [D loss: 1.159531, acc: 84.96%] [G loss: 1.211067]\n",
      "[Epoch 17/50] [Batch 66/235] [D loss: 1.139122, acc: 84.77%] [G loss: 1.185066]\n",
      "[Epoch 17/50] [Batch 67/235] [D loss: 1.120404, acc: 83.98%] [G loss: 1.115732]\n",
      "[Epoch 17/50] [Batch 68/235] [D loss: 1.147420, acc: 84.38%] [G loss: 1.207183]\n",
      "[Epoch 17/50] [Batch 69/235] [D loss: 1.153984, acc: 84.38%] [G loss: 1.247810]\n",
      "[Epoch 17/50] [Batch 70/235] [D loss: 1.112390, acc: 85.74%] [G loss: 1.163245]\n",
      "[Epoch 17/50] [Batch 71/235] [D loss: 1.155753, acc: 85.16%] [G loss: 1.186182]\n",
      "[Epoch 17/50] [Batch 72/235] [D loss: 1.123087, acc: 87.30%] [G loss: 1.116528]\n",
      "[Epoch 17/50] [Batch 73/235] [D loss: 1.159353, acc: 84.77%] [G loss: 1.198615]\n",
      "[Epoch 17/50] [Batch 74/235] [D loss: 1.159899, acc: 84.77%] [G loss: 1.197507]\n",
      "[Epoch 17/50] [Batch 75/235] [D loss: 1.097480, acc: 83.20%] [G loss: 1.092302]\n",
      "[Epoch 17/50] [Batch 76/235] [D loss: 1.145334, acc: 83.79%] [G loss: 1.148874]\n",
      "[Epoch 17/50] [Batch 77/235] [D loss: 1.069492, acc: 86.52%] [G loss: 1.292088]\n",
      "[Epoch 17/50] [Batch 78/235] [D loss: 1.118470, acc: 84.18%] [G loss: 1.222754]\n",
      "[Epoch 17/50] [Batch 79/235] [D loss: 1.107163, acc: 84.18%] [G loss: 1.212308]\n",
      "[Epoch 17/50] [Batch 80/235] [D loss: 1.147536, acc: 88.09%] [G loss: 1.212855]\n",
      "[Epoch 17/50] [Batch 81/235] [D loss: 1.112669, acc: 86.91%] [G loss: 1.140584]\n",
      "[Epoch 17/50] [Batch 82/235] [D loss: 1.117755, acc: 88.67%] [G loss: 1.038683]\n",
      "[Epoch 17/50] [Batch 83/235] [D loss: 1.179250, acc: 83.40%] [G loss: 1.215744]\n",
      "[Epoch 17/50] [Batch 84/235] [D loss: 1.097556, acc: 87.11%] [G loss: 1.229167]\n",
      "[Epoch 17/50] [Batch 85/235] [D loss: 1.136798, acc: 88.48%] [G loss: 1.102255]\n",
      "[Epoch 17/50] [Batch 86/235] [D loss: 1.126631, acc: 84.38%] [G loss: 1.109762]\n",
      "[Epoch 17/50] [Batch 87/235] [D loss: 1.146897, acc: 82.23%] [G loss: 1.185110]\n",
      "[Epoch 17/50] [Batch 88/235] [D loss: 1.097160, acc: 86.52%] [G loss: 1.263511]\n",
      "[Epoch 17/50] [Batch 89/235] [D loss: 1.095254, acc: 84.96%] [G loss: 1.142599]\n",
      "[Epoch 17/50] [Batch 90/235] [D loss: 1.145987, acc: 85.35%] [G loss: 1.180397]\n",
      "[Epoch 17/50] [Batch 91/235] [D loss: 1.154890, acc: 84.18%] [G loss: 1.223397]\n",
      "[Epoch 17/50] [Batch 92/235] [D loss: 1.131588, acc: 85.55%] [G loss: 1.184363]\n",
      "[Epoch 17/50] [Batch 93/235] [D loss: 1.097609, acc: 87.70%] [G loss: 1.226506]\n",
      "[Epoch 17/50] [Batch 94/235] [D loss: 1.100535, acc: 84.57%] [G loss: 1.219493]\n",
      "[Epoch 17/50] [Batch 95/235] [D loss: 1.133904, acc: 85.94%] [G loss: 1.072130]\n",
      "[Epoch 17/50] [Batch 96/235] [D loss: 1.071058, acc: 87.50%] [G loss: 1.220351]\n",
      "[Epoch 17/50] [Batch 97/235] [D loss: 1.145808, acc: 86.13%] [G loss: 1.095226]\n",
      "[Epoch 17/50] [Batch 98/235] [D loss: 1.097820, acc: 84.57%] [G loss: 1.129338]\n",
      "[Epoch 17/50] [Batch 99/235] [D loss: 1.115451, acc: 86.52%] [G loss: 1.056299]\n",
      "[Epoch 17/50] [Batch 100/235] [D loss: 1.129800, acc: 87.50%] [G loss: 1.164510]\n",
      "[Epoch 17/50] [Batch 101/235] [D loss: 1.131932, acc: 83.98%] [G loss: 1.158741]\n",
      "[Epoch 17/50] [Batch 102/235] [D loss: 1.157783, acc: 85.74%] [G loss: 1.086561]\n",
      "[Epoch 17/50] [Batch 103/235] [D loss: 1.138893, acc: 82.62%] [G loss: 1.254506]\n",
      "[Epoch 17/50] [Batch 104/235] [D loss: 1.188617, acc: 83.20%] [G loss: 1.130713]\n",
      "[Epoch 17/50] [Batch 105/235] [D loss: 1.104433, acc: 86.91%] [G loss: 1.178016]\n",
      "[Epoch 17/50] [Batch 106/235] [D loss: 1.116073, acc: 85.74%] [G loss: 1.228516]\n",
      "[Epoch 17/50] [Batch 107/235] [D loss: 1.117073, acc: 85.74%] [G loss: 1.148135]\n",
      "[Epoch 17/50] [Batch 108/235] [D loss: 1.116148, acc: 85.35%] [G loss: 1.057630]\n",
      "[Epoch 17/50] [Batch 109/235] [D loss: 1.158051, acc: 85.94%] [G loss: 1.080290]\n",
      "[Epoch 17/50] [Batch 110/235] [D loss: 1.088290, acc: 86.52%] [G loss: 1.209054]\n",
      "[Epoch 17/50] [Batch 111/235] [D loss: 1.088544, acc: 85.94%] [G loss: 1.263908]\n",
      "[Epoch 17/50] [Batch 112/235] [D loss: 1.087198, acc: 86.72%] [G loss: 1.050652]\n",
      "[Epoch 17/50] [Batch 113/235] [D loss: 1.157766, acc: 87.30%] [G loss: 1.129674]\n",
      "[Epoch 17/50] [Batch 114/235] [D loss: 1.108138, acc: 88.87%] [G loss: 1.126587]\n",
      "[Epoch 17/50] [Batch 115/235] [D loss: 1.075734, acc: 85.74%] [G loss: 1.386062]\n",
      "[Epoch 17/50] [Batch 116/235] [D loss: 1.118044, acc: 85.74%] [G loss: 1.242031]\n",
      "[Epoch 17/50] [Batch 117/235] [D loss: 1.105335, acc: 86.72%] [G loss: 1.082711]\n",
      "[Epoch 17/50] [Batch 118/235] [D loss: 1.143896, acc: 85.74%] [G loss: 1.220129]\n",
      "[Epoch 17/50] [Batch 119/235] [D loss: 1.087555, acc: 86.33%] [G loss: 1.151733]\n",
      "[Epoch 17/50] [Batch 120/235] [D loss: 1.076761, acc: 86.33%] [G loss: 1.293325]\n",
      "[Epoch 17/50] [Batch 121/235] [D loss: 1.147047, acc: 86.72%] [G loss: 1.332295]\n",
      "[Epoch 17/50] [Batch 122/235] [D loss: 1.104999, acc: 83.40%] [G loss: 1.188847]\n",
      "[Epoch 17/50] [Batch 123/235] [D loss: 1.106703, acc: 86.13%] [G loss: 1.015140]\n",
      "[Epoch 17/50] [Batch 124/235] [D loss: 1.070139, acc: 86.91%] [G loss: 1.129035]\n",
      "[Epoch 17/50] [Batch 125/235] [D loss: 1.106802, acc: 87.30%] [G loss: 1.145540]\n",
      "[Epoch 17/50] [Batch 126/235] [D loss: 1.083186, acc: 87.11%] [G loss: 1.268139]\n",
      "[Epoch 17/50] [Batch 127/235] [D loss: 1.110159, acc: 84.77%] [G loss: 1.196112]\n",
      "[Epoch 17/50] [Batch 128/235] [D loss: 1.120861, acc: 87.11%] [G loss: 1.183958]\n",
      "[Epoch 17/50] [Batch 129/235] [D loss: 1.149398, acc: 83.98%] [G loss: 1.266700]\n",
      "[Epoch 17/50] [Batch 130/235] [D loss: 1.150106, acc: 84.96%] [G loss: 1.157043]\n",
      "[Epoch 17/50] [Batch 131/235] [D loss: 1.213840, acc: 83.79%] [G loss: 1.193232]\n",
      "[Epoch 17/50] [Batch 132/235] [D loss: 1.155115, acc: 87.30%] [G loss: 1.197343]\n",
      "[Epoch 17/50] [Batch 133/235] [D loss: 1.084266, acc: 87.30%] [G loss: 1.154192]\n",
      "[Epoch 17/50] [Batch 134/235] [D loss: 1.121293, acc: 83.40%] [G loss: 1.214700]\n",
      "[Epoch 17/50] [Batch 135/235] [D loss: 1.120957, acc: 84.38%] [G loss: 1.206676]\n",
      "[Epoch 17/50] [Batch 136/235] [D loss: 1.127227, acc: 85.55%] [G loss: 1.175208]\n",
      "[Epoch 17/50] [Batch 137/235] [D loss: 1.129525, acc: 83.20%] [G loss: 1.133929]\n",
      "[Epoch 17/50] [Batch 138/235] [D loss: 1.096995, acc: 85.94%] [G loss: 1.332645]\n",
      "[Epoch 17/50] [Batch 139/235] [D loss: 1.108592, acc: 84.77%] [G loss: 1.040044]\n",
      "[Epoch 17/50] [Batch 140/235] [D loss: 1.112847, acc: 82.42%] [G loss: 1.360959]\n",
      "[Epoch 17/50] [Batch 141/235] [D loss: 1.110152, acc: 86.33%] [G loss: 1.164709]\n",
      "[Epoch 17/50] [Batch 142/235] [D loss: 1.131602, acc: 85.55%] [G loss: 1.115430]\n",
      "[Epoch 17/50] [Batch 143/235] [D loss: 1.157155, acc: 86.33%] [G loss: 1.332354]\n",
      "[Epoch 17/50] [Batch 144/235] [D loss: 1.141893, acc: 86.91%] [G loss: 1.207253]\n",
      "[Epoch 17/50] [Batch 145/235] [D loss: 1.139306, acc: 85.74%] [G loss: 1.077303]\n",
      "[Epoch 17/50] [Batch 146/235] [D loss: 1.028192, acc: 85.74%] [G loss: 1.333071]\n",
      "[Epoch 17/50] [Batch 147/235] [D loss: 1.103103, acc: 87.70%] [G loss: 1.261444]\n",
      "[Epoch 17/50] [Batch 148/235] [D loss: 1.080974, acc: 85.94%] [G loss: 1.196419]\n",
      "[Epoch 17/50] [Batch 149/235] [D loss: 1.161470, acc: 83.01%] [G loss: 1.199152]\n",
      "[Epoch 17/50] [Batch 150/235] [D loss: 1.122878, acc: 83.01%] [G loss: 1.209371]\n",
      "[Epoch 17/50] [Batch 151/235] [D loss: 1.134907, acc: 82.23%] [G loss: 1.151707]\n",
      "[Epoch 17/50] [Batch 152/235] [D loss: 1.171622, acc: 84.38%] [G loss: 1.174341]\n",
      "[Epoch 17/50] [Batch 153/235] [D loss: 1.093217, acc: 88.09%] [G loss: 1.188428]\n",
      "[Epoch 17/50] [Batch 154/235] [D loss: 1.112937, acc: 84.57%] [G loss: 1.246470]\n",
      "[Epoch 17/50] [Batch 155/235] [D loss: 1.156619, acc: 83.98%] [G loss: 1.253003]\n",
      "[Epoch 17/50] [Batch 156/235] [D loss: 1.136504, acc: 86.72%] [G loss: 1.057060]\n",
      "[Epoch 17/50] [Batch 157/235] [D loss: 1.109147, acc: 84.57%] [G loss: 1.220757]\n",
      "[Epoch 17/50] [Batch 158/235] [D loss: 1.141826, acc: 85.55%] [G loss: 1.274781]\n",
      "[Epoch 17/50] [Batch 159/235] [D loss: 1.075712, acc: 86.72%] [G loss: 1.174858]\n",
      "[Epoch 17/50] [Batch 160/235] [D loss: 1.096846, acc: 88.09%] [G loss: 1.103185]\n",
      "[Epoch 17/50] [Batch 161/235] [D loss: 1.124602, acc: 85.74%] [G loss: 1.084407]\n",
      "[Epoch 17/50] [Batch 162/235] [D loss: 1.141344, acc: 85.55%] [G loss: 1.202105]\n",
      "[Epoch 17/50] [Batch 163/235] [D loss: 1.184163, acc: 83.01%] [G loss: 1.191821]\n",
      "[Epoch 17/50] [Batch 164/235] [D loss: 1.138104, acc: 83.20%] [G loss: 1.107966]\n",
      "[Epoch 17/50] [Batch 165/235] [D loss: 1.140360, acc: 87.89%] [G loss: 1.122219]\n",
      "[Epoch 17/50] [Batch 166/235] [D loss: 1.158275, acc: 87.70%] [G loss: 1.202380]\n",
      "[Epoch 17/50] [Batch 167/235] [D loss: 1.199810, acc: 83.59%] [G loss: 1.116109]\n",
      "[Epoch 17/50] [Batch 168/235] [D loss: 1.100824, acc: 84.57%] [G loss: 1.210731]\n",
      "[Epoch 17/50] [Batch 169/235] [D loss: 1.141058, acc: 86.13%] [G loss: 1.232084]\n",
      "[Epoch 17/50] [Batch 170/235] [D loss: 1.065625, acc: 85.74%] [G loss: 1.296694]\n",
      "[Epoch 17/50] [Batch 171/235] [D loss: 1.128706, acc: 86.52%] [G loss: 1.154137]\n",
      "[Epoch 17/50] [Batch 172/235] [D loss: 1.115293, acc: 85.55%] [G loss: 1.167258]\n",
      "[Epoch 17/50] [Batch 173/235] [D loss: 1.115326, acc: 84.57%] [G loss: 1.140014]\n",
      "[Epoch 17/50] [Batch 174/235] [D loss: 1.097719, acc: 88.09%] [G loss: 1.251193]\n",
      "[Epoch 17/50] [Batch 175/235] [D loss: 1.109192, acc: 85.94%] [G loss: 1.202910]\n",
      "[Epoch 17/50] [Batch 176/235] [D loss: 1.152430, acc: 84.96%] [G loss: 1.293412]\n",
      "[Epoch 17/50] [Batch 177/235] [D loss: 1.082998, acc: 84.96%] [G loss: 1.182683]\n",
      "[Epoch 17/50] [Batch 178/235] [D loss: 1.116682, acc: 84.77%] [G loss: 1.174202]\n",
      "[Epoch 17/50] [Batch 179/235] [D loss: 1.083309, acc: 85.94%] [G loss: 1.291386]\n",
      "[Epoch 17/50] [Batch 180/235] [D loss: 1.123419, acc: 87.89%] [G loss: 1.073110]\n",
      "[Epoch 17/50] [Batch 181/235] [D loss: 1.144865, acc: 83.79%] [G loss: 1.281734]\n",
      "[Epoch 17/50] [Batch 182/235] [D loss: 1.093341, acc: 87.50%] [G loss: 1.133793]\n",
      "[Epoch 17/50] [Batch 183/235] [D loss: 1.140202, acc: 86.91%] [G loss: 1.247977]\n",
      "[Epoch 17/50] [Batch 184/235] [D loss: 1.102735, acc: 86.52%] [G loss: 1.121179]\n",
      "[Epoch 17/50] [Batch 185/235] [D loss: 1.201305, acc: 83.79%] [G loss: 1.139870]\n",
      "[Epoch 17/50] [Batch 186/235] [D loss: 1.121447, acc: 88.67%] [G loss: 1.163599]\n",
      "[Epoch 17/50] [Batch 187/235] [D loss: 1.118911, acc: 87.11%] [G loss: 1.110039]\n",
      "[Epoch 17/50] [Batch 188/235] [D loss: 1.135886, acc: 86.72%] [G loss: 1.131777]\n",
      "[Epoch 17/50] [Batch 189/235] [D loss: 1.089819, acc: 85.74%] [G loss: 1.207897]\n",
      "[Epoch 17/50] [Batch 190/235] [D loss: 1.124736, acc: 83.59%] [G loss: 1.235499]\n",
      "[Epoch 17/50] [Batch 191/235] [D loss: 1.116377, acc: 87.50%] [G loss: 1.093832]\n",
      "[Epoch 17/50] [Batch 192/235] [D loss: 1.098512, acc: 84.57%] [G loss: 1.230139]\n",
      "[Epoch 17/50] [Batch 193/235] [D loss: 1.143512, acc: 85.16%] [G loss: 1.143046]\n",
      "[Epoch 17/50] [Batch 194/235] [D loss: 1.131376, acc: 85.16%] [G loss: 1.121255]\n",
      "[Epoch 17/50] [Batch 195/235] [D loss: 1.164207, acc: 83.98%] [G loss: 1.165921]\n",
      "[Epoch 17/50] [Batch 196/235] [D loss: 1.186579, acc: 88.09%] [G loss: 1.223500]\n",
      "[Epoch 17/50] [Batch 197/235] [D loss: 1.161997, acc: 84.77%] [G loss: 1.354972]\n",
      "[Epoch 17/50] [Batch 198/235] [D loss: 1.125173, acc: 87.30%] [G loss: 1.160651]\n",
      "[Epoch 17/50] [Batch 199/235] [D loss: 1.111836, acc: 84.18%] [G loss: 1.207854]\n",
      "[Epoch 17/50] [Batch 200/235] [D loss: 1.130280, acc: 88.48%] [G loss: 1.060083]\n",
      "[Epoch 17/50] [Batch 201/235] [D loss: 1.143527, acc: 85.94%] [G loss: 1.069551]\n",
      "[Epoch 17/50] [Batch 202/235] [D loss: 1.156036, acc: 86.72%] [G loss: 1.226222]\n",
      "[Epoch 17/50] [Batch 203/235] [D loss: 1.134678, acc: 88.48%] [G loss: 1.323235]\n",
      "[Epoch 17/50] [Batch 204/235] [D loss: 1.123057, acc: 87.70%] [G loss: 1.142242]\n",
      "[Epoch 17/50] [Batch 205/235] [D loss: 1.144141, acc: 86.52%] [G loss: 1.091289]\n",
      "[Epoch 17/50] [Batch 206/235] [D loss: 1.062856, acc: 86.33%] [G loss: 1.162142]\n",
      "[Epoch 17/50] [Batch 207/235] [D loss: 1.119663, acc: 85.94%] [G loss: 1.201111]\n",
      "[Epoch 17/50] [Batch 208/235] [D loss: 1.142017, acc: 83.98%] [G loss: 1.150123]\n",
      "[Epoch 17/50] [Batch 209/235] [D loss: 1.154009, acc: 85.55%] [G loss: 1.171008]\n",
      "[Epoch 17/50] [Batch 210/235] [D loss: 1.143138, acc: 86.33%] [G loss: 1.152526]\n",
      "[Epoch 17/50] [Batch 211/235] [D loss: 1.116052, acc: 84.18%] [G loss: 1.197228]\n",
      "[Epoch 17/50] [Batch 212/235] [D loss: 1.162129, acc: 83.59%] [G loss: 1.137195]\n",
      "[Epoch 17/50] [Batch 213/235] [D loss: 1.091567, acc: 87.30%] [G loss: 1.128522]\n",
      "[Epoch 17/50] [Batch 214/235] [D loss: 1.074835, acc: 86.52%] [G loss: 1.254149]\n",
      "[Epoch 17/50] [Batch 215/235] [D loss: 1.201229, acc: 85.16%] [G loss: 1.188287]\n",
      "[Epoch 17/50] [Batch 216/235] [D loss: 1.120803, acc: 86.72%] [G loss: 1.225585]\n",
      "[Epoch 17/50] [Batch 217/235] [D loss: 1.121006, acc: 89.45%] [G loss: 1.244541]\n",
      "[Epoch 17/50] [Batch 218/235] [D loss: 1.112011, acc: 86.91%] [G loss: 1.158183]\n",
      "[Epoch 17/50] [Batch 219/235] [D loss: 1.130068, acc: 84.96%] [G loss: 1.161488]\n",
      "[Epoch 17/50] [Batch 220/235] [D loss: 1.119117, acc: 85.35%] [G loss: 1.090038]\n",
      "[Epoch 17/50] [Batch 221/235] [D loss: 1.130024, acc: 82.81%] [G loss: 1.210651]\n",
      "[Epoch 17/50] [Batch 222/235] [D loss: 1.120310, acc: 85.16%] [G loss: 1.141265]\n",
      "[Epoch 17/50] [Batch 223/235] [D loss: 1.099572, acc: 85.94%] [G loss: 1.219961]\n",
      "[Epoch 17/50] [Batch 224/235] [D loss: 1.115426, acc: 84.77%] [G loss: 1.136027]\n",
      "[Epoch 17/50] [Batch 225/235] [D loss: 1.095003, acc: 85.35%] [G loss: 1.263531]\n",
      "[Epoch 17/50] [Batch 226/235] [D loss: 1.094169, acc: 87.89%] [G loss: 1.115769]\n",
      "[Epoch 17/50] [Batch 227/235] [D loss: 1.082495, acc: 88.09%] [G loss: 1.172046]\n",
      "[Epoch 17/50] [Batch 228/235] [D loss: 1.043943, acc: 85.74%] [G loss: 1.231063]\n",
      "[Epoch 17/50] [Batch 229/235] [D loss: 1.123757, acc: 82.42%] [G loss: 1.141512]\n",
      "[Epoch 17/50] [Batch 230/235] [D loss: 1.127644, acc: 84.77%] [G loss: 1.162461]\n",
      "[Epoch 17/50] [Batch 231/235] [D loss: 1.141651, acc: 83.98%] [G loss: 1.156001]\n",
      "[Epoch 17/50] [Batch 232/235] [D loss: 1.103120, acc: 86.13%] [G loss: 1.339387]\n",
      "[Epoch 17/50] [Batch 233/235] [D loss: 1.128862, acc: 84.96%] [G loss: 1.139198]\n",
      "[Epoch 17/50] [Batch 234/235] [D loss: 1.095828, acc: 89.58%] [G loss: 1.141962]\n",
      "[Epoch 18/50] [Batch 0/235] [D loss: 1.072805, acc: 87.11%] [G loss: 1.200086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/50] [Batch 1/235] [D loss: 1.065279, acc: 88.09%] [G loss: 1.235741]\n",
      "[Epoch 18/50] [Batch 2/235] [D loss: 1.129440, acc: 85.16%] [G loss: 1.206293]\n",
      "[Epoch 18/50] [Batch 3/235] [D loss: 1.115270, acc: 82.23%] [G loss: 1.286019]\n",
      "[Epoch 18/50] [Batch 4/235] [D loss: 1.143948, acc: 83.20%] [G loss: 1.152978]\n",
      "[Epoch 18/50] [Batch 5/235] [D loss: 1.132344, acc: 87.50%] [G loss: 1.194673]\n",
      "[Epoch 18/50] [Batch 6/235] [D loss: 1.126905, acc: 87.11%] [G loss: 1.122458]\n",
      "[Epoch 18/50] [Batch 7/235] [D loss: 1.113593, acc: 85.94%] [G loss: 1.137983]\n",
      "[Epoch 18/50] [Batch 8/235] [D loss: 1.125178, acc: 88.48%] [G loss: 1.319842]\n",
      "[Epoch 18/50] [Batch 9/235] [D loss: 1.144885, acc: 86.72%] [G loss: 1.147651]\n",
      "[Epoch 18/50] [Batch 10/235] [D loss: 1.113174, acc: 85.35%] [G loss: 1.139356]\n",
      "[Epoch 18/50] [Batch 11/235] [D loss: 1.125179, acc: 84.38%] [G loss: 1.224372]\n",
      "[Epoch 18/50] [Batch 12/235] [D loss: 1.095678, acc: 86.91%] [G loss: 1.179625]\n",
      "[Epoch 18/50] [Batch 13/235] [D loss: 1.071984, acc: 87.89%] [G loss: 1.314731]\n",
      "[Epoch 18/50] [Batch 14/235] [D loss: 1.092929, acc: 84.96%] [G loss: 1.351310]\n",
      "[Epoch 18/50] [Batch 15/235] [D loss: 1.158693, acc: 86.72%] [G loss: 1.097280]\n",
      "[Epoch 18/50] [Batch 16/235] [D loss: 1.148681, acc: 85.55%] [G loss: 1.069671]\n",
      "[Epoch 18/50] [Batch 17/235] [D loss: 1.100517, acc: 86.72%] [G loss: 1.286893]\n",
      "[Epoch 18/50] [Batch 18/235] [D loss: 1.075003, acc: 84.18%] [G loss: 1.254889]\n",
      "[Epoch 18/50] [Batch 19/235] [D loss: 1.109520, acc: 85.16%] [G loss: 1.145149]\n",
      "[Epoch 18/50] [Batch 20/235] [D loss: 1.143744, acc: 85.94%] [G loss: 1.166065]\n",
      "[Epoch 18/50] [Batch 21/235] [D loss: 1.097250, acc: 86.72%] [G loss: 1.191764]\n",
      "[Epoch 18/50] [Batch 22/235] [D loss: 1.089613, acc: 85.55%] [G loss: 1.117074]\n",
      "[Epoch 18/50] [Batch 23/235] [D loss: 1.060202, acc: 86.33%] [G loss: 1.191403]\n",
      "[Epoch 18/50] [Batch 24/235] [D loss: 1.090465, acc: 88.09%] [G loss: 1.179864]\n",
      "[Epoch 18/50] [Batch 25/235] [D loss: 1.089242, acc: 87.70%] [G loss: 1.176095]\n",
      "[Epoch 18/50] [Batch 26/235] [D loss: 1.104995, acc: 83.20%] [G loss: 1.166935]\n",
      "[Epoch 18/50] [Batch 27/235] [D loss: 1.155875, acc: 81.25%] [G loss: 1.179370]\n",
      "[Epoch 18/50] [Batch 28/235] [D loss: 1.120203, acc: 86.13%] [G loss: 1.240814]\n",
      "[Epoch 18/50] [Batch 29/235] [D loss: 1.148298, acc: 87.70%] [G loss: 1.166761]\n",
      "[Epoch 18/50] [Batch 30/235] [D loss: 1.119693, acc: 85.35%] [G loss: 1.130864]\n",
      "[Epoch 18/50] [Batch 31/235] [D loss: 1.108332, acc: 87.89%] [G loss: 1.141734]\n",
      "[Epoch 18/50] [Batch 32/235] [D loss: 1.134067, acc: 85.16%] [G loss: 1.090736]\n",
      "[Epoch 18/50] [Batch 33/235] [D loss: 1.154252, acc: 87.11%] [G loss: 1.339391]\n",
      "[Epoch 18/50] [Batch 34/235] [D loss: 1.121994, acc: 84.57%] [G loss: 1.211617]\n",
      "[Epoch 18/50] [Batch 35/235] [D loss: 1.137385, acc: 81.84%] [G loss: 1.148075]\n",
      "[Epoch 18/50] [Batch 36/235] [D loss: 1.136231, acc: 84.57%] [G loss: 1.114985]\n",
      "[Epoch 18/50] [Batch 37/235] [D loss: 1.056809, acc: 86.72%] [G loss: 1.224510]\n",
      "[Epoch 18/50] [Batch 38/235] [D loss: 1.103935, acc: 86.33%] [G loss: 1.120459]\n",
      "[Epoch 18/50] [Batch 39/235] [D loss: 1.053629, acc: 86.13%] [G loss: 1.071776]\n",
      "[Epoch 18/50] [Batch 40/235] [D loss: 1.113740, acc: 83.98%] [G loss: 1.273380]\n",
      "[Epoch 18/50] [Batch 41/235] [D loss: 1.099656, acc: 85.35%] [G loss: 1.172332]\n",
      "[Epoch 18/50] [Batch 42/235] [D loss: 1.083389, acc: 85.16%] [G loss: 1.158153]\n",
      "[Epoch 18/50] [Batch 43/235] [D loss: 1.069229, acc: 83.79%] [G loss: 1.161896]\n",
      "[Epoch 18/50] [Batch 44/235] [D loss: 1.162379, acc: 85.16%] [G loss: 1.144537]\n",
      "[Epoch 18/50] [Batch 45/235] [D loss: 1.083392, acc: 85.94%] [G loss: 1.268368]\n",
      "[Epoch 18/50] [Batch 46/235] [D loss: 1.123769, acc: 86.72%] [G loss: 1.242296]\n",
      "[Epoch 18/50] [Batch 47/235] [D loss: 1.188895, acc: 84.18%] [G loss: 1.090499]\n",
      "[Epoch 18/50] [Batch 48/235] [D loss: 1.145062, acc: 83.40%] [G loss: 1.229664]\n",
      "[Epoch 18/50] [Batch 49/235] [D loss: 1.107783, acc: 86.33%] [G loss: 1.124593]\n",
      "[Epoch 18/50] [Batch 50/235] [D loss: 1.178484, acc: 87.50%] [G loss: 1.143549]\n",
      "[Epoch 18/50] [Batch 51/235] [D loss: 1.088306, acc: 86.13%] [G loss: 1.317480]\n",
      "[Epoch 18/50] [Batch 52/235] [D loss: 1.100992, acc: 86.72%] [G loss: 1.231738]\n",
      "[Epoch 18/50] [Batch 53/235] [D loss: 1.170098, acc: 85.35%] [G loss: 1.104812]\n",
      "[Epoch 18/50] [Batch 54/235] [D loss: 1.159728, acc: 83.98%] [G loss: 1.132549]\n",
      "[Epoch 18/50] [Batch 55/235] [D loss: 1.059600, acc: 85.74%] [G loss: 1.190254]\n",
      "[Epoch 18/50] [Batch 56/235] [D loss: 1.141947, acc: 85.35%] [G loss: 1.072669]\n",
      "[Epoch 18/50] [Batch 57/235] [D loss: 1.097073, acc: 84.18%] [G loss: 1.158951]\n",
      "[Epoch 18/50] [Batch 58/235] [D loss: 1.073438, acc: 88.28%] [G loss: 1.128044]\n",
      "[Epoch 18/50] [Batch 59/235] [D loss: 1.101150, acc: 85.35%] [G loss: 1.242883]\n",
      "[Epoch 18/50] [Batch 60/235] [D loss: 1.127394, acc: 86.52%] [G loss: 1.221495]\n",
      "[Epoch 18/50] [Batch 61/235] [D loss: 1.100788, acc: 87.50%] [G loss: 1.127772]\n",
      "[Epoch 18/50] [Batch 62/235] [D loss: 1.160825, acc: 84.57%] [G loss: 1.242244]\n",
      "[Epoch 18/50] [Batch 63/235] [D loss: 1.125061, acc: 85.35%] [G loss: 1.153969]\n",
      "[Epoch 18/50] [Batch 64/235] [D loss: 1.142873, acc: 87.30%] [G loss: 1.200166]\n",
      "[Epoch 18/50] [Batch 65/235] [D loss: 1.071090, acc: 86.33%] [G loss: 1.140229]\n",
      "[Epoch 18/50] [Batch 66/235] [D loss: 1.085138, acc: 84.57%] [G loss: 1.193712]\n",
      "[Epoch 18/50] [Batch 67/235] [D loss: 1.116808, acc: 84.18%] [G loss: 1.070927]\n",
      "[Epoch 18/50] [Batch 68/235] [D loss: 1.153026, acc: 87.50%] [G loss: 1.289079]\n",
      "[Epoch 18/50] [Batch 69/235] [D loss: 1.157078, acc: 84.77%] [G loss: 1.307934]\n",
      "[Epoch 18/50] [Batch 70/235] [D loss: 1.129894, acc: 86.72%] [G loss: 1.124032]\n",
      "[Epoch 18/50] [Batch 71/235] [D loss: 1.113444, acc: 85.94%] [G loss: 1.105663]\n",
      "[Epoch 18/50] [Batch 72/235] [D loss: 1.094643, acc: 84.96%] [G loss: 1.294628]\n",
      "[Epoch 18/50] [Batch 73/235] [D loss: 1.092404, acc: 86.13%] [G loss: 1.262277]\n",
      "[Epoch 18/50] [Batch 74/235] [D loss: 1.148202, acc: 85.16%] [G loss: 1.171341]\n",
      "[Epoch 18/50] [Batch 75/235] [D loss: 1.069352, acc: 88.67%] [G loss: 1.151013]\n",
      "[Epoch 18/50] [Batch 76/235] [D loss: 1.139130, acc: 87.11%] [G loss: 1.280174]\n",
      "[Epoch 18/50] [Batch 77/235] [D loss: 1.138129, acc: 86.13%] [G loss: 1.160915]\n",
      "[Epoch 18/50] [Batch 78/235] [D loss: 1.106807, acc: 86.33%] [G loss: 1.064496]\n",
      "[Epoch 18/50] [Batch 79/235] [D loss: 1.113820, acc: 85.74%] [G loss: 1.122353]\n",
      "[Epoch 18/50] [Batch 80/235] [D loss: 1.039672, acc: 86.72%] [G loss: 1.223520]\n",
      "[Epoch 18/50] [Batch 81/235] [D loss: 1.182906, acc: 86.52%] [G loss: 1.321931]\n",
      "[Epoch 18/50] [Batch 82/235] [D loss: 1.120359, acc: 88.48%] [G loss: 1.219573]\n",
      "[Epoch 18/50] [Batch 83/235] [D loss: 1.138381, acc: 87.11%] [G loss: 1.001246]\n",
      "[Epoch 18/50] [Batch 84/235] [D loss: 1.116785, acc: 86.91%] [G loss: 1.310273]\n",
      "[Epoch 18/50] [Batch 85/235] [D loss: 1.113555, acc: 88.09%] [G loss: 1.097326]\n",
      "[Epoch 18/50] [Batch 86/235] [D loss: 1.164349, acc: 87.11%] [G loss: 1.183375]\n",
      "[Epoch 18/50] [Batch 87/235] [D loss: 1.182892, acc: 87.89%] [G loss: 1.188800]\n",
      "[Epoch 18/50] [Batch 88/235] [D loss: 1.114741, acc: 85.16%] [G loss: 1.065578]\n",
      "[Epoch 18/50] [Batch 89/235] [D loss: 1.108761, acc: 85.94%] [G loss: 1.141051]\n",
      "[Epoch 18/50] [Batch 90/235] [D loss: 1.123063, acc: 81.64%] [G loss: 1.133061]\n",
      "[Epoch 18/50] [Batch 91/235] [D loss: 1.139119, acc: 87.30%] [G loss: 1.202775]\n",
      "[Epoch 18/50] [Batch 92/235] [D loss: 1.116447, acc: 85.16%] [G loss: 1.208107]\n",
      "[Epoch 18/50] [Batch 93/235] [D loss: 1.115453, acc: 88.87%] [G loss: 1.221134]\n",
      "[Epoch 18/50] [Batch 94/235] [D loss: 1.065249, acc: 87.50%] [G loss: 1.130517]\n",
      "[Epoch 18/50] [Batch 95/235] [D loss: 1.084938, acc: 85.35%] [G loss: 1.133903]\n",
      "[Epoch 18/50] [Batch 96/235] [D loss: 1.138799, acc: 85.55%] [G loss: 1.106177]\n",
      "[Epoch 18/50] [Batch 97/235] [D loss: 1.151706, acc: 83.59%] [G loss: 1.121442]\n",
      "[Epoch 18/50] [Batch 98/235] [D loss: 1.096392, acc: 84.57%] [G loss: 1.096192]\n",
      "[Epoch 18/50] [Batch 99/235] [D loss: 1.131712, acc: 85.55%] [G loss: 1.142763]\n",
      "[Epoch 18/50] [Batch 100/235] [D loss: 1.104275, acc: 84.96%] [G loss: 1.219430]\n",
      "[Epoch 18/50] [Batch 101/235] [D loss: 1.103963, acc: 86.52%] [G loss: 1.076140]\n",
      "[Epoch 18/50] [Batch 102/235] [D loss: 1.127427, acc: 86.91%] [G loss: 1.111886]\n",
      "[Epoch 18/50] [Batch 103/235] [D loss: 1.100828, acc: 86.72%] [G loss: 1.242316]\n",
      "[Epoch 18/50] [Batch 104/235] [D loss: 1.111130, acc: 85.74%] [G loss: 1.203052]\n",
      "[Epoch 18/50] [Batch 105/235] [D loss: 1.073746, acc: 84.57%] [G loss: 1.099057]\n",
      "[Epoch 18/50] [Batch 106/235] [D loss: 1.142026, acc: 86.52%] [G loss: 1.216859]\n",
      "[Epoch 18/50] [Batch 107/235] [D loss: 1.146868, acc: 86.33%] [G loss: 1.085346]\n",
      "[Epoch 18/50] [Batch 108/235] [D loss: 1.068178, acc: 86.13%] [G loss: 1.278787]\n",
      "[Epoch 18/50] [Batch 109/235] [D loss: 1.109978, acc: 86.91%] [G loss: 1.245510]\n",
      "[Epoch 18/50] [Batch 110/235] [D loss: 1.170855, acc: 84.77%] [G loss: 1.096432]\n",
      "[Epoch 18/50] [Batch 111/235] [D loss: 1.152591, acc: 83.40%] [G loss: 1.194332]\n",
      "[Epoch 18/50] [Batch 112/235] [D loss: 1.112075, acc: 84.96%] [G loss: 1.123953]\n",
      "[Epoch 18/50] [Batch 113/235] [D loss: 1.131914, acc: 85.55%] [G loss: 1.229054]\n",
      "[Epoch 18/50] [Batch 114/235] [D loss: 1.154009, acc: 84.18%] [G loss: 1.153730]\n",
      "[Epoch 18/50] [Batch 115/235] [D loss: 1.122830, acc: 86.33%] [G loss: 1.141712]\n",
      "[Epoch 18/50] [Batch 116/235] [D loss: 1.143268, acc: 85.55%] [G loss: 1.179150]\n",
      "[Epoch 18/50] [Batch 117/235] [D loss: 1.112287, acc: 86.33%] [G loss: 1.293846]\n",
      "[Epoch 18/50] [Batch 118/235] [D loss: 1.107285, acc: 87.50%] [G loss: 1.264384]\n",
      "[Epoch 18/50] [Batch 119/235] [D loss: 1.161663, acc: 84.18%] [G loss: 1.183553]\n",
      "[Epoch 18/50] [Batch 120/235] [D loss: 1.150717, acc: 86.13%] [G loss: 1.115906]\n",
      "[Epoch 18/50] [Batch 121/235] [D loss: 1.118097, acc: 85.94%] [G loss: 1.245461]\n",
      "[Epoch 18/50] [Batch 122/235] [D loss: 1.090330, acc: 88.48%] [G loss: 1.246818]\n",
      "[Epoch 18/50] [Batch 123/235] [D loss: 1.078269, acc: 86.91%] [G loss: 1.202806]\n",
      "[Epoch 18/50] [Batch 124/235] [D loss: 1.129616, acc: 84.18%] [G loss: 1.061782]\n",
      "[Epoch 18/50] [Batch 125/235] [D loss: 1.111713, acc: 84.38%] [G loss: 1.144515]\n",
      "[Epoch 18/50] [Batch 126/235] [D loss: 1.152914, acc: 81.45%] [G loss: 1.251013]\n",
      "[Epoch 18/50] [Batch 127/235] [D loss: 1.137607, acc: 83.59%] [G loss: 1.196656]\n",
      "[Epoch 18/50] [Batch 128/235] [D loss: 1.094025, acc: 85.55%] [G loss: 1.255394]\n",
      "[Epoch 18/50] [Batch 129/235] [D loss: 1.122739, acc: 83.98%] [G loss: 1.051426]\n",
      "[Epoch 18/50] [Batch 130/235] [D loss: 1.093388, acc: 86.72%] [G loss: 1.091192]\n",
      "[Epoch 18/50] [Batch 131/235] [D loss: 1.131861, acc: 85.94%] [G loss: 1.142430]\n",
      "[Epoch 18/50] [Batch 132/235] [D loss: 1.066826, acc: 87.50%] [G loss: 1.187093]\n",
      "[Epoch 18/50] [Batch 133/235] [D loss: 1.097264, acc: 84.77%] [G loss: 1.154225]\n",
      "[Epoch 18/50] [Batch 134/235] [D loss: 1.149324, acc: 83.40%] [G loss: 1.170717]\n",
      "[Epoch 18/50] [Batch 135/235] [D loss: 1.096598, acc: 85.74%] [G loss: 1.192489]\n",
      "[Epoch 18/50] [Batch 136/235] [D loss: 1.077604, acc: 85.74%] [G loss: 1.241989]\n",
      "[Epoch 18/50] [Batch 137/235] [D loss: 1.173614, acc: 85.35%] [G loss: 1.261016]\n",
      "[Epoch 18/50] [Batch 138/235] [D loss: 1.089467, acc: 86.13%] [G loss: 1.185964]\n",
      "[Epoch 18/50] [Batch 139/235] [D loss: 1.115145, acc: 84.38%] [G loss: 1.126964]\n",
      "[Epoch 18/50] [Batch 140/235] [D loss: 1.063802, acc: 84.77%] [G loss: 1.135541]\n",
      "[Epoch 18/50] [Batch 141/235] [D loss: 1.089706, acc: 85.35%] [G loss: 1.261348]\n",
      "[Epoch 18/50] [Batch 142/235] [D loss: 1.119312, acc: 85.55%] [G loss: 1.131204]\n",
      "[Epoch 18/50] [Batch 143/235] [D loss: 1.105945, acc: 84.96%] [G loss: 1.128106]\n",
      "[Epoch 18/50] [Batch 144/235] [D loss: 1.163135, acc: 85.94%] [G loss: 1.088276]\n",
      "[Epoch 18/50] [Batch 145/235] [D loss: 1.120587, acc: 86.33%] [G loss: 1.208835]\n",
      "[Epoch 18/50] [Batch 146/235] [D loss: 1.140297, acc: 87.11%] [G loss: 1.111141]\n",
      "[Epoch 18/50] [Batch 147/235] [D loss: 1.144580, acc: 85.16%] [G loss: 1.213610]\n",
      "[Epoch 18/50] [Batch 148/235] [D loss: 1.100739, acc: 85.16%] [G loss: 1.078555]\n",
      "[Epoch 18/50] [Batch 149/235] [D loss: 1.122575, acc: 85.55%] [G loss: 1.128608]\n",
      "[Epoch 18/50] [Batch 150/235] [D loss: 1.142269, acc: 85.55%] [G loss: 1.204904]\n",
      "[Epoch 18/50] [Batch 151/235] [D loss: 1.088947, acc: 86.13%] [G loss: 1.126458]\n",
      "[Epoch 18/50] [Batch 152/235] [D loss: 1.088423, acc: 84.38%] [G loss: 1.158112]\n",
      "[Epoch 18/50] [Batch 153/235] [D loss: 1.132517, acc: 86.72%] [G loss: 1.190707]\n",
      "[Epoch 18/50] [Batch 154/235] [D loss: 1.108976, acc: 87.11%] [G loss: 1.206772]\n",
      "[Epoch 18/50] [Batch 155/235] [D loss: 1.127717, acc: 86.72%] [G loss: 1.126712]\n",
      "[Epoch 18/50] [Batch 156/235] [D loss: 1.187253, acc: 83.20%] [G loss: 1.258825]\n",
      "[Epoch 18/50] [Batch 157/235] [D loss: 1.112587, acc: 86.72%] [G loss: 1.193101]\n",
      "[Epoch 18/50] [Batch 158/235] [D loss: 1.115577, acc: 85.74%] [G loss: 1.155444]\n",
      "[Epoch 18/50] [Batch 159/235] [D loss: 1.138824, acc: 82.81%] [G loss: 1.112785]\n",
      "[Epoch 18/50] [Batch 160/235] [D loss: 1.171547, acc: 85.74%] [G loss: 1.144081]\n",
      "[Epoch 18/50] [Batch 161/235] [D loss: 1.096588, acc: 84.96%] [G loss: 1.070627]\n",
      "[Epoch 18/50] [Batch 162/235] [D loss: 1.130390, acc: 85.35%] [G loss: 1.130871]\n",
      "[Epoch 18/50] [Batch 163/235] [D loss: 1.109733, acc: 86.33%] [G loss: 1.197488]\n",
      "[Epoch 18/50] [Batch 164/235] [D loss: 1.173268, acc: 85.74%] [G loss: 1.186785]\n",
      "[Epoch 18/50] [Batch 165/235] [D loss: 1.153506, acc: 84.38%] [G loss: 1.184552]\n",
      "[Epoch 18/50] [Batch 166/235] [D loss: 1.094002, acc: 86.52%] [G loss: 1.115789]\n",
      "[Epoch 18/50] [Batch 167/235] [D loss: 1.092623, acc: 86.33%] [G loss: 1.170900]\n",
      "[Epoch 18/50] [Batch 168/235] [D loss: 1.132703, acc: 85.35%] [G loss: 1.310719]\n",
      "[Epoch 18/50] [Batch 169/235] [D loss: 1.143850, acc: 86.91%] [G loss: 1.114990]\n",
      "[Epoch 18/50] [Batch 170/235] [D loss: 1.150406, acc: 87.50%] [G loss: 1.215887]\n",
      "[Epoch 18/50] [Batch 171/235] [D loss: 1.136597, acc: 86.33%] [G loss: 1.220217]\n",
      "[Epoch 18/50] [Batch 172/235] [D loss: 1.135600, acc: 83.98%] [G loss: 1.184973]\n",
      "[Epoch 18/50] [Batch 173/235] [D loss: 1.093004, acc: 87.30%] [G loss: 1.125793]\n",
      "[Epoch 18/50] [Batch 174/235] [D loss: 1.102409, acc: 87.70%] [G loss: 1.196663]\n",
      "[Epoch 18/50] [Batch 175/235] [D loss: 1.132518, acc: 85.35%] [G loss: 1.156617]\n",
      "[Epoch 18/50] [Batch 176/235] [D loss: 1.127072, acc: 84.57%] [G loss: 1.193181]\n",
      "[Epoch 18/50] [Batch 177/235] [D loss: 1.157202, acc: 85.16%] [G loss: 1.163194]\n",
      "[Epoch 18/50] [Batch 178/235] [D loss: 1.137351, acc: 85.55%] [G loss: 1.191256]\n",
      "[Epoch 18/50] [Batch 179/235] [D loss: 1.095395, acc: 88.48%] [G loss: 1.207236]\n",
      "[Epoch 18/50] [Batch 180/235] [D loss: 1.138062, acc: 86.13%] [G loss: 1.235254]\n",
      "[Epoch 18/50] [Batch 181/235] [D loss: 1.109614, acc: 85.35%] [G loss: 1.317827]\n",
      "[Epoch 18/50] [Batch 182/235] [D loss: 1.139448, acc: 85.94%] [G loss: 1.246319]\n",
      "[Epoch 18/50] [Batch 183/235] [D loss: 1.127753, acc: 88.28%] [G loss: 1.286494]\n",
      "[Epoch 18/50] [Batch 184/235] [D loss: 1.110361, acc: 85.16%] [G loss: 1.172341]\n",
      "[Epoch 18/50] [Batch 185/235] [D loss: 1.107273, acc: 88.87%] [G loss: 1.157837]\n",
      "[Epoch 18/50] [Batch 186/235] [D loss: 1.119774, acc: 88.48%] [G loss: 1.203656]\n",
      "[Epoch 18/50] [Batch 187/235] [D loss: 1.104380, acc: 86.13%] [G loss: 1.304947]\n",
      "[Epoch 18/50] [Batch 188/235] [D loss: 1.130207, acc: 87.11%] [G loss: 1.102431]\n",
      "[Epoch 18/50] [Batch 189/235] [D loss: 1.145552, acc: 83.98%] [G loss: 1.184011]\n",
      "[Epoch 18/50] [Batch 190/235] [D loss: 1.118669, acc: 83.20%] [G loss: 1.158616]\n",
      "[Epoch 18/50] [Batch 191/235] [D loss: 1.182135, acc: 88.09%] [G loss: 1.180258]\n",
      "[Epoch 18/50] [Batch 192/235] [D loss: 1.131320, acc: 87.30%] [G loss: 1.212917]\n",
      "[Epoch 18/50] [Batch 193/235] [D loss: 1.160903, acc: 84.38%] [G loss: 1.126263]\n",
      "[Epoch 18/50] [Batch 194/235] [D loss: 1.076919, acc: 86.33%] [G loss: 1.207922]\n",
      "[Epoch 18/50] [Batch 195/235] [D loss: 1.093267, acc: 86.33%] [G loss: 1.264398]\n",
      "[Epoch 18/50] [Batch 196/235] [D loss: 1.110539, acc: 83.20%] [G loss: 1.198175]\n",
      "[Epoch 18/50] [Batch 197/235] [D loss: 1.181062, acc: 83.20%] [G loss: 1.193376]\n",
      "[Epoch 18/50] [Batch 198/235] [D loss: 1.127601, acc: 85.94%] [G loss: 1.174134]\n",
      "[Epoch 18/50] [Batch 199/235] [D loss: 1.111980, acc: 86.91%] [G loss: 1.216746]\n",
      "[Epoch 18/50] [Batch 200/235] [D loss: 1.134651, acc: 88.67%] [G loss: 1.183670]\n",
      "[Epoch 18/50] [Batch 201/235] [D loss: 1.151433, acc: 84.77%] [G loss: 1.141180]\n",
      "[Epoch 18/50] [Batch 202/235] [D loss: 1.125946, acc: 85.35%] [G loss: 1.186771]\n",
      "[Epoch 18/50] [Batch 203/235] [D loss: 1.122080, acc: 85.55%] [G loss: 1.271094]\n",
      "[Epoch 18/50] [Batch 204/235] [D loss: 1.081205, acc: 86.91%] [G loss: 1.133196]\n",
      "[Epoch 18/50] [Batch 205/235] [D loss: 1.141717, acc: 85.74%] [G loss: 1.229221]\n",
      "[Epoch 18/50] [Batch 206/235] [D loss: 1.142124, acc: 85.35%] [G loss: 1.181723]\n",
      "[Epoch 18/50] [Batch 207/235] [D loss: 1.123595, acc: 85.55%] [G loss: 1.123942]\n",
      "[Epoch 18/50] [Batch 208/235] [D loss: 1.115772, acc: 84.77%] [G loss: 1.173900]\n",
      "[Epoch 18/50] [Batch 209/235] [D loss: 1.145678, acc: 87.50%] [G loss: 1.149844]\n",
      "[Epoch 18/50] [Batch 210/235] [D loss: 1.074194, acc: 84.57%] [G loss: 1.215985]\n",
      "[Epoch 18/50] [Batch 211/235] [D loss: 1.184775, acc: 84.96%] [G loss: 1.193290]\n",
      "[Epoch 18/50] [Batch 212/235] [D loss: 1.172962, acc: 87.50%] [G loss: 1.103673]\n",
      "[Epoch 18/50] [Batch 213/235] [D loss: 1.141615, acc: 85.94%] [G loss: 1.215327]\n",
      "[Epoch 18/50] [Batch 214/235] [D loss: 1.105726, acc: 85.94%] [G loss: 1.222784]\n",
      "[Epoch 18/50] [Batch 215/235] [D loss: 1.153805, acc: 84.96%] [G loss: 1.254167]\n",
      "[Epoch 18/50] [Batch 216/235] [D loss: 1.120902, acc: 87.11%] [G loss: 1.117917]\n",
      "[Epoch 18/50] [Batch 217/235] [D loss: 1.092772, acc: 86.72%] [G loss: 1.208399]\n",
      "[Epoch 18/50] [Batch 218/235] [D loss: 1.147318, acc: 86.72%] [G loss: 1.072059]\n",
      "[Epoch 18/50] [Batch 219/235] [D loss: 1.148301, acc: 84.96%] [G loss: 1.261711]\n",
      "[Epoch 18/50] [Batch 220/235] [D loss: 1.126532, acc: 86.33%] [G loss: 1.228958]\n",
      "[Epoch 18/50] [Batch 221/235] [D loss: 1.124118, acc: 82.81%] [G loss: 1.105822]\n",
      "[Epoch 18/50] [Batch 222/235] [D loss: 1.174237, acc: 86.72%] [G loss: 1.161630]\n",
      "[Epoch 18/50] [Batch 223/235] [D loss: 1.109421, acc: 85.16%] [G loss: 1.062915]\n",
      "[Epoch 18/50] [Batch 224/235] [D loss: 1.127760, acc: 83.79%] [G loss: 1.304559]\n",
      "[Epoch 18/50] [Batch 225/235] [D loss: 1.148015, acc: 87.30%] [G loss: 1.134847]\n",
      "[Epoch 18/50] [Batch 226/235] [D loss: 1.141471, acc: 85.55%] [G loss: 1.269521]\n",
      "[Epoch 18/50] [Batch 227/235] [D loss: 1.114489, acc: 84.38%] [G loss: 1.204493]\n",
      "[Epoch 18/50] [Batch 228/235] [D loss: 1.155414, acc: 86.13%] [G loss: 1.110859]\n",
      "[Epoch 18/50] [Batch 229/235] [D loss: 1.103508, acc: 88.67%] [G loss: 1.161800]\n",
      "[Epoch 18/50] [Batch 230/235] [D loss: 1.113697, acc: 86.72%] [G loss: 1.039476]\n",
      "[Epoch 18/50] [Batch 231/235] [D loss: 1.147018, acc: 84.57%] [G loss: 1.118195]\n",
      "[Epoch 18/50] [Batch 232/235] [D loss: 1.084047, acc: 85.35%] [G loss: 1.065647]\n",
      "[Epoch 18/50] [Batch 233/235] [D loss: 1.159914, acc: 84.77%] [G loss: 1.157105]\n",
      "[Epoch 18/50] [Batch 234/235] [D loss: 1.055376, acc: 88.02%] [G loss: 1.269923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/50] [Batch 0/235] [D loss: 1.132341, acc: 88.09%] [G loss: 1.087723]\n",
      "[Epoch 19/50] [Batch 1/235] [D loss: 1.114125, acc: 84.18%] [G loss: 1.131457]\n",
      "[Epoch 19/50] [Batch 2/235] [D loss: 1.123263, acc: 86.52%] [G loss: 1.199724]\n",
      "[Epoch 19/50] [Batch 3/235] [D loss: 1.148744, acc: 86.33%] [G loss: 1.147683]\n",
      "[Epoch 19/50] [Batch 4/235] [D loss: 1.094426, acc: 86.33%] [G loss: 1.247091]\n",
      "[Epoch 19/50] [Batch 5/235] [D loss: 1.124526, acc: 84.57%] [G loss: 1.102246]\n",
      "[Epoch 19/50] [Batch 6/235] [D loss: 1.148456, acc: 84.77%] [G loss: 1.132593]\n",
      "[Epoch 19/50] [Batch 7/235] [D loss: 1.165543, acc: 85.74%] [G loss: 1.270462]\n",
      "[Epoch 19/50] [Batch 8/235] [D loss: 1.116025, acc: 85.16%] [G loss: 1.198912]\n",
      "[Epoch 19/50] [Batch 9/235] [D loss: 1.123976, acc: 88.09%] [G loss: 1.132837]\n",
      "[Epoch 19/50] [Batch 10/235] [D loss: 1.104321, acc: 86.52%] [G loss: 1.116681]\n",
      "[Epoch 19/50] [Batch 11/235] [D loss: 1.162231, acc: 84.18%] [G loss: 1.240662]\n",
      "[Epoch 19/50] [Batch 12/235] [D loss: 1.217533, acc: 86.52%] [G loss: 1.083127]\n",
      "[Epoch 19/50] [Batch 13/235] [D loss: 1.105892, acc: 85.35%] [G loss: 1.110198]\n",
      "[Epoch 19/50] [Batch 14/235] [D loss: 1.127666, acc: 85.35%] [G loss: 1.175622]\n",
      "[Epoch 19/50] [Batch 15/235] [D loss: 1.105851, acc: 87.11%] [G loss: 1.102142]\n",
      "[Epoch 19/50] [Batch 16/235] [D loss: 1.123868, acc: 84.77%] [G loss: 1.087109]\n",
      "[Epoch 19/50] [Batch 17/235] [D loss: 1.116077, acc: 85.16%] [G loss: 1.170467]\n",
      "[Epoch 19/50] [Batch 18/235] [D loss: 1.059991, acc: 87.70%] [G loss: 1.141890]\n",
      "[Epoch 19/50] [Batch 19/235] [D loss: 1.158747, acc: 82.81%] [G loss: 1.111375]\n",
      "[Epoch 19/50] [Batch 20/235] [D loss: 1.107508, acc: 82.62%] [G loss: 1.282933]\n",
      "[Epoch 19/50] [Batch 21/235] [D loss: 1.076302, acc: 85.94%] [G loss: 1.293300]\n",
      "[Epoch 19/50] [Batch 22/235] [D loss: 1.143503, acc: 85.16%] [G loss: 1.206443]\n",
      "[Epoch 19/50] [Batch 23/235] [D loss: 1.102905, acc: 86.13%] [G loss: 1.256705]\n",
      "[Epoch 19/50] [Batch 24/235] [D loss: 1.098262, acc: 85.16%] [G loss: 1.163564]\n",
      "[Epoch 19/50] [Batch 25/235] [D loss: 1.119198, acc: 83.79%] [G loss: 1.110200]\n",
      "[Epoch 19/50] [Batch 26/235] [D loss: 1.151322, acc: 82.42%] [G loss: 1.228866]\n",
      "[Epoch 19/50] [Batch 27/235] [D loss: 1.127511, acc: 85.55%] [G loss: 1.080640]\n",
      "[Epoch 19/50] [Batch 28/235] [D loss: 1.146251, acc: 85.94%] [G loss: 1.080911]\n",
      "[Epoch 19/50] [Batch 29/235] [D loss: 1.053717, acc: 87.50%] [G loss: 1.165424]\n",
      "[Epoch 19/50] [Batch 30/235] [D loss: 1.166863, acc: 85.94%] [G loss: 1.257127]\n",
      "[Epoch 19/50] [Batch 31/235] [D loss: 1.142153, acc: 87.11%] [G loss: 1.162735]\n",
      "[Epoch 19/50] [Batch 32/235] [D loss: 1.181429, acc: 83.98%] [G loss: 1.090421]\n",
      "[Epoch 19/50] [Batch 33/235] [D loss: 1.130997, acc: 85.55%] [G loss: 1.135249]\n",
      "[Epoch 19/50] [Batch 34/235] [D loss: 1.139912, acc: 85.55%] [G loss: 1.091504]\n",
      "[Epoch 19/50] [Batch 35/235] [D loss: 1.152181, acc: 85.94%] [G loss: 1.129549]\n",
      "[Epoch 19/50] [Batch 36/235] [D loss: 1.124829, acc: 82.62%] [G loss: 1.259969]\n",
      "[Epoch 19/50] [Batch 37/235] [D loss: 1.128819, acc: 83.59%] [G loss: 1.165752]\n",
      "[Epoch 19/50] [Batch 38/235] [D loss: 1.089732, acc: 83.40%] [G loss: 1.153449]\n",
      "[Epoch 19/50] [Batch 39/235] [D loss: 1.143274, acc: 87.50%] [G loss: 1.133967]\n",
      "[Epoch 19/50] [Batch 40/235] [D loss: 1.107101, acc: 86.52%] [G loss: 1.136690]\n",
      "[Epoch 19/50] [Batch 41/235] [D loss: 1.095495, acc: 86.13%] [G loss: 1.188009]\n",
      "[Epoch 19/50] [Batch 42/235] [D loss: 1.111611, acc: 87.11%] [G loss: 1.134835]\n",
      "[Epoch 19/50] [Batch 43/235] [D loss: 1.099514, acc: 89.45%] [G loss: 1.302996]\n",
      "[Epoch 19/50] [Batch 44/235] [D loss: 1.135628, acc: 87.30%] [G loss: 1.029705]\n",
      "[Epoch 19/50] [Batch 45/235] [D loss: 1.121718, acc: 88.48%] [G loss: 1.126414]\n",
      "[Epoch 19/50] [Batch 46/235] [D loss: 1.132276, acc: 84.18%] [G loss: 1.233360]\n",
      "[Epoch 19/50] [Batch 47/235] [D loss: 1.168630, acc: 85.94%] [G loss: 1.210218]\n",
      "[Epoch 19/50] [Batch 48/235] [D loss: 1.176785, acc: 82.03%] [G loss: 1.266873]\n",
      "[Epoch 19/50] [Batch 49/235] [D loss: 1.163731, acc: 86.91%] [G loss: 1.205407]\n",
      "[Epoch 19/50] [Batch 50/235] [D loss: 1.095202, acc: 88.48%] [G loss: 1.171783]\n",
      "[Epoch 19/50] [Batch 51/235] [D loss: 1.156230, acc: 84.38%] [G loss: 1.162248]\n",
      "[Epoch 19/50] [Batch 52/235] [D loss: 1.167557, acc: 86.33%] [G loss: 1.114663]\n",
      "[Epoch 19/50] [Batch 53/235] [D loss: 1.125584, acc: 86.91%] [G loss: 1.308417]\n",
      "[Epoch 19/50] [Batch 54/235] [D loss: 1.106816, acc: 86.52%] [G loss: 1.220550]\n",
      "[Epoch 19/50] [Batch 55/235] [D loss: 1.115321, acc: 84.57%] [G loss: 1.111039]\n",
      "[Epoch 19/50] [Batch 56/235] [D loss: 1.121840, acc: 85.74%] [G loss: 1.224362]\n",
      "[Epoch 19/50] [Batch 57/235] [D loss: 1.105445, acc: 86.33%] [G loss: 1.345299]\n",
      "[Epoch 19/50] [Batch 58/235] [D loss: 1.120601, acc: 85.74%] [G loss: 1.116179]\n",
      "[Epoch 19/50] [Batch 59/235] [D loss: 1.185699, acc: 84.57%] [G loss: 1.168768]\n",
      "[Epoch 19/50] [Batch 60/235] [D loss: 1.085801, acc: 84.96%] [G loss: 1.119450]\n",
      "[Epoch 19/50] [Batch 61/235] [D loss: 1.095176, acc: 84.38%] [G loss: 1.028230]\n",
      "[Epoch 19/50] [Batch 62/235] [D loss: 1.113637, acc: 89.45%] [G loss: 1.176937]\n",
      "[Epoch 19/50] [Batch 63/235] [D loss: 1.148808, acc: 85.94%] [G loss: 1.242925]\n",
      "[Epoch 19/50] [Batch 64/235] [D loss: 1.119680, acc: 83.98%] [G loss: 1.135773]\n",
      "[Epoch 19/50] [Batch 65/235] [D loss: 1.095956, acc: 87.50%] [G loss: 1.118605]\n",
      "[Epoch 19/50] [Batch 66/235] [D loss: 1.066179, acc: 88.67%] [G loss: 1.065971]\n",
      "[Epoch 19/50] [Batch 67/235] [D loss: 1.117165, acc: 87.30%] [G loss: 1.075088]\n",
      "[Epoch 19/50] [Batch 68/235] [D loss: 1.188900, acc: 84.96%] [G loss: 1.213673]\n",
      "[Epoch 19/50] [Batch 69/235] [D loss: 1.190384, acc: 84.57%] [G loss: 1.207417]\n",
      "[Epoch 19/50] [Batch 70/235] [D loss: 1.174665, acc: 85.35%] [G loss: 1.168447]\n",
      "[Epoch 19/50] [Batch 71/235] [D loss: 1.180707, acc: 84.57%] [G loss: 1.138340]\n",
      "[Epoch 19/50] [Batch 72/235] [D loss: 1.168896, acc: 86.72%] [G loss: 1.179957]\n",
      "[Epoch 19/50] [Batch 73/235] [D loss: 1.108957, acc: 85.94%] [G loss: 1.182091]\n",
      "[Epoch 19/50] [Batch 74/235] [D loss: 1.090907, acc: 87.70%] [G loss: 1.121542]\n",
      "[Epoch 19/50] [Batch 75/235] [D loss: 1.170989, acc: 85.35%] [G loss: 1.183920]\n",
      "[Epoch 19/50] [Batch 76/235] [D loss: 1.123510, acc: 86.52%] [G loss: 1.178670]\n",
      "[Epoch 19/50] [Batch 77/235] [D loss: 1.130177, acc: 85.55%] [G loss: 1.290619]\n",
      "[Epoch 19/50] [Batch 78/235] [D loss: 1.131738, acc: 85.35%] [G loss: 1.202811]\n",
      "[Epoch 19/50] [Batch 79/235] [D loss: 1.075460, acc: 84.96%] [G loss: 1.293459]\n",
      "[Epoch 19/50] [Batch 80/235] [D loss: 1.098117, acc: 86.72%] [G loss: 1.346995]\n",
      "[Epoch 19/50] [Batch 81/235] [D loss: 1.146858, acc: 85.55%] [G loss: 1.110100]\n",
      "[Epoch 19/50] [Batch 82/235] [D loss: 1.095119, acc: 86.91%] [G loss: 1.258077]\n",
      "[Epoch 19/50] [Batch 83/235] [D loss: 1.135058, acc: 85.35%] [G loss: 1.178579]\n",
      "[Epoch 19/50] [Batch 84/235] [D loss: 1.160626, acc: 86.72%] [G loss: 1.243917]\n",
      "[Epoch 19/50] [Batch 85/235] [D loss: 1.110827, acc: 87.50%] [G loss: 1.128788]\n",
      "[Epoch 19/50] [Batch 86/235] [D loss: 1.118692, acc: 85.55%] [G loss: 1.170138]\n",
      "[Epoch 19/50] [Batch 87/235] [D loss: 1.109293, acc: 85.35%] [G loss: 1.176382]\n",
      "[Epoch 19/50] [Batch 88/235] [D loss: 1.067096, acc: 86.33%] [G loss: 1.262592]\n",
      "[Epoch 19/50] [Batch 89/235] [D loss: 1.153704, acc: 84.96%] [G loss: 1.176908]\n",
      "[Epoch 19/50] [Batch 90/235] [D loss: 1.083874, acc: 86.13%] [G loss: 1.197245]\n",
      "[Epoch 19/50] [Batch 91/235] [D loss: 1.146076, acc: 86.33%] [G loss: 1.216717]\n",
      "[Epoch 19/50] [Batch 92/235] [D loss: 1.079413, acc: 89.06%] [G loss: 1.307593]\n",
      "[Epoch 19/50] [Batch 93/235] [D loss: 1.089849, acc: 85.16%] [G loss: 1.197053]\n",
      "[Epoch 19/50] [Batch 94/235] [D loss: 1.127220, acc: 86.52%] [G loss: 1.155166]\n",
      "[Epoch 19/50] [Batch 95/235] [D loss: 1.153135, acc: 82.62%] [G loss: 1.113597]\n",
      "[Epoch 19/50] [Batch 96/235] [D loss: 1.137156, acc: 86.52%] [G loss: 1.244987]\n",
      "[Epoch 19/50] [Batch 97/235] [D loss: 1.112241, acc: 86.72%] [G loss: 1.182382]\n",
      "[Epoch 19/50] [Batch 98/235] [D loss: 1.130837, acc: 85.16%] [G loss: 1.199890]\n",
      "[Epoch 19/50] [Batch 99/235] [D loss: 1.143356, acc: 88.28%] [G loss: 1.319889]\n",
      "[Epoch 19/50] [Batch 100/235] [D loss: 1.175419, acc: 85.94%] [G loss: 1.166935]\n",
      "[Epoch 19/50] [Batch 101/235] [D loss: 1.111066, acc: 87.30%] [G loss: 1.144775]\n",
      "[Epoch 19/50] [Batch 102/235] [D loss: 1.136889, acc: 85.74%] [G loss: 1.259867]\n",
      "[Epoch 19/50] [Batch 103/235] [D loss: 1.128446, acc: 86.52%] [G loss: 1.242331]\n",
      "[Epoch 19/50] [Batch 104/235] [D loss: 1.076964, acc: 86.13%] [G loss: 1.208277]\n",
      "[Epoch 19/50] [Batch 105/235] [D loss: 1.070037, acc: 87.11%] [G loss: 1.173704]\n",
      "[Epoch 19/50] [Batch 106/235] [D loss: 1.134672, acc: 85.35%] [G loss: 1.232636]\n",
      "[Epoch 19/50] [Batch 107/235] [D loss: 1.167209, acc: 85.55%] [G loss: 1.111368]\n",
      "[Epoch 19/50] [Batch 108/235] [D loss: 1.151013, acc: 85.35%] [G loss: 1.138644]\n",
      "[Epoch 19/50] [Batch 109/235] [D loss: 1.123569, acc: 84.96%] [G loss: 1.182470]\n",
      "[Epoch 19/50] [Batch 110/235] [D loss: 1.063921, acc: 85.74%] [G loss: 1.258703]\n",
      "[Epoch 19/50] [Batch 111/235] [D loss: 1.184453, acc: 83.98%] [G loss: 1.275471]\n",
      "[Epoch 19/50] [Batch 112/235] [D loss: 1.137583, acc: 89.26%] [G loss: 1.237611]\n",
      "[Epoch 19/50] [Batch 113/235] [D loss: 1.088004, acc: 86.52%] [G loss: 1.115745]\n",
      "[Epoch 19/50] [Batch 114/235] [D loss: 1.126329, acc: 85.74%] [G loss: 1.142524]\n",
      "[Epoch 19/50] [Batch 115/235] [D loss: 1.121106, acc: 84.38%] [G loss: 1.192460]\n",
      "[Epoch 19/50] [Batch 116/235] [D loss: 1.205960, acc: 81.84%] [G loss: 1.120003]\n",
      "[Epoch 19/50] [Batch 117/235] [D loss: 1.100814, acc: 85.35%] [G loss: 1.059432]\n",
      "[Epoch 19/50] [Batch 118/235] [D loss: 1.106579, acc: 85.94%] [G loss: 1.104801]\n",
      "[Epoch 19/50] [Batch 119/235] [D loss: 1.086912, acc: 85.74%] [G loss: 1.251643]\n",
      "[Epoch 19/50] [Batch 120/235] [D loss: 1.119845, acc: 84.18%] [G loss: 1.227432]\n",
      "[Epoch 19/50] [Batch 121/235] [D loss: 1.145114, acc: 88.09%] [G loss: 1.177672]\n",
      "[Epoch 19/50] [Batch 122/235] [D loss: 1.105603, acc: 87.30%] [G loss: 1.070427]\n",
      "[Epoch 19/50] [Batch 123/235] [D loss: 1.153867, acc: 84.18%] [G loss: 1.045685]\n",
      "[Epoch 19/50] [Batch 124/235] [D loss: 1.104113, acc: 90.82%] [G loss: 1.239458]\n",
      "[Epoch 19/50] [Batch 125/235] [D loss: 1.132001, acc: 83.79%] [G loss: 1.213577]\n",
      "[Epoch 19/50] [Batch 126/235] [D loss: 1.111314, acc: 86.13%] [G loss: 1.269523]\n",
      "[Epoch 19/50] [Batch 127/235] [D loss: 1.131247, acc: 84.18%] [G loss: 1.314740]\n",
      "[Epoch 19/50] [Batch 128/235] [D loss: 1.170666, acc: 85.94%] [G loss: 1.134585]\n",
      "[Epoch 19/50] [Batch 129/235] [D loss: 1.104464, acc: 84.77%] [G loss: 1.103377]\n",
      "[Epoch 19/50] [Batch 130/235] [D loss: 1.134326, acc: 86.33%] [G loss: 1.288749]\n",
      "[Epoch 19/50] [Batch 131/235] [D loss: 1.174051, acc: 84.18%] [G loss: 1.190013]\n",
      "[Epoch 19/50] [Batch 132/235] [D loss: 1.146159, acc: 85.74%] [G loss: 1.241593]\n",
      "[Epoch 19/50] [Batch 133/235] [D loss: 1.141819, acc: 80.66%] [G loss: 1.130979]\n",
      "[Epoch 19/50] [Batch 134/235] [D loss: 1.093762, acc: 87.30%] [G loss: 1.145048]\n",
      "[Epoch 19/50] [Batch 135/235] [D loss: 1.154083, acc: 87.89%] [G loss: 1.136279]\n",
      "[Epoch 19/50] [Batch 136/235] [D loss: 1.158129, acc: 84.96%] [G loss: 1.245191]\n",
      "[Epoch 19/50] [Batch 137/235] [D loss: 1.077904, acc: 85.16%] [G loss: 1.235062]\n",
      "[Epoch 19/50] [Batch 138/235] [D loss: 1.055386, acc: 85.16%] [G loss: 1.170518]\n",
      "[Epoch 19/50] [Batch 139/235] [D loss: 1.151269, acc: 85.16%] [G loss: 1.120003]\n",
      "[Epoch 19/50] [Batch 140/235] [D loss: 1.081515, acc: 86.33%] [G loss: 1.284427]\n",
      "[Epoch 19/50] [Batch 141/235] [D loss: 1.101657, acc: 87.50%] [G loss: 1.121846]\n",
      "[Epoch 19/50] [Batch 142/235] [D loss: 1.073436, acc: 86.33%] [G loss: 1.156996]\n",
      "[Epoch 19/50] [Batch 143/235] [D loss: 1.129774, acc: 84.57%] [G loss: 1.142854]\n",
      "[Epoch 19/50] [Batch 144/235] [D loss: 1.066988, acc: 88.09%] [G loss: 1.239381]\n",
      "[Epoch 19/50] [Batch 145/235] [D loss: 1.147856, acc: 86.91%] [G loss: 1.169280]\n",
      "[Epoch 19/50] [Batch 146/235] [D loss: 1.070097, acc: 86.33%] [G loss: 1.127749]\n",
      "[Epoch 19/50] [Batch 147/235] [D loss: 1.133274, acc: 87.70%] [G loss: 1.219355]\n",
      "[Epoch 19/50] [Batch 148/235] [D loss: 1.183727, acc: 86.13%] [G loss: 1.213468]\n",
      "[Epoch 19/50] [Batch 149/235] [D loss: 1.126657, acc: 87.30%] [G loss: 1.126135]\n",
      "[Epoch 19/50] [Batch 150/235] [D loss: 1.136014, acc: 86.33%] [G loss: 1.107512]\n",
      "[Epoch 19/50] [Batch 151/235] [D loss: 1.093012, acc: 83.59%] [G loss: 1.191749]\n",
      "[Epoch 19/50] [Batch 152/235] [D loss: 1.131204, acc: 85.55%] [G loss: 1.208122]\n",
      "[Epoch 19/50] [Batch 153/235] [D loss: 1.096236, acc: 86.52%] [G loss: 1.181731]\n",
      "[Epoch 19/50] [Batch 154/235] [D loss: 1.092831, acc: 86.72%] [G loss: 1.156209]\n",
      "[Epoch 19/50] [Batch 155/235] [D loss: 1.109917, acc: 86.91%] [G loss: 1.124917]\n",
      "[Epoch 19/50] [Batch 156/235] [D loss: 1.118737, acc: 86.91%] [G loss: 1.128622]\n",
      "[Epoch 19/50] [Batch 157/235] [D loss: 1.135035, acc: 85.94%] [G loss: 1.210713]\n",
      "[Epoch 19/50] [Batch 158/235] [D loss: 1.074958, acc: 87.11%] [G loss: 1.300363]\n",
      "[Epoch 19/50] [Batch 159/235] [D loss: 1.080236, acc: 85.74%] [G loss: 1.152528]\n",
      "[Epoch 19/50] [Batch 160/235] [D loss: 1.133481, acc: 86.72%] [G loss: 1.094239]\n",
      "[Epoch 19/50] [Batch 161/235] [D loss: 1.115467, acc: 87.11%] [G loss: 1.163577]\n",
      "[Epoch 19/50] [Batch 162/235] [D loss: 1.134849, acc: 84.38%] [G loss: 1.112604]\n",
      "[Epoch 19/50] [Batch 163/235] [D loss: 1.092326, acc: 87.89%] [G loss: 1.191226]\n",
      "[Epoch 19/50] [Batch 164/235] [D loss: 1.071824, acc: 85.94%] [G loss: 1.210807]\n",
      "[Epoch 19/50] [Batch 165/235] [D loss: 1.124600, acc: 86.33%] [G loss: 1.229055]\n",
      "[Epoch 19/50] [Batch 166/235] [D loss: 1.147768, acc: 85.94%] [G loss: 1.139458]\n",
      "[Epoch 19/50] [Batch 167/235] [D loss: 1.145778, acc: 84.96%] [G loss: 1.307570]\n",
      "[Epoch 19/50] [Batch 168/235] [D loss: 1.167488, acc: 83.98%] [G loss: 1.158432]\n",
      "[Epoch 19/50] [Batch 169/235] [D loss: 1.090788, acc: 85.74%] [G loss: 1.243621]\n",
      "[Epoch 19/50] [Batch 170/235] [D loss: 1.093828, acc: 83.98%] [G loss: 1.133072]\n",
      "[Epoch 19/50] [Batch 171/235] [D loss: 1.105969, acc: 87.89%] [G loss: 1.134962]\n",
      "[Epoch 19/50] [Batch 172/235] [D loss: 1.122739, acc: 88.28%] [G loss: 1.094702]\n",
      "[Epoch 19/50] [Batch 173/235] [D loss: 1.090287, acc: 83.98%] [G loss: 1.114190]\n",
      "[Epoch 19/50] [Batch 174/235] [D loss: 1.128683, acc: 84.96%] [G loss: 1.141079]\n",
      "[Epoch 19/50] [Batch 175/235] [D loss: 1.131955, acc: 85.94%] [G loss: 1.145218]\n",
      "[Epoch 19/50] [Batch 176/235] [D loss: 1.101024, acc: 85.55%] [G loss: 1.230028]\n",
      "[Epoch 19/50] [Batch 177/235] [D loss: 1.099833, acc: 84.57%] [G loss: 1.134405]\n",
      "[Epoch 19/50] [Batch 178/235] [D loss: 1.149373, acc: 85.74%] [G loss: 1.121061]\n",
      "[Epoch 19/50] [Batch 179/235] [D loss: 1.091550, acc: 86.13%] [G loss: 1.293996]\n",
      "[Epoch 19/50] [Batch 180/235] [D loss: 1.147652, acc: 84.38%] [G loss: 1.155120]\n",
      "[Epoch 19/50] [Batch 181/235] [D loss: 1.105308, acc: 85.55%] [G loss: 1.171307]\n",
      "[Epoch 19/50] [Batch 182/235] [D loss: 1.083037, acc: 85.16%] [G loss: 1.212055]\n",
      "[Epoch 19/50] [Batch 183/235] [D loss: 1.138462, acc: 86.13%] [G loss: 1.106826]\n",
      "[Epoch 19/50] [Batch 184/235] [D loss: 1.109399, acc: 85.94%] [G loss: 1.284803]\n",
      "[Epoch 19/50] [Batch 185/235] [D loss: 1.099305, acc: 85.94%] [G loss: 1.314171]\n",
      "[Epoch 19/50] [Batch 186/235] [D loss: 1.137774, acc: 85.16%] [G loss: 1.073691]\n",
      "[Epoch 19/50] [Batch 187/235] [D loss: 1.120159, acc: 84.77%] [G loss: 1.164521]\n",
      "[Epoch 19/50] [Batch 188/235] [D loss: 1.129934, acc: 85.94%] [G loss: 1.025560]\n",
      "[Epoch 19/50] [Batch 189/235] [D loss: 1.059474, acc: 87.11%] [G loss: 1.125068]\n",
      "[Epoch 19/50] [Batch 190/235] [D loss: 1.114431, acc: 85.35%] [G loss: 1.179817]\n",
      "[Epoch 19/50] [Batch 191/235] [D loss: 1.139355, acc: 85.74%] [G loss: 1.235883]\n",
      "[Epoch 19/50] [Batch 192/235] [D loss: 1.158161, acc: 85.74%] [G loss: 1.175924]\n",
      "[Epoch 19/50] [Batch 193/235] [D loss: 1.118307, acc: 86.13%] [G loss: 1.146293]\n",
      "[Epoch 19/50] [Batch 194/235] [D loss: 1.092904, acc: 87.70%] [G loss: 1.183991]\n",
      "[Epoch 19/50] [Batch 195/235] [D loss: 1.108165, acc: 88.28%] [G loss: 1.183948]\n",
      "[Epoch 19/50] [Batch 196/235] [D loss: 1.116365, acc: 87.11%] [G loss: 1.238190]\n",
      "[Epoch 19/50] [Batch 197/235] [D loss: 1.110763, acc: 87.11%] [G loss: 1.187345]\n",
      "[Epoch 19/50] [Batch 198/235] [D loss: 1.091858, acc: 89.06%] [G loss: 1.177845]\n",
      "[Epoch 19/50] [Batch 199/235] [D loss: 1.104465, acc: 87.50%] [G loss: 1.172612]\n",
      "[Epoch 19/50] [Batch 200/235] [D loss: 1.078881, acc: 85.16%] [G loss: 1.186219]\n",
      "[Epoch 19/50] [Batch 201/235] [D loss: 1.181748, acc: 87.50%] [G loss: 1.225432]\n",
      "[Epoch 19/50] [Batch 202/235] [D loss: 1.146157, acc: 85.94%] [G loss: 1.199736]\n",
      "[Epoch 19/50] [Batch 203/235] [D loss: 1.131849, acc: 85.74%] [G loss: 1.145450]\n",
      "[Epoch 19/50] [Batch 204/235] [D loss: 1.142929, acc: 86.91%] [G loss: 1.249668]\n",
      "[Epoch 19/50] [Batch 205/235] [D loss: 1.115863, acc: 84.96%] [G loss: 1.349763]\n",
      "[Epoch 19/50] [Batch 206/235] [D loss: 1.092588, acc: 85.94%] [G loss: 1.194647]\n",
      "[Epoch 19/50] [Batch 207/235] [D loss: 1.128538, acc: 84.18%] [G loss: 1.104975]\n",
      "[Epoch 19/50] [Batch 208/235] [D loss: 1.097858, acc: 84.77%] [G loss: 1.295537]\n",
      "[Epoch 19/50] [Batch 209/235] [D loss: 1.086638, acc: 82.81%] [G loss: 1.304770]\n",
      "[Epoch 19/50] [Batch 210/235] [D loss: 1.133991, acc: 87.50%] [G loss: 1.193726]\n",
      "[Epoch 19/50] [Batch 211/235] [D loss: 1.093866, acc: 86.91%] [G loss: 1.199846]\n",
      "[Epoch 19/50] [Batch 212/235] [D loss: 1.127824, acc: 85.74%] [G loss: 1.108341]\n",
      "[Epoch 19/50] [Batch 213/235] [D loss: 1.091680, acc: 85.55%] [G loss: 1.111696]\n",
      "[Epoch 19/50] [Batch 214/235] [D loss: 1.121430, acc: 86.13%] [G loss: 1.167841]\n",
      "[Epoch 19/50] [Batch 215/235] [D loss: 1.078127, acc: 84.38%] [G loss: 1.239950]\n",
      "[Epoch 19/50] [Batch 216/235] [D loss: 1.114484, acc: 84.77%] [G loss: 1.137792]\n",
      "[Epoch 19/50] [Batch 217/235] [D loss: 1.180550, acc: 83.79%] [G loss: 1.164057]\n",
      "[Epoch 19/50] [Batch 218/235] [D loss: 1.107844, acc: 86.52%] [G loss: 1.149578]\n",
      "[Epoch 19/50] [Batch 219/235] [D loss: 1.090807, acc: 86.72%] [G loss: 1.195513]\n",
      "[Epoch 19/50] [Batch 220/235] [D loss: 1.122698, acc: 82.62%] [G loss: 1.090039]\n",
      "[Epoch 19/50] [Batch 221/235] [D loss: 1.122319, acc: 86.33%] [G loss: 1.050856]\n",
      "[Epoch 19/50] [Batch 222/235] [D loss: 1.127318, acc: 86.13%] [G loss: 1.228479]\n",
      "[Epoch 19/50] [Batch 223/235] [D loss: 1.096073, acc: 86.13%] [G loss: 1.463798]\n",
      "[Epoch 19/50] [Batch 224/235] [D loss: 1.173007, acc: 85.55%] [G loss: 1.191955]\n",
      "[Epoch 19/50] [Batch 225/235] [D loss: 1.070791, acc: 86.33%] [G loss: 1.209168]\n",
      "[Epoch 19/50] [Batch 226/235] [D loss: 1.105404, acc: 84.57%] [G loss: 1.162902]\n",
      "[Epoch 19/50] [Batch 227/235] [D loss: 1.132499, acc: 84.57%] [G loss: 1.273167]\n",
      "[Epoch 19/50] [Batch 228/235] [D loss: 1.051347, acc: 85.55%] [G loss: 1.147998]\n",
      "[Epoch 19/50] [Batch 229/235] [D loss: 1.142403, acc: 86.91%] [G loss: 1.181252]\n",
      "[Epoch 19/50] [Batch 230/235] [D loss: 1.114737, acc: 87.50%] [G loss: 1.163525]\n",
      "[Epoch 19/50] [Batch 231/235] [D loss: 1.096226, acc: 86.52%] [G loss: 1.221091]\n",
      "[Epoch 19/50] [Batch 232/235] [D loss: 1.175471, acc: 86.52%] [G loss: 1.103648]\n",
      "[Epoch 19/50] [Batch 233/235] [D loss: 1.084675, acc: 85.55%] [G loss: 1.229254]\n",
      "[Epoch 19/50] [Batch 234/235] [D loss: 1.086897, acc: 85.94%] [G loss: 1.287478]\n",
      "[Epoch 20/50] [Batch 0/235] [D loss: 1.125223, acc: 83.79%] [G loss: 1.156772]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/50] [Batch 1/235] [D loss: 1.082232, acc: 86.33%] [G loss: 1.209180]\n",
      "[Epoch 20/50] [Batch 2/235] [D loss: 1.106302, acc: 85.16%] [G loss: 1.207093]\n",
      "[Epoch 20/50] [Batch 3/235] [D loss: 1.048550, acc: 86.13%] [G loss: 1.141152]\n",
      "[Epoch 20/50] [Batch 4/235] [D loss: 1.153392, acc: 88.67%] [G loss: 1.046684]\n",
      "[Epoch 20/50] [Batch 5/235] [D loss: 1.080487, acc: 88.28%] [G loss: 1.113887]\n",
      "[Epoch 20/50] [Batch 6/235] [D loss: 1.069294, acc: 84.77%] [G loss: 1.164180]\n",
      "[Epoch 20/50] [Batch 7/235] [D loss: 1.119070, acc: 89.06%] [G loss: 1.126721]\n",
      "[Epoch 20/50] [Batch 8/235] [D loss: 1.123852, acc: 85.35%] [G loss: 1.208720]\n",
      "[Epoch 20/50] [Batch 9/235] [D loss: 1.109645, acc: 86.52%] [G loss: 1.214203]\n",
      "[Epoch 20/50] [Batch 10/235] [D loss: 1.127565, acc: 86.52%] [G loss: 1.186697]\n",
      "[Epoch 20/50] [Batch 11/235] [D loss: 1.165793, acc: 85.35%] [G loss: 1.326317]\n",
      "[Epoch 20/50] [Batch 12/235] [D loss: 1.082704, acc: 84.96%] [G loss: 1.122762]\n",
      "[Epoch 20/50] [Batch 13/235] [D loss: 1.135138, acc: 85.74%] [G loss: 1.178963]\n",
      "[Epoch 20/50] [Batch 14/235] [D loss: 1.107263, acc: 88.09%] [G loss: 1.206496]\n",
      "[Epoch 20/50] [Batch 15/235] [D loss: 1.126290, acc: 87.70%] [G loss: 1.082000]\n",
      "[Epoch 20/50] [Batch 16/235] [D loss: 1.059295, acc: 88.67%] [G loss: 1.187739]\n",
      "[Epoch 20/50] [Batch 17/235] [D loss: 1.235542, acc: 83.98%] [G loss: 1.220555]\n",
      "[Epoch 20/50] [Batch 18/235] [D loss: 1.110560, acc: 84.18%] [G loss: 1.252327]\n",
      "[Epoch 20/50] [Batch 19/235] [D loss: 1.117262, acc: 89.26%] [G loss: 1.283193]\n",
      "[Epoch 20/50] [Batch 20/235] [D loss: 1.113133, acc: 87.30%] [G loss: 1.121147]\n",
      "[Epoch 20/50] [Batch 21/235] [D loss: 1.151882, acc: 86.33%] [G loss: 1.030201]\n",
      "[Epoch 20/50] [Batch 22/235] [D loss: 1.082112, acc: 86.91%] [G loss: 1.211044]\n",
      "[Epoch 20/50] [Batch 23/235] [D loss: 1.135285, acc: 87.50%] [G loss: 1.325027]\n",
      "[Epoch 20/50] [Batch 24/235] [D loss: 1.116664, acc: 87.89%] [G loss: 1.210792]\n",
      "[Epoch 20/50] [Batch 25/235] [D loss: 1.094732, acc: 85.55%] [G loss: 1.139369]\n",
      "[Epoch 20/50] [Batch 26/235] [D loss: 1.124725, acc: 87.11%] [G loss: 1.113010]\n",
      "[Epoch 20/50] [Batch 27/235] [D loss: 1.125324, acc: 86.13%] [G loss: 1.287013]\n",
      "[Epoch 20/50] [Batch 28/235] [D loss: 1.107351, acc: 86.91%] [G loss: 1.278238]\n",
      "[Epoch 20/50] [Batch 29/235] [D loss: 1.154787, acc: 84.18%] [G loss: 1.093870]\n",
      "[Epoch 20/50] [Batch 30/235] [D loss: 1.130600, acc: 87.11%] [G loss: 1.203542]\n",
      "[Epoch 20/50] [Batch 31/235] [D loss: 1.139123, acc: 85.55%] [G loss: 1.065886]\n",
      "[Epoch 20/50] [Batch 32/235] [D loss: 1.071410, acc: 84.77%] [G loss: 1.142523]\n",
      "[Epoch 20/50] [Batch 33/235] [D loss: 1.144179, acc: 87.70%] [G loss: 1.194743]\n",
      "[Epoch 20/50] [Batch 34/235] [D loss: 1.106409, acc: 83.40%] [G loss: 1.177470]\n",
      "[Epoch 20/50] [Batch 35/235] [D loss: 1.172134, acc: 84.38%] [G loss: 1.079066]\n",
      "[Epoch 20/50] [Batch 36/235] [D loss: 1.099241, acc: 84.96%] [G loss: 1.206203]\n",
      "[Epoch 20/50] [Batch 37/235] [D loss: 1.095127, acc: 86.91%] [G loss: 1.159581]\n",
      "[Epoch 20/50] [Batch 38/235] [D loss: 1.100740, acc: 84.38%] [G loss: 1.108987]\n",
      "[Epoch 20/50] [Batch 39/235] [D loss: 1.128768, acc: 83.59%] [G loss: 1.252403]\n",
      "[Epoch 20/50] [Batch 40/235] [D loss: 1.087338, acc: 85.94%] [G loss: 1.130257]\n",
      "[Epoch 20/50] [Batch 41/235] [D loss: 1.081230, acc: 87.30%] [G loss: 1.372666]\n",
      "[Epoch 20/50] [Batch 42/235] [D loss: 1.127752, acc: 86.91%] [G loss: 1.113443]\n",
      "[Epoch 20/50] [Batch 43/235] [D loss: 1.088855, acc: 85.74%] [G loss: 1.102488]\n",
      "[Epoch 20/50] [Batch 44/235] [D loss: 1.085555, acc: 85.16%] [G loss: 1.247590]\n",
      "[Epoch 20/50] [Batch 45/235] [D loss: 1.085807, acc: 85.74%] [G loss: 1.348840]\n",
      "[Epoch 20/50] [Batch 46/235] [D loss: 1.128775, acc: 85.35%] [G loss: 1.233170]\n",
      "[Epoch 20/50] [Batch 47/235] [D loss: 1.145781, acc: 87.70%] [G loss: 1.224816]\n",
      "[Epoch 20/50] [Batch 48/235] [D loss: 1.114177, acc: 86.33%] [G loss: 1.027543]\n",
      "[Epoch 20/50] [Batch 49/235] [D loss: 1.044842, acc: 85.35%] [G loss: 1.085720]\n",
      "[Epoch 20/50] [Batch 50/235] [D loss: 1.099242, acc: 86.91%] [G loss: 1.153104]\n",
      "[Epoch 20/50] [Batch 51/235] [D loss: 1.115707, acc: 86.91%] [G loss: 1.189160]\n",
      "[Epoch 20/50] [Batch 52/235] [D loss: 1.110464, acc: 83.40%] [G loss: 1.062830]\n",
      "[Epoch 20/50] [Batch 53/235] [D loss: 1.112688, acc: 86.33%] [G loss: 1.056519]\n",
      "[Epoch 20/50] [Batch 54/235] [D loss: 1.131269, acc: 85.16%] [G loss: 1.347652]\n",
      "[Epoch 20/50] [Batch 55/235] [D loss: 1.091810, acc: 84.18%] [G loss: 1.106047]\n",
      "[Epoch 20/50] [Batch 56/235] [D loss: 1.131769, acc: 85.94%] [G loss: 1.117019]\n",
      "[Epoch 20/50] [Batch 57/235] [D loss: 1.093336, acc: 85.35%] [G loss: 1.345637]\n",
      "[Epoch 20/50] [Batch 58/235] [D loss: 1.131953, acc: 86.13%] [G loss: 1.239488]\n",
      "[Epoch 20/50] [Batch 59/235] [D loss: 1.115314, acc: 87.11%] [G loss: 1.416138]\n",
      "[Epoch 20/50] [Batch 60/235] [D loss: 1.172426, acc: 85.74%] [G loss: 1.118294]\n",
      "[Epoch 20/50] [Batch 61/235] [D loss: 1.078042, acc: 86.13%] [G loss: 1.085517]\n",
      "[Epoch 20/50] [Batch 62/235] [D loss: 1.177349, acc: 87.30%] [G loss: 1.121391]\n",
      "[Epoch 20/50] [Batch 63/235] [D loss: 1.096027, acc: 86.13%] [G loss: 1.331061]\n",
      "[Epoch 20/50] [Batch 64/235] [D loss: 1.158247, acc: 86.91%] [G loss: 1.204030]\n",
      "[Epoch 20/50] [Batch 65/235] [D loss: 1.144288, acc: 87.50%] [G loss: 1.132323]\n",
      "[Epoch 20/50] [Batch 66/235] [D loss: 1.151591, acc: 85.55%] [G loss: 1.203467]\n",
      "[Epoch 20/50] [Batch 67/235] [D loss: 1.155188, acc: 86.33%] [G loss: 1.235995]\n",
      "[Epoch 20/50] [Batch 68/235] [D loss: 1.108497, acc: 86.33%] [G loss: 1.154723]\n",
      "[Epoch 20/50] [Batch 69/235] [D loss: 1.174722, acc: 83.59%] [G loss: 1.046136]\n",
      "[Epoch 20/50] [Batch 70/235] [D loss: 1.101439, acc: 85.16%] [G loss: 1.078835]\n",
      "[Epoch 20/50] [Batch 71/235] [D loss: 1.150219, acc: 84.18%] [G loss: 1.184807]\n",
      "[Epoch 20/50] [Batch 72/235] [D loss: 1.074257, acc: 88.09%] [G loss: 1.196133]\n",
      "[Epoch 20/50] [Batch 73/235] [D loss: 1.099357, acc: 86.52%] [G loss: 1.254009]\n",
      "[Epoch 20/50] [Batch 74/235] [D loss: 1.083219, acc: 87.30%] [G loss: 1.103505]\n",
      "[Epoch 20/50] [Batch 75/235] [D loss: 1.072276, acc: 84.57%] [G loss: 1.231173]\n",
      "[Epoch 20/50] [Batch 76/235] [D loss: 1.084033, acc: 83.98%] [G loss: 1.247551]\n",
      "[Epoch 20/50] [Batch 77/235] [D loss: 1.118612, acc: 88.09%] [G loss: 1.235057]\n",
      "[Epoch 20/50] [Batch 78/235] [D loss: 1.100467, acc: 85.94%] [G loss: 1.198679]\n",
      "[Epoch 20/50] [Batch 79/235] [D loss: 1.109766, acc: 88.28%] [G loss: 1.193707]\n",
      "[Epoch 20/50] [Batch 80/235] [D loss: 1.079900, acc: 86.33%] [G loss: 1.060086]\n",
      "[Epoch 20/50] [Batch 81/235] [D loss: 1.161726, acc: 85.35%] [G loss: 1.044361]\n",
      "[Epoch 20/50] [Batch 82/235] [D loss: 1.107788, acc: 87.70%] [G loss: 1.275614]\n",
      "[Epoch 20/50] [Batch 83/235] [D loss: 1.095219, acc: 86.72%] [G loss: 1.277905]\n",
      "[Epoch 20/50] [Batch 84/235] [D loss: 1.144986, acc: 85.94%] [G loss: 1.141032]\n",
      "[Epoch 20/50] [Batch 85/235] [D loss: 1.104499, acc: 87.30%] [G loss: 1.144564]\n",
      "[Epoch 20/50] [Batch 86/235] [D loss: 1.124938, acc: 84.96%] [G loss: 1.237495]\n",
      "[Epoch 20/50] [Batch 87/235] [D loss: 1.143868, acc: 84.96%] [G loss: 1.352620]\n",
      "[Epoch 20/50] [Batch 88/235] [D loss: 1.098841, acc: 85.16%] [G loss: 1.179724]\n",
      "[Epoch 20/50] [Batch 89/235] [D loss: 1.138260, acc: 86.13%] [G loss: 1.144779]\n",
      "[Epoch 20/50] [Batch 90/235] [D loss: 1.087896, acc: 85.94%] [G loss: 1.147745]\n",
      "[Epoch 20/50] [Batch 91/235] [D loss: 1.162026, acc: 82.03%] [G loss: 1.207232]\n",
      "[Epoch 20/50] [Batch 92/235] [D loss: 1.131125, acc: 84.96%] [G loss: 1.210661]\n",
      "[Epoch 20/50] [Batch 93/235] [D loss: 1.072460, acc: 87.89%] [G loss: 1.198696]\n",
      "[Epoch 20/50] [Batch 94/235] [D loss: 1.132054, acc: 84.18%] [G loss: 1.241182]\n",
      "[Epoch 20/50] [Batch 95/235] [D loss: 1.084318, acc: 88.67%] [G loss: 1.226696]\n",
      "[Epoch 20/50] [Batch 96/235] [D loss: 1.097166, acc: 87.30%] [G loss: 1.100766]\n",
      "[Epoch 20/50] [Batch 97/235] [D loss: 1.176484, acc: 84.96%] [G loss: 1.123468]\n",
      "[Epoch 20/50] [Batch 98/235] [D loss: 1.111773, acc: 84.18%] [G loss: 1.262876]\n",
      "[Epoch 20/50] [Batch 99/235] [D loss: 1.166013, acc: 84.38%] [G loss: 1.117004]\n",
      "[Epoch 20/50] [Batch 100/235] [D loss: 1.108038, acc: 85.55%] [G loss: 1.077782]\n",
      "[Epoch 20/50] [Batch 101/235] [D loss: 1.178346, acc: 85.16%] [G loss: 1.009294]\n",
      "[Epoch 20/50] [Batch 102/235] [D loss: 1.129595, acc: 85.94%] [G loss: 1.360431]\n",
      "[Epoch 20/50] [Batch 103/235] [D loss: 1.161531, acc: 87.50%] [G loss: 1.161980]\n",
      "[Epoch 20/50] [Batch 104/235] [D loss: 1.148676, acc: 87.11%] [G loss: 1.121979]\n",
      "[Epoch 20/50] [Batch 105/235] [D loss: 1.142272, acc: 82.81%] [G loss: 1.315106]\n",
      "[Epoch 20/50] [Batch 106/235] [D loss: 1.116226, acc: 84.18%] [G loss: 1.145393]\n",
      "[Epoch 20/50] [Batch 107/235] [D loss: 1.113656, acc: 85.55%] [G loss: 1.080682]\n",
      "[Epoch 20/50] [Batch 108/235] [D loss: 1.118656, acc: 87.70%] [G loss: 1.104552]\n",
      "[Epoch 20/50] [Batch 109/235] [D loss: 1.107652, acc: 89.26%] [G loss: 1.114066]\n",
      "[Epoch 20/50] [Batch 110/235] [D loss: 1.131034, acc: 86.91%] [G loss: 1.158070]\n",
      "[Epoch 20/50] [Batch 111/235] [D loss: 1.106927, acc: 83.98%] [G loss: 1.150362]\n",
      "[Epoch 20/50] [Batch 112/235] [D loss: 1.180577, acc: 86.72%] [G loss: 1.077569]\n",
      "[Epoch 20/50] [Batch 113/235] [D loss: 1.120682, acc: 88.48%] [G loss: 1.316897]\n",
      "[Epoch 20/50] [Batch 114/235] [D loss: 1.131117, acc: 83.59%] [G loss: 1.309797]\n",
      "[Epoch 20/50] [Batch 115/235] [D loss: 1.161458, acc: 83.20%] [G loss: 1.178563]\n",
      "[Epoch 20/50] [Batch 116/235] [D loss: 1.205789, acc: 86.72%] [G loss: 1.079007]\n",
      "[Epoch 20/50] [Batch 117/235] [D loss: 1.077782, acc: 86.52%] [G loss: 1.255713]\n",
      "[Epoch 20/50] [Batch 118/235] [D loss: 1.091147, acc: 87.30%] [G loss: 1.118891]\n",
      "[Epoch 20/50] [Batch 119/235] [D loss: 1.114115, acc: 87.30%] [G loss: 1.153109]\n",
      "[Epoch 20/50] [Batch 120/235] [D loss: 1.149363, acc: 85.55%] [G loss: 1.132562]\n",
      "[Epoch 20/50] [Batch 121/235] [D loss: 1.089822, acc: 86.91%] [G loss: 1.072747]\n",
      "[Epoch 20/50] [Batch 122/235] [D loss: 1.086512, acc: 85.55%] [G loss: 1.376764]\n",
      "[Epoch 20/50] [Batch 123/235] [D loss: 1.119270, acc: 86.13%] [G loss: 1.177322]\n",
      "[Epoch 20/50] [Batch 124/235] [D loss: 1.083269, acc: 85.94%] [G loss: 1.152053]\n",
      "[Epoch 20/50] [Batch 125/235] [D loss: 1.147538, acc: 85.35%] [G loss: 1.121921]\n",
      "[Epoch 20/50] [Batch 126/235] [D loss: 1.112088, acc: 88.87%] [G loss: 1.159279]\n",
      "[Epoch 20/50] [Batch 127/235] [D loss: 1.125354, acc: 87.30%] [G loss: 1.152154]\n",
      "[Epoch 20/50] [Batch 128/235] [D loss: 1.118538, acc: 87.70%] [G loss: 1.165947]\n",
      "[Epoch 20/50] [Batch 129/235] [D loss: 1.068295, acc: 88.28%] [G loss: 1.092807]\n",
      "[Epoch 20/50] [Batch 130/235] [D loss: 1.126210, acc: 87.50%] [G loss: 1.138475]\n",
      "[Epoch 20/50] [Batch 131/235] [D loss: 1.109601, acc: 84.96%] [G loss: 1.170107]\n",
      "[Epoch 20/50] [Batch 132/235] [D loss: 1.200808, acc: 85.35%] [G loss: 1.244918]\n",
      "[Epoch 20/50] [Batch 133/235] [D loss: 1.134269, acc: 85.74%] [G loss: 1.179957]\n",
      "[Epoch 20/50] [Batch 134/235] [D loss: 1.089938, acc: 86.33%] [G loss: 1.090999]\n",
      "[Epoch 20/50] [Batch 135/235] [D loss: 1.105202, acc: 88.09%] [G loss: 1.227511]\n",
      "[Epoch 20/50] [Batch 136/235] [D loss: 1.153458, acc: 87.89%] [G loss: 1.137309]\n",
      "[Epoch 20/50] [Batch 137/235] [D loss: 1.146583, acc: 86.72%] [G loss: 1.139659]\n",
      "[Epoch 20/50] [Batch 138/235] [D loss: 1.156119, acc: 85.74%] [G loss: 1.201011]\n",
      "[Epoch 20/50] [Batch 139/235] [D loss: 1.116980, acc: 86.72%] [G loss: 1.228279]\n",
      "[Epoch 20/50] [Batch 140/235] [D loss: 1.177500, acc: 84.38%] [G loss: 1.223329]\n",
      "[Epoch 20/50] [Batch 141/235] [D loss: 1.112971, acc: 87.50%] [G loss: 1.169010]\n",
      "[Epoch 20/50] [Batch 142/235] [D loss: 1.122230, acc: 86.13%] [G loss: 1.156328]\n",
      "[Epoch 20/50] [Batch 143/235] [D loss: 1.110136, acc: 86.72%] [G loss: 1.165942]\n",
      "[Epoch 20/50] [Batch 144/235] [D loss: 1.112679, acc: 87.89%] [G loss: 1.153326]\n",
      "[Epoch 20/50] [Batch 145/235] [D loss: 1.121606, acc: 86.52%] [G loss: 1.232547]\n",
      "[Epoch 20/50] [Batch 146/235] [D loss: 1.141585, acc: 86.91%] [G loss: 1.134271]\n",
      "[Epoch 20/50] [Batch 147/235] [D loss: 1.116938, acc: 85.74%] [G loss: 1.243519]\n",
      "[Epoch 20/50] [Batch 148/235] [D loss: 1.065601, acc: 87.30%] [G loss: 1.206770]\n",
      "[Epoch 20/50] [Batch 149/235] [D loss: 1.117827, acc: 87.11%] [G loss: 1.005222]\n",
      "[Epoch 20/50] [Batch 150/235] [D loss: 1.120561, acc: 84.96%] [G loss: 1.109911]\n",
      "[Epoch 20/50] [Batch 151/235] [D loss: 1.090670, acc: 85.74%] [G loss: 1.260801]\n",
      "[Epoch 20/50] [Batch 152/235] [D loss: 1.127714, acc: 85.55%] [G loss: 1.238806]\n",
      "[Epoch 20/50] [Batch 153/235] [D loss: 1.068210, acc: 86.52%] [G loss: 1.125623]\n",
      "[Epoch 20/50] [Batch 154/235] [D loss: 1.089437, acc: 86.52%] [G loss: 1.146258]\n",
      "[Epoch 20/50] [Batch 155/235] [D loss: 1.125752, acc: 83.98%] [G loss: 1.225705]\n",
      "[Epoch 20/50] [Batch 156/235] [D loss: 1.102481, acc: 86.91%] [G loss: 1.120432]\n",
      "[Epoch 20/50] [Batch 157/235] [D loss: 1.082217, acc: 85.55%] [G loss: 0.999690]\n",
      "[Epoch 20/50] [Batch 158/235] [D loss: 1.220664, acc: 85.55%] [G loss: 1.255428]\n",
      "[Epoch 20/50] [Batch 159/235] [D loss: 1.114907, acc: 87.11%] [G loss: 1.290117]\n",
      "[Epoch 20/50] [Batch 160/235] [D loss: 1.131454, acc: 85.55%] [G loss: 1.137127]\n",
      "[Epoch 20/50] [Batch 161/235] [D loss: 1.136375, acc: 84.77%] [G loss: 1.157051]\n",
      "[Epoch 20/50] [Batch 162/235] [D loss: 1.118941, acc: 85.35%] [G loss: 1.137727]\n",
      "[Epoch 20/50] [Batch 163/235] [D loss: 1.177183, acc: 85.74%] [G loss: 1.211481]\n",
      "[Epoch 20/50] [Batch 164/235] [D loss: 1.139171, acc: 83.40%] [G loss: 1.013718]\n",
      "[Epoch 20/50] [Batch 165/235] [D loss: 1.121400, acc: 83.98%] [G loss: 1.178268]\n",
      "[Epoch 20/50] [Batch 166/235] [D loss: 1.134244, acc: 86.33%] [G loss: 1.336181]\n",
      "[Epoch 20/50] [Batch 167/235] [D loss: 1.100811, acc: 85.16%] [G loss: 1.097127]\n",
      "[Epoch 20/50] [Batch 168/235] [D loss: 1.130811, acc: 84.38%] [G loss: 1.063107]\n",
      "[Epoch 20/50] [Batch 169/235] [D loss: 1.120962, acc: 86.33%] [G loss: 1.198295]\n",
      "[Epoch 20/50] [Batch 170/235] [D loss: 1.139976, acc: 85.35%] [G loss: 1.237703]\n",
      "[Epoch 20/50] [Batch 171/235] [D loss: 1.119408, acc: 84.57%] [G loss: 1.120196]\n",
      "[Epoch 20/50] [Batch 172/235] [D loss: 1.110413, acc: 88.09%] [G loss: 1.134889]\n",
      "[Epoch 20/50] [Batch 173/235] [D loss: 1.129116, acc: 84.77%] [G loss: 1.197341]\n",
      "[Epoch 20/50] [Batch 174/235] [D loss: 1.129396, acc: 88.48%] [G loss: 1.303228]\n",
      "[Epoch 20/50] [Batch 175/235] [D loss: 1.114159, acc: 86.52%] [G loss: 1.239733]\n",
      "[Epoch 20/50] [Batch 176/235] [D loss: 1.113399, acc: 84.77%] [G loss: 1.019724]\n",
      "[Epoch 20/50] [Batch 177/235] [D loss: 1.174093, acc: 84.57%] [G loss: 1.109387]\n",
      "[Epoch 20/50] [Batch 178/235] [D loss: 1.128401, acc: 85.94%] [G loss: 1.243155]\n",
      "[Epoch 20/50] [Batch 179/235] [D loss: 1.092207, acc: 85.55%] [G loss: 1.274114]\n",
      "[Epoch 20/50] [Batch 180/235] [D loss: 1.090546, acc: 88.09%] [G loss: 1.176844]\n",
      "[Epoch 20/50] [Batch 181/235] [D loss: 1.078154, acc: 88.28%] [G loss: 1.168416]\n",
      "[Epoch 20/50] [Batch 182/235] [D loss: 1.162729, acc: 87.70%] [G loss: 1.094018]\n",
      "[Epoch 20/50] [Batch 183/235] [D loss: 1.124661, acc: 84.57%] [G loss: 1.263705]\n",
      "[Epoch 20/50] [Batch 184/235] [D loss: 1.153199, acc: 84.57%] [G loss: 1.206123]\n",
      "[Epoch 20/50] [Batch 185/235] [D loss: 1.187363, acc: 83.98%] [G loss: 1.102334]\n",
      "[Epoch 20/50] [Batch 186/235] [D loss: 1.110571, acc: 86.91%] [G loss: 1.151636]\n",
      "[Epoch 20/50] [Batch 187/235] [D loss: 1.127361, acc: 86.13%] [G loss: 1.282494]\n",
      "[Epoch 20/50] [Batch 188/235] [D loss: 1.156010, acc: 86.13%] [G loss: 1.143981]\n",
      "[Epoch 20/50] [Batch 189/235] [D loss: 1.057919, acc: 86.52%] [G loss: 1.162691]\n",
      "[Epoch 20/50] [Batch 190/235] [D loss: 1.124690, acc: 85.55%] [G loss: 1.151506]\n",
      "[Epoch 20/50] [Batch 191/235] [D loss: 1.100457, acc: 85.16%] [G loss: 1.080803]\n",
      "[Epoch 20/50] [Batch 192/235] [D loss: 1.103843, acc: 86.91%] [G loss: 1.047283]\n",
      "[Epoch 20/50] [Batch 193/235] [D loss: 1.148303, acc: 86.33%] [G loss: 1.227245]\n",
      "[Epoch 20/50] [Batch 194/235] [D loss: 1.143019, acc: 85.55%] [G loss: 1.173965]\n",
      "[Epoch 20/50] [Batch 195/235] [D loss: 1.125154, acc: 85.35%] [G loss: 1.289369]\n",
      "[Epoch 20/50] [Batch 196/235] [D loss: 1.068632, acc: 86.33%] [G loss: 1.310155]\n",
      "[Epoch 20/50] [Batch 197/235] [D loss: 1.143503, acc: 86.52%] [G loss: 1.171296]\n",
      "[Epoch 20/50] [Batch 198/235] [D loss: 1.163800, acc: 85.74%] [G loss: 1.144071]\n",
      "[Epoch 20/50] [Batch 199/235] [D loss: 1.128080, acc: 83.98%] [G loss: 1.356002]\n",
      "[Epoch 20/50] [Batch 200/235] [D loss: 1.132298, acc: 86.13%] [G loss: 1.209737]\n",
      "[Epoch 20/50] [Batch 201/235] [D loss: 1.163203, acc: 86.33%] [G loss: 1.100846]\n",
      "[Epoch 20/50] [Batch 202/235] [D loss: 1.158290, acc: 85.74%] [G loss: 1.443317]\n",
      "[Epoch 20/50] [Batch 203/235] [D loss: 1.071573, acc: 86.91%] [G loss: 1.124357]\n",
      "[Epoch 20/50] [Batch 204/235] [D loss: 1.084606, acc: 86.72%] [G loss: 1.268764]\n",
      "[Epoch 20/50] [Batch 205/235] [D loss: 1.104609, acc: 84.57%] [G loss: 1.180022]\n",
      "[Epoch 20/50] [Batch 206/235] [D loss: 1.140522, acc: 86.72%] [G loss: 1.260924]\n",
      "[Epoch 20/50] [Batch 207/235] [D loss: 1.094658, acc: 88.87%] [G loss: 1.196363]\n",
      "[Epoch 20/50] [Batch 208/235] [D loss: 1.081675, acc: 85.74%] [G loss: 1.278950]\n",
      "[Epoch 20/50] [Batch 209/235] [D loss: 1.104297, acc: 83.79%] [G loss: 1.219309]\n",
      "[Epoch 20/50] [Batch 210/235] [D loss: 1.101128, acc: 85.94%] [G loss: 1.032089]\n",
      "[Epoch 20/50] [Batch 211/235] [D loss: 1.098983, acc: 86.13%] [G loss: 1.144371]\n",
      "[Epoch 20/50] [Batch 212/235] [D loss: 1.139421, acc: 83.79%] [G loss: 1.172715]\n",
      "[Epoch 20/50] [Batch 213/235] [D loss: 1.064113, acc: 85.55%] [G loss: 1.245152]\n",
      "[Epoch 20/50] [Batch 214/235] [D loss: 1.102370, acc: 88.28%] [G loss: 1.256340]\n",
      "[Epoch 20/50] [Batch 215/235] [D loss: 1.196047, acc: 85.35%] [G loss: 1.096429]\n",
      "[Epoch 20/50] [Batch 216/235] [D loss: 1.109425, acc: 85.74%] [G loss: 1.220508]\n",
      "[Epoch 20/50] [Batch 217/235] [D loss: 1.067640, acc: 83.98%] [G loss: 1.089434]\n",
      "[Epoch 20/50] [Batch 218/235] [D loss: 1.100012, acc: 87.70%] [G loss: 1.129378]\n",
      "[Epoch 20/50] [Batch 219/235] [D loss: 1.137410, acc: 86.13%] [G loss: 1.208293]\n",
      "[Epoch 20/50] [Batch 220/235] [D loss: 1.117750, acc: 86.52%] [G loss: 1.139779]\n",
      "[Epoch 20/50] [Batch 221/235] [D loss: 1.193098, acc: 84.96%] [G loss: 1.082543]\n",
      "[Epoch 20/50] [Batch 222/235] [D loss: 1.070614, acc: 87.50%] [G loss: 1.237616]\n",
      "[Epoch 20/50] [Batch 223/235] [D loss: 1.125325, acc: 83.79%] [G loss: 1.204942]\n",
      "[Epoch 20/50] [Batch 224/235] [D loss: 1.137022, acc: 86.52%] [G loss: 1.150760]\n",
      "[Epoch 20/50] [Batch 225/235] [D loss: 1.082046, acc: 87.89%] [G loss: 1.244683]\n",
      "[Epoch 20/50] [Batch 226/235] [D loss: 1.140631, acc: 84.96%] [G loss: 1.172364]\n",
      "[Epoch 20/50] [Batch 227/235] [D loss: 1.155743, acc: 85.74%] [G loss: 1.017092]\n",
      "[Epoch 20/50] [Batch 228/235] [D loss: 1.077110, acc: 86.91%] [G loss: 1.109938]\n",
      "[Epoch 20/50] [Batch 229/235] [D loss: 1.151799, acc: 88.09%] [G loss: 1.070517]\n",
      "[Epoch 20/50] [Batch 230/235] [D loss: 1.081876, acc: 83.98%] [G loss: 1.246554]\n",
      "[Epoch 20/50] [Batch 231/235] [D loss: 1.080030, acc: 86.72%] [G loss: 1.174788]\n",
      "[Epoch 20/50] [Batch 232/235] [D loss: 1.072678, acc: 86.33%] [G loss: 1.202460]\n",
      "[Epoch 20/50] [Batch 233/235] [D loss: 1.102778, acc: 86.72%] [G loss: 1.259239]\n",
      "[Epoch 20/50] [Batch 234/235] [D loss: 1.056163, acc: 87.50%] [G loss: 1.170994]\n",
      "[Epoch 21/50] [Batch 0/235] [D loss: 1.098559, acc: 86.52%] [G loss: 1.207294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/50] [Batch 1/235] [D loss: 1.147161, acc: 86.52%] [G loss: 1.136312]\n",
      "[Epoch 21/50] [Batch 2/235] [D loss: 1.115477, acc: 83.20%] [G loss: 1.293877]\n",
      "[Epoch 21/50] [Batch 3/235] [D loss: 1.114076, acc: 88.48%] [G loss: 1.176876]\n",
      "[Epoch 21/50] [Batch 4/235] [D loss: 1.148409, acc: 86.52%] [G loss: 1.258641]\n",
      "[Epoch 21/50] [Batch 5/235] [D loss: 1.102319, acc: 85.94%] [G loss: 1.208853]\n",
      "[Epoch 21/50] [Batch 6/235] [D loss: 1.110023, acc: 86.52%] [G loss: 0.987669]\n",
      "[Epoch 21/50] [Batch 7/235] [D loss: 1.179848, acc: 86.52%] [G loss: 1.155878]\n",
      "[Epoch 21/50] [Batch 8/235] [D loss: 1.142396, acc: 88.67%] [G loss: 1.296080]\n",
      "[Epoch 21/50] [Batch 9/235] [D loss: 1.170209, acc: 85.74%] [G loss: 1.154465]\n",
      "[Epoch 21/50] [Batch 10/235] [D loss: 1.174244, acc: 83.59%] [G loss: 1.106077]\n",
      "[Epoch 21/50] [Batch 11/235] [D loss: 1.146284, acc: 83.20%] [G loss: 1.165291]\n",
      "[Epoch 21/50] [Batch 12/235] [D loss: 1.157702, acc: 85.55%] [G loss: 1.307420]\n",
      "[Epoch 21/50] [Batch 13/235] [D loss: 1.123931, acc: 86.13%] [G loss: 1.126776]\n",
      "[Epoch 21/50] [Batch 14/235] [D loss: 1.114525, acc: 87.11%] [G loss: 1.037256]\n",
      "[Epoch 21/50] [Batch 15/235] [D loss: 1.179141, acc: 83.20%] [G loss: 1.310634]\n",
      "[Epoch 21/50] [Batch 16/235] [D loss: 1.131428, acc: 86.91%] [G loss: 1.221200]\n",
      "[Epoch 21/50] [Batch 17/235] [D loss: 1.084023, acc: 86.91%] [G loss: 1.168919]\n",
      "[Epoch 21/50] [Batch 18/235] [D loss: 1.106686, acc: 86.52%] [G loss: 1.114168]\n",
      "[Epoch 21/50] [Batch 19/235] [D loss: 1.151205, acc: 85.55%] [G loss: 1.135500]\n",
      "[Epoch 21/50] [Batch 20/235] [D loss: 1.116070, acc: 84.96%] [G loss: 1.129212]\n",
      "[Epoch 21/50] [Batch 21/235] [D loss: 1.134189, acc: 86.52%] [G loss: 1.180335]\n",
      "[Epoch 21/50] [Batch 22/235] [D loss: 1.105258, acc: 84.18%] [G loss: 1.228203]\n",
      "[Epoch 21/50] [Batch 23/235] [D loss: 1.134774, acc: 85.35%] [G loss: 1.106025]\n",
      "[Epoch 21/50] [Batch 24/235] [D loss: 1.098075, acc: 86.13%] [G loss: 1.257827]\n",
      "[Epoch 21/50] [Batch 25/235] [D loss: 1.094777, acc: 87.50%] [G loss: 1.246979]\n",
      "[Epoch 21/50] [Batch 26/235] [D loss: 1.155973, acc: 86.52%] [G loss: 1.147589]\n",
      "[Epoch 21/50] [Batch 27/235] [D loss: 1.087468, acc: 85.16%] [G loss: 1.118232]\n",
      "[Epoch 21/50] [Batch 28/235] [D loss: 1.141593, acc: 86.33%] [G loss: 1.077421]\n",
      "[Epoch 21/50] [Batch 29/235] [D loss: 1.138055, acc: 83.20%] [G loss: 1.246894]\n",
      "[Epoch 21/50] [Batch 30/235] [D loss: 1.048137, acc: 87.11%] [G loss: 1.201215]\n",
      "[Epoch 21/50] [Batch 31/235] [D loss: 1.121667, acc: 85.16%] [G loss: 1.166182]\n",
      "[Epoch 21/50] [Batch 32/235] [D loss: 1.145918, acc: 85.35%] [G loss: 1.137606]\n",
      "[Epoch 21/50] [Batch 33/235] [D loss: 1.056821, acc: 86.13%] [G loss: 1.154226]\n",
      "[Epoch 21/50] [Batch 34/235] [D loss: 1.143399, acc: 87.11%] [G loss: 1.075056]\n",
      "[Epoch 21/50] [Batch 35/235] [D loss: 1.164219, acc: 85.55%] [G loss: 1.141116]\n",
      "[Epoch 21/50] [Batch 36/235] [D loss: 1.169251, acc: 85.55%] [G loss: 1.216339]\n",
      "[Epoch 21/50] [Batch 37/235] [D loss: 1.084479, acc: 87.11%] [G loss: 1.063600]\n",
      "[Epoch 21/50] [Batch 38/235] [D loss: 1.097303, acc: 87.89%] [G loss: 1.125441]\n",
      "[Epoch 21/50] [Batch 39/235] [D loss: 1.081378, acc: 85.94%] [G loss: 1.254947]\n",
      "[Epoch 21/50] [Batch 40/235] [D loss: 1.153037, acc: 86.52%] [G loss: 1.283738]\n",
      "[Epoch 21/50] [Batch 41/235] [D loss: 1.143170, acc: 85.94%] [G loss: 1.117321]\n",
      "[Epoch 21/50] [Batch 42/235] [D loss: 1.079113, acc: 87.89%] [G loss: 1.147051]\n",
      "[Epoch 21/50] [Batch 43/235] [D loss: 1.129418, acc: 86.13%] [G loss: 1.089912]\n",
      "[Epoch 21/50] [Batch 44/235] [D loss: 1.142345, acc: 86.52%] [G loss: 1.204122]\n",
      "[Epoch 21/50] [Batch 45/235] [D loss: 1.093321, acc: 85.35%] [G loss: 1.192896]\n",
      "[Epoch 21/50] [Batch 46/235] [D loss: 1.074731, acc: 88.09%] [G loss: 1.227063]\n",
      "[Epoch 21/50] [Batch 47/235] [D loss: 1.143933, acc: 84.18%] [G loss: 1.118910]\n",
      "[Epoch 21/50] [Batch 48/235] [D loss: 1.148897, acc: 84.38%] [G loss: 1.112912]\n",
      "[Epoch 21/50] [Batch 49/235] [D loss: 1.082589, acc: 86.52%] [G loss: 1.130626]\n",
      "[Epoch 21/50] [Batch 50/235] [D loss: 1.112161, acc: 86.72%] [G loss: 1.081792]\n",
      "[Epoch 21/50] [Batch 51/235] [D loss: 1.113781, acc: 85.74%] [G loss: 1.191412]\n",
      "[Epoch 21/50] [Batch 52/235] [D loss: 1.110663, acc: 88.28%] [G loss: 1.309950]\n",
      "[Epoch 21/50] [Batch 53/235] [D loss: 1.072580, acc: 83.79%] [G loss: 1.113348]\n",
      "[Epoch 21/50] [Batch 54/235] [D loss: 1.137774, acc: 86.72%] [G loss: 1.187771]\n",
      "[Epoch 21/50] [Batch 55/235] [D loss: 1.125926, acc: 85.16%] [G loss: 1.142651]\n",
      "[Epoch 21/50] [Batch 56/235] [D loss: 1.120624, acc: 90.04%] [G loss: 1.035669]\n",
      "[Epoch 21/50] [Batch 57/235] [D loss: 1.119256, acc: 87.70%] [G loss: 1.174460]\n",
      "[Epoch 21/50] [Batch 58/235] [D loss: 1.146230, acc: 86.72%] [G loss: 1.281481]\n",
      "[Epoch 21/50] [Batch 59/235] [D loss: 1.135752, acc: 83.98%] [G loss: 1.174392]\n",
      "[Epoch 21/50] [Batch 60/235] [D loss: 1.119493, acc: 85.16%] [G loss: 1.192454]\n",
      "[Epoch 21/50] [Batch 61/235] [D loss: 1.057966, acc: 85.55%] [G loss: 1.195596]\n",
      "[Epoch 21/50] [Batch 62/235] [D loss: 1.063073, acc: 84.57%] [G loss: 1.144354]\n",
      "[Epoch 21/50] [Batch 63/235] [D loss: 1.117293, acc: 87.11%] [G loss: 1.321190]\n",
      "[Epoch 21/50] [Batch 64/235] [D loss: 1.109866, acc: 86.72%] [G loss: 1.186243]\n",
      "[Epoch 21/50] [Batch 65/235] [D loss: 1.078778, acc: 85.94%] [G loss: 1.061710]\n",
      "[Epoch 21/50] [Batch 66/235] [D loss: 1.113128, acc: 86.33%] [G loss: 1.197735]\n",
      "[Epoch 21/50] [Batch 67/235] [D loss: 1.189027, acc: 84.57%] [G loss: 1.187200]\n",
      "[Epoch 21/50] [Batch 68/235] [D loss: 1.116553, acc: 87.89%] [G loss: 1.270244]\n",
      "[Epoch 21/50] [Batch 69/235] [D loss: 1.091943, acc: 87.11%] [G loss: 1.239664]\n",
      "[Epoch 21/50] [Batch 70/235] [D loss: 1.126147, acc: 85.16%] [G loss: 1.133513]\n",
      "[Epoch 21/50] [Batch 71/235] [D loss: 1.135965, acc: 86.13%] [G loss: 1.094700]\n",
      "[Epoch 21/50] [Batch 72/235] [D loss: 1.144133, acc: 85.94%] [G loss: 1.271291]\n",
      "[Epoch 21/50] [Batch 73/235] [D loss: 1.160076, acc: 84.57%] [G loss: 1.262022]\n",
      "[Epoch 21/50] [Batch 74/235] [D loss: 1.140565, acc: 86.52%] [G loss: 1.134704]\n",
      "[Epoch 21/50] [Batch 75/235] [D loss: 1.116744, acc: 84.38%] [G loss: 1.100575]\n",
      "[Epoch 21/50] [Batch 76/235] [D loss: 1.143326, acc: 89.06%] [G loss: 1.141689]\n",
      "[Epoch 21/50] [Batch 77/235] [D loss: 1.099414, acc: 87.30%] [G loss: 1.272521]\n",
      "[Epoch 21/50] [Batch 78/235] [D loss: 1.116690, acc: 84.57%] [G loss: 1.178065]\n",
      "[Epoch 21/50] [Batch 79/235] [D loss: 1.079772, acc: 89.65%] [G loss: 1.031423]\n",
      "[Epoch 21/50] [Batch 80/235] [D loss: 1.151902, acc: 86.72%] [G loss: 1.142247]\n",
      "[Epoch 21/50] [Batch 81/235] [D loss: 1.124173, acc: 86.72%] [G loss: 1.115979]\n",
      "[Epoch 21/50] [Batch 82/235] [D loss: 1.068838, acc: 84.77%] [G loss: 1.166276]\n",
      "[Epoch 21/50] [Batch 83/235] [D loss: 1.099740, acc: 86.13%] [G loss: 1.104393]\n",
      "[Epoch 21/50] [Batch 84/235] [D loss: 1.100303, acc: 85.94%] [G loss: 1.259704]\n",
      "[Epoch 21/50] [Batch 85/235] [D loss: 1.119506, acc: 87.11%] [G loss: 1.194725]\n",
      "[Epoch 21/50] [Batch 86/235] [D loss: 1.160447, acc: 86.72%] [G loss: 1.191747]\n",
      "[Epoch 21/50] [Batch 87/235] [D loss: 1.124802, acc: 87.30%] [G loss: 1.226676]\n",
      "[Epoch 21/50] [Batch 88/235] [D loss: 1.115889, acc: 87.11%] [G loss: 1.200007]\n",
      "[Epoch 21/50] [Batch 89/235] [D loss: 1.127885, acc: 86.91%] [G loss: 1.179931]\n",
      "[Epoch 21/50] [Batch 90/235] [D loss: 1.093002, acc: 86.91%] [G loss: 1.114183]\n",
      "[Epoch 21/50] [Batch 91/235] [D loss: 1.101956, acc: 87.30%] [G loss: 1.071065]\n",
      "[Epoch 21/50] [Batch 92/235] [D loss: 1.199711, acc: 85.55%] [G loss: 1.202866]\n",
      "[Epoch 21/50] [Batch 93/235] [D loss: 1.095693, acc: 85.35%] [G loss: 1.130233]\n",
      "[Epoch 21/50] [Batch 94/235] [D loss: 1.129919, acc: 88.09%] [G loss: 1.169400]\n",
      "[Epoch 21/50] [Batch 95/235] [D loss: 1.141481, acc: 86.91%] [G loss: 1.109769]\n",
      "[Epoch 21/50] [Batch 96/235] [D loss: 1.150815, acc: 85.94%] [G loss: 1.160968]\n",
      "[Epoch 21/50] [Batch 97/235] [D loss: 1.147885, acc: 84.96%] [G loss: 1.272524]\n",
      "[Epoch 21/50] [Batch 98/235] [D loss: 1.082632, acc: 86.91%] [G loss: 1.147685]\n",
      "[Epoch 21/50] [Batch 99/235] [D loss: 1.149766, acc: 85.74%] [G loss: 1.240911]\n",
      "[Epoch 21/50] [Batch 100/235] [D loss: 1.154990, acc: 84.96%] [G loss: 1.036783]\n",
      "[Epoch 21/50] [Batch 101/235] [D loss: 1.111330, acc: 85.94%] [G loss: 1.127331]\n",
      "[Epoch 21/50] [Batch 102/235] [D loss: 1.127820, acc: 87.11%] [G loss: 1.113809]\n",
      "[Epoch 21/50] [Batch 103/235] [D loss: 1.127055, acc: 87.70%] [G loss: 1.153068]\n",
      "[Epoch 21/50] [Batch 104/235] [D loss: 1.124580, acc: 86.52%] [G loss: 1.152410]\n",
      "[Epoch 21/50] [Batch 105/235] [D loss: 1.100521, acc: 85.16%] [G loss: 1.229702]\n",
      "[Epoch 21/50] [Batch 106/235] [D loss: 1.090937, acc: 85.55%] [G loss: 1.098360]\n",
      "[Epoch 21/50] [Batch 107/235] [D loss: 1.143202, acc: 84.77%] [G loss: 1.203036]\n",
      "[Epoch 21/50] [Batch 108/235] [D loss: 1.099267, acc: 88.87%] [G loss: 1.315824]\n",
      "[Epoch 21/50] [Batch 109/235] [D loss: 1.122685, acc: 87.11%] [G loss: 1.152900]\n",
      "[Epoch 21/50] [Batch 110/235] [D loss: 1.097020, acc: 85.16%] [G loss: 1.154383]\n",
      "[Epoch 21/50] [Batch 111/235] [D loss: 1.138593, acc: 87.30%] [G loss: 1.170541]\n",
      "[Epoch 21/50] [Batch 112/235] [D loss: 1.103538, acc: 84.96%] [G loss: 1.209612]\n",
      "[Epoch 21/50] [Batch 113/235] [D loss: 1.104458, acc: 85.74%] [G loss: 1.114325]\n",
      "[Epoch 21/50] [Batch 114/235] [D loss: 1.148305, acc: 84.18%] [G loss: 1.272627]\n",
      "[Epoch 21/50] [Batch 115/235] [D loss: 1.173845, acc: 82.42%] [G loss: 1.236888]\n",
      "[Epoch 21/50] [Batch 116/235] [D loss: 1.159789, acc: 90.43%] [G loss: 1.187152]\n",
      "[Epoch 21/50] [Batch 117/235] [D loss: 1.106523, acc: 85.74%] [G loss: 1.149017]\n",
      "[Epoch 21/50] [Batch 118/235] [D loss: 1.088124, acc: 84.77%] [G loss: 1.220739]\n",
      "[Epoch 21/50] [Batch 119/235] [D loss: 1.128960, acc: 88.28%] [G loss: 1.130664]\n",
      "[Epoch 21/50] [Batch 120/235] [D loss: 1.136903, acc: 86.13%] [G loss: 1.122361]\n",
      "[Epoch 21/50] [Batch 121/235] [D loss: 1.173997, acc: 85.74%] [G loss: 1.077549]\n",
      "[Epoch 21/50] [Batch 122/235] [D loss: 1.065103, acc: 88.67%] [G loss: 1.145516]\n",
      "[Epoch 21/50] [Batch 123/235] [D loss: 1.113331, acc: 87.30%] [G loss: 1.158125]\n",
      "[Epoch 21/50] [Batch 124/235] [D loss: 1.205492, acc: 83.98%] [G loss: 1.198980]\n",
      "[Epoch 21/50] [Batch 125/235] [D loss: 1.178869, acc: 84.38%] [G loss: 1.103047]\n",
      "[Epoch 21/50] [Batch 126/235] [D loss: 1.096566, acc: 84.38%] [G loss: 1.134660]\n",
      "[Epoch 21/50] [Batch 127/235] [D loss: 1.089218, acc: 85.94%] [G loss: 1.167321]\n",
      "[Epoch 21/50] [Batch 128/235] [D loss: 1.107501, acc: 87.50%] [G loss: 1.104634]\n",
      "[Epoch 21/50] [Batch 129/235] [D loss: 1.111548, acc: 88.28%] [G loss: 1.147190]\n",
      "[Epoch 21/50] [Batch 130/235] [D loss: 1.104830, acc: 86.72%] [G loss: 1.191945]\n",
      "[Epoch 21/50] [Batch 131/235] [D loss: 1.067962, acc: 88.28%] [G loss: 1.244123]\n",
      "[Epoch 21/50] [Batch 132/235] [D loss: 1.107208, acc: 88.48%] [G loss: 1.133869]\n",
      "[Epoch 21/50] [Batch 133/235] [D loss: 1.103107, acc: 85.94%] [G loss: 1.216707]\n",
      "[Epoch 21/50] [Batch 134/235] [D loss: 1.157010, acc: 86.52%] [G loss: 1.072023]\n",
      "[Epoch 21/50] [Batch 135/235] [D loss: 1.152906, acc: 85.35%] [G loss: 1.235299]\n",
      "[Epoch 21/50] [Batch 136/235] [D loss: 1.123996, acc: 85.16%] [G loss: 1.134369]\n",
      "[Epoch 21/50] [Batch 137/235] [D loss: 1.168755, acc: 84.96%] [G loss: 1.096123]\n",
      "[Epoch 21/50] [Batch 138/235] [D loss: 1.100621, acc: 88.87%] [G loss: 1.315686]\n",
      "[Epoch 21/50] [Batch 139/235] [D loss: 1.076950, acc: 86.33%] [G loss: 1.183220]\n",
      "[Epoch 21/50] [Batch 140/235] [D loss: 1.105487, acc: 86.91%] [G loss: 1.325535]\n",
      "[Epoch 21/50] [Batch 141/235] [D loss: 1.099104, acc: 85.55%] [G loss: 1.110573]\n",
      "[Epoch 21/50] [Batch 142/235] [D loss: 1.071479, acc: 87.89%] [G loss: 1.118265]\n",
      "[Epoch 21/50] [Batch 143/235] [D loss: 1.098626, acc: 87.11%] [G loss: 1.073939]\n",
      "[Epoch 21/50] [Batch 144/235] [D loss: 1.142093, acc: 86.52%] [G loss: 1.205399]\n",
      "[Epoch 21/50] [Batch 145/235] [D loss: 1.160054, acc: 86.13%] [G loss: 1.255117]\n",
      "[Epoch 21/50] [Batch 146/235] [D loss: 1.140916, acc: 87.89%] [G loss: 1.145716]\n",
      "[Epoch 21/50] [Batch 147/235] [D loss: 1.157961, acc: 83.59%] [G loss: 1.202829]\n",
      "[Epoch 21/50] [Batch 148/235] [D loss: 1.132296, acc: 87.11%] [G loss: 1.193198]\n",
      "[Epoch 21/50] [Batch 149/235] [D loss: 1.124846, acc: 83.98%] [G loss: 1.240849]\n",
      "[Epoch 21/50] [Batch 150/235] [D loss: 1.081194, acc: 87.70%] [G loss: 1.167931]\n",
      "[Epoch 21/50] [Batch 151/235] [D loss: 1.118285, acc: 88.48%] [G loss: 1.121290]\n",
      "[Epoch 21/50] [Batch 152/235] [D loss: 1.144276, acc: 85.16%] [G loss: 1.073138]\n",
      "[Epoch 21/50] [Batch 153/235] [D loss: 1.111908, acc: 84.38%] [G loss: 1.153872]\n",
      "[Epoch 21/50] [Batch 154/235] [D loss: 1.140605, acc: 83.79%] [G loss: 1.381432]\n",
      "[Epoch 21/50] [Batch 155/235] [D loss: 1.107108, acc: 86.91%] [G loss: 1.161583]\n",
      "[Epoch 21/50] [Batch 156/235] [D loss: 1.128256, acc: 84.18%] [G loss: 0.978751]\n",
      "[Epoch 21/50] [Batch 157/235] [D loss: 1.062358, acc: 87.70%] [G loss: 1.024394]\n",
      "[Epoch 21/50] [Batch 158/235] [D loss: 1.146431, acc: 84.96%] [G loss: 1.072005]\n",
      "[Epoch 21/50] [Batch 159/235] [D loss: 1.199602, acc: 84.18%] [G loss: 1.332163]\n",
      "[Epoch 21/50] [Batch 160/235] [D loss: 1.120460, acc: 87.89%] [G loss: 1.187169]\n",
      "[Epoch 21/50] [Batch 161/235] [D loss: 1.150059, acc: 84.77%] [G loss: 1.092897]\n",
      "[Epoch 21/50] [Batch 162/235] [D loss: 1.159639, acc: 85.35%] [G loss: 1.124758]\n",
      "[Epoch 21/50] [Batch 163/235] [D loss: 1.141279, acc: 84.77%] [G loss: 1.363693]\n",
      "[Epoch 21/50] [Batch 164/235] [D loss: 1.109151, acc: 85.55%] [G loss: 1.137065]\n",
      "[Epoch 21/50] [Batch 165/235] [D loss: 1.114596, acc: 85.94%] [G loss: 1.088819]\n",
      "[Epoch 21/50] [Batch 166/235] [D loss: 1.119231, acc: 87.50%] [G loss: 1.229984]\n",
      "[Epoch 21/50] [Batch 167/235] [D loss: 1.126498, acc: 85.55%] [G loss: 1.266814]\n",
      "[Epoch 21/50] [Batch 168/235] [D loss: 1.118630, acc: 87.89%] [G loss: 1.141342]\n",
      "[Epoch 21/50] [Batch 169/235] [D loss: 1.124467, acc: 86.52%] [G loss: 1.001401]\n",
      "[Epoch 21/50] [Batch 170/235] [D loss: 1.109406, acc: 86.91%] [G loss: 1.348738]\n",
      "[Epoch 21/50] [Batch 171/235] [D loss: 1.081109, acc: 87.50%] [G loss: 1.204645]\n",
      "[Epoch 21/50] [Batch 172/235] [D loss: 1.070117, acc: 87.11%] [G loss: 1.133871]\n",
      "[Epoch 21/50] [Batch 173/235] [D loss: 1.154942, acc: 84.77%] [G loss: 1.104658]\n",
      "[Epoch 21/50] [Batch 174/235] [D loss: 1.165987, acc: 85.94%] [G loss: 1.118060]\n",
      "[Epoch 21/50] [Batch 175/235] [D loss: 1.080767, acc: 88.09%] [G loss: 1.162781]\n",
      "[Epoch 21/50] [Batch 176/235] [D loss: 1.139126, acc: 86.13%] [G loss: 1.224184]\n",
      "[Epoch 21/50] [Batch 177/235] [D loss: 1.149209, acc: 83.79%] [G loss: 1.208946]\n",
      "[Epoch 21/50] [Batch 178/235] [D loss: 1.140031, acc: 84.57%] [G loss: 1.045467]\n",
      "[Epoch 21/50] [Batch 179/235] [D loss: 1.140286, acc: 84.96%] [G loss: 1.227598]\n",
      "[Epoch 21/50] [Batch 180/235] [D loss: 1.124417, acc: 88.09%] [G loss: 1.209664]\n",
      "[Epoch 21/50] [Batch 181/235] [D loss: 1.078319, acc: 84.18%] [G loss: 1.180741]\n",
      "[Epoch 21/50] [Batch 182/235] [D loss: 1.118087, acc: 87.50%] [G loss: 1.137922]\n",
      "[Epoch 21/50] [Batch 183/235] [D loss: 1.106899, acc: 84.96%] [G loss: 1.200461]\n",
      "[Epoch 21/50] [Batch 184/235] [D loss: 1.177740, acc: 86.91%] [G loss: 1.282747]\n",
      "[Epoch 21/50] [Batch 185/235] [D loss: 1.112616, acc: 88.09%] [G loss: 1.131434]\n",
      "[Epoch 21/50] [Batch 186/235] [D loss: 1.112346, acc: 85.94%] [G loss: 1.088070]\n",
      "[Epoch 21/50] [Batch 187/235] [D loss: 1.089295, acc: 88.09%] [G loss: 1.113306]\n",
      "[Epoch 21/50] [Batch 188/235] [D loss: 1.055943, acc: 88.09%] [G loss: 1.298599]\n",
      "[Epoch 21/50] [Batch 189/235] [D loss: 1.102373, acc: 85.94%] [G loss: 1.189031]\n",
      "[Epoch 21/50] [Batch 190/235] [D loss: 1.122219, acc: 85.74%] [G loss: 1.070616]\n",
      "[Epoch 21/50] [Batch 191/235] [D loss: 1.111396, acc: 84.96%] [G loss: 1.084362]\n",
      "[Epoch 21/50] [Batch 192/235] [D loss: 1.050824, acc: 87.89%] [G loss: 1.204693]\n",
      "[Epoch 21/50] [Batch 193/235] [D loss: 1.142292, acc: 84.77%] [G loss: 1.150755]\n",
      "[Epoch 21/50] [Batch 194/235] [D loss: 1.119583, acc: 84.57%] [G loss: 1.344085]\n",
      "[Epoch 21/50] [Batch 195/235] [D loss: 1.071575, acc: 88.09%] [G loss: 1.235919]\n",
      "[Epoch 21/50] [Batch 196/235] [D loss: 1.081459, acc: 88.87%] [G loss: 1.111558]\n",
      "[Epoch 21/50] [Batch 197/235] [D loss: 1.161354, acc: 85.94%] [G loss: 1.235768]\n",
      "[Epoch 21/50] [Batch 198/235] [D loss: 1.100929, acc: 85.94%] [G loss: 1.179323]\n",
      "[Epoch 21/50] [Batch 199/235] [D loss: 1.186387, acc: 86.13%] [G loss: 1.193747]\n",
      "[Epoch 21/50] [Batch 200/235] [D loss: 1.074487, acc: 87.11%] [G loss: 1.245828]\n",
      "[Epoch 21/50] [Batch 201/235] [D loss: 1.114450, acc: 86.91%] [G loss: 1.111689]\n",
      "[Epoch 21/50] [Batch 202/235] [D loss: 1.058395, acc: 87.89%] [G loss: 1.183245]\n",
      "[Epoch 21/50] [Batch 203/235] [D loss: 1.111863, acc: 87.89%] [G loss: 1.210692]\n",
      "[Epoch 21/50] [Batch 204/235] [D loss: 1.125587, acc: 86.72%] [G loss: 1.243218]\n",
      "[Epoch 21/50] [Batch 205/235] [D loss: 1.112936, acc: 83.20%] [G loss: 1.219831]\n",
      "[Epoch 21/50] [Batch 206/235] [D loss: 1.179725, acc: 83.40%] [G loss: 1.209590]\n",
      "[Epoch 21/50] [Batch 207/235] [D loss: 1.050294, acc: 86.72%] [G loss: 1.078559]\n",
      "[Epoch 21/50] [Batch 208/235] [D loss: 1.084318, acc: 84.77%] [G loss: 1.264780]\n",
      "[Epoch 21/50] [Batch 209/235] [D loss: 1.103464, acc: 87.89%] [G loss: 1.215477]\n",
      "[Epoch 21/50] [Batch 210/235] [D loss: 1.092740, acc: 86.72%] [G loss: 1.138697]\n",
      "[Epoch 21/50] [Batch 211/235] [D loss: 1.133143, acc: 83.98%] [G loss: 1.155180]\n",
      "[Epoch 21/50] [Batch 212/235] [D loss: 1.104213, acc: 85.16%] [G loss: 1.278392]\n",
      "[Epoch 21/50] [Batch 213/235] [D loss: 1.144675, acc: 85.16%] [G loss: 1.309802]\n",
      "[Epoch 21/50] [Batch 214/235] [D loss: 1.161584, acc: 89.26%] [G loss: 1.157354]\n",
      "[Epoch 21/50] [Batch 215/235] [D loss: 1.120702, acc: 86.33%] [G loss: 1.100437]\n",
      "[Epoch 21/50] [Batch 216/235] [D loss: 1.138989, acc: 86.52%] [G loss: 1.322231]\n",
      "[Epoch 21/50] [Batch 217/235] [D loss: 1.120685, acc: 85.35%] [G loss: 1.176979]\n",
      "[Epoch 21/50] [Batch 218/235] [D loss: 1.159940, acc: 86.13%] [G loss: 1.018970]\n",
      "[Epoch 21/50] [Batch 219/235] [D loss: 1.030902, acc: 87.70%] [G loss: 1.157506]\n",
      "[Epoch 21/50] [Batch 220/235] [D loss: 1.120664, acc: 83.79%] [G loss: 1.222554]\n",
      "[Epoch 21/50] [Batch 221/235] [D loss: 1.128088, acc: 85.35%] [G loss: 1.155295]\n",
      "[Epoch 21/50] [Batch 222/235] [D loss: 1.141140, acc: 87.11%] [G loss: 1.081879]\n",
      "[Epoch 21/50] [Batch 223/235] [D loss: 1.138279, acc: 85.74%] [G loss: 1.238673]\n",
      "[Epoch 21/50] [Batch 224/235] [D loss: 1.087766, acc: 87.11%] [G loss: 1.214525]\n",
      "[Epoch 21/50] [Batch 225/235] [D loss: 1.142597, acc: 84.77%] [G loss: 1.117460]\n",
      "[Epoch 21/50] [Batch 226/235] [D loss: 1.115833, acc: 86.13%] [G loss: 1.174850]\n",
      "[Epoch 21/50] [Batch 227/235] [D loss: 1.135334, acc: 87.70%] [G loss: 1.288838]\n",
      "[Epoch 21/50] [Batch 228/235] [D loss: 1.144300, acc: 84.96%] [G loss: 1.215033]\n",
      "[Epoch 21/50] [Batch 229/235] [D loss: 1.179752, acc: 84.77%] [G loss: 1.090203]\n",
      "[Epoch 21/50] [Batch 230/235] [D loss: 1.123549, acc: 85.35%] [G loss: 1.200077]\n",
      "[Epoch 21/50] [Batch 231/235] [D loss: 1.129555, acc: 86.13%] [G loss: 1.163375]\n",
      "[Epoch 21/50] [Batch 232/235] [D loss: 1.154938, acc: 87.70%] [G loss: 1.201504]\n",
      "[Epoch 21/50] [Batch 233/235] [D loss: 1.131566, acc: 86.52%] [G loss: 1.137191]\n",
      "[Epoch 21/50] [Batch 234/235] [D loss: 1.095973, acc: 85.94%] [G loss: 1.169812]\n",
      "[Epoch 22/50] [Batch 0/235] [D loss: 1.170624, acc: 84.96%] [G loss: 1.158664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/50] [Batch 1/235] [D loss: 1.095543, acc: 85.74%] [G loss: 1.123930]\n",
      "[Epoch 22/50] [Batch 2/235] [D loss: 1.149074, acc: 89.06%] [G loss: 1.149790]\n",
      "[Epoch 22/50] [Batch 3/235] [D loss: 1.087303, acc: 83.98%] [G loss: 1.212961]\n",
      "[Epoch 22/50] [Batch 4/235] [D loss: 1.112295, acc: 85.94%] [G loss: 1.152056]\n",
      "[Epoch 22/50] [Batch 5/235] [D loss: 1.117694, acc: 87.11%] [G loss: 1.122479]\n",
      "[Epoch 22/50] [Batch 6/235] [D loss: 1.112432, acc: 85.35%] [G loss: 1.263939]\n",
      "[Epoch 22/50] [Batch 7/235] [D loss: 1.103939, acc: 84.57%] [G loss: 1.209847]\n",
      "[Epoch 22/50] [Batch 8/235] [D loss: 1.119692, acc: 84.96%] [G loss: 1.256361]\n",
      "[Epoch 22/50] [Batch 9/235] [D loss: 1.156125, acc: 89.26%] [G loss: 1.114787]\n",
      "[Epoch 22/50] [Batch 10/235] [D loss: 1.040136, acc: 89.65%] [G loss: 1.227347]\n",
      "[Epoch 22/50] [Batch 11/235] [D loss: 1.100419, acc: 85.94%] [G loss: 1.376659]\n",
      "[Epoch 22/50] [Batch 12/235] [D loss: 1.129539, acc: 85.74%] [G loss: 1.135491]\n",
      "[Epoch 22/50] [Batch 13/235] [D loss: 1.058491, acc: 89.26%] [G loss: 1.106204]\n",
      "[Epoch 22/50] [Batch 14/235] [D loss: 1.158423, acc: 83.40%] [G loss: 1.103649]\n",
      "[Epoch 22/50] [Batch 15/235] [D loss: 1.106723, acc: 86.33%] [G loss: 1.275710]\n",
      "[Epoch 22/50] [Batch 16/235] [D loss: 1.117098, acc: 88.28%] [G loss: 1.208358]\n",
      "[Epoch 22/50] [Batch 17/235] [D loss: 1.112783, acc: 85.94%] [G loss: 1.098346]\n",
      "[Epoch 22/50] [Batch 18/235] [D loss: 1.113196, acc: 87.30%] [G loss: 1.073192]\n",
      "[Epoch 22/50] [Batch 19/235] [D loss: 1.083202, acc: 83.40%] [G loss: 1.071758]\n",
      "[Epoch 22/50] [Batch 20/235] [D loss: 1.070181, acc: 84.96%] [G loss: 1.119834]\n",
      "[Epoch 22/50] [Batch 21/235] [D loss: 1.186737, acc: 87.11%] [G loss: 1.154626]\n",
      "[Epoch 22/50] [Batch 22/235] [D loss: 1.143481, acc: 90.04%] [G loss: 1.133275]\n",
      "[Epoch 22/50] [Batch 23/235] [D loss: 1.131032, acc: 87.11%] [G loss: 1.158348]\n",
      "[Epoch 22/50] [Batch 24/235] [D loss: 1.127675, acc: 86.72%] [G loss: 1.194886]\n",
      "[Epoch 22/50] [Batch 25/235] [D loss: 1.047789, acc: 87.70%] [G loss: 1.137683]\n",
      "[Epoch 22/50] [Batch 26/235] [D loss: 1.084772, acc: 87.50%] [G loss: 1.115846]\n",
      "[Epoch 22/50] [Batch 27/235] [D loss: 1.067249, acc: 85.94%] [G loss: 1.143579]\n",
      "[Epoch 22/50] [Batch 28/235] [D loss: 1.144496, acc: 85.94%] [G loss: 1.132288]\n",
      "[Epoch 22/50] [Batch 29/235] [D loss: 1.150875, acc: 89.26%] [G loss: 1.155832]\n",
      "[Epoch 22/50] [Batch 30/235] [D loss: 1.177825, acc: 82.62%] [G loss: 1.231070]\n",
      "[Epoch 22/50] [Batch 31/235] [D loss: 1.127345, acc: 85.35%] [G loss: 1.154681]\n",
      "[Epoch 22/50] [Batch 32/235] [D loss: 1.138545, acc: 88.48%] [G loss: 1.076244]\n",
      "[Epoch 22/50] [Batch 33/235] [D loss: 1.137734, acc: 85.94%] [G loss: 1.121373]\n",
      "[Epoch 22/50] [Batch 34/235] [D loss: 1.075785, acc: 86.91%] [G loss: 1.194660]\n",
      "[Epoch 22/50] [Batch 35/235] [D loss: 1.148452, acc: 86.91%] [G loss: 1.204113]\n",
      "[Epoch 22/50] [Batch 36/235] [D loss: 1.105929, acc: 87.70%] [G loss: 1.241524]\n",
      "[Epoch 22/50] [Batch 37/235] [D loss: 1.087522, acc: 84.57%] [G loss: 1.094693]\n",
      "[Epoch 22/50] [Batch 38/235] [D loss: 1.116679, acc: 84.57%] [G loss: 1.159048]\n",
      "[Epoch 22/50] [Batch 39/235] [D loss: 1.140347, acc: 86.13%] [G loss: 1.168568]\n",
      "[Epoch 22/50] [Batch 40/235] [D loss: 1.133973, acc: 83.59%] [G loss: 1.137753]\n",
      "[Epoch 22/50] [Batch 41/235] [D loss: 1.102679, acc: 88.48%] [G loss: 0.997902]\n",
      "[Epoch 22/50] [Batch 42/235] [D loss: 1.142106, acc: 87.11%] [G loss: 1.082216]\n",
      "[Epoch 22/50] [Batch 43/235] [D loss: 1.162951, acc: 85.94%] [G loss: 1.138667]\n",
      "[Epoch 22/50] [Batch 44/235] [D loss: 1.149093, acc: 84.38%] [G loss: 1.316308]\n",
      "[Epoch 22/50] [Batch 45/235] [D loss: 1.110844, acc: 87.50%] [G loss: 1.237508]\n",
      "[Epoch 22/50] [Batch 46/235] [D loss: 1.141826, acc: 86.33%] [G loss: 1.111999]\n",
      "[Epoch 22/50] [Batch 47/235] [D loss: 1.140075, acc: 83.01%] [G loss: 1.169675]\n",
      "[Epoch 22/50] [Batch 48/235] [D loss: 1.099173, acc: 85.94%] [G loss: 1.225946]\n",
      "[Epoch 22/50] [Batch 49/235] [D loss: 1.088075, acc: 86.52%] [G loss: 1.130103]\n",
      "[Epoch 22/50] [Batch 50/235] [D loss: 1.117763, acc: 84.77%] [G loss: 1.184595]\n",
      "[Epoch 22/50] [Batch 51/235] [D loss: 1.111451, acc: 87.50%] [G loss: 1.234565]\n",
      "[Epoch 22/50] [Batch 52/235] [D loss: 1.091412, acc: 85.94%] [G loss: 1.337817]\n",
      "[Epoch 22/50] [Batch 53/235] [D loss: 1.130385, acc: 86.33%] [G loss: 1.301337]\n",
      "[Epoch 22/50] [Batch 54/235] [D loss: 1.088943, acc: 86.72%] [G loss: 1.162154]\n",
      "[Epoch 22/50] [Batch 55/235] [D loss: 1.083071, acc: 85.94%] [G loss: 1.165466]\n",
      "[Epoch 22/50] [Batch 56/235] [D loss: 1.097410, acc: 87.70%] [G loss: 1.324811]\n",
      "[Epoch 22/50] [Batch 57/235] [D loss: 1.209635, acc: 83.01%] [G loss: 1.197523]\n",
      "[Epoch 22/50] [Batch 58/235] [D loss: 1.155556, acc: 85.94%] [G loss: 1.246643]\n",
      "[Epoch 22/50] [Batch 59/235] [D loss: 1.109476, acc: 88.87%] [G loss: 1.130326]\n",
      "[Epoch 22/50] [Batch 60/235] [D loss: 1.139405, acc: 86.72%] [G loss: 1.139714]\n",
      "[Epoch 22/50] [Batch 61/235] [D loss: 1.067982, acc: 86.33%] [G loss: 1.165962]\n",
      "[Epoch 22/50] [Batch 62/235] [D loss: 1.156185, acc: 86.52%] [G loss: 1.199342]\n",
      "[Epoch 22/50] [Batch 63/235] [D loss: 1.106811, acc: 84.77%] [G loss: 1.173243]\n",
      "[Epoch 22/50] [Batch 64/235] [D loss: 1.101784, acc: 88.28%] [G loss: 1.076630]\n",
      "[Epoch 22/50] [Batch 65/235] [D loss: 1.144098, acc: 83.98%] [G loss: 1.205966]\n",
      "[Epoch 22/50] [Batch 66/235] [D loss: 1.155288, acc: 84.57%] [G loss: 1.143537]\n",
      "[Epoch 22/50] [Batch 67/235] [D loss: 1.099156, acc: 84.77%] [G loss: 1.241191]\n",
      "[Epoch 22/50] [Batch 68/235] [D loss: 1.107251, acc: 89.45%] [G loss: 1.144133]\n",
      "[Epoch 22/50] [Batch 69/235] [D loss: 1.092546, acc: 87.70%] [G loss: 1.237028]\n",
      "[Epoch 22/50] [Batch 70/235] [D loss: 1.097250, acc: 84.57%] [G loss: 1.126585]\n",
      "[Epoch 22/50] [Batch 71/235] [D loss: 1.157643, acc: 85.35%] [G loss: 1.043018]\n",
      "[Epoch 22/50] [Batch 72/235] [D loss: 1.108887, acc: 86.72%] [G loss: 1.254777]\n",
      "[Epoch 22/50] [Batch 73/235] [D loss: 1.122741, acc: 86.72%] [G loss: 1.178559]\n",
      "[Epoch 22/50] [Batch 74/235] [D loss: 1.116519, acc: 84.18%] [G loss: 1.180764]\n",
      "[Epoch 22/50] [Batch 75/235] [D loss: 1.178512, acc: 82.62%] [G loss: 1.098386]\n",
      "[Epoch 22/50] [Batch 76/235] [D loss: 1.126148, acc: 85.35%] [G loss: 1.259083]\n",
      "[Epoch 22/50] [Batch 77/235] [D loss: 1.142766, acc: 85.94%] [G loss: 1.177655]\n",
      "[Epoch 22/50] [Batch 78/235] [D loss: 1.133193, acc: 86.33%] [G loss: 1.097784]\n",
      "[Epoch 22/50] [Batch 79/235] [D loss: 1.096583, acc: 88.09%] [G loss: 1.052196]\n",
      "[Epoch 22/50] [Batch 80/235] [D loss: 1.095482, acc: 87.50%] [G loss: 1.028682]\n",
      "[Epoch 22/50] [Batch 81/235] [D loss: 1.067717, acc: 88.87%] [G loss: 1.272153]\n",
      "[Epoch 22/50] [Batch 82/235] [D loss: 1.099522, acc: 85.74%] [G loss: 1.103565]\n",
      "[Epoch 22/50] [Batch 83/235] [D loss: 1.091056, acc: 88.09%] [G loss: 1.174958]\n",
      "[Epoch 22/50] [Batch 84/235] [D loss: 1.129064, acc: 90.04%] [G loss: 1.231279]\n",
      "[Epoch 22/50] [Batch 85/235] [D loss: 1.071007, acc: 87.50%] [G loss: 1.144572]\n",
      "[Epoch 22/50] [Batch 86/235] [D loss: 1.060761, acc: 84.96%] [G loss: 1.189192]\n",
      "[Epoch 22/50] [Batch 87/235] [D loss: 1.126152, acc: 86.72%] [G loss: 1.207575]\n",
      "[Epoch 22/50] [Batch 88/235] [D loss: 1.152383, acc: 88.67%] [G loss: 1.164466]\n",
      "[Epoch 22/50] [Batch 89/235] [D loss: 1.157840, acc: 86.91%] [G loss: 1.000668]\n",
      "[Epoch 22/50] [Batch 90/235] [D loss: 1.150752, acc: 87.89%] [G loss: 1.312412]\n",
      "[Epoch 22/50] [Batch 91/235] [D loss: 1.152393, acc: 84.38%] [G loss: 1.250542]\n",
      "[Epoch 22/50] [Batch 92/235] [D loss: 1.131612, acc: 85.55%] [G loss: 1.069092]\n",
      "[Epoch 22/50] [Batch 93/235] [D loss: 1.148396, acc: 85.35%] [G loss: 1.069895]\n",
      "[Epoch 22/50] [Batch 94/235] [D loss: 1.115606, acc: 85.74%] [G loss: 1.218466]\n",
      "[Epoch 22/50] [Batch 95/235] [D loss: 1.140439, acc: 87.30%] [G loss: 1.232477]\n",
      "[Epoch 22/50] [Batch 96/235] [D loss: 1.163777, acc: 87.11%] [G loss: 1.064296]\n",
      "[Epoch 22/50] [Batch 97/235] [D loss: 1.133875, acc: 89.06%] [G loss: 1.284067]\n",
      "[Epoch 22/50] [Batch 98/235] [D loss: 1.150883, acc: 87.89%] [G loss: 1.121816]\n",
      "[Epoch 22/50] [Batch 99/235] [D loss: 1.156196, acc: 84.77%] [G loss: 1.174914]\n",
      "[Epoch 22/50] [Batch 100/235] [D loss: 1.150246, acc: 84.57%] [G loss: 1.156337]\n",
      "[Epoch 22/50] [Batch 101/235] [D loss: 1.074302, acc: 87.70%] [G loss: 1.123163]\n",
      "[Epoch 22/50] [Batch 102/235] [D loss: 1.144728, acc: 84.77%] [G loss: 1.270425]\n",
      "[Epoch 22/50] [Batch 103/235] [D loss: 1.148727, acc: 84.77%] [G loss: 1.110243]\n",
      "[Epoch 22/50] [Batch 104/235] [D loss: 1.150849, acc: 86.91%] [G loss: 1.191126]\n",
      "[Epoch 22/50] [Batch 105/235] [D loss: 1.108424, acc: 87.11%] [G loss: 1.257630]\n",
      "[Epoch 22/50] [Batch 106/235] [D loss: 1.095285, acc: 87.11%] [G loss: 1.199294]\n",
      "[Epoch 22/50] [Batch 107/235] [D loss: 1.102677, acc: 86.33%] [G loss: 1.045360]\n",
      "[Epoch 22/50] [Batch 108/235] [D loss: 1.105179, acc: 87.11%] [G loss: 1.113634]\n",
      "[Epoch 22/50] [Batch 109/235] [D loss: 1.107773, acc: 87.30%] [G loss: 1.207061]\n",
      "[Epoch 22/50] [Batch 110/235] [D loss: 1.157815, acc: 83.98%] [G loss: 1.137347]\n",
      "[Epoch 22/50] [Batch 111/235] [D loss: 1.127252, acc: 87.89%] [G loss: 1.146281]\n",
      "[Epoch 22/50] [Batch 112/235] [D loss: 1.110206, acc: 83.59%] [G loss: 1.185834]\n",
      "[Epoch 22/50] [Batch 113/235] [D loss: 1.134846, acc: 84.77%] [G loss: 1.184384]\n",
      "[Epoch 22/50] [Batch 114/235] [D loss: 1.103761, acc: 84.96%] [G loss: 1.164403]\n",
      "[Epoch 22/50] [Batch 115/235] [D loss: 1.082159, acc: 85.94%] [G loss: 1.210001]\n",
      "[Epoch 22/50] [Batch 116/235] [D loss: 1.135488, acc: 84.96%] [G loss: 1.067314]\n",
      "[Epoch 22/50] [Batch 117/235] [D loss: 1.128918, acc: 85.94%] [G loss: 1.261539]\n",
      "[Epoch 22/50] [Batch 118/235] [D loss: 1.142024, acc: 85.74%] [G loss: 1.190338]\n",
      "[Epoch 22/50] [Batch 119/235] [D loss: 1.136607, acc: 85.94%] [G loss: 1.142798]\n",
      "[Epoch 22/50] [Batch 120/235] [D loss: 1.159042, acc: 84.96%] [G loss: 1.094466]\n",
      "[Epoch 22/50] [Batch 121/235] [D loss: 1.090179, acc: 87.70%] [G loss: 1.124650]\n",
      "[Epoch 22/50] [Batch 122/235] [D loss: 1.128316, acc: 86.33%] [G loss: 1.150137]\n",
      "[Epoch 22/50] [Batch 123/235] [D loss: 1.117783, acc: 84.96%] [G loss: 1.157025]\n",
      "[Epoch 22/50] [Batch 124/235] [D loss: 1.070413, acc: 85.94%] [G loss: 1.121973]\n",
      "[Epoch 22/50] [Batch 125/235] [D loss: 1.095976, acc: 84.57%] [G loss: 1.174642]\n",
      "[Epoch 22/50] [Batch 126/235] [D loss: 1.086957, acc: 87.50%] [G loss: 1.198732]\n",
      "[Epoch 22/50] [Batch 127/235] [D loss: 1.100460, acc: 87.30%] [G loss: 1.303707]\n",
      "[Epoch 22/50] [Batch 128/235] [D loss: 1.128271, acc: 87.30%] [G loss: 1.225867]\n",
      "[Epoch 22/50] [Batch 129/235] [D loss: 1.120016, acc: 83.79%] [G loss: 1.077074]\n",
      "[Epoch 22/50] [Batch 130/235] [D loss: 1.152503, acc: 86.52%] [G loss: 1.157815]\n",
      "[Epoch 22/50] [Batch 131/235] [D loss: 1.130728, acc: 87.11%] [G loss: 1.153497]\n",
      "[Epoch 22/50] [Batch 132/235] [D loss: 1.148471, acc: 86.33%] [G loss: 1.136892]\n",
      "[Epoch 22/50] [Batch 133/235] [D loss: 1.107333, acc: 87.11%] [G loss: 1.204886]\n",
      "[Epoch 22/50] [Batch 134/235] [D loss: 1.090621, acc: 86.52%] [G loss: 1.153175]\n",
      "[Epoch 22/50] [Batch 135/235] [D loss: 1.126412, acc: 85.94%] [G loss: 1.144656]\n",
      "[Epoch 22/50] [Batch 136/235] [D loss: 1.130136, acc: 85.94%] [G loss: 1.113609]\n",
      "[Epoch 22/50] [Batch 137/235] [D loss: 1.108865, acc: 84.77%] [G loss: 1.119887]\n",
      "[Epoch 22/50] [Batch 138/235] [D loss: 1.102710, acc: 86.52%] [G loss: 1.081002]\n",
      "[Epoch 22/50] [Batch 139/235] [D loss: 1.114442, acc: 91.21%] [G loss: 1.162227]\n",
      "[Epoch 22/50] [Batch 140/235] [D loss: 1.119377, acc: 87.11%] [G loss: 1.104113]\n",
      "[Epoch 22/50] [Batch 141/235] [D loss: 1.127429, acc: 85.55%] [G loss: 1.158623]\n",
      "[Epoch 22/50] [Batch 142/235] [D loss: 1.102769, acc: 88.28%] [G loss: 1.137495]\n",
      "[Epoch 22/50] [Batch 143/235] [D loss: 1.122901, acc: 86.33%] [G loss: 1.129624]\n",
      "[Epoch 22/50] [Batch 144/235] [D loss: 1.105686, acc: 84.38%] [G loss: 1.135945]\n",
      "[Epoch 22/50] [Batch 145/235] [D loss: 1.098447, acc: 88.28%] [G loss: 1.146456]\n",
      "[Epoch 22/50] [Batch 146/235] [D loss: 1.103776, acc: 87.50%] [G loss: 1.104898]\n",
      "[Epoch 22/50] [Batch 147/235] [D loss: 1.148092, acc: 86.33%] [G loss: 1.111190]\n",
      "[Epoch 22/50] [Batch 148/235] [D loss: 1.082546, acc: 87.11%] [G loss: 1.179215]\n",
      "[Epoch 22/50] [Batch 149/235] [D loss: 1.097028, acc: 86.52%] [G loss: 1.265199]\n",
      "[Epoch 22/50] [Batch 150/235] [D loss: 1.141056, acc: 85.94%] [G loss: 1.148972]\n",
      "[Epoch 22/50] [Batch 151/235] [D loss: 1.116602, acc: 84.96%] [G loss: 1.159479]\n",
      "[Epoch 22/50] [Batch 152/235] [D loss: 1.129453, acc: 83.59%] [G loss: 1.113789]\n",
      "[Epoch 22/50] [Batch 153/235] [D loss: 1.121723, acc: 87.11%] [G loss: 1.139017]\n",
      "[Epoch 22/50] [Batch 154/235] [D loss: 1.129277, acc: 85.74%] [G loss: 1.253643]\n",
      "[Epoch 22/50] [Batch 155/235] [D loss: 1.133757, acc: 87.11%] [G loss: 1.163190]\n",
      "[Epoch 22/50] [Batch 156/235] [D loss: 1.152472, acc: 81.25%] [G loss: 1.136010]\n",
      "[Epoch 22/50] [Batch 157/235] [D loss: 1.131620, acc: 83.20%] [G loss: 1.129174]\n",
      "[Epoch 22/50] [Batch 158/235] [D loss: 1.134224, acc: 87.70%] [G loss: 1.105596]\n",
      "[Epoch 22/50] [Batch 159/235] [D loss: 1.114074, acc: 83.98%] [G loss: 1.326911]\n",
      "[Epoch 22/50] [Batch 160/235] [D loss: 1.130419, acc: 84.18%] [G loss: 1.228384]\n",
      "[Epoch 22/50] [Batch 161/235] [D loss: 1.129512, acc: 87.70%] [G loss: 1.127849]\n",
      "[Epoch 22/50] [Batch 162/235] [D loss: 1.079526, acc: 86.33%] [G loss: 1.194907]\n",
      "[Epoch 22/50] [Batch 163/235] [D loss: 1.120235, acc: 86.13%] [G loss: 1.260191]\n",
      "[Epoch 22/50] [Batch 164/235] [D loss: 1.144841, acc: 85.35%] [G loss: 1.194196]\n",
      "[Epoch 22/50] [Batch 165/235] [D loss: 1.092395, acc: 85.35%] [G loss: 1.194057]\n",
      "[Epoch 22/50] [Batch 166/235] [D loss: 1.073638, acc: 87.11%] [G loss: 1.174280]\n",
      "[Epoch 22/50] [Batch 167/235] [D loss: 1.136727, acc: 87.30%] [G loss: 1.171870]\n",
      "[Epoch 22/50] [Batch 168/235] [D loss: 1.132533, acc: 85.74%] [G loss: 1.160688]\n",
      "[Epoch 22/50] [Batch 169/235] [D loss: 1.178624, acc: 86.13%] [G loss: 1.039220]\n",
      "[Epoch 22/50] [Batch 170/235] [D loss: 1.127517, acc: 86.91%] [G loss: 1.112082]\n",
      "[Epoch 22/50] [Batch 171/235] [D loss: 1.103906, acc: 85.74%] [G loss: 1.289239]\n",
      "[Epoch 22/50] [Batch 172/235] [D loss: 1.065884, acc: 85.35%] [G loss: 1.215396]\n",
      "[Epoch 22/50] [Batch 173/235] [D loss: 1.165779, acc: 89.45%] [G loss: 1.012693]\n",
      "[Epoch 22/50] [Batch 174/235] [D loss: 1.075404, acc: 84.57%] [G loss: 1.147303]\n",
      "[Epoch 22/50] [Batch 175/235] [D loss: 1.106410, acc: 85.94%] [G loss: 1.241231]\n",
      "[Epoch 22/50] [Batch 176/235] [D loss: 1.107953, acc: 84.96%] [G loss: 1.264507]\n",
      "[Epoch 22/50] [Batch 177/235] [D loss: 1.125573, acc: 84.96%] [G loss: 1.175531]\n",
      "[Epoch 22/50] [Batch 178/235] [D loss: 1.184108, acc: 83.20%] [G loss: 1.252742]\n",
      "[Epoch 22/50] [Batch 179/235] [D loss: 1.125338, acc: 87.30%] [G loss: 1.258576]\n",
      "[Epoch 22/50] [Batch 180/235] [D loss: 1.139681, acc: 85.94%] [G loss: 1.127762]\n",
      "[Epoch 22/50] [Batch 181/235] [D loss: 1.070478, acc: 86.13%] [G loss: 1.165168]\n",
      "[Epoch 22/50] [Batch 182/235] [D loss: 1.114114, acc: 86.52%] [G loss: 1.175993]\n",
      "[Epoch 22/50] [Batch 183/235] [D loss: 1.098020, acc: 85.55%] [G loss: 1.270812]\n",
      "[Epoch 22/50] [Batch 184/235] [D loss: 1.136767, acc: 88.48%] [G loss: 1.110613]\n",
      "[Epoch 22/50] [Batch 185/235] [D loss: 1.103045, acc: 86.72%] [G loss: 1.177228]\n",
      "[Epoch 22/50] [Batch 186/235] [D loss: 1.144664, acc: 87.30%] [G loss: 1.147609]\n",
      "[Epoch 22/50] [Batch 187/235] [D loss: 1.156905, acc: 88.87%] [G loss: 1.222782]\n",
      "[Epoch 22/50] [Batch 188/235] [D loss: 1.045024, acc: 85.74%] [G loss: 1.244979]\n",
      "[Epoch 22/50] [Batch 189/235] [D loss: 1.139540, acc: 83.20%] [G loss: 1.149062]\n",
      "[Epoch 22/50] [Batch 190/235] [D loss: 1.113821, acc: 86.52%] [G loss: 1.267120]\n",
      "[Epoch 22/50] [Batch 191/235] [D loss: 1.160547, acc: 84.77%] [G loss: 1.066563]\n",
      "[Epoch 22/50] [Batch 192/235] [D loss: 1.142382, acc: 86.13%] [G loss: 1.132995]\n",
      "[Epoch 22/50] [Batch 193/235] [D loss: 1.090555, acc: 86.91%] [G loss: 1.125996]\n",
      "[Epoch 22/50] [Batch 194/235] [D loss: 1.159705, acc: 82.42%] [G loss: 1.243138]\n",
      "[Epoch 22/50] [Batch 195/235] [D loss: 1.123736, acc: 85.74%] [G loss: 1.218558]\n",
      "[Epoch 22/50] [Batch 196/235] [D loss: 1.078478, acc: 83.20%] [G loss: 1.128369]\n",
      "[Epoch 22/50] [Batch 197/235] [D loss: 1.120492, acc: 90.04%] [G loss: 1.227976]\n",
      "[Epoch 22/50] [Batch 198/235] [D loss: 1.162715, acc: 83.59%] [G loss: 1.190504]\n",
      "[Epoch 22/50] [Batch 199/235] [D loss: 1.127060, acc: 86.52%] [G loss: 1.081903]\n",
      "[Epoch 22/50] [Batch 200/235] [D loss: 1.090938, acc: 86.52%] [G loss: 1.211370]\n",
      "[Epoch 22/50] [Batch 201/235] [D loss: 1.107109, acc: 83.20%] [G loss: 1.157947]\n",
      "[Epoch 22/50] [Batch 202/235] [D loss: 1.100411, acc: 86.91%] [G loss: 1.209163]\n",
      "[Epoch 22/50] [Batch 203/235] [D loss: 1.111459, acc: 85.16%] [G loss: 1.158834]\n",
      "[Epoch 22/50] [Batch 204/235] [D loss: 1.100808, acc: 88.09%] [G loss: 1.258867]\n",
      "[Epoch 22/50] [Batch 205/235] [D loss: 1.095663, acc: 88.28%] [G loss: 1.194849]\n",
      "[Epoch 22/50] [Batch 206/235] [D loss: 1.107955, acc: 86.13%] [G loss: 1.084137]\n",
      "[Epoch 22/50] [Batch 207/235] [D loss: 1.176446, acc: 83.01%] [G loss: 1.104734]\n",
      "[Epoch 22/50] [Batch 208/235] [D loss: 1.147235, acc: 87.50%] [G loss: 1.269033]\n",
      "[Epoch 22/50] [Batch 209/235] [D loss: 1.089267, acc: 88.87%] [G loss: 1.142284]\n",
      "[Epoch 22/50] [Batch 210/235] [D loss: 1.150836, acc: 85.16%] [G loss: 1.024010]\n",
      "[Epoch 22/50] [Batch 211/235] [D loss: 1.136417, acc: 85.35%] [G loss: 1.135370]\n",
      "[Epoch 22/50] [Batch 212/235] [D loss: 1.108874, acc: 88.67%] [G loss: 1.259014]\n",
      "[Epoch 22/50] [Batch 213/235] [D loss: 1.132925, acc: 85.94%] [G loss: 1.206023]\n",
      "[Epoch 22/50] [Batch 214/235] [D loss: 1.105152, acc: 86.13%] [G loss: 1.152034]\n",
      "[Epoch 22/50] [Batch 215/235] [D loss: 1.112024, acc: 87.11%] [G loss: 1.166458]\n",
      "[Epoch 22/50] [Batch 216/235] [D loss: 1.146013, acc: 84.18%] [G loss: 1.134907]\n",
      "[Epoch 22/50] [Batch 217/235] [D loss: 1.133877, acc: 84.57%] [G loss: 1.190199]\n",
      "[Epoch 22/50] [Batch 218/235] [D loss: 1.079572, acc: 87.70%] [G loss: 1.277012]\n",
      "[Epoch 22/50] [Batch 219/235] [D loss: 1.113970, acc: 85.74%] [G loss: 1.194068]\n",
      "[Epoch 22/50] [Batch 220/235] [D loss: 1.089069, acc: 85.16%] [G loss: 1.148338]\n",
      "[Epoch 22/50] [Batch 221/235] [D loss: 1.124747, acc: 86.52%] [G loss: 1.135956]\n",
      "[Epoch 22/50] [Batch 222/235] [D loss: 1.103115, acc: 87.70%] [G loss: 1.113458]\n",
      "[Epoch 22/50] [Batch 223/235] [D loss: 1.132290, acc: 87.70%] [G loss: 1.214781]\n",
      "[Epoch 22/50] [Batch 224/235] [D loss: 1.088289, acc: 88.28%] [G loss: 1.081510]\n",
      "[Epoch 22/50] [Batch 225/235] [D loss: 1.155341, acc: 86.72%] [G loss: 1.153148]\n",
      "[Epoch 22/50] [Batch 226/235] [D loss: 1.091899, acc: 87.11%] [G loss: 1.180011]\n",
      "[Epoch 22/50] [Batch 227/235] [D loss: 1.166429, acc: 84.57%] [G loss: 1.214596]\n",
      "[Epoch 22/50] [Batch 228/235] [D loss: 1.117892, acc: 86.13%] [G loss: 1.229413]\n",
      "[Epoch 22/50] [Batch 229/235] [D loss: 1.130010, acc: 86.52%] [G loss: 1.161637]\n",
      "[Epoch 22/50] [Batch 230/235] [D loss: 1.170058, acc: 85.74%] [G loss: 1.206083]\n",
      "[Epoch 22/50] [Batch 231/235] [D loss: 1.072270, acc: 87.70%] [G loss: 1.299640]\n",
      "[Epoch 22/50] [Batch 232/235] [D loss: 1.077152, acc: 85.55%] [G loss: 1.175526]\n",
      "[Epoch 22/50] [Batch 233/235] [D loss: 1.132916, acc: 86.72%] [G loss: 1.126592]\n",
      "[Epoch 22/50] [Batch 234/235] [D loss: 1.054714, acc: 83.85%] [G loss: 1.265193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/50] [Batch 0/235] [D loss: 1.128610, acc: 87.30%] [G loss: 1.163011]\n",
      "[Epoch 23/50] [Batch 1/235] [D loss: 1.134430, acc: 85.35%] [G loss: 1.102150]\n",
      "[Epoch 23/50] [Batch 2/235] [D loss: 1.134530, acc: 84.57%] [G loss: 1.161189]\n",
      "[Epoch 23/50] [Batch 3/235] [D loss: 1.106098, acc: 89.06%] [G loss: 1.205369]\n",
      "[Epoch 23/50] [Batch 4/235] [D loss: 1.115365, acc: 83.98%] [G loss: 1.208271]\n",
      "[Epoch 23/50] [Batch 5/235] [D loss: 1.103549, acc: 86.13%] [G loss: 1.053622]\n",
      "[Epoch 23/50] [Batch 6/235] [D loss: 1.071553, acc: 85.94%] [G loss: 1.378820]\n",
      "[Epoch 23/50] [Batch 7/235] [D loss: 1.091988, acc: 85.94%] [G loss: 1.191583]\n",
      "[Epoch 23/50] [Batch 8/235] [D loss: 1.088702, acc: 84.18%] [G loss: 1.101007]\n",
      "[Epoch 23/50] [Batch 9/235] [D loss: 1.110623, acc: 87.89%] [G loss: 1.149908]\n",
      "[Epoch 23/50] [Batch 10/235] [D loss: 1.162835, acc: 85.94%] [G loss: 1.249590]\n",
      "[Epoch 23/50] [Batch 11/235] [D loss: 1.119426, acc: 87.50%] [G loss: 1.218353]\n",
      "[Epoch 23/50] [Batch 12/235] [D loss: 1.125053, acc: 87.11%] [G loss: 1.208956]\n",
      "[Epoch 23/50] [Batch 13/235] [D loss: 1.122590, acc: 86.13%] [G loss: 1.136599]\n",
      "[Epoch 23/50] [Batch 14/235] [D loss: 1.123551, acc: 83.79%] [G loss: 1.315709]\n",
      "[Epoch 23/50] [Batch 15/235] [D loss: 1.136919, acc: 83.79%] [G loss: 1.187407]\n",
      "[Epoch 23/50] [Batch 16/235] [D loss: 1.040376, acc: 87.70%] [G loss: 1.153739]\n",
      "[Epoch 23/50] [Batch 17/235] [D loss: 1.049579, acc: 88.09%] [G loss: 1.138061]\n",
      "[Epoch 23/50] [Batch 18/235] [D loss: 1.135640, acc: 87.50%] [G loss: 1.182152]\n",
      "[Epoch 23/50] [Batch 19/235] [D loss: 1.102030, acc: 84.77%] [G loss: 1.141169]\n",
      "[Epoch 23/50] [Batch 20/235] [D loss: 1.094677, acc: 86.52%] [G loss: 1.256401]\n",
      "[Epoch 23/50] [Batch 21/235] [D loss: 1.097188, acc: 87.89%] [G loss: 1.128681]\n",
      "[Epoch 23/50] [Batch 22/235] [D loss: 1.113894, acc: 87.11%] [G loss: 1.223380]\n",
      "[Epoch 23/50] [Batch 23/235] [D loss: 1.093568, acc: 84.77%] [G loss: 1.136218]\n",
      "[Epoch 23/50] [Batch 24/235] [D loss: 1.138456, acc: 85.16%] [G loss: 1.136718]\n",
      "[Epoch 23/50] [Batch 25/235] [D loss: 1.092218, acc: 88.48%] [G loss: 1.218888]\n",
      "[Epoch 23/50] [Batch 26/235] [D loss: 1.094962, acc: 88.09%] [G loss: 1.058573]\n",
      "[Epoch 23/50] [Batch 27/235] [D loss: 1.106090, acc: 86.13%] [G loss: 1.168593]\n",
      "[Epoch 23/50] [Batch 28/235] [D loss: 1.108901, acc: 85.94%] [G loss: 1.202904]\n",
      "[Epoch 23/50] [Batch 29/235] [D loss: 1.142569, acc: 85.74%] [G loss: 1.131373]\n",
      "[Epoch 23/50] [Batch 30/235] [D loss: 1.134022, acc: 85.55%] [G loss: 1.130736]\n",
      "[Epoch 23/50] [Batch 31/235] [D loss: 1.170350, acc: 86.91%] [G loss: 1.127966]\n",
      "[Epoch 23/50] [Batch 32/235] [D loss: 1.105069, acc: 87.11%] [G loss: 1.155119]\n",
      "[Epoch 23/50] [Batch 33/235] [D loss: 1.114009, acc: 86.52%] [G loss: 1.276020]\n",
      "[Epoch 23/50] [Batch 34/235] [D loss: 1.100377, acc: 85.74%] [G loss: 1.081837]\n",
      "[Epoch 23/50] [Batch 35/235] [D loss: 1.130876, acc: 85.74%] [G loss: 1.105478]\n",
      "[Epoch 23/50] [Batch 36/235] [D loss: 1.110945, acc: 84.18%] [G loss: 1.237567]\n",
      "[Epoch 23/50] [Batch 37/235] [D loss: 1.132931, acc: 85.35%] [G loss: 1.230525]\n",
      "[Epoch 23/50] [Batch 38/235] [D loss: 1.146679, acc: 86.33%] [G loss: 1.183512]\n",
      "[Epoch 23/50] [Batch 39/235] [D loss: 1.119619, acc: 86.13%] [G loss: 1.110008]\n",
      "[Epoch 23/50] [Batch 40/235] [D loss: 1.122203, acc: 86.52%] [G loss: 1.236968]\n",
      "[Epoch 23/50] [Batch 41/235] [D loss: 1.186646, acc: 87.89%] [G loss: 1.209396]\n",
      "[Epoch 23/50] [Batch 42/235] [D loss: 1.147791, acc: 83.98%] [G loss: 1.083030]\n",
      "[Epoch 23/50] [Batch 43/235] [D loss: 1.133889, acc: 85.94%] [G loss: 1.095023]\n",
      "[Epoch 23/50] [Batch 44/235] [D loss: 1.124332, acc: 89.26%] [G loss: 1.206272]\n",
      "[Epoch 23/50] [Batch 45/235] [D loss: 1.117970, acc: 87.70%] [G loss: 1.150846]\n",
      "[Epoch 23/50] [Batch 46/235] [D loss: 1.122152, acc: 86.72%] [G loss: 1.236796]\n",
      "[Epoch 23/50] [Batch 47/235] [D loss: 1.126841, acc: 85.16%] [G loss: 1.281407]\n",
      "[Epoch 23/50] [Batch 48/235] [D loss: 1.116208, acc: 85.35%] [G loss: 1.088328]\n",
      "[Epoch 23/50] [Batch 49/235] [D loss: 1.110451, acc: 89.65%] [G loss: 1.067429]\n",
      "[Epoch 23/50] [Batch 50/235] [D loss: 1.115283, acc: 87.89%] [G loss: 1.132722]\n",
      "[Epoch 23/50] [Batch 51/235] [D loss: 1.081772, acc: 85.55%] [G loss: 1.271135]\n",
      "[Epoch 23/50] [Batch 52/235] [D loss: 1.121188, acc: 86.52%] [G loss: 1.146312]\n",
      "[Epoch 23/50] [Batch 53/235] [D loss: 1.162558, acc: 84.96%] [G loss: 1.261584]\n",
      "[Epoch 23/50] [Batch 54/235] [D loss: 1.190485, acc: 85.94%] [G loss: 1.205400]\n",
      "[Epoch 23/50] [Batch 55/235] [D loss: 1.109966, acc: 88.28%] [G loss: 1.186637]\n",
      "[Epoch 23/50] [Batch 56/235] [D loss: 1.114170, acc: 85.35%] [G loss: 1.108385]\n",
      "[Epoch 23/50] [Batch 57/235] [D loss: 1.113852, acc: 88.28%] [G loss: 1.146271]\n",
      "[Epoch 23/50] [Batch 58/235] [D loss: 1.110125, acc: 86.33%] [G loss: 1.138515]\n",
      "[Epoch 23/50] [Batch 59/235] [D loss: 1.101113, acc: 86.52%] [G loss: 1.008029]\n",
      "[Epoch 23/50] [Batch 60/235] [D loss: 1.106748, acc: 88.87%] [G loss: 1.145948]\n",
      "[Epoch 23/50] [Batch 61/235] [D loss: 1.133583, acc: 85.94%] [G loss: 1.208252]\n",
      "[Epoch 23/50] [Batch 62/235] [D loss: 1.081626, acc: 86.91%] [G loss: 1.165550]\n",
      "[Epoch 23/50] [Batch 63/235] [D loss: 1.085026, acc: 85.16%] [G loss: 1.136925]\n",
      "[Epoch 23/50] [Batch 64/235] [D loss: 1.129307, acc: 85.94%] [G loss: 1.190452]\n",
      "[Epoch 23/50] [Batch 65/235] [D loss: 1.069280, acc: 88.09%] [G loss: 1.429221]\n",
      "[Epoch 23/50] [Batch 66/235] [D loss: 1.186326, acc: 86.52%] [G loss: 1.189622]\n",
      "[Epoch 23/50] [Batch 67/235] [D loss: 1.141625, acc: 87.30%] [G loss: 1.218509]\n",
      "[Epoch 23/50] [Batch 68/235] [D loss: 1.172235, acc: 85.74%] [G loss: 1.088139]\n",
      "[Epoch 23/50] [Batch 69/235] [D loss: 1.173026, acc: 85.55%] [G loss: 1.103588]\n",
      "[Epoch 23/50] [Batch 70/235] [D loss: 1.090255, acc: 84.18%] [G loss: 1.294878]\n",
      "[Epoch 23/50] [Batch 71/235] [D loss: 1.084183, acc: 86.72%] [G loss: 1.197211]\n",
      "[Epoch 23/50] [Batch 72/235] [D loss: 1.130758, acc: 85.55%] [G loss: 1.156281]\n",
      "[Epoch 23/50] [Batch 73/235] [D loss: 1.141792, acc: 84.96%] [G loss: 1.081230]\n",
      "[Epoch 23/50] [Batch 74/235] [D loss: 1.121357, acc: 86.72%] [G loss: 1.173097]\n",
      "[Epoch 23/50] [Batch 75/235] [D loss: 1.161059, acc: 85.35%] [G loss: 1.350613]\n",
      "[Epoch 23/50] [Batch 76/235] [D loss: 1.090887, acc: 85.35%] [G loss: 1.167965]\n",
      "[Epoch 23/50] [Batch 77/235] [D loss: 1.112431, acc: 88.87%] [G loss: 1.181379]\n",
      "[Epoch 23/50] [Batch 78/235] [D loss: 1.094045, acc: 83.79%] [G loss: 1.075368]\n",
      "[Epoch 23/50] [Batch 79/235] [D loss: 1.069360, acc: 86.91%] [G loss: 1.266706]\n",
      "[Epoch 23/50] [Batch 80/235] [D loss: 1.143063, acc: 86.72%] [G loss: 1.179514]\n",
      "[Epoch 23/50] [Batch 81/235] [D loss: 1.116929, acc: 84.77%] [G loss: 1.247730]\n",
      "[Epoch 23/50] [Batch 82/235] [D loss: 1.127610, acc: 83.59%] [G loss: 1.231524]\n",
      "[Epoch 23/50] [Batch 83/235] [D loss: 1.166706, acc: 86.91%] [G loss: 1.155398]\n",
      "[Epoch 23/50] [Batch 84/235] [D loss: 1.141902, acc: 87.30%] [G loss: 1.161976]\n",
      "[Epoch 23/50] [Batch 85/235] [D loss: 1.132743, acc: 86.33%] [G loss: 1.114897]\n",
      "[Epoch 23/50] [Batch 86/235] [D loss: 1.122932, acc: 87.11%] [G loss: 1.209770]\n",
      "[Epoch 23/50] [Batch 87/235] [D loss: 1.094716, acc: 86.52%] [G loss: 1.179442]\n",
      "[Epoch 23/50] [Batch 88/235] [D loss: 1.159684, acc: 84.18%] [G loss: 1.128869]\n",
      "[Epoch 23/50] [Batch 89/235] [D loss: 1.164988, acc: 87.70%] [G loss: 1.149010]\n",
      "[Epoch 23/50] [Batch 90/235] [D loss: 1.129165, acc: 86.33%] [G loss: 1.249583]\n",
      "[Epoch 23/50] [Batch 91/235] [D loss: 1.127727, acc: 87.30%] [G loss: 1.168171]\n",
      "[Epoch 23/50] [Batch 92/235] [D loss: 1.104931, acc: 86.13%] [G loss: 1.140161]\n",
      "[Epoch 23/50] [Batch 93/235] [D loss: 1.131431, acc: 85.35%] [G loss: 1.116805]\n",
      "[Epoch 23/50] [Batch 94/235] [D loss: 1.124941, acc: 85.16%] [G loss: 1.227977]\n",
      "[Epoch 23/50] [Batch 95/235] [D loss: 1.128996, acc: 85.55%] [G loss: 1.199484]\n",
      "[Epoch 23/50] [Batch 96/235] [D loss: 1.152273, acc: 85.35%] [G loss: 1.089970]\n",
      "[Epoch 23/50] [Batch 97/235] [D loss: 1.126702, acc: 84.57%] [G loss: 1.069238]\n",
      "[Epoch 23/50] [Batch 98/235] [D loss: 1.146158, acc: 84.77%] [G loss: 1.130293]\n",
      "[Epoch 23/50] [Batch 99/235] [D loss: 1.109804, acc: 85.55%] [G loss: 1.295789]\n",
      "[Epoch 23/50] [Batch 100/235] [D loss: 1.216560, acc: 85.74%] [G loss: 1.143346]\n",
      "[Epoch 23/50] [Batch 101/235] [D loss: 1.110820, acc: 89.45%] [G loss: 1.085383]\n",
      "[Epoch 23/50] [Batch 102/235] [D loss: 1.070006, acc: 87.30%] [G loss: 1.246584]\n",
      "[Epoch 23/50] [Batch 103/235] [D loss: 1.136694, acc: 87.30%] [G loss: 1.206026]\n",
      "[Epoch 23/50] [Batch 104/235] [D loss: 1.128517, acc: 89.06%] [G loss: 1.115798]\n",
      "[Epoch 23/50] [Batch 105/235] [D loss: 1.070578, acc: 88.67%] [G loss: 1.114892]\n",
      "[Epoch 23/50] [Batch 106/235] [D loss: 1.158303, acc: 86.52%] [G loss: 1.122057]\n",
      "[Epoch 23/50] [Batch 107/235] [D loss: 1.137775, acc: 85.55%] [G loss: 1.139535]\n",
      "[Epoch 23/50] [Batch 108/235] [D loss: 1.142571, acc: 85.16%] [G loss: 1.135227]\n",
      "[Epoch 23/50] [Batch 109/235] [D loss: 1.150303, acc: 88.28%] [G loss: 1.110259]\n",
      "[Epoch 23/50] [Batch 110/235] [D loss: 1.094040, acc: 87.30%] [G loss: 1.158256]\n",
      "[Epoch 23/50] [Batch 111/235] [D loss: 1.113001, acc: 85.94%] [G loss: 1.108556]\n",
      "[Epoch 23/50] [Batch 112/235] [D loss: 1.103254, acc: 84.18%] [G loss: 1.169124]\n",
      "[Epoch 23/50] [Batch 113/235] [D loss: 1.107897, acc: 87.89%] [G loss: 1.190546]\n",
      "[Epoch 23/50] [Batch 114/235] [D loss: 1.141961, acc: 86.91%] [G loss: 1.164711]\n",
      "[Epoch 23/50] [Batch 115/235] [D loss: 1.063047, acc: 87.70%] [G loss: 1.174374]\n",
      "[Epoch 23/50] [Batch 116/235] [D loss: 1.111371, acc: 87.70%] [G loss: 1.161494]\n",
      "[Epoch 23/50] [Batch 117/235] [D loss: 1.081915, acc: 87.30%] [G loss: 1.123463]\n",
      "[Epoch 23/50] [Batch 118/235] [D loss: 1.133297, acc: 89.06%] [G loss: 1.004119]\n",
      "[Epoch 23/50] [Batch 119/235] [D loss: 1.122788, acc: 86.91%] [G loss: 1.210490]\n",
      "[Epoch 23/50] [Batch 120/235] [D loss: 1.140496, acc: 88.09%] [G loss: 1.112560]\n",
      "[Epoch 23/50] [Batch 121/235] [D loss: 1.095180, acc: 87.89%] [G loss: 1.197443]\n",
      "[Epoch 23/50] [Batch 122/235] [D loss: 1.083422, acc: 85.74%] [G loss: 1.168250]\n",
      "[Epoch 23/50] [Batch 123/235] [D loss: 1.136649, acc: 86.13%] [G loss: 1.121823]\n",
      "[Epoch 23/50] [Batch 124/235] [D loss: 1.106168, acc: 86.33%] [G loss: 1.326763]\n",
      "[Epoch 23/50] [Batch 125/235] [D loss: 1.157590, acc: 85.94%] [G loss: 1.230885]\n",
      "[Epoch 23/50] [Batch 126/235] [D loss: 1.060682, acc: 86.52%] [G loss: 1.064307]\n",
      "[Epoch 23/50] [Batch 127/235] [D loss: 1.160748, acc: 87.11%] [G loss: 1.229539]\n",
      "[Epoch 23/50] [Batch 128/235] [D loss: 1.162144, acc: 86.52%] [G loss: 1.188062]\n",
      "[Epoch 23/50] [Batch 129/235] [D loss: 1.089649, acc: 88.28%] [G loss: 1.183580]\n",
      "[Epoch 23/50] [Batch 130/235] [D loss: 1.096362, acc: 85.74%] [G loss: 1.087008]\n",
      "[Epoch 23/50] [Batch 131/235] [D loss: 1.136317, acc: 86.72%] [G loss: 1.112334]\n",
      "[Epoch 23/50] [Batch 132/235] [D loss: 1.118695, acc: 88.09%] [G loss: 1.135656]\n",
      "[Epoch 23/50] [Batch 133/235] [D loss: 1.099509, acc: 87.11%] [G loss: 1.285397]\n",
      "[Epoch 23/50] [Batch 134/235] [D loss: 1.137663, acc: 84.57%] [G loss: 1.132629]\n",
      "[Epoch 23/50] [Batch 135/235] [D loss: 1.134785, acc: 84.96%] [G loss: 1.065506]\n",
      "[Epoch 23/50] [Batch 136/235] [D loss: 1.047825, acc: 87.70%] [G loss: 1.140781]\n",
      "[Epoch 23/50] [Batch 137/235] [D loss: 1.147002, acc: 86.13%] [G loss: 1.177660]\n",
      "[Epoch 23/50] [Batch 138/235] [D loss: 1.122680, acc: 84.96%] [G loss: 1.267405]\n",
      "[Epoch 23/50] [Batch 139/235] [D loss: 1.070129, acc: 88.87%] [G loss: 1.162631]\n",
      "[Epoch 23/50] [Batch 140/235] [D loss: 1.116157, acc: 87.11%] [G loss: 1.192579]\n",
      "[Epoch 23/50] [Batch 141/235] [D loss: 1.122720, acc: 86.91%] [G loss: 1.167606]\n",
      "[Epoch 23/50] [Batch 142/235] [D loss: 1.075206, acc: 87.50%] [G loss: 1.180617]\n",
      "[Epoch 23/50] [Batch 143/235] [D loss: 1.078356, acc: 86.91%] [G loss: 1.151311]\n",
      "[Epoch 23/50] [Batch 144/235] [D loss: 1.106540, acc: 85.35%] [G loss: 1.337597]\n",
      "[Epoch 23/50] [Batch 145/235] [D loss: 1.111397, acc: 85.35%] [G loss: 1.071896]\n",
      "[Epoch 23/50] [Batch 146/235] [D loss: 1.069914, acc: 88.09%] [G loss: 1.168020]\n",
      "[Epoch 23/50] [Batch 147/235] [D loss: 1.126863, acc: 86.72%] [G loss: 1.055505]\n",
      "[Epoch 23/50] [Batch 148/235] [D loss: 1.080289, acc: 84.96%] [G loss: 1.185969]\n",
      "[Epoch 23/50] [Batch 149/235] [D loss: 1.132387, acc: 85.74%] [G loss: 1.112212]\n",
      "[Epoch 23/50] [Batch 150/235] [D loss: 1.090683, acc: 88.67%] [G loss: 1.027283]\n",
      "[Epoch 23/50] [Batch 151/235] [D loss: 1.094994, acc: 86.13%] [G loss: 1.132736]\n",
      "[Epoch 23/50] [Batch 152/235] [D loss: 1.062323, acc: 87.70%] [G loss: 1.214388]\n",
      "[Epoch 23/50] [Batch 153/235] [D loss: 1.221019, acc: 85.35%] [G loss: 1.136937]\n",
      "[Epoch 23/50] [Batch 154/235] [D loss: 1.142062, acc: 87.70%] [G loss: 1.177025]\n",
      "[Epoch 23/50] [Batch 155/235] [D loss: 1.073099, acc: 86.91%] [G loss: 1.294323]\n",
      "[Epoch 23/50] [Batch 156/235] [D loss: 1.119138, acc: 84.57%] [G loss: 1.206303]\n",
      "[Epoch 23/50] [Batch 157/235] [D loss: 1.106896, acc: 87.70%] [G loss: 1.137681]\n",
      "[Epoch 23/50] [Batch 158/235] [D loss: 1.114338, acc: 87.89%] [G loss: 1.155094]\n",
      "[Epoch 23/50] [Batch 159/235] [D loss: 1.135109, acc: 84.77%] [G loss: 1.125124]\n",
      "[Epoch 23/50] [Batch 160/235] [D loss: 1.114829, acc: 85.74%] [G loss: 1.181226]\n",
      "[Epoch 23/50] [Batch 161/235] [D loss: 1.088577, acc: 87.11%] [G loss: 1.094607]\n",
      "[Epoch 23/50] [Batch 162/235] [D loss: 1.134372, acc: 86.52%] [G loss: 1.180376]\n",
      "[Epoch 23/50] [Batch 163/235] [D loss: 1.116490, acc: 88.87%] [G loss: 1.189965]\n",
      "[Epoch 23/50] [Batch 164/235] [D loss: 1.155936, acc: 86.33%] [G loss: 1.253909]\n",
      "[Epoch 23/50] [Batch 165/235] [D loss: 1.123596, acc: 87.30%] [G loss: 1.211862]\n",
      "[Epoch 23/50] [Batch 166/235] [D loss: 1.124359, acc: 87.70%] [G loss: 1.024016]\n",
      "[Epoch 23/50] [Batch 167/235] [D loss: 1.059214, acc: 87.70%] [G loss: 1.290332]\n",
      "[Epoch 23/50] [Batch 168/235] [D loss: 1.114651, acc: 86.72%] [G loss: 1.256809]\n",
      "[Epoch 23/50] [Batch 169/235] [D loss: 1.080791, acc: 87.11%] [G loss: 1.212143]\n",
      "[Epoch 23/50] [Batch 170/235] [D loss: 1.152352, acc: 83.40%] [G loss: 1.112288]\n",
      "[Epoch 23/50] [Batch 171/235] [D loss: 1.088523, acc: 83.79%] [G loss: 1.182693]\n",
      "[Epoch 23/50] [Batch 172/235] [D loss: 1.097961, acc: 85.74%] [G loss: 1.140915]\n",
      "[Epoch 23/50] [Batch 173/235] [D loss: 1.111495, acc: 86.52%] [G loss: 1.279750]\n",
      "[Epoch 23/50] [Batch 174/235] [D loss: 1.113456, acc: 90.62%] [G loss: 1.176218]\n",
      "[Epoch 23/50] [Batch 175/235] [D loss: 1.153678, acc: 87.50%] [G loss: 1.104774]\n",
      "[Epoch 23/50] [Batch 176/235] [D loss: 1.129315, acc: 84.57%] [G loss: 1.113105]\n",
      "[Epoch 23/50] [Batch 177/235] [D loss: 1.086382, acc: 87.11%] [G loss: 1.208032]\n",
      "[Epoch 23/50] [Batch 178/235] [D loss: 1.095889, acc: 87.89%] [G loss: 1.068922]\n",
      "[Epoch 23/50] [Batch 179/235] [D loss: 1.104048, acc: 85.94%] [G loss: 1.127985]\n",
      "[Epoch 23/50] [Batch 180/235] [D loss: 1.103840, acc: 87.89%] [G loss: 1.177260]\n",
      "[Epoch 23/50] [Batch 181/235] [D loss: 1.100417, acc: 88.09%] [G loss: 1.335742]\n",
      "[Epoch 23/50] [Batch 182/235] [D loss: 1.127415, acc: 88.67%] [G loss: 1.027015]\n",
      "[Epoch 23/50] [Batch 183/235] [D loss: 1.123790, acc: 87.70%] [G loss: 1.047502]\n",
      "[Epoch 23/50] [Batch 184/235] [D loss: 1.067899, acc: 86.13%] [G loss: 1.256024]\n",
      "[Epoch 23/50] [Batch 185/235] [D loss: 1.141943, acc: 84.77%] [G loss: 1.228453]\n",
      "[Epoch 23/50] [Batch 186/235] [D loss: 1.155429, acc: 87.11%] [G loss: 1.216158]\n",
      "[Epoch 23/50] [Batch 187/235] [D loss: 1.140545, acc: 85.16%] [G loss: 1.173192]\n",
      "[Epoch 23/50] [Batch 188/235] [D loss: 1.072451, acc: 86.52%] [G loss: 1.182058]\n",
      "[Epoch 23/50] [Batch 189/235] [D loss: 1.145570, acc: 86.13%] [G loss: 1.091543]\n",
      "[Epoch 23/50] [Batch 190/235] [D loss: 1.100310, acc: 86.52%] [G loss: 1.113831]\n",
      "[Epoch 23/50] [Batch 191/235] [D loss: 1.178960, acc: 87.30%] [G loss: 1.215890]\n",
      "[Epoch 23/50] [Batch 192/235] [D loss: 1.122115, acc: 88.48%] [G loss: 1.232920]\n",
      "[Epoch 23/50] [Batch 193/235] [D loss: 1.090103, acc: 86.52%] [G loss: 1.218775]\n",
      "[Epoch 23/50] [Batch 194/235] [D loss: 1.147024, acc: 84.18%] [G loss: 1.127594]\n",
      "[Epoch 23/50] [Batch 195/235] [D loss: 1.085135, acc: 88.28%] [G loss: 1.212352]\n",
      "[Epoch 23/50] [Batch 196/235] [D loss: 1.043586, acc: 85.55%] [G loss: 1.213999]\n",
      "[Epoch 23/50] [Batch 197/235] [D loss: 1.075074, acc: 85.35%] [G loss: 1.277011]\n",
      "[Epoch 23/50] [Batch 198/235] [D loss: 1.141463, acc: 86.72%] [G loss: 1.136568]\n",
      "[Epoch 23/50] [Batch 199/235] [D loss: 1.152648, acc: 87.11%] [G loss: 1.111863]\n",
      "[Epoch 23/50] [Batch 200/235] [D loss: 1.071195, acc: 84.38%] [G loss: 1.174232]\n",
      "[Epoch 23/50] [Batch 201/235] [D loss: 1.119432, acc: 87.70%] [G loss: 1.171957]\n",
      "[Epoch 23/50] [Batch 202/235] [D loss: 1.122905, acc: 85.55%] [G loss: 1.075959]\n",
      "[Epoch 23/50] [Batch 203/235] [D loss: 1.086082, acc: 87.89%] [G loss: 1.221288]\n",
      "[Epoch 23/50] [Batch 204/235] [D loss: 1.111931, acc: 87.11%] [G loss: 1.192359]\n",
      "[Epoch 23/50] [Batch 205/235] [D loss: 1.141955, acc: 84.57%] [G loss: 1.170829]\n",
      "[Epoch 23/50] [Batch 206/235] [D loss: 1.061929, acc: 86.13%] [G loss: 1.169544]\n",
      "[Epoch 23/50] [Batch 207/235] [D loss: 1.135771, acc: 85.16%] [G loss: 1.188936]\n",
      "[Epoch 23/50] [Batch 208/235] [D loss: 1.105173, acc: 85.74%] [G loss: 1.152889]\n",
      "[Epoch 23/50] [Batch 209/235] [D loss: 1.070601, acc: 87.50%] [G loss: 1.112567]\n",
      "[Epoch 23/50] [Batch 210/235] [D loss: 1.064594, acc: 86.72%] [G loss: 1.228150]\n",
      "[Epoch 23/50] [Batch 211/235] [D loss: 1.068971, acc: 87.50%] [G loss: 1.245320]\n",
      "[Epoch 23/50] [Batch 212/235] [D loss: 1.135968, acc: 86.13%] [G loss: 1.127311]\n",
      "[Epoch 23/50] [Batch 213/235] [D loss: 1.122364, acc: 87.11%] [G loss: 1.186964]\n",
      "[Epoch 23/50] [Batch 214/235] [D loss: 1.122128, acc: 86.91%] [G loss: 1.219842]\n",
      "[Epoch 23/50] [Batch 215/235] [D loss: 1.109694, acc: 86.13%] [G loss: 1.132872]\n",
      "[Epoch 23/50] [Batch 216/235] [D loss: 1.093016, acc: 84.96%] [G loss: 1.216405]\n",
      "[Epoch 23/50] [Batch 217/235] [D loss: 1.143898, acc: 86.91%] [G loss: 1.101572]\n",
      "[Epoch 23/50] [Batch 218/235] [D loss: 1.158488, acc: 84.57%] [G loss: 1.302187]\n",
      "[Epoch 23/50] [Batch 219/235] [D loss: 1.128242, acc: 85.55%] [G loss: 1.152504]\n",
      "[Epoch 23/50] [Batch 220/235] [D loss: 1.088089, acc: 84.96%] [G loss: 1.230867]\n",
      "[Epoch 23/50] [Batch 221/235] [D loss: 1.065063, acc: 87.89%] [G loss: 1.270599]\n",
      "[Epoch 23/50] [Batch 222/235] [D loss: 1.108564, acc: 84.96%] [G loss: 1.194124]\n",
      "[Epoch 23/50] [Batch 223/235] [D loss: 1.082365, acc: 87.50%] [G loss: 1.150830]\n",
      "[Epoch 23/50] [Batch 224/235] [D loss: 1.073176, acc: 85.94%] [G loss: 1.086926]\n",
      "[Epoch 23/50] [Batch 225/235] [D loss: 1.086393, acc: 86.33%] [G loss: 1.127053]\n",
      "[Epoch 23/50] [Batch 226/235] [D loss: 1.130715, acc: 86.91%] [G loss: 1.117923]\n",
      "[Epoch 23/50] [Batch 227/235] [D loss: 1.122531, acc: 86.91%] [G loss: 1.304595]\n",
      "[Epoch 23/50] [Batch 228/235] [D loss: 1.115363, acc: 87.11%] [G loss: 1.168436]\n",
      "[Epoch 23/50] [Batch 229/235] [D loss: 1.093616, acc: 84.38%] [G loss: 1.179131]\n",
      "[Epoch 23/50] [Batch 230/235] [D loss: 1.089652, acc: 88.87%] [G loss: 1.191684]\n",
      "[Epoch 23/50] [Batch 231/235] [D loss: 1.077947, acc: 83.98%] [G loss: 1.071774]\n",
      "[Epoch 23/50] [Batch 232/235] [D loss: 1.105020, acc: 85.55%] [G loss: 1.119796]\n",
      "[Epoch 23/50] [Batch 233/235] [D loss: 1.174786, acc: 83.59%] [G loss: 1.256702]\n",
      "[Epoch 23/50] [Batch 234/235] [D loss: 1.122470, acc: 85.94%] [G loss: 1.146719]\n",
      "[Epoch 24/50] [Batch 0/235] [D loss: 1.138214, acc: 84.57%] [G loss: 1.075937]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/50] [Batch 1/235] [D loss: 1.117970, acc: 86.33%] [G loss: 1.187132]\n",
      "[Epoch 24/50] [Batch 2/235] [D loss: 1.106109, acc: 85.94%] [G loss: 1.305396]\n",
      "[Epoch 24/50] [Batch 3/235] [D loss: 1.161015, acc: 88.48%] [G loss: 1.108975]\n",
      "[Epoch 24/50] [Batch 4/235] [D loss: 1.121063, acc: 86.33%] [G loss: 1.062042]\n",
      "[Epoch 24/50] [Batch 5/235] [D loss: 1.106292, acc: 85.74%] [G loss: 1.200726]\n",
      "[Epoch 24/50] [Batch 6/235] [D loss: 1.138845, acc: 86.91%] [G loss: 1.234164]\n",
      "[Epoch 24/50] [Batch 7/235] [D loss: 1.125020, acc: 87.30%] [G loss: 1.168518]\n",
      "[Epoch 24/50] [Batch 8/235] [D loss: 1.106837, acc: 82.62%] [G loss: 1.136939]\n",
      "[Epoch 24/50] [Batch 9/235] [D loss: 1.066421, acc: 87.30%] [G loss: 1.164999]\n",
      "[Epoch 24/50] [Batch 10/235] [D loss: 1.184775, acc: 87.11%] [G loss: 1.282152]\n",
      "[Epoch 24/50] [Batch 11/235] [D loss: 1.109686, acc: 88.87%] [G loss: 1.180564]\n",
      "[Epoch 24/50] [Batch 12/235] [D loss: 1.122446, acc: 85.74%] [G loss: 1.300681]\n",
      "[Epoch 24/50] [Batch 13/235] [D loss: 1.132971, acc: 88.28%] [G loss: 1.084460]\n",
      "[Epoch 24/50] [Batch 14/235] [D loss: 1.137578, acc: 84.18%] [G loss: 1.119344]\n",
      "[Epoch 24/50] [Batch 15/235] [D loss: 1.114581, acc: 85.94%] [G loss: 1.118887]\n",
      "[Epoch 24/50] [Batch 16/235] [D loss: 1.130096, acc: 86.72%] [G loss: 1.130737]\n",
      "[Epoch 24/50] [Batch 17/235] [D loss: 1.144023, acc: 86.13%] [G loss: 1.139406]\n",
      "[Epoch 24/50] [Batch 18/235] [D loss: 1.115955, acc: 86.52%] [G loss: 1.182444]\n",
      "[Epoch 24/50] [Batch 19/235] [D loss: 1.168299, acc: 86.91%] [G loss: 1.246292]\n",
      "[Epoch 24/50] [Batch 20/235] [D loss: 1.151748, acc: 88.09%] [G loss: 1.063009]\n",
      "[Epoch 24/50] [Batch 21/235] [D loss: 1.182411, acc: 84.77%] [G loss: 1.041733]\n",
      "[Epoch 24/50] [Batch 22/235] [D loss: 1.148765, acc: 86.13%] [G loss: 1.151664]\n",
      "[Epoch 24/50] [Batch 23/235] [D loss: 1.134110, acc: 88.09%] [G loss: 1.222838]\n",
      "[Epoch 24/50] [Batch 24/235] [D loss: 1.154812, acc: 86.52%] [G loss: 1.134174]\n",
      "[Epoch 24/50] [Batch 25/235] [D loss: 1.086527, acc: 85.35%] [G loss: 1.230782]\n",
      "[Epoch 24/50] [Batch 26/235] [D loss: 1.098710, acc: 86.33%] [G loss: 1.143860]\n",
      "[Epoch 24/50] [Batch 27/235] [D loss: 1.121884, acc: 85.55%] [G loss: 1.243876]\n",
      "[Epoch 24/50] [Batch 28/235] [D loss: 1.065053, acc: 86.13%] [G loss: 1.129917]\n",
      "[Epoch 24/50] [Batch 29/235] [D loss: 1.127925, acc: 85.94%] [G loss: 1.201424]\n",
      "[Epoch 24/50] [Batch 30/235] [D loss: 1.071412, acc: 85.35%] [G loss: 1.246078]\n",
      "[Epoch 24/50] [Batch 31/235] [D loss: 1.118456, acc: 86.13%] [G loss: 1.150991]\n",
      "[Epoch 24/50] [Batch 32/235] [D loss: 1.098852, acc: 87.30%] [G loss: 1.159805]\n",
      "[Epoch 24/50] [Batch 33/235] [D loss: 1.116534, acc: 85.74%] [G loss: 1.127005]\n",
      "[Epoch 24/50] [Batch 34/235] [D loss: 1.109115, acc: 85.94%] [G loss: 1.156963]\n",
      "[Epoch 24/50] [Batch 35/235] [D loss: 1.153396, acc: 88.28%] [G loss: 1.305237]\n",
      "[Epoch 24/50] [Batch 36/235] [D loss: 1.118149, acc: 87.30%] [G loss: 1.216909]\n",
      "[Epoch 24/50] [Batch 37/235] [D loss: 1.058364, acc: 86.72%] [G loss: 1.061986]\n",
      "[Epoch 24/50] [Batch 38/235] [D loss: 1.190343, acc: 85.35%] [G loss: 1.063634]\n",
      "[Epoch 24/50] [Batch 39/235] [D loss: 1.133721, acc: 86.52%] [G loss: 1.127714]\n",
      "[Epoch 24/50] [Batch 40/235] [D loss: 1.136364, acc: 88.87%] [G loss: 1.136303]\n",
      "[Epoch 24/50] [Batch 41/235] [D loss: 1.099460, acc: 87.30%] [G loss: 1.111914]\n",
      "[Epoch 24/50] [Batch 42/235] [D loss: 1.105396, acc: 86.33%] [G loss: 1.099267]\n",
      "[Epoch 24/50] [Batch 43/235] [D loss: 1.093608, acc: 87.30%] [G loss: 1.178916]\n",
      "[Epoch 24/50] [Batch 44/235] [D loss: 1.118551, acc: 86.33%] [G loss: 1.151472]\n",
      "[Epoch 24/50] [Batch 45/235] [D loss: 1.123516, acc: 87.50%] [G loss: 1.152785]\n",
      "[Epoch 24/50] [Batch 46/235] [D loss: 1.138593, acc: 84.96%] [G loss: 1.225306]\n",
      "[Epoch 24/50] [Batch 47/235] [D loss: 1.138940, acc: 83.40%] [G loss: 1.263080]\n",
      "[Epoch 24/50] [Batch 48/235] [D loss: 1.126094, acc: 88.09%] [G loss: 1.196811]\n",
      "[Epoch 24/50] [Batch 49/235] [D loss: 1.137344, acc: 84.57%] [G loss: 1.049517]\n",
      "[Epoch 24/50] [Batch 50/235] [D loss: 1.083589, acc: 87.50%] [G loss: 1.332374]\n",
      "[Epoch 24/50] [Batch 51/235] [D loss: 1.071836, acc: 88.09%] [G loss: 1.239627]\n",
      "[Epoch 24/50] [Batch 52/235] [D loss: 1.159160, acc: 86.52%] [G loss: 1.092752]\n",
      "[Epoch 24/50] [Batch 53/235] [D loss: 1.159024, acc: 85.35%] [G loss: 1.102223]\n",
      "[Epoch 24/50] [Batch 54/235] [D loss: 1.114013, acc: 87.30%] [G loss: 1.122772]\n",
      "[Epoch 24/50] [Batch 55/235] [D loss: 1.151258, acc: 86.13%] [G loss: 1.187267]\n",
      "[Epoch 24/50] [Batch 56/235] [D loss: 1.083592, acc: 86.72%] [G loss: 1.198979]\n",
      "[Epoch 24/50] [Batch 57/235] [D loss: 1.149007, acc: 87.11%] [G loss: 1.074280]\n",
      "[Epoch 24/50] [Batch 58/235] [D loss: 1.096183, acc: 86.72%] [G loss: 1.210842]\n",
      "[Epoch 24/50] [Batch 59/235] [D loss: 1.129723, acc: 87.70%] [G loss: 1.150856]\n",
      "[Epoch 24/50] [Batch 60/235] [D loss: 1.119171, acc: 87.70%] [G loss: 1.148097]\n",
      "[Epoch 24/50] [Batch 61/235] [D loss: 1.095072, acc: 85.35%] [G loss: 1.157488]\n",
      "[Epoch 24/50] [Batch 62/235] [D loss: 1.095036, acc: 87.50%] [G loss: 1.131304]\n",
      "[Epoch 24/50] [Batch 63/235] [D loss: 1.183275, acc: 84.18%] [G loss: 1.182663]\n",
      "[Epoch 24/50] [Batch 64/235] [D loss: 1.163234, acc: 87.11%] [G loss: 1.214760]\n",
      "[Epoch 24/50] [Batch 65/235] [D loss: 1.124465, acc: 84.77%] [G loss: 1.104364]\n",
      "[Epoch 24/50] [Batch 66/235] [D loss: 1.103154, acc: 86.72%] [G loss: 1.168941]\n",
      "[Epoch 24/50] [Batch 67/235] [D loss: 1.102348, acc: 85.16%] [G loss: 1.251177]\n",
      "[Epoch 24/50] [Batch 68/235] [D loss: 1.119911, acc: 86.91%] [G loss: 1.204665]\n",
      "[Epoch 24/50] [Batch 69/235] [D loss: 1.104142, acc: 88.09%] [G loss: 1.129571]\n",
      "[Epoch 24/50] [Batch 70/235] [D loss: 1.078267, acc: 87.89%] [G loss: 1.209419]\n",
      "[Epoch 24/50] [Batch 71/235] [D loss: 1.168893, acc: 83.40%] [G loss: 1.100161]\n",
      "[Epoch 24/50] [Batch 72/235] [D loss: 1.153807, acc: 86.91%] [G loss: 1.042759]\n",
      "[Epoch 24/50] [Batch 73/235] [D loss: 1.152802, acc: 84.38%] [G loss: 1.209808]\n",
      "[Epoch 24/50] [Batch 74/235] [D loss: 1.135574, acc: 85.16%] [G loss: 1.262745]\n",
      "[Epoch 24/50] [Batch 75/235] [D loss: 1.139919, acc: 86.13%] [G loss: 1.205112]\n",
      "[Epoch 24/50] [Batch 76/235] [D loss: 1.107816, acc: 85.16%] [G loss: 1.106067]\n",
      "[Epoch 24/50] [Batch 77/235] [D loss: 1.087912, acc: 84.77%] [G loss: 1.274994]\n",
      "[Epoch 24/50] [Batch 78/235] [D loss: 1.077090, acc: 86.72%] [G loss: 1.281172]\n",
      "[Epoch 24/50] [Batch 79/235] [D loss: 1.114255, acc: 86.52%] [G loss: 1.170877]\n",
      "[Epoch 24/50] [Batch 80/235] [D loss: 1.133661, acc: 86.13%] [G loss: 1.110943]\n",
      "[Epoch 24/50] [Batch 81/235] [D loss: 1.108536, acc: 83.79%] [G loss: 1.122113]\n",
      "[Epoch 24/50] [Batch 82/235] [D loss: 1.124599, acc: 87.89%] [G loss: 1.336502]\n",
      "[Epoch 24/50] [Batch 83/235] [D loss: 1.058301, acc: 86.72%] [G loss: 1.076828]\n",
      "[Epoch 24/50] [Batch 84/235] [D loss: 1.086300, acc: 86.72%] [G loss: 1.117675]\n",
      "[Epoch 24/50] [Batch 85/235] [D loss: 1.151922, acc: 84.18%] [G loss: 1.124545]\n",
      "[Epoch 24/50] [Batch 86/235] [D loss: 1.096605, acc: 85.55%] [G loss: 1.153299]\n",
      "[Epoch 24/50] [Batch 87/235] [D loss: 1.114936, acc: 86.13%] [G loss: 1.173838]\n",
      "[Epoch 24/50] [Batch 88/235] [D loss: 1.144828, acc: 84.38%] [G loss: 1.250161]\n",
      "[Epoch 24/50] [Batch 89/235] [D loss: 1.094035, acc: 86.33%] [G loss: 1.350566]\n",
      "[Epoch 24/50] [Batch 90/235] [D loss: 1.095914, acc: 89.84%] [G loss: 1.060338]\n",
      "[Epoch 24/50] [Batch 91/235] [D loss: 1.107613, acc: 88.09%] [G loss: 1.089926]\n",
      "[Epoch 24/50] [Batch 92/235] [D loss: 1.095898, acc: 87.50%] [G loss: 1.151278]\n",
      "[Epoch 24/50] [Batch 93/235] [D loss: 1.108779, acc: 81.84%] [G loss: 1.150999]\n",
      "[Epoch 24/50] [Batch 94/235] [D loss: 1.087043, acc: 84.57%] [G loss: 1.122071]\n",
      "[Epoch 24/50] [Batch 95/235] [D loss: 1.112005, acc: 84.77%] [G loss: 1.186703]\n",
      "[Epoch 24/50] [Batch 96/235] [D loss: 1.093920, acc: 88.09%] [G loss: 1.131278]\n",
      "[Epoch 24/50] [Batch 97/235] [D loss: 1.142694, acc: 84.57%] [G loss: 1.163716]\n",
      "[Epoch 24/50] [Batch 98/235] [D loss: 1.080215, acc: 87.11%] [G loss: 1.213297]\n",
      "[Epoch 24/50] [Batch 99/235] [D loss: 1.097127, acc: 86.72%] [G loss: 1.106868]\n",
      "[Epoch 24/50] [Batch 100/235] [D loss: 1.124462, acc: 86.52%] [G loss: 1.222822]\n",
      "[Epoch 24/50] [Batch 101/235] [D loss: 1.113330, acc: 86.33%] [G loss: 1.111209]\n",
      "[Epoch 24/50] [Batch 102/235] [D loss: 1.112375, acc: 89.06%] [G loss: 1.151502]\n",
      "[Epoch 24/50] [Batch 103/235] [D loss: 1.112142, acc: 86.72%] [G loss: 1.186679]\n",
      "[Epoch 24/50] [Batch 104/235] [D loss: 1.111825, acc: 84.77%] [G loss: 1.145014]\n",
      "[Epoch 24/50] [Batch 105/235] [D loss: 1.103045, acc: 88.87%] [G loss: 1.160652]\n",
      "[Epoch 24/50] [Batch 106/235] [D loss: 1.105956, acc: 83.20%] [G loss: 1.187423]\n",
      "[Epoch 24/50] [Batch 107/235] [D loss: 1.076303, acc: 87.11%] [G loss: 1.150937]\n",
      "[Epoch 24/50] [Batch 108/235] [D loss: 1.068929, acc: 88.09%] [G loss: 1.089295]\n",
      "[Epoch 24/50] [Batch 109/235] [D loss: 1.111179, acc: 86.13%] [G loss: 1.272325]\n",
      "[Epoch 24/50] [Batch 110/235] [D loss: 1.079293, acc: 87.70%] [G loss: 1.394474]\n",
      "[Epoch 24/50] [Batch 111/235] [D loss: 1.083328, acc: 86.52%] [G loss: 1.157422]\n",
      "[Epoch 24/50] [Batch 112/235] [D loss: 1.199292, acc: 84.18%] [G loss: 1.062979]\n",
      "[Epoch 24/50] [Batch 113/235] [D loss: 1.056115, acc: 87.70%] [G loss: 1.158350]\n",
      "[Epoch 24/50] [Batch 114/235] [D loss: 1.124082, acc: 88.67%] [G loss: 1.210625]\n",
      "[Epoch 24/50] [Batch 115/235] [D loss: 1.116866, acc: 85.94%] [G loss: 1.252927]\n",
      "[Epoch 24/50] [Batch 116/235] [D loss: 1.107962, acc: 85.55%] [G loss: 1.105516]\n",
      "[Epoch 24/50] [Batch 117/235] [D loss: 1.186049, acc: 86.52%] [G loss: 1.221443]\n",
      "[Epoch 24/50] [Batch 118/235] [D loss: 1.142947, acc: 87.89%] [G loss: 1.228845]\n",
      "[Epoch 24/50] [Batch 119/235] [D loss: 1.134884, acc: 88.09%] [G loss: 1.043020]\n",
      "[Epoch 24/50] [Batch 120/235] [D loss: 1.155217, acc: 84.96%] [G loss: 1.038304]\n",
      "[Epoch 24/50] [Batch 121/235] [D loss: 1.096938, acc: 87.70%] [G loss: 1.195982]\n",
      "[Epoch 24/50] [Batch 122/235] [D loss: 1.116843, acc: 86.52%] [G loss: 1.167867]\n",
      "[Epoch 24/50] [Batch 123/235] [D loss: 1.136864, acc: 85.35%] [G loss: 1.100044]\n",
      "[Epoch 24/50] [Batch 124/235] [D loss: 1.075295, acc: 88.09%] [G loss: 1.426368]\n",
      "[Epoch 24/50] [Batch 125/235] [D loss: 1.179531, acc: 84.96%] [G loss: 1.093154]\n",
      "[Epoch 24/50] [Batch 126/235] [D loss: 1.118959, acc: 83.98%] [G loss: 1.167200]\n",
      "[Epoch 24/50] [Batch 127/235] [D loss: 1.124023, acc: 83.01%] [G loss: 1.229926]\n",
      "[Epoch 24/50] [Batch 128/235] [D loss: 1.078144, acc: 89.06%] [G loss: 1.269497]\n",
      "[Epoch 24/50] [Batch 129/235] [D loss: 1.120279, acc: 89.06%] [G loss: 1.133511]\n",
      "[Epoch 24/50] [Batch 130/235] [D loss: 1.116996, acc: 86.72%] [G loss: 1.124664]\n",
      "[Epoch 24/50] [Batch 131/235] [D loss: 1.096477, acc: 87.11%] [G loss: 1.138008]\n",
      "[Epoch 24/50] [Batch 132/235] [D loss: 1.154535, acc: 85.35%] [G loss: 1.264294]\n",
      "[Epoch 24/50] [Batch 133/235] [D loss: 1.098750, acc: 85.74%] [G loss: 1.157212]\n",
      "[Epoch 24/50] [Batch 134/235] [D loss: 1.093522, acc: 86.52%] [G loss: 1.195783]\n",
      "[Epoch 24/50] [Batch 135/235] [D loss: 1.068313, acc: 88.67%] [G loss: 1.141493]\n",
      "[Epoch 24/50] [Batch 136/235] [D loss: 1.173231, acc: 83.20%] [G loss: 1.138391]\n",
      "[Epoch 24/50] [Batch 137/235] [D loss: 1.150798, acc: 84.96%] [G loss: 1.298749]\n",
      "[Epoch 24/50] [Batch 138/235] [D loss: 1.166879, acc: 87.11%] [G loss: 1.163574]\n",
      "[Epoch 24/50] [Batch 139/235] [D loss: 1.133107, acc: 86.33%] [G loss: 1.138251]\n",
      "[Epoch 24/50] [Batch 140/235] [D loss: 1.150532, acc: 87.70%] [G loss: 1.044323]\n",
      "[Epoch 24/50] [Batch 141/235] [D loss: 1.067535, acc: 87.30%] [G loss: 1.180723]\n",
      "[Epoch 24/50] [Batch 142/235] [D loss: 1.105493, acc: 86.91%] [G loss: 1.159141]\n",
      "[Epoch 24/50] [Batch 143/235] [D loss: 1.105535, acc: 87.30%] [G loss: 1.259325]\n",
      "[Epoch 24/50] [Batch 144/235] [D loss: 1.146215, acc: 87.89%] [G loss: 1.185116]\n",
      "[Epoch 24/50] [Batch 145/235] [D loss: 1.114168, acc: 84.96%] [G loss: 1.169543]\n",
      "[Epoch 24/50] [Batch 146/235] [D loss: 1.105824, acc: 86.52%] [G loss: 1.123177]\n",
      "[Epoch 24/50] [Batch 147/235] [D loss: 1.144889, acc: 87.30%] [G loss: 1.109790]\n",
      "[Epoch 24/50] [Batch 148/235] [D loss: 1.129684, acc: 87.70%] [G loss: 1.155360]\n",
      "[Epoch 24/50] [Batch 149/235] [D loss: 1.128646, acc: 87.50%] [G loss: 1.336201]\n",
      "[Epoch 24/50] [Batch 150/235] [D loss: 1.121663, acc: 84.96%] [G loss: 1.096968]\n",
      "[Epoch 24/50] [Batch 151/235] [D loss: 1.128175, acc: 86.13%] [G loss: 1.151306]\n",
      "[Epoch 24/50] [Batch 152/235] [D loss: 1.101455, acc: 84.18%] [G loss: 1.096735]\n",
      "[Epoch 24/50] [Batch 153/235] [D loss: 1.197625, acc: 83.79%] [G loss: 1.213243]\n",
      "[Epoch 24/50] [Batch 154/235] [D loss: 1.143644, acc: 84.77%] [G loss: 1.188951]\n",
      "[Epoch 24/50] [Batch 155/235] [D loss: 1.139980, acc: 87.30%] [G loss: 1.166905]\n",
      "[Epoch 24/50] [Batch 156/235] [D loss: 1.112390, acc: 85.94%] [G loss: 1.163731]\n",
      "[Epoch 24/50] [Batch 157/235] [D loss: 1.125265, acc: 84.57%] [G loss: 1.189207]\n",
      "[Epoch 24/50] [Batch 158/235] [D loss: 1.126354, acc: 86.33%] [G loss: 1.170846]\n",
      "[Epoch 24/50] [Batch 159/235] [D loss: 1.153308, acc: 86.52%] [G loss: 1.064374]\n",
      "[Epoch 24/50] [Batch 160/235] [D loss: 1.148041, acc: 87.11%] [G loss: 1.233721]\n",
      "[Epoch 24/50] [Batch 161/235] [D loss: 1.164184, acc: 83.40%] [G loss: 1.177861]\n",
      "[Epoch 24/50] [Batch 162/235] [D loss: 1.093954, acc: 88.87%] [G loss: 1.197577]\n",
      "[Epoch 24/50] [Batch 163/235] [D loss: 1.164948, acc: 82.62%] [G loss: 1.073597]\n",
      "[Epoch 24/50] [Batch 164/235] [D loss: 1.109175, acc: 86.91%] [G loss: 1.205681]\n",
      "[Epoch 24/50] [Batch 165/235] [D loss: 1.143454, acc: 86.91%] [G loss: 1.179127]\n",
      "[Epoch 24/50] [Batch 166/235] [D loss: 1.114769, acc: 85.35%] [G loss: 1.184366]\n",
      "[Epoch 24/50] [Batch 167/235] [D loss: 1.161718, acc: 86.72%] [G loss: 1.135535]\n",
      "[Epoch 24/50] [Batch 168/235] [D loss: 1.069849, acc: 86.13%] [G loss: 1.147508]\n",
      "[Epoch 24/50] [Batch 169/235] [D loss: 1.130986, acc: 87.70%] [G loss: 1.086402]\n",
      "[Epoch 24/50] [Batch 170/235] [D loss: 1.140966, acc: 89.65%] [G loss: 1.141241]\n",
      "[Epoch 24/50] [Batch 171/235] [D loss: 1.155956, acc: 86.13%] [G loss: 1.198007]\n",
      "[Epoch 24/50] [Batch 172/235] [D loss: 1.097071, acc: 84.96%] [G loss: 1.117528]\n",
      "[Epoch 24/50] [Batch 173/235] [D loss: 1.116886, acc: 88.09%] [G loss: 1.258524]\n",
      "[Epoch 24/50] [Batch 174/235] [D loss: 1.111531, acc: 84.57%] [G loss: 1.020637]\n",
      "[Epoch 24/50] [Batch 175/235] [D loss: 1.134133, acc: 87.89%] [G loss: 1.162152]\n",
      "[Epoch 24/50] [Batch 176/235] [D loss: 1.142211, acc: 87.70%] [G loss: 1.145924]\n",
      "[Epoch 24/50] [Batch 177/235] [D loss: 1.114447, acc: 89.84%] [G loss: 1.153316]\n",
      "[Epoch 24/50] [Batch 178/235] [D loss: 1.136168, acc: 85.35%] [G loss: 1.211063]\n",
      "[Epoch 24/50] [Batch 179/235] [D loss: 1.153526, acc: 87.11%] [G loss: 1.263026]\n",
      "[Epoch 24/50] [Batch 180/235] [D loss: 1.096748, acc: 86.33%] [G loss: 1.215820]\n",
      "[Epoch 24/50] [Batch 181/235] [D loss: 1.120785, acc: 87.70%] [G loss: 1.170491]\n",
      "[Epoch 24/50] [Batch 182/235] [D loss: 1.162596, acc: 84.77%] [G loss: 1.133483]\n",
      "[Epoch 24/50] [Batch 183/235] [D loss: 1.129623, acc: 86.13%] [G loss: 1.158692]\n",
      "[Epoch 24/50] [Batch 184/235] [D loss: 1.135240, acc: 86.72%] [G loss: 1.137938]\n",
      "[Epoch 24/50] [Batch 185/235] [D loss: 1.091806, acc: 86.33%] [G loss: 1.198849]\n",
      "[Epoch 24/50] [Batch 186/235] [D loss: 1.086236, acc: 86.52%] [G loss: 1.104484]\n",
      "[Epoch 24/50] [Batch 187/235] [D loss: 1.088618, acc: 87.89%] [G loss: 1.221518]\n",
      "[Epoch 24/50] [Batch 188/235] [D loss: 1.143425, acc: 86.52%] [G loss: 1.060066]\n",
      "[Epoch 24/50] [Batch 189/235] [D loss: 1.130845, acc: 88.48%] [G loss: 1.048174]\n",
      "[Epoch 24/50] [Batch 190/235] [D loss: 1.101583, acc: 86.72%] [G loss: 1.292458]\n",
      "[Epoch 24/50] [Batch 191/235] [D loss: 1.099616, acc: 87.11%] [G loss: 1.188012]\n",
      "[Epoch 24/50] [Batch 192/235] [D loss: 1.057914, acc: 87.70%] [G loss: 1.196968]\n",
      "[Epoch 24/50] [Batch 193/235] [D loss: 1.109271, acc: 86.52%] [G loss: 1.224185]\n",
      "[Epoch 24/50] [Batch 194/235] [D loss: 1.165378, acc: 86.72%] [G loss: 1.073580]\n",
      "[Epoch 24/50] [Batch 195/235] [D loss: 1.116802, acc: 86.13%] [G loss: 1.241565]\n",
      "[Epoch 24/50] [Batch 196/235] [D loss: 1.122834, acc: 89.06%] [G loss: 1.303241]\n",
      "[Epoch 24/50] [Batch 197/235] [D loss: 1.158059, acc: 85.35%] [G loss: 1.081142]\n",
      "[Epoch 24/50] [Batch 198/235] [D loss: 1.166163, acc: 89.06%] [G loss: 1.008286]\n",
      "[Epoch 24/50] [Batch 199/235] [D loss: 1.124635, acc: 86.13%] [G loss: 1.214509]\n",
      "[Epoch 24/50] [Batch 200/235] [D loss: 1.154824, acc: 87.89%] [G loss: 1.325896]\n",
      "[Epoch 24/50] [Batch 201/235] [D loss: 1.118288, acc: 88.28%] [G loss: 1.091468]\n",
      "[Epoch 24/50] [Batch 202/235] [D loss: 1.056947, acc: 90.23%] [G loss: 1.116210]\n",
      "[Epoch 24/50] [Batch 203/235] [D loss: 1.117857, acc: 86.33%] [G loss: 1.267241]\n",
      "[Epoch 24/50] [Batch 204/235] [D loss: 1.159144, acc: 87.50%] [G loss: 1.390519]\n",
      "[Epoch 24/50] [Batch 205/235] [D loss: 1.153129, acc: 87.89%] [G loss: 1.092709]\n",
      "[Epoch 24/50] [Batch 206/235] [D loss: 1.110383, acc: 86.33%] [G loss: 1.123245]\n",
      "[Epoch 24/50] [Batch 207/235] [D loss: 1.133866, acc: 85.94%] [G loss: 1.277588]\n",
      "[Epoch 24/50] [Batch 208/235] [D loss: 1.078223, acc: 87.89%] [G loss: 1.181936]\n",
      "[Epoch 24/50] [Batch 209/235] [D loss: 1.101080, acc: 88.28%] [G loss: 0.994974]\n",
      "[Epoch 24/50] [Batch 210/235] [D loss: 1.081149, acc: 87.70%] [G loss: 1.156708]\n",
      "[Epoch 24/50] [Batch 211/235] [D loss: 1.100432, acc: 84.57%] [G loss: 1.177551]\n",
      "[Epoch 24/50] [Batch 212/235] [D loss: 1.075970, acc: 89.26%] [G loss: 1.247427]\n",
      "[Epoch 24/50] [Batch 213/235] [D loss: 1.121187, acc: 86.13%] [G loss: 1.026824]\n",
      "[Epoch 24/50] [Batch 214/235] [D loss: 1.141018, acc: 86.13%] [G loss: 1.188129]\n",
      "[Epoch 24/50] [Batch 215/235] [D loss: 1.060928, acc: 87.89%] [G loss: 1.186497]\n",
      "[Epoch 24/50] [Batch 216/235] [D loss: 1.117437, acc: 84.57%] [G loss: 1.140652]\n",
      "[Epoch 24/50] [Batch 217/235] [D loss: 1.182751, acc: 87.11%] [G loss: 1.239992]\n",
      "[Epoch 24/50] [Batch 218/235] [D loss: 1.105775, acc: 86.91%] [G loss: 1.124328]\n",
      "[Epoch 24/50] [Batch 219/235] [D loss: 1.087684, acc: 86.72%] [G loss: 1.199934]\n",
      "[Epoch 24/50] [Batch 220/235] [D loss: 1.089571, acc: 86.72%] [G loss: 1.154853]\n",
      "[Epoch 24/50] [Batch 221/235] [D loss: 1.146931, acc: 87.50%] [G loss: 1.101628]\n",
      "[Epoch 24/50] [Batch 222/235] [D loss: 1.149997, acc: 86.13%] [G loss: 1.178070]\n",
      "[Epoch 24/50] [Batch 223/235] [D loss: 1.092155, acc: 87.50%] [G loss: 1.149838]\n",
      "[Epoch 24/50] [Batch 224/235] [D loss: 1.086904, acc: 87.30%] [G loss: 1.097331]\n",
      "[Epoch 24/50] [Batch 225/235] [D loss: 1.150422, acc: 87.11%] [G loss: 1.285092]\n",
      "[Epoch 24/50] [Batch 226/235] [D loss: 1.096414, acc: 89.06%] [G loss: 1.205187]\n",
      "[Epoch 24/50] [Batch 227/235] [D loss: 1.114993, acc: 86.13%] [G loss: 1.092257]\n",
      "[Epoch 24/50] [Batch 228/235] [D loss: 1.085051, acc: 86.52%] [G loss: 1.111950]\n",
      "[Epoch 24/50] [Batch 229/235] [D loss: 1.142081, acc: 87.89%] [G loss: 1.184899]\n",
      "[Epoch 24/50] [Batch 230/235] [D loss: 1.113200, acc: 87.30%] [G loss: 1.145767]\n",
      "[Epoch 24/50] [Batch 231/235] [D loss: 1.093092, acc: 87.89%] [G loss: 1.075130]\n",
      "[Epoch 24/50] [Batch 232/235] [D loss: 1.104958, acc: 88.28%] [G loss: 1.097891]\n",
      "[Epoch 24/50] [Batch 233/235] [D loss: 1.106100, acc: 87.89%] [G loss: 1.228421]\n",
      "[Epoch 24/50] [Batch 234/235] [D loss: 1.095952, acc: 87.50%] [G loss: 1.344169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/50] [Batch 0/235] [D loss: 1.158867, acc: 86.33%] [G loss: 1.184700]\n",
      "[Epoch 25/50] [Batch 1/235] [D loss: 1.136742, acc: 86.91%] [G loss: 1.053931]\n",
      "[Epoch 25/50] [Batch 2/235] [D loss: 1.145485, acc: 84.38%] [G loss: 1.151189]\n",
      "[Epoch 25/50] [Batch 3/235] [D loss: 1.071872, acc: 86.72%] [G loss: 1.170444]\n",
      "[Epoch 25/50] [Batch 4/235] [D loss: 1.149226, acc: 85.35%] [G loss: 1.184328]\n",
      "[Epoch 25/50] [Batch 5/235] [D loss: 1.100276, acc: 84.77%] [G loss: 1.196141]\n",
      "[Epoch 25/50] [Batch 6/235] [D loss: 1.142634, acc: 85.16%] [G loss: 1.157212]\n",
      "[Epoch 25/50] [Batch 7/235] [D loss: 1.104275, acc: 85.94%] [G loss: 1.125643]\n",
      "[Epoch 25/50] [Batch 8/235] [D loss: 1.091445, acc: 87.89%] [G loss: 1.220179]\n",
      "[Epoch 25/50] [Batch 9/235] [D loss: 1.162802, acc: 88.28%] [G loss: 1.151592]\n",
      "[Epoch 25/50] [Batch 10/235] [D loss: 1.090597, acc: 88.28%] [G loss: 1.245281]\n",
      "[Epoch 25/50] [Batch 11/235] [D loss: 1.159577, acc: 88.87%] [G loss: 1.194543]\n",
      "[Epoch 25/50] [Batch 12/235] [D loss: 1.107128, acc: 86.52%] [G loss: 1.133270]\n",
      "[Epoch 25/50] [Batch 13/235] [D loss: 1.161071, acc: 84.18%] [G loss: 1.232523]\n",
      "[Epoch 25/50] [Batch 14/235] [D loss: 1.073943, acc: 85.74%] [G loss: 1.193994]\n",
      "[Epoch 25/50] [Batch 15/235] [D loss: 1.081951, acc: 86.91%] [G loss: 1.111387]\n",
      "[Epoch 25/50] [Batch 16/235] [D loss: 1.137134, acc: 88.28%] [G loss: 1.069937]\n",
      "[Epoch 25/50] [Batch 17/235] [D loss: 1.087321, acc: 88.28%] [G loss: 1.145677]\n",
      "[Epoch 25/50] [Batch 18/235] [D loss: 1.092141, acc: 87.11%] [G loss: 1.226023]\n",
      "[Epoch 25/50] [Batch 19/235] [D loss: 1.193149, acc: 87.70%] [G loss: 1.242798]\n",
      "[Epoch 25/50] [Batch 20/235] [D loss: 1.083231, acc: 85.16%] [G loss: 1.144207]\n",
      "[Epoch 25/50] [Batch 21/235] [D loss: 1.136552, acc: 85.16%] [G loss: 1.079165]\n",
      "[Epoch 25/50] [Batch 22/235] [D loss: 1.109566, acc: 86.33%] [G loss: 1.053837]\n",
      "[Epoch 25/50] [Batch 23/235] [D loss: 1.126556, acc: 87.11%] [G loss: 1.029591]\n",
      "[Epoch 25/50] [Batch 24/235] [D loss: 1.073838, acc: 87.89%] [G loss: 1.211633]\n",
      "[Epoch 25/50] [Batch 25/235] [D loss: 1.114941, acc: 87.50%] [G loss: 1.078121]\n",
      "[Epoch 25/50] [Batch 26/235] [D loss: 1.093311, acc: 87.70%] [G loss: 1.224959]\n",
      "[Epoch 25/50] [Batch 27/235] [D loss: 1.080632, acc: 87.70%] [G loss: 1.128118]\n",
      "[Epoch 25/50] [Batch 28/235] [D loss: 1.154865, acc: 84.96%] [G loss: 1.099554]\n",
      "[Epoch 25/50] [Batch 29/235] [D loss: 1.192380, acc: 83.79%] [G loss: 1.134635]\n",
      "[Epoch 25/50] [Batch 30/235] [D loss: 1.083980, acc: 90.04%] [G loss: 1.124840]\n",
      "[Epoch 25/50] [Batch 31/235] [D loss: 1.094815, acc: 85.16%] [G loss: 1.155402]\n",
      "[Epoch 25/50] [Batch 32/235] [D loss: 1.172532, acc: 84.57%] [G loss: 1.303957]\n",
      "[Epoch 25/50] [Batch 33/235] [D loss: 1.112712, acc: 84.96%] [G loss: 1.228537]\n",
      "[Epoch 25/50] [Batch 34/235] [D loss: 1.061649, acc: 87.50%] [G loss: 1.209738]\n",
      "[Epoch 25/50] [Batch 35/235] [D loss: 1.115560, acc: 83.40%] [G loss: 1.182874]\n",
      "[Epoch 25/50] [Batch 36/235] [D loss: 1.133654, acc: 85.35%] [G loss: 1.117956]\n",
      "[Epoch 25/50] [Batch 37/235] [D loss: 1.112090, acc: 87.89%] [G loss: 1.146374]\n",
      "[Epoch 25/50] [Batch 38/235] [D loss: 1.058200, acc: 87.30%] [G loss: 1.301746]\n",
      "[Epoch 25/50] [Batch 39/235] [D loss: 1.107699, acc: 85.55%] [G loss: 1.101360]\n",
      "[Epoch 25/50] [Batch 40/235] [D loss: 1.063510, acc: 89.45%] [G loss: 1.229450]\n",
      "[Epoch 25/50] [Batch 41/235] [D loss: 1.111184, acc: 84.96%] [G loss: 1.267295]\n",
      "[Epoch 25/50] [Batch 42/235] [D loss: 1.147287, acc: 87.89%] [G loss: 1.095022]\n",
      "[Epoch 25/50] [Batch 43/235] [D loss: 1.104036, acc: 86.72%] [G loss: 1.141257]\n",
      "[Epoch 25/50] [Batch 44/235] [D loss: 1.095358, acc: 85.16%] [G loss: 1.057092]\n",
      "[Epoch 25/50] [Batch 45/235] [D loss: 1.122138, acc: 86.72%] [G loss: 1.234532]\n",
      "[Epoch 25/50] [Batch 46/235] [D loss: 1.124111, acc: 86.91%] [G loss: 1.195959]\n",
      "[Epoch 25/50] [Batch 47/235] [D loss: 1.075820, acc: 87.70%] [G loss: 1.169083]\n",
      "[Epoch 25/50] [Batch 48/235] [D loss: 1.074273, acc: 83.59%] [G loss: 1.176191]\n",
      "[Epoch 25/50] [Batch 49/235] [D loss: 1.109897, acc: 86.13%] [G loss: 1.129126]\n",
      "[Epoch 25/50] [Batch 50/235] [D loss: 1.034664, acc: 88.48%] [G loss: 1.142942]\n",
      "[Epoch 25/50] [Batch 51/235] [D loss: 1.127695, acc: 87.30%] [G loss: 1.174150]\n",
      "[Epoch 25/50] [Batch 52/235] [D loss: 1.105579, acc: 87.30%] [G loss: 1.066805]\n",
      "[Epoch 25/50] [Batch 53/235] [D loss: 1.152989, acc: 85.16%] [G loss: 1.138316]\n",
      "[Epoch 25/50] [Batch 54/235] [D loss: 1.074862, acc: 89.26%] [G loss: 1.253973]\n",
      "[Epoch 25/50] [Batch 55/235] [D loss: 1.171419, acc: 85.35%] [G loss: 1.157391]\n",
      "[Epoch 25/50] [Batch 56/235] [D loss: 1.068060, acc: 85.94%] [G loss: 1.138726]\n",
      "[Epoch 25/50] [Batch 57/235] [D loss: 1.165390, acc: 87.50%] [G loss: 1.076427]\n",
      "[Epoch 25/50] [Batch 58/235] [D loss: 1.050242, acc: 86.13%] [G loss: 1.396505]\n",
      "[Epoch 25/50] [Batch 59/235] [D loss: 1.128152, acc: 85.94%] [G loss: 1.384593]\n",
      "[Epoch 25/50] [Batch 60/235] [D loss: 1.136304, acc: 85.55%] [G loss: 1.138374]\n",
      "[Epoch 25/50] [Batch 61/235] [D loss: 1.143677, acc: 85.35%] [G loss: 1.040636]\n",
      "[Epoch 25/50] [Batch 62/235] [D loss: 1.156967, acc: 86.52%] [G loss: 1.094746]\n",
      "[Epoch 25/50] [Batch 63/235] [D loss: 1.101732, acc: 87.30%] [G loss: 1.178524]\n",
      "[Epoch 25/50] [Batch 64/235] [D loss: 1.112986, acc: 86.72%] [G loss: 1.228688]\n",
      "[Epoch 25/50] [Batch 65/235] [D loss: 1.073130, acc: 87.50%] [G loss: 1.154804]\n",
      "[Epoch 25/50] [Batch 66/235] [D loss: 1.176028, acc: 85.55%] [G loss: 1.118419]\n",
      "[Epoch 25/50] [Batch 67/235] [D loss: 1.054598, acc: 85.55%] [G loss: 1.213645]\n",
      "[Epoch 25/50] [Batch 68/235] [D loss: 1.137568, acc: 85.16%] [G loss: 1.174723]\n",
      "[Epoch 25/50] [Batch 69/235] [D loss: 1.118633, acc: 87.30%] [G loss: 1.148232]\n",
      "[Epoch 25/50] [Batch 70/235] [D loss: 1.132620, acc: 84.57%] [G loss: 1.302084]\n",
      "[Epoch 25/50] [Batch 71/235] [D loss: 1.123868, acc: 87.89%] [G loss: 1.223993]\n",
      "[Epoch 25/50] [Batch 72/235] [D loss: 1.137860, acc: 84.77%] [G loss: 1.404159]\n",
      "[Epoch 25/50] [Batch 73/235] [D loss: 1.092941, acc: 89.45%] [G loss: 1.076721]\n",
      "[Epoch 25/50] [Batch 74/235] [D loss: 1.086000, acc: 84.96%] [G loss: 1.196693]\n",
      "[Epoch 25/50] [Batch 75/235] [D loss: 1.153400, acc: 87.30%] [G loss: 1.062641]\n",
      "[Epoch 25/50] [Batch 76/235] [D loss: 1.103850, acc: 86.91%] [G loss: 1.177791]\n",
      "[Epoch 25/50] [Batch 77/235] [D loss: 1.150446, acc: 87.30%] [G loss: 1.139571]\n",
      "[Epoch 25/50] [Batch 78/235] [D loss: 1.095608, acc: 87.89%] [G loss: 1.124806]\n",
      "[Epoch 25/50] [Batch 79/235] [D loss: 1.089631, acc: 86.33%] [G loss: 1.124742]\n",
      "[Epoch 25/50] [Batch 80/235] [D loss: 1.109326, acc: 87.70%] [G loss: 1.145492]\n",
      "[Epoch 25/50] [Batch 81/235] [D loss: 1.104321, acc: 86.52%] [G loss: 1.363174]\n",
      "[Epoch 25/50] [Batch 82/235] [D loss: 1.129547, acc: 87.11%] [G loss: 1.100170]\n",
      "[Epoch 25/50] [Batch 83/235] [D loss: 1.075862, acc: 85.94%] [G loss: 1.026081]\n",
      "[Epoch 25/50] [Batch 84/235] [D loss: 1.113535, acc: 86.33%] [G loss: 1.136634]\n",
      "[Epoch 25/50] [Batch 85/235] [D loss: 1.128345, acc: 87.70%] [G loss: 1.280174]\n",
      "[Epoch 25/50] [Batch 86/235] [D loss: 1.096205, acc: 86.91%] [G loss: 1.275879]\n",
      "[Epoch 25/50] [Batch 87/235] [D loss: 1.118156, acc: 86.13%] [G loss: 1.254119]\n",
      "[Epoch 25/50] [Batch 88/235] [D loss: 1.089729, acc: 86.91%] [G loss: 1.292543]\n",
      "[Epoch 25/50] [Batch 89/235] [D loss: 1.061711, acc: 84.38%] [G loss: 1.233614]\n",
      "[Epoch 25/50] [Batch 90/235] [D loss: 1.094435, acc: 84.57%] [G loss: 1.183591]\n",
      "[Epoch 25/50] [Batch 91/235] [D loss: 1.128135, acc: 87.11%] [G loss: 1.181977]\n",
      "[Epoch 25/50] [Batch 92/235] [D loss: 1.132566, acc: 84.77%] [G loss: 1.077281]\n",
      "[Epoch 25/50] [Batch 93/235] [D loss: 1.151672, acc: 84.38%] [G loss: 1.046892]\n",
      "[Epoch 25/50] [Batch 94/235] [D loss: 1.065038, acc: 86.33%] [G loss: 1.256909]\n",
      "[Epoch 25/50] [Batch 95/235] [D loss: 1.130125, acc: 84.77%] [G loss: 1.110566]\n",
      "[Epoch 25/50] [Batch 96/235] [D loss: 1.100318, acc: 86.33%] [G loss: 1.262113]\n",
      "[Epoch 25/50] [Batch 97/235] [D loss: 1.085301, acc: 85.55%] [G loss: 1.143745]\n",
      "[Epoch 25/50] [Batch 98/235] [D loss: 1.077828, acc: 88.48%] [G loss: 1.138994]\n",
      "[Epoch 25/50] [Batch 99/235] [D loss: 1.099775, acc: 87.11%] [G loss: 1.314208]\n",
      "[Epoch 25/50] [Batch 100/235] [D loss: 1.070931, acc: 85.94%] [G loss: 1.150996]\n",
      "[Epoch 25/50] [Batch 101/235] [D loss: 1.101302, acc: 85.74%] [G loss: 1.236717]\n",
      "[Epoch 25/50] [Batch 102/235] [D loss: 1.119224, acc: 86.52%] [G loss: 1.205609]\n",
      "[Epoch 25/50] [Batch 103/235] [D loss: 1.098628, acc: 87.50%] [G loss: 1.316775]\n",
      "[Epoch 25/50] [Batch 104/235] [D loss: 1.126424, acc: 86.13%] [G loss: 1.139236]\n",
      "[Epoch 25/50] [Batch 105/235] [D loss: 1.123698, acc: 85.74%] [G loss: 1.056273]\n",
      "[Epoch 25/50] [Batch 106/235] [D loss: 1.138287, acc: 85.94%] [G loss: 1.095899]\n",
      "[Epoch 25/50] [Batch 107/235] [D loss: 1.149553, acc: 84.96%] [G loss: 1.117880]\n",
      "[Epoch 25/50] [Batch 108/235] [D loss: 1.091733, acc: 88.28%] [G loss: 1.196794]\n",
      "[Epoch 25/50] [Batch 109/235] [D loss: 1.140670, acc: 86.33%] [G loss: 1.065342]\n",
      "[Epoch 25/50] [Batch 110/235] [D loss: 1.074137, acc: 86.72%] [G loss: 1.185515]\n",
      "[Epoch 25/50] [Batch 111/235] [D loss: 1.074932, acc: 87.89%] [G loss: 1.254202]\n",
      "[Epoch 25/50] [Batch 112/235] [D loss: 1.099611, acc: 85.74%] [G loss: 1.171088]\n",
      "[Epoch 25/50] [Batch 113/235] [D loss: 1.089869, acc: 86.13%] [G loss: 1.168212]\n",
      "[Epoch 25/50] [Batch 114/235] [D loss: 1.155132, acc: 85.94%] [G loss: 1.166945]\n",
      "[Epoch 25/50] [Batch 115/235] [D loss: 1.154869, acc: 84.57%] [G loss: 1.024856]\n",
      "[Epoch 25/50] [Batch 116/235] [D loss: 1.080889, acc: 85.55%] [G loss: 1.205821]\n",
      "[Epoch 25/50] [Batch 117/235] [D loss: 1.092061, acc: 87.50%] [G loss: 1.156869]\n",
      "[Epoch 25/50] [Batch 118/235] [D loss: 1.104451, acc: 83.98%] [G loss: 1.144568]\n",
      "[Epoch 25/50] [Batch 119/235] [D loss: 1.113976, acc: 86.52%] [G loss: 1.242366]\n",
      "[Epoch 25/50] [Batch 120/235] [D loss: 1.125803, acc: 85.74%] [G loss: 1.102693]\n",
      "[Epoch 25/50] [Batch 121/235] [D loss: 1.155515, acc: 88.67%] [G loss: 1.266008]\n",
      "[Epoch 25/50] [Batch 122/235] [D loss: 1.102190, acc: 88.48%] [G loss: 1.167607]\n",
      "[Epoch 25/50] [Batch 123/235] [D loss: 1.150581, acc: 84.38%] [G loss: 1.150353]\n",
      "[Epoch 25/50] [Batch 124/235] [D loss: 1.120173, acc: 86.52%] [G loss: 1.123865]\n",
      "[Epoch 25/50] [Batch 125/235] [D loss: 1.102707, acc: 89.06%] [G loss: 1.170454]\n",
      "[Epoch 25/50] [Batch 126/235] [D loss: 1.126731, acc: 87.50%] [G loss: 1.029343]\n",
      "[Epoch 25/50] [Batch 127/235] [D loss: 1.124342, acc: 86.33%] [G loss: 1.073479]\n",
      "[Epoch 25/50] [Batch 128/235] [D loss: 1.128277, acc: 86.13%] [G loss: 1.262236]\n",
      "[Epoch 25/50] [Batch 129/235] [D loss: 1.123024, acc: 85.94%] [G loss: 1.300561]\n",
      "[Epoch 25/50] [Batch 130/235] [D loss: 1.169386, acc: 88.67%] [G loss: 1.233282]\n",
      "[Epoch 25/50] [Batch 131/235] [D loss: 1.148436, acc: 85.55%] [G loss: 1.156708]\n",
      "[Epoch 25/50] [Batch 132/235] [D loss: 1.127468, acc: 87.30%] [G loss: 1.284794]\n",
      "[Epoch 25/50] [Batch 133/235] [D loss: 1.091381, acc: 87.11%] [G loss: 1.020549]\n",
      "[Epoch 25/50] [Batch 134/235] [D loss: 1.106174, acc: 87.11%] [G loss: 1.005784]\n",
      "[Epoch 25/50] [Batch 135/235] [D loss: 1.144579, acc: 85.55%] [G loss: 1.164028]\n",
      "[Epoch 25/50] [Batch 136/235] [D loss: 1.113910, acc: 85.55%] [G loss: 1.195043]\n",
      "[Epoch 25/50] [Batch 137/235] [D loss: 1.052759, acc: 88.67%] [G loss: 1.119408]\n",
      "[Epoch 25/50] [Batch 138/235] [D loss: 1.079636, acc: 88.09%] [G loss: 1.034467]\n",
      "[Epoch 25/50] [Batch 139/235] [D loss: 1.110762, acc: 85.16%] [G loss: 1.199167]\n",
      "[Epoch 25/50] [Batch 140/235] [D loss: 1.100116, acc: 88.67%] [G loss: 1.214713]\n",
      "[Epoch 25/50] [Batch 141/235] [D loss: 1.153566, acc: 85.55%] [G loss: 1.149480]\n",
      "[Epoch 25/50] [Batch 142/235] [D loss: 1.152141, acc: 85.74%] [G loss: 1.166001]\n",
      "[Epoch 25/50] [Batch 143/235] [D loss: 1.146476, acc: 86.52%] [G loss: 1.044201]\n",
      "[Epoch 25/50] [Batch 144/235] [D loss: 1.104788, acc: 87.30%] [G loss: 1.196004]\n",
      "[Epoch 25/50] [Batch 145/235] [D loss: 1.057600, acc: 83.40%] [G loss: 1.175028]\n",
      "[Epoch 25/50] [Batch 146/235] [D loss: 1.122344, acc: 87.11%] [G loss: 1.158318]\n",
      "[Epoch 25/50] [Batch 147/235] [D loss: 1.084466, acc: 86.91%] [G loss: 1.166805]\n",
      "[Epoch 25/50] [Batch 148/235] [D loss: 1.112571, acc: 87.70%] [G loss: 1.083721]\n",
      "[Epoch 25/50] [Batch 149/235] [D loss: 1.046835, acc: 87.50%] [G loss: 1.086348]\n",
      "[Epoch 25/50] [Batch 150/235] [D loss: 1.139602, acc: 84.96%] [G loss: 1.156884]\n",
      "[Epoch 25/50] [Batch 151/235] [D loss: 1.048967, acc: 88.09%] [G loss: 1.272420]\n",
      "[Epoch 25/50] [Batch 152/235] [D loss: 1.099926, acc: 88.09%] [G loss: 1.160651]\n",
      "[Epoch 25/50] [Batch 153/235] [D loss: 1.093660, acc: 87.30%] [G loss: 1.130004]\n",
      "[Epoch 25/50] [Batch 154/235] [D loss: 1.129271, acc: 87.89%] [G loss: 1.153312]\n",
      "[Epoch 25/50] [Batch 155/235] [D loss: 1.119823, acc: 86.13%] [G loss: 1.005593]\n",
      "[Epoch 25/50] [Batch 156/235] [D loss: 1.115260, acc: 86.91%] [G loss: 1.213184]\n",
      "[Epoch 25/50] [Batch 157/235] [D loss: 1.138293, acc: 89.26%] [G loss: 1.226369]\n",
      "[Epoch 25/50] [Batch 158/235] [D loss: 1.133356, acc: 87.89%] [G loss: 1.069859]\n",
      "[Epoch 25/50] [Batch 159/235] [D loss: 1.115905, acc: 86.91%] [G loss: 1.141517]\n",
      "[Epoch 25/50] [Batch 160/235] [D loss: 1.132101, acc: 88.67%] [G loss: 1.228949]\n",
      "[Epoch 25/50] [Batch 161/235] [D loss: 1.079377, acc: 86.91%] [G loss: 1.161481]\n",
      "[Epoch 25/50] [Batch 162/235] [D loss: 1.123453, acc: 89.45%] [G loss: 0.980773]\n",
      "[Epoch 25/50] [Batch 163/235] [D loss: 1.117754, acc: 84.77%] [G loss: 1.275919]\n",
      "[Epoch 25/50] [Batch 164/235] [D loss: 1.043775, acc: 89.65%] [G loss: 1.133160]\n",
      "[Epoch 25/50] [Batch 165/235] [D loss: 1.087525, acc: 85.35%] [G loss: 1.140505]\n",
      "[Epoch 25/50] [Batch 166/235] [D loss: 1.087623, acc: 86.33%] [G loss: 1.266407]\n",
      "[Epoch 25/50] [Batch 167/235] [D loss: 1.093832, acc: 86.13%] [G loss: 1.128703]\n",
      "[Epoch 25/50] [Batch 168/235] [D loss: 1.149731, acc: 86.13%] [G loss: 1.176475]\n",
      "[Epoch 25/50] [Batch 169/235] [D loss: 1.095038, acc: 87.30%] [G loss: 1.109576]\n",
      "[Epoch 25/50] [Batch 170/235] [D loss: 1.116286, acc: 87.70%] [G loss: 1.072226]\n",
      "[Epoch 25/50] [Batch 171/235] [D loss: 1.155879, acc: 88.67%] [G loss: 1.124428]\n",
      "[Epoch 25/50] [Batch 172/235] [D loss: 1.127929, acc: 86.52%] [G loss: 1.262709]\n",
      "[Epoch 25/50] [Batch 173/235] [D loss: 1.108184, acc: 86.72%] [G loss: 1.318464]\n",
      "[Epoch 25/50] [Batch 174/235] [D loss: 1.183578, acc: 84.57%] [G loss: 1.147114]\n",
      "[Epoch 25/50] [Batch 175/235] [D loss: 1.129874, acc: 85.16%] [G loss: 1.187189]\n",
      "[Epoch 25/50] [Batch 176/235] [D loss: 1.071774, acc: 87.50%] [G loss: 1.127761]\n",
      "[Epoch 25/50] [Batch 177/235] [D loss: 1.096019, acc: 87.70%] [G loss: 1.130508]\n",
      "[Epoch 25/50] [Batch 178/235] [D loss: 1.098766, acc: 85.94%] [G loss: 1.208150]\n",
      "[Epoch 25/50] [Batch 179/235] [D loss: 1.087038, acc: 87.89%] [G loss: 1.243449]\n",
      "[Epoch 25/50] [Batch 180/235] [D loss: 1.124029, acc: 89.06%] [G loss: 1.148083]\n",
      "[Epoch 25/50] [Batch 181/235] [D loss: 1.087773, acc: 89.06%] [G loss: 1.152606]\n",
      "[Epoch 25/50] [Batch 182/235] [D loss: 1.132107, acc: 86.13%] [G loss: 1.061646]\n",
      "[Epoch 25/50] [Batch 183/235] [D loss: 1.109879, acc: 85.74%] [G loss: 1.161487]\n",
      "[Epoch 25/50] [Batch 184/235] [D loss: 1.080091, acc: 85.55%] [G loss: 1.168961]\n",
      "[Epoch 25/50] [Batch 185/235] [D loss: 1.146222, acc: 87.30%] [G loss: 1.128284]\n",
      "[Epoch 25/50] [Batch 186/235] [D loss: 1.084112, acc: 89.06%] [G loss: 1.195753]\n",
      "[Epoch 25/50] [Batch 187/235] [D loss: 1.139657, acc: 83.79%] [G loss: 1.108642]\n",
      "[Epoch 25/50] [Batch 188/235] [D loss: 1.122875, acc: 85.55%] [G loss: 1.137570]\n",
      "[Epoch 25/50] [Batch 189/235] [D loss: 1.119351, acc: 86.33%] [G loss: 1.175461]\n",
      "[Epoch 25/50] [Batch 190/235] [D loss: 1.094188, acc: 86.72%] [G loss: 1.169830]\n",
      "[Epoch 25/50] [Batch 191/235] [D loss: 1.079456, acc: 87.30%] [G loss: 1.348798]\n",
      "[Epoch 25/50] [Batch 192/235] [D loss: 1.114494, acc: 86.72%] [G loss: 1.212021]\n",
      "[Epoch 25/50] [Batch 193/235] [D loss: 1.138938, acc: 88.67%] [G loss: 1.008656]\n",
      "[Epoch 25/50] [Batch 194/235] [D loss: 1.093954, acc: 87.70%] [G loss: 1.067727]\n",
      "[Epoch 25/50] [Batch 195/235] [D loss: 1.165128, acc: 86.72%] [G loss: 1.179259]\n",
      "[Epoch 25/50] [Batch 196/235] [D loss: 1.150258, acc: 86.33%] [G loss: 1.137352]\n",
      "[Epoch 25/50] [Batch 197/235] [D loss: 1.146217, acc: 87.30%] [G loss: 0.950335]\n",
      "[Epoch 25/50] [Batch 198/235] [D loss: 1.119244, acc: 85.35%] [G loss: 1.151148]\n",
      "[Epoch 25/50] [Batch 199/235] [D loss: 1.092746, acc: 86.33%] [G loss: 1.254865]\n",
      "[Epoch 25/50] [Batch 200/235] [D loss: 1.153339, acc: 85.94%] [G loss: 1.193984]\n",
      "[Epoch 25/50] [Batch 201/235] [D loss: 1.145887, acc: 87.11%] [G loss: 1.125717]\n",
      "[Epoch 25/50] [Batch 202/235] [D loss: 1.082718, acc: 84.38%] [G loss: 1.241487]\n",
      "[Epoch 25/50] [Batch 203/235] [D loss: 1.117600, acc: 86.52%] [G loss: 1.101267]\n",
      "[Epoch 25/50] [Batch 204/235] [D loss: 1.175986, acc: 85.94%] [G loss: 1.131684]\n",
      "[Epoch 25/50] [Batch 205/235] [D loss: 1.075550, acc: 86.52%] [G loss: 1.196888]\n",
      "[Epoch 25/50] [Batch 206/235] [D loss: 1.116767, acc: 85.74%] [G loss: 1.404814]\n",
      "[Epoch 25/50] [Batch 207/235] [D loss: 1.162699, acc: 86.91%] [G loss: 1.130774]\n",
      "[Epoch 25/50] [Batch 208/235] [D loss: 1.084520, acc: 86.52%] [G loss: 1.129044]\n",
      "[Epoch 25/50] [Batch 209/235] [D loss: 1.140827, acc: 86.33%] [G loss: 1.157628]\n",
      "[Epoch 25/50] [Batch 210/235] [D loss: 1.085682, acc: 87.50%] [G loss: 1.233268]\n",
      "[Epoch 25/50] [Batch 211/235] [D loss: 1.105077, acc: 88.87%] [G loss: 1.154229]\n",
      "[Epoch 25/50] [Batch 212/235] [D loss: 1.131315, acc: 86.72%] [G loss: 1.216432]\n",
      "[Epoch 25/50] [Batch 213/235] [D loss: 1.130951, acc: 85.74%] [G loss: 1.187924]\n",
      "[Epoch 25/50] [Batch 214/235] [D loss: 1.070204, acc: 85.55%] [G loss: 1.189227]\n",
      "[Epoch 25/50] [Batch 215/235] [D loss: 1.127396, acc: 86.91%] [G loss: 1.132743]\n",
      "[Epoch 25/50] [Batch 216/235] [D loss: 1.134229, acc: 86.72%] [G loss: 1.131810]\n",
      "[Epoch 25/50] [Batch 217/235] [D loss: 1.138394, acc: 86.13%] [G loss: 1.144014]\n",
      "[Epoch 25/50] [Batch 218/235] [D loss: 1.106339, acc: 85.94%] [G loss: 1.073225]\n",
      "[Epoch 25/50] [Batch 219/235] [D loss: 1.138316, acc: 84.96%] [G loss: 1.163296]\n",
      "[Epoch 25/50] [Batch 220/235] [D loss: 1.151661, acc: 87.30%] [G loss: 1.265062]\n",
      "[Epoch 25/50] [Batch 221/235] [D loss: 1.084192, acc: 85.74%] [G loss: 1.247829]\n",
      "[Epoch 25/50] [Batch 222/235] [D loss: 1.101007, acc: 87.70%] [G loss: 1.188326]\n",
      "[Epoch 25/50] [Batch 223/235] [D loss: 1.134423, acc: 87.50%] [G loss: 1.180254]\n",
      "[Epoch 25/50] [Batch 224/235] [D loss: 1.142496, acc: 85.74%] [G loss: 1.138887]\n",
      "[Epoch 25/50] [Batch 225/235] [D loss: 1.122398, acc: 88.67%] [G loss: 1.314143]\n",
      "[Epoch 25/50] [Batch 226/235] [D loss: 1.107021, acc: 87.11%] [G loss: 1.172150]\n",
      "[Epoch 25/50] [Batch 227/235] [D loss: 1.146345, acc: 83.98%] [G loss: 1.127829]\n",
      "[Epoch 25/50] [Batch 228/235] [D loss: 1.109878, acc: 86.13%] [G loss: 1.052484]\n",
      "[Epoch 25/50] [Batch 229/235] [D loss: 1.078789, acc: 87.30%] [G loss: 1.123806]\n",
      "[Epoch 25/50] [Batch 230/235] [D loss: 1.066931, acc: 88.09%] [G loss: 1.173120]\n",
      "[Epoch 25/50] [Batch 231/235] [D loss: 1.149686, acc: 86.13%] [G loss: 1.252278]\n",
      "[Epoch 25/50] [Batch 232/235] [D loss: 1.096179, acc: 87.30%] [G loss: 1.089522]\n",
      "[Epoch 25/50] [Batch 233/235] [D loss: 1.084321, acc: 88.48%] [G loss: 1.086187]\n",
      "[Epoch 25/50] [Batch 234/235] [D loss: 1.130288, acc: 84.38%] [G loss: 1.011011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/50] [Batch 0/235] [D loss: 1.108467, acc: 86.52%] [G loss: 1.385392]\n",
      "[Epoch 26/50] [Batch 1/235] [D loss: 1.091467, acc: 85.16%] [G loss: 1.237796]\n",
      "[Epoch 26/50] [Batch 2/235] [D loss: 1.153061, acc: 85.55%] [G loss: 1.148556]\n",
      "[Epoch 26/50] [Batch 3/235] [D loss: 1.081720, acc: 85.16%] [G loss: 1.058609]\n",
      "[Epoch 26/50] [Batch 4/235] [D loss: 1.146249, acc: 85.55%] [G loss: 1.276855]\n",
      "[Epoch 26/50] [Batch 5/235] [D loss: 1.068716, acc: 89.06%] [G loss: 1.191842]\n",
      "[Epoch 26/50] [Batch 6/235] [D loss: 1.118820, acc: 86.52%] [G loss: 1.191902]\n",
      "[Epoch 26/50] [Batch 7/235] [D loss: 1.075301, acc: 87.70%] [G loss: 1.025524]\n",
      "[Epoch 26/50] [Batch 8/235] [D loss: 1.123017, acc: 87.70%] [G loss: 1.223160]\n",
      "[Epoch 26/50] [Batch 9/235] [D loss: 1.111785, acc: 86.91%] [G loss: 1.168507]\n",
      "[Epoch 26/50] [Batch 10/235] [D loss: 1.201598, acc: 85.94%] [G loss: 1.271492]\n",
      "[Epoch 26/50] [Batch 11/235] [D loss: 1.200922, acc: 88.67%] [G loss: 1.160122]\n",
      "[Epoch 26/50] [Batch 12/235] [D loss: 1.140720, acc: 85.74%] [G loss: 1.162354]\n",
      "[Epoch 26/50] [Batch 13/235] [D loss: 1.087417, acc: 85.94%] [G loss: 1.267466]\n",
      "[Epoch 26/50] [Batch 14/235] [D loss: 1.129861, acc: 86.33%] [G loss: 1.098110]\n",
      "[Epoch 26/50] [Batch 15/235] [D loss: 1.076994, acc: 85.74%] [G loss: 1.111582]\n",
      "[Epoch 26/50] [Batch 16/235] [D loss: 1.094678, acc: 87.11%] [G loss: 1.242695]\n",
      "[Epoch 26/50] [Batch 17/235] [D loss: 1.104689, acc: 85.74%] [G loss: 1.243042]\n",
      "[Epoch 26/50] [Batch 18/235] [D loss: 1.115160, acc: 88.87%] [G loss: 1.028181]\n",
      "[Epoch 26/50] [Batch 19/235] [D loss: 1.141123, acc: 86.52%] [G loss: 1.022236]\n",
      "[Epoch 26/50] [Batch 20/235] [D loss: 1.166854, acc: 85.16%] [G loss: 1.239299]\n",
      "[Epoch 26/50] [Batch 21/235] [D loss: 1.109310, acc: 87.30%] [G loss: 1.183753]\n",
      "[Epoch 26/50] [Batch 22/235] [D loss: 1.178216, acc: 86.52%] [G loss: 1.195137]\n",
      "[Epoch 26/50] [Batch 23/235] [D loss: 1.072755, acc: 86.72%] [G loss: 1.176291]\n",
      "[Epoch 26/50] [Batch 24/235] [D loss: 1.185734, acc: 84.96%] [G loss: 1.264648]\n",
      "[Epoch 26/50] [Batch 25/235] [D loss: 1.157176, acc: 82.23%] [G loss: 1.008246]\n",
      "[Epoch 26/50] [Batch 26/235] [D loss: 1.109715, acc: 86.91%] [G loss: 1.081303]\n",
      "[Epoch 26/50] [Batch 27/235] [D loss: 1.134141, acc: 85.35%] [G loss: 1.163385]\n",
      "[Epoch 26/50] [Batch 28/235] [D loss: 1.105790, acc: 88.87%] [G loss: 1.097920]\n",
      "[Epoch 26/50] [Batch 29/235] [D loss: 1.111412, acc: 86.13%] [G loss: 1.141196]\n",
      "[Epoch 26/50] [Batch 30/235] [D loss: 1.086497, acc: 88.67%] [G loss: 1.172996]\n",
      "[Epoch 26/50] [Batch 31/235] [D loss: 1.177516, acc: 86.91%] [G loss: 1.142444]\n",
      "[Epoch 26/50] [Batch 32/235] [D loss: 1.079433, acc: 87.89%] [G loss: 1.290153]\n",
      "[Epoch 26/50] [Batch 33/235] [D loss: 1.125491, acc: 84.96%] [G loss: 1.156718]\n",
      "[Epoch 26/50] [Batch 34/235] [D loss: 1.108713, acc: 86.52%] [G loss: 1.412549]\n",
      "[Epoch 26/50] [Batch 35/235] [D loss: 1.102116, acc: 89.06%] [G loss: 1.161224]\n",
      "[Epoch 26/50] [Batch 36/235] [D loss: 1.173180, acc: 88.87%] [G loss: 0.985176]\n",
      "[Epoch 26/50] [Batch 37/235] [D loss: 1.100304, acc: 84.57%] [G loss: 1.172158]\n",
      "[Epoch 26/50] [Batch 38/235] [D loss: 1.068910, acc: 88.09%] [G loss: 1.339833]\n",
      "[Epoch 26/50] [Batch 39/235] [D loss: 1.063747, acc: 86.52%] [G loss: 1.080842]\n",
      "[Epoch 26/50] [Batch 40/235] [D loss: 1.073542, acc: 86.72%] [G loss: 1.184456]\n",
      "[Epoch 26/50] [Batch 41/235] [D loss: 1.113757, acc: 85.55%] [G loss: 1.165126]\n",
      "[Epoch 26/50] [Batch 42/235] [D loss: 1.141122, acc: 89.84%] [G loss: 1.091959]\n",
      "[Epoch 26/50] [Batch 43/235] [D loss: 1.124077, acc: 83.59%] [G loss: 1.152452]\n",
      "[Epoch 26/50] [Batch 44/235] [D loss: 1.128734, acc: 86.13%] [G loss: 1.027480]\n",
      "[Epoch 26/50] [Batch 45/235] [D loss: 1.102183, acc: 86.13%] [G loss: 1.071476]\n",
      "[Epoch 26/50] [Batch 46/235] [D loss: 1.169035, acc: 89.06%] [G loss: 1.164308]\n",
      "[Epoch 26/50] [Batch 47/235] [D loss: 1.120746, acc: 87.50%] [G loss: 1.202336]\n",
      "[Epoch 26/50] [Batch 48/235] [D loss: 1.081509, acc: 87.30%] [G loss: 1.080202]\n",
      "[Epoch 26/50] [Batch 49/235] [D loss: 1.046582, acc: 87.70%] [G loss: 1.211341]\n",
      "[Epoch 26/50] [Batch 50/235] [D loss: 1.097657, acc: 89.26%] [G loss: 1.228405]\n",
      "[Epoch 26/50] [Batch 51/235] [D loss: 1.180351, acc: 83.79%] [G loss: 1.113818]\n",
      "[Epoch 26/50] [Batch 52/235] [D loss: 1.143777, acc: 86.72%] [G loss: 1.119893]\n",
      "[Epoch 26/50] [Batch 53/235] [D loss: 1.123526, acc: 86.33%] [G loss: 1.223965]\n",
      "[Epoch 26/50] [Batch 54/235] [D loss: 1.149362, acc: 83.98%] [G loss: 1.170094]\n",
      "[Epoch 26/50] [Batch 55/235] [D loss: 1.141213, acc: 84.96%] [G loss: 1.128254]\n",
      "[Epoch 26/50] [Batch 56/235] [D loss: 1.154276, acc: 86.33%] [G loss: 1.126428]\n",
      "[Epoch 26/50] [Batch 57/235] [D loss: 1.097796, acc: 85.74%] [G loss: 1.234969]\n",
      "[Epoch 26/50] [Batch 58/235] [D loss: 1.098798, acc: 87.50%] [G loss: 1.142319]\n",
      "[Epoch 26/50] [Batch 59/235] [D loss: 1.077330, acc: 87.89%] [G loss: 1.015691]\n",
      "[Epoch 26/50] [Batch 60/235] [D loss: 1.081037, acc: 87.89%] [G loss: 1.279298]\n",
      "[Epoch 26/50] [Batch 61/235] [D loss: 1.096620, acc: 89.26%] [G loss: 1.331479]\n",
      "[Epoch 26/50] [Batch 62/235] [D loss: 1.115629, acc: 86.91%] [G loss: 1.088460]\n",
      "[Epoch 26/50] [Batch 63/235] [D loss: 1.103203, acc: 88.87%] [G loss: 1.050973]\n",
      "[Epoch 26/50] [Batch 64/235] [D loss: 1.135810, acc: 86.33%] [G loss: 1.044882]\n",
      "[Epoch 26/50] [Batch 65/235] [D loss: 1.162572, acc: 89.26%] [G loss: 1.262906]\n",
      "[Epoch 26/50] [Batch 66/235] [D loss: 1.097956, acc: 83.98%] [G loss: 1.237197]\n",
      "[Epoch 26/50] [Batch 67/235] [D loss: 1.059160, acc: 87.70%] [G loss: 1.127550]\n",
      "[Epoch 26/50] [Batch 68/235] [D loss: 1.113111, acc: 86.52%] [G loss: 1.196447]\n",
      "[Epoch 26/50] [Batch 69/235] [D loss: 1.174461, acc: 86.72%] [G loss: 1.166042]\n",
      "[Epoch 26/50] [Batch 70/235] [D loss: 1.128328, acc: 90.23%] [G loss: 1.032095]\n",
      "[Epoch 26/50] [Batch 71/235] [D loss: 1.129376, acc: 87.89%] [G loss: 1.080979]\n",
      "[Epoch 26/50] [Batch 72/235] [D loss: 1.173957, acc: 83.79%] [G loss: 1.299593]\n",
      "[Epoch 26/50] [Batch 73/235] [D loss: 1.107315, acc: 85.74%] [G loss: 1.223975]\n",
      "[Epoch 26/50] [Batch 74/235] [D loss: 1.096104, acc: 86.91%] [G loss: 1.200812]\n",
      "[Epoch 26/50] [Batch 75/235] [D loss: 1.149139, acc: 85.94%] [G loss: 1.073373]\n",
      "[Epoch 26/50] [Batch 76/235] [D loss: 1.115513, acc: 85.55%] [G loss: 1.268706]\n",
      "[Epoch 26/50] [Batch 77/235] [D loss: 1.190241, acc: 86.13%] [G loss: 1.221080]\n",
      "[Epoch 26/50] [Batch 78/235] [D loss: 1.129475, acc: 87.30%] [G loss: 1.134117]\n",
      "[Epoch 26/50] [Batch 79/235] [D loss: 1.101484, acc: 88.67%] [G loss: 1.331281]\n",
      "[Epoch 26/50] [Batch 80/235] [D loss: 1.181402, acc: 87.30%] [G loss: 1.188802]\n",
      "[Epoch 26/50] [Batch 81/235] [D loss: 1.114609, acc: 86.33%] [G loss: 1.185678]\n",
      "[Epoch 26/50] [Batch 82/235] [D loss: 1.090830, acc: 86.13%] [G loss: 1.172544]\n",
      "[Epoch 26/50] [Batch 83/235] [D loss: 1.142682, acc: 86.91%] [G loss: 1.117467]\n",
      "[Epoch 26/50] [Batch 84/235] [D loss: 1.127099, acc: 88.48%] [G loss: 1.180470]\n",
      "[Epoch 26/50] [Batch 85/235] [D loss: 1.127265, acc: 87.89%] [G loss: 1.070290]\n",
      "[Epoch 26/50] [Batch 86/235] [D loss: 1.083928, acc: 85.55%] [G loss: 1.231141]\n",
      "[Epoch 26/50] [Batch 87/235] [D loss: 1.079752, acc: 89.84%] [G loss: 1.262662]\n",
      "[Epoch 26/50] [Batch 88/235] [D loss: 1.095071, acc: 86.13%] [G loss: 1.241767]\n",
      "[Epoch 26/50] [Batch 89/235] [D loss: 1.105555, acc: 88.48%] [G loss: 1.199350]\n",
      "[Epoch 26/50] [Batch 90/235] [D loss: 1.139653, acc: 85.94%] [G loss: 1.055360]\n",
      "[Epoch 26/50] [Batch 91/235] [D loss: 1.113827, acc: 87.30%] [G loss: 1.123801]\n",
      "[Epoch 26/50] [Batch 92/235] [D loss: 1.069674, acc: 86.33%] [G loss: 1.209716]\n",
      "[Epoch 26/50] [Batch 93/235] [D loss: 1.110892, acc: 86.13%] [G loss: 1.114117]\n",
      "[Epoch 26/50] [Batch 94/235] [D loss: 1.149812, acc: 84.57%] [G loss: 1.088407]\n",
      "[Epoch 26/50] [Batch 95/235] [D loss: 1.129567, acc: 86.52%] [G loss: 1.161392]\n",
      "[Epoch 26/50] [Batch 96/235] [D loss: 1.136290, acc: 88.28%] [G loss: 1.245343]\n",
      "[Epoch 26/50] [Batch 97/235] [D loss: 1.079013, acc: 86.52%] [G loss: 1.131538]\n",
      "[Epoch 26/50] [Batch 98/235] [D loss: 1.102683, acc: 87.50%] [G loss: 1.136302]\n",
      "[Epoch 26/50] [Batch 99/235] [D loss: 1.142575, acc: 85.35%] [G loss: 1.166926]\n",
      "[Epoch 26/50] [Batch 100/235] [D loss: 1.126392, acc: 86.13%] [G loss: 1.052676]\n",
      "[Epoch 26/50] [Batch 101/235] [D loss: 1.122894, acc: 86.91%] [G loss: 1.157346]\n",
      "[Epoch 26/50] [Batch 102/235] [D loss: 1.078065, acc: 87.70%] [G loss: 1.234647]\n",
      "[Epoch 26/50] [Batch 103/235] [D loss: 1.148533, acc: 87.50%] [G loss: 1.219044]\n",
      "[Epoch 26/50] [Batch 104/235] [D loss: 1.128303, acc: 85.94%] [G loss: 1.157155]\n",
      "[Epoch 26/50] [Batch 105/235] [D loss: 1.132187, acc: 88.28%] [G loss: 1.137138]\n",
      "[Epoch 26/50] [Batch 106/235] [D loss: 1.092844, acc: 88.48%] [G loss: 1.139827]\n",
      "[Epoch 26/50] [Batch 107/235] [D loss: 1.094826, acc: 86.91%] [G loss: 1.109770]\n",
      "[Epoch 26/50] [Batch 108/235] [D loss: 1.053161, acc: 87.30%] [G loss: 1.032495]\n",
      "[Epoch 26/50] [Batch 109/235] [D loss: 1.064898, acc: 88.87%] [G loss: 1.157117]\n",
      "[Epoch 26/50] [Batch 110/235] [D loss: 1.082684, acc: 86.72%] [G loss: 1.309151]\n",
      "[Epoch 26/50] [Batch 111/235] [D loss: 1.159060, acc: 87.70%] [G loss: 1.092616]\n",
      "[Epoch 26/50] [Batch 112/235] [D loss: 1.181425, acc: 87.11%] [G loss: 1.180292]\n",
      "[Epoch 26/50] [Batch 113/235] [D loss: 1.188504, acc: 85.55%] [G loss: 1.085679]\n",
      "[Epoch 26/50] [Batch 114/235] [D loss: 1.158882, acc: 85.55%] [G loss: 1.229435]\n",
      "[Epoch 26/50] [Batch 115/235] [D loss: 1.143515, acc: 83.98%] [G loss: 1.220608]\n",
      "[Epoch 26/50] [Batch 116/235] [D loss: 1.138884, acc: 85.74%] [G loss: 1.245627]\n",
      "[Epoch 26/50] [Batch 117/235] [D loss: 1.115306, acc: 86.52%] [G loss: 1.293012]\n",
      "[Epoch 26/50] [Batch 118/235] [D loss: 1.080994, acc: 86.91%] [G loss: 1.250484]\n",
      "[Epoch 26/50] [Batch 119/235] [D loss: 1.104532, acc: 83.20%] [G loss: 1.145152]\n",
      "[Epoch 26/50] [Batch 120/235] [D loss: 1.134865, acc: 84.77%] [G loss: 1.049328]\n",
      "[Epoch 26/50] [Batch 121/235] [D loss: 1.097372, acc: 88.87%] [G loss: 1.061722]\n",
      "[Epoch 26/50] [Batch 122/235] [D loss: 1.123778, acc: 86.91%] [G loss: 1.180695]\n",
      "[Epoch 26/50] [Batch 123/235] [D loss: 1.086596, acc: 88.67%] [G loss: 1.120136]\n",
      "[Epoch 26/50] [Batch 124/235] [D loss: 1.134458, acc: 86.33%] [G loss: 1.088162]\n",
      "[Epoch 26/50] [Batch 125/235] [D loss: 1.115697, acc: 86.33%] [G loss: 1.105346]\n",
      "[Epoch 26/50] [Batch 126/235] [D loss: 1.096077, acc: 86.91%] [G loss: 1.178514]\n",
      "[Epoch 26/50] [Batch 127/235] [D loss: 1.096830, acc: 86.52%] [G loss: 1.109879]\n",
      "[Epoch 26/50] [Batch 128/235] [D loss: 1.131916, acc: 84.38%] [G loss: 1.134099]\n",
      "[Epoch 26/50] [Batch 129/235] [D loss: 1.107299, acc: 86.52%] [G loss: 1.091655]\n",
      "[Epoch 26/50] [Batch 130/235] [D loss: 1.087593, acc: 86.33%] [G loss: 1.089087]\n",
      "[Epoch 26/50] [Batch 131/235] [D loss: 1.101673, acc: 85.94%] [G loss: 1.109679]\n",
      "[Epoch 26/50] [Batch 132/235] [D loss: 1.137538, acc: 87.89%] [G loss: 1.145132]\n",
      "[Epoch 26/50] [Batch 133/235] [D loss: 1.175298, acc: 86.13%] [G loss: 1.169795]\n",
      "[Epoch 26/50] [Batch 134/235] [D loss: 1.140585, acc: 86.91%] [G loss: 1.126559]\n",
      "[Epoch 26/50] [Batch 135/235] [D loss: 1.073501, acc: 87.89%] [G loss: 1.055556]\n",
      "[Epoch 26/50] [Batch 136/235] [D loss: 1.153517, acc: 85.74%] [G loss: 1.071739]\n",
      "[Epoch 26/50] [Batch 137/235] [D loss: 1.118365, acc: 87.30%] [G loss: 1.286501]\n",
      "[Epoch 26/50] [Batch 138/235] [D loss: 1.117119, acc: 88.67%] [G loss: 1.234811]\n",
      "[Epoch 26/50] [Batch 139/235] [D loss: 1.148599, acc: 88.48%] [G loss: 1.096559]\n",
      "[Epoch 26/50] [Batch 140/235] [D loss: 1.112288, acc: 84.77%] [G loss: 1.061030]\n",
      "[Epoch 26/50] [Batch 141/235] [D loss: 1.119230, acc: 84.18%] [G loss: 1.244073]\n",
      "[Epoch 26/50] [Batch 142/235] [D loss: 1.138811, acc: 85.35%] [G loss: 1.251545]\n",
      "[Epoch 26/50] [Batch 143/235] [D loss: 1.133653, acc: 88.09%] [G loss: 1.017000]\n",
      "[Epoch 26/50] [Batch 144/235] [D loss: 1.106148, acc: 87.89%] [G loss: 1.211140]\n",
      "[Epoch 26/50] [Batch 145/235] [D loss: 1.154676, acc: 85.16%] [G loss: 1.457394]\n",
      "[Epoch 26/50] [Batch 146/235] [D loss: 1.132084, acc: 87.50%] [G loss: 1.173073]\n",
      "[Epoch 26/50] [Batch 147/235] [D loss: 1.146789, acc: 86.91%] [G loss: 1.230763]\n",
      "[Epoch 26/50] [Batch 148/235] [D loss: 1.139317, acc: 84.57%] [G loss: 1.132653]\n",
      "[Epoch 26/50] [Batch 149/235] [D loss: 1.136040, acc: 85.94%] [G loss: 1.125885]\n",
      "[Epoch 26/50] [Batch 150/235] [D loss: 1.105758, acc: 86.52%] [G loss: 1.153369]\n",
      "[Epoch 26/50] [Batch 151/235] [D loss: 1.129294, acc: 86.13%] [G loss: 1.227511]\n",
      "[Epoch 26/50] [Batch 152/235] [D loss: 1.129951, acc: 88.67%] [G loss: 1.279041]\n",
      "[Epoch 26/50] [Batch 153/235] [D loss: 1.106250, acc: 85.55%] [G loss: 1.167789]\n",
      "[Epoch 26/50] [Batch 154/235] [D loss: 1.167915, acc: 87.50%] [G loss: 1.156386]\n",
      "[Epoch 26/50] [Batch 155/235] [D loss: 1.115412, acc: 86.72%] [G loss: 1.159596]\n",
      "[Epoch 26/50] [Batch 156/235] [D loss: 1.063644, acc: 87.30%] [G loss: 1.096601]\n",
      "[Epoch 26/50] [Batch 157/235] [D loss: 1.136930, acc: 87.11%] [G loss: 1.177545]\n",
      "[Epoch 26/50] [Batch 158/235] [D loss: 1.170490, acc: 85.94%] [G loss: 1.309865]\n",
      "[Epoch 26/50] [Batch 159/235] [D loss: 1.109112, acc: 87.70%] [G loss: 1.145973]\n",
      "[Epoch 26/50] [Batch 160/235] [D loss: 1.139059, acc: 85.55%] [G loss: 1.049346]\n",
      "[Epoch 26/50] [Batch 161/235] [D loss: 1.076257, acc: 85.35%] [G loss: 1.097410]\n",
      "[Epoch 26/50] [Batch 162/235] [D loss: 1.091983, acc: 87.70%] [G loss: 1.158368]\n",
      "[Epoch 26/50] [Batch 163/235] [D loss: 1.089770, acc: 87.70%] [G loss: 1.233532]\n",
      "[Epoch 26/50] [Batch 164/235] [D loss: 1.132007, acc: 86.52%] [G loss: 1.023216]\n",
      "[Epoch 26/50] [Batch 165/235] [D loss: 1.164877, acc: 87.30%] [G loss: 1.182152]\n",
      "[Epoch 26/50] [Batch 166/235] [D loss: 1.130809, acc: 88.28%] [G loss: 1.236047]\n",
      "[Epoch 26/50] [Batch 167/235] [D loss: 1.161860, acc: 88.67%] [G loss: 1.319018]\n",
      "[Epoch 26/50] [Batch 168/235] [D loss: 1.145239, acc: 87.30%] [G loss: 1.093522]\n",
      "[Epoch 26/50] [Batch 169/235] [D loss: 1.129479, acc: 88.48%] [G loss: 1.029896]\n",
      "[Epoch 26/50] [Batch 170/235] [D loss: 1.128561, acc: 83.59%] [G loss: 1.119974]\n",
      "[Epoch 26/50] [Batch 171/235] [D loss: 1.187076, acc: 87.11%] [G loss: 1.419668]\n",
      "[Epoch 26/50] [Batch 172/235] [D loss: 1.074730, acc: 87.11%] [G loss: 1.197256]\n",
      "[Epoch 26/50] [Batch 173/235] [D loss: 1.079784, acc: 86.52%] [G loss: 1.109980]\n",
      "[Epoch 26/50] [Batch 174/235] [D loss: 1.098592, acc: 86.13%] [G loss: 1.050637]\n",
      "[Epoch 26/50] [Batch 175/235] [D loss: 1.125644, acc: 86.33%] [G loss: 1.170554]\n",
      "[Epoch 26/50] [Batch 176/235] [D loss: 1.133866, acc: 86.33%] [G loss: 1.191901]\n",
      "[Epoch 26/50] [Batch 177/235] [D loss: 1.053726, acc: 86.13%] [G loss: 1.210140]\n",
      "[Epoch 26/50] [Batch 178/235] [D loss: 1.090891, acc: 88.87%] [G loss: 1.126418]\n",
      "[Epoch 26/50] [Batch 179/235] [D loss: 1.087623, acc: 86.72%] [G loss: 1.085684]\n",
      "[Epoch 26/50] [Batch 180/235] [D loss: 1.139269, acc: 85.74%] [G loss: 1.096581]\n",
      "[Epoch 26/50] [Batch 181/235] [D loss: 1.116892, acc: 88.09%] [G loss: 1.112900]\n",
      "[Epoch 26/50] [Batch 182/235] [D loss: 1.073783, acc: 84.96%] [G loss: 1.158212]\n",
      "[Epoch 26/50] [Batch 183/235] [D loss: 1.078933, acc: 86.72%] [G loss: 1.076108]\n",
      "[Epoch 26/50] [Batch 184/235] [D loss: 1.086642, acc: 85.55%] [G loss: 1.145119]\n",
      "[Epoch 26/50] [Batch 185/235] [D loss: 1.113250, acc: 88.67%] [G loss: 1.239914]\n",
      "[Epoch 26/50] [Batch 186/235] [D loss: 1.196015, acc: 83.40%] [G loss: 1.177577]\n",
      "[Epoch 26/50] [Batch 187/235] [D loss: 1.090790, acc: 86.33%] [G loss: 1.150749]\n",
      "[Epoch 26/50] [Batch 188/235] [D loss: 1.149216, acc: 86.33%] [G loss: 1.126091]\n",
      "[Epoch 26/50] [Batch 189/235] [D loss: 1.126189, acc: 86.72%] [G loss: 1.180403]\n",
      "[Epoch 26/50] [Batch 190/235] [D loss: 1.087690, acc: 88.28%] [G loss: 1.257466]\n",
      "[Epoch 26/50] [Batch 191/235] [D loss: 1.065610, acc: 86.91%] [G loss: 1.162907]\n",
      "[Epoch 26/50] [Batch 192/235] [D loss: 1.074841, acc: 85.74%] [G loss: 1.146834]\n",
      "[Epoch 26/50] [Batch 193/235] [D loss: 1.054224, acc: 83.59%] [G loss: 1.123117]\n",
      "[Epoch 26/50] [Batch 194/235] [D loss: 1.131742, acc: 84.96%] [G loss: 1.102360]\n",
      "[Epoch 26/50] [Batch 195/235] [D loss: 1.146698, acc: 84.77%] [G loss: 1.280527]\n",
      "[Epoch 26/50] [Batch 196/235] [D loss: 1.111590, acc: 86.72%] [G loss: 1.126028]\n",
      "[Epoch 26/50] [Batch 197/235] [D loss: 1.102380, acc: 87.11%] [G loss: 1.149173]\n",
      "[Epoch 26/50] [Batch 198/235] [D loss: 1.104568, acc: 87.70%] [G loss: 1.215813]\n",
      "[Epoch 26/50] [Batch 199/235] [D loss: 1.114748, acc: 84.77%] [G loss: 1.201064]\n",
      "[Epoch 26/50] [Batch 200/235] [D loss: 1.112466, acc: 85.94%] [G loss: 1.053852]\n",
      "[Epoch 26/50] [Batch 201/235] [D loss: 1.128226, acc: 88.28%] [G loss: 1.151341]\n",
      "[Epoch 26/50] [Batch 202/235] [D loss: 1.121902, acc: 87.30%] [G loss: 1.087676]\n",
      "[Epoch 26/50] [Batch 203/235] [D loss: 1.159386, acc: 87.30%] [G loss: 1.190998]\n",
      "[Epoch 26/50] [Batch 204/235] [D loss: 1.137133, acc: 86.13%] [G loss: 1.233062]\n",
      "[Epoch 26/50] [Batch 205/235] [D loss: 1.158505, acc: 82.81%] [G loss: 1.136433]\n",
      "[Epoch 26/50] [Batch 206/235] [D loss: 1.113935, acc: 87.50%] [G loss: 0.996881]\n",
      "[Epoch 26/50] [Batch 207/235] [D loss: 1.142535, acc: 87.11%] [G loss: 1.101044]\n",
      "[Epoch 26/50] [Batch 208/235] [D loss: 1.077073, acc: 86.13%] [G loss: 1.112931]\n",
      "[Epoch 26/50] [Batch 209/235] [D loss: 1.140773, acc: 88.09%] [G loss: 1.146916]\n",
      "[Epoch 26/50] [Batch 210/235] [D loss: 1.093404, acc: 86.72%] [G loss: 1.213183]\n",
      "[Epoch 26/50] [Batch 211/235] [D loss: 1.081665, acc: 87.11%] [G loss: 1.128436]\n",
      "[Epoch 26/50] [Batch 212/235] [D loss: 1.092549, acc: 86.52%] [G loss: 1.091443]\n",
      "[Epoch 26/50] [Batch 213/235] [D loss: 1.157632, acc: 86.91%] [G loss: 1.258578]\n",
      "[Epoch 26/50] [Batch 214/235] [D loss: 1.142597, acc: 87.70%] [G loss: 1.335493]\n",
      "[Epoch 26/50] [Batch 215/235] [D loss: 1.142860, acc: 86.33%] [G loss: 1.174012]\n",
      "[Epoch 26/50] [Batch 216/235] [D loss: 1.097575, acc: 87.11%] [G loss: 1.070039]\n",
      "[Epoch 26/50] [Batch 217/235] [D loss: 1.112926, acc: 85.94%] [G loss: 1.238749]\n",
      "[Epoch 26/50] [Batch 218/235] [D loss: 1.110211, acc: 88.09%] [G loss: 1.162822]\n",
      "[Epoch 26/50] [Batch 219/235] [D loss: 1.092535, acc: 86.91%] [G loss: 1.079313]\n",
      "[Epoch 26/50] [Batch 220/235] [D loss: 1.093053, acc: 83.40%] [G loss: 1.248944]\n",
      "[Epoch 26/50] [Batch 221/235] [D loss: 1.104255, acc: 86.52%] [G loss: 1.063031]\n",
      "[Epoch 26/50] [Batch 222/235] [D loss: 1.085792, acc: 87.11%] [G loss: 1.139521]\n",
      "[Epoch 26/50] [Batch 223/235] [D loss: 1.121691, acc: 84.77%] [G loss: 1.322520]\n",
      "[Epoch 26/50] [Batch 224/235] [D loss: 1.162997, acc: 85.94%] [G loss: 1.139529]\n",
      "[Epoch 26/50] [Batch 225/235] [D loss: 1.126643, acc: 85.94%] [G loss: 1.085848]\n",
      "[Epoch 26/50] [Batch 226/235] [D loss: 1.141454, acc: 86.33%] [G loss: 1.066524]\n",
      "[Epoch 26/50] [Batch 227/235] [D loss: 1.121586, acc: 86.91%] [G loss: 1.143038]\n",
      "[Epoch 26/50] [Batch 228/235] [D loss: 1.122383, acc: 84.38%] [G loss: 1.155504]\n",
      "[Epoch 26/50] [Batch 229/235] [D loss: 1.141982, acc: 88.28%] [G loss: 1.127139]\n",
      "[Epoch 26/50] [Batch 230/235] [D loss: 1.161759, acc: 83.40%] [G loss: 1.252681]\n",
      "[Epoch 26/50] [Batch 231/235] [D loss: 1.117046, acc: 88.28%] [G loss: 1.295482]\n",
      "[Epoch 26/50] [Batch 232/235] [D loss: 1.089373, acc: 86.52%] [G loss: 1.182068]\n",
      "[Epoch 26/50] [Batch 233/235] [D loss: 1.173767, acc: 86.33%] [G loss: 1.204663]\n",
      "[Epoch 26/50] [Batch 234/235] [D loss: 1.094378, acc: 86.46%] [G loss: 1.054359]\n",
      "[Epoch 27/50] [Batch 0/235] [D loss: 1.148890, acc: 84.57%] [G loss: 1.166690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/50] [Batch 1/235] [D loss: 1.085024, acc: 86.13%] [G loss: 1.117837]\n",
      "[Epoch 27/50] [Batch 2/235] [D loss: 1.094816, acc: 89.45%] [G loss: 1.165733]\n",
      "[Epoch 27/50] [Batch 3/235] [D loss: 1.099513, acc: 85.74%] [G loss: 1.226032]\n",
      "[Epoch 27/50] [Batch 4/235] [D loss: 1.090711, acc: 86.72%] [G loss: 1.045621]\n",
      "[Epoch 27/50] [Batch 5/235] [D loss: 1.145142, acc: 84.57%] [G loss: 1.055639]\n",
      "[Epoch 27/50] [Batch 6/235] [D loss: 1.146301, acc: 85.74%] [G loss: 1.100393]\n",
      "[Epoch 27/50] [Batch 7/235] [D loss: 1.074989, acc: 86.52%] [G loss: 1.358872]\n",
      "[Epoch 27/50] [Batch 8/235] [D loss: 1.158672, acc: 86.13%] [G loss: 1.361637]\n",
      "[Epoch 27/50] [Batch 9/235] [D loss: 1.140327, acc: 84.38%] [G loss: 1.137566]\n",
      "[Epoch 27/50] [Batch 10/235] [D loss: 1.095481, acc: 86.91%] [G loss: 1.044996]\n",
      "[Epoch 27/50] [Batch 11/235] [D loss: 1.114809, acc: 86.13%] [G loss: 1.080366]\n",
      "[Epoch 27/50] [Batch 12/235] [D loss: 1.178019, acc: 84.96%] [G loss: 1.154699]\n",
      "[Epoch 27/50] [Batch 13/235] [D loss: 1.156565, acc: 84.77%] [G loss: 1.238928]\n",
      "[Epoch 27/50] [Batch 14/235] [D loss: 1.192471, acc: 85.74%] [G loss: 1.259626]\n",
      "[Epoch 27/50] [Batch 15/235] [D loss: 1.128024, acc: 86.13%] [G loss: 1.083031]\n",
      "[Epoch 27/50] [Batch 16/235] [D loss: 1.153027, acc: 85.94%] [G loss: 1.107517]\n",
      "[Epoch 27/50] [Batch 17/235] [D loss: 1.059309, acc: 87.11%] [G loss: 1.312015]\n",
      "[Epoch 27/50] [Batch 18/235] [D loss: 1.087910, acc: 87.30%] [G loss: 1.252269]\n",
      "[Epoch 27/50] [Batch 19/235] [D loss: 1.098880, acc: 85.94%] [G loss: 1.103750]\n",
      "[Epoch 27/50] [Batch 20/235] [D loss: 1.103363, acc: 87.70%] [G loss: 1.058568]\n",
      "[Epoch 27/50] [Batch 21/235] [D loss: 1.139679, acc: 86.33%] [G loss: 1.022714]\n",
      "[Epoch 27/50] [Batch 22/235] [D loss: 1.135826, acc: 86.13%] [G loss: 1.186715]\n",
      "[Epoch 27/50] [Batch 23/235] [D loss: 1.133876, acc: 84.96%] [G loss: 1.298442]\n",
      "[Epoch 27/50] [Batch 24/235] [D loss: 1.133989, acc: 84.96%] [G loss: 1.101269]\n",
      "[Epoch 27/50] [Batch 25/235] [D loss: 1.119684, acc: 85.74%] [G loss: 1.120412]\n",
      "[Epoch 27/50] [Batch 26/235] [D loss: 1.112817, acc: 87.30%] [G loss: 1.216457]\n",
      "[Epoch 27/50] [Batch 27/235] [D loss: 1.154293, acc: 85.74%] [G loss: 1.223092]\n",
      "[Epoch 27/50] [Batch 28/235] [D loss: 1.165237, acc: 87.89%] [G loss: 1.074683]\n",
      "[Epoch 27/50] [Batch 29/235] [D loss: 1.091087, acc: 88.09%] [G loss: 1.145945]\n",
      "[Epoch 27/50] [Batch 30/235] [D loss: 1.072065, acc: 87.70%] [G loss: 1.176938]\n",
      "[Epoch 27/50] [Batch 31/235] [D loss: 1.139808, acc: 85.94%] [G loss: 1.300626]\n",
      "[Epoch 27/50] [Batch 32/235] [D loss: 1.093389, acc: 84.57%] [G loss: 1.107558]\n",
      "[Epoch 27/50] [Batch 33/235] [D loss: 1.110551, acc: 87.50%] [G loss: 1.203993]\n",
      "[Epoch 27/50] [Batch 34/235] [D loss: 1.157114, acc: 86.72%] [G loss: 1.190533]\n",
      "[Epoch 27/50] [Batch 35/235] [D loss: 1.160912, acc: 86.13%] [G loss: 1.154285]\n",
      "[Epoch 27/50] [Batch 36/235] [D loss: 1.142713, acc: 86.72%] [G loss: 1.208926]\n",
      "[Epoch 27/50] [Batch 37/235] [D loss: 1.044869, acc: 88.09%] [G loss: 1.136007]\n",
      "[Epoch 27/50] [Batch 38/235] [D loss: 1.082644, acc: 86.91%] [G loss: 1.243949]\n",
      "[Epoch 27/50] [Batch 39/235] [D loss: 1.098144, acc: 85.16%] [G loss: 1.233829]\n",
      "[Epoch 27/50] [Batch 40/235] [D loss: 1.115968, acc: 83.40%] [G loss: 1.074935]\n",
      "[Epoch 27/50] [Batch 41/235] [D loss: 1.130361, acc: 87.30%] [G loss: 1.138486]\n",
      "[Epoch 27/50] [Batch 42/235] [D loss: 1.123412, acc: 87.70%] [G loss: 1.131005]\n",
      "[Epoch 27/50] [Batch 43/235] [D loss: 1.112313, acc: 86.72%] [G loss: 1.101659]\n",
      "[Epoch 27/50] [Batch 44/235] [D loss: 1.110081, acc: 87.11%] [G loss: 1.239293]\n",
      "[Epoch 27/50] [Batch 45/235] [D loss: 1.113627, acc: 87.11%] [G loss: 1.089199]\n",
      "[Epoch 27/50] [Batch 46/235] [D loss: 1.139247, acc: 85.35%] [G loss: 1.204024]\n",
      "[Epoch 27/50] [Batch 47/235] [D loss: 1.046108, acc: 90.04%] [G loss: 1.178260]\n",
      "[Epoch 27/50] [Batch 48/235] [D loss: 1.112904, acc: 86.13%] [G loss: 1.127737]\n",
      "[Epoch 27/50] [Batch 49/235] [D loss: 1.084335, acc: 84.77%] [G loss: 1.179529]\n",
      "[Epoch 27/50] [Batch 50/235] [D loss: 1.089563, acc: 87.70%] [G loss: 1.375119]\n",
      "[Epoch 27/50] [Batch 51/235] [D loss: 1.071029, acc: 88.09%] [G loss: 1.197529]\n",
      "[Epoch 27/50] [Batch 52/235] [D loss: 1.117512, acc: 85.94%] [G loss: 1.131347]\n",
      "[Epoch 27/50] [Batch 53/235] [D loss: 1.109359, acc: 86.33%] [G loss: 1.132224]\n",
      "[Epoch 27/50] [Batch 54/235] [D loss: 1.158290, acc: 88.09%] [G loss: 1.204224]\n",
      "[Epoch 27/50] [Batch 55/235] [D loss: 1.169419, acc: 87.89%] [G loss: 1.092728]\n",
      "[Epoch 27/50] [Batch 56/235] [D loss: 1.153791, acc: 87.89%] [G loss: 1.176689]\n",
      "[Epoch 27/50] [Batch 57/235] [D loss: 1.121665, acc: 88.48%] [G loss: 1.136751]\n",
      "[Epoch 27/50] [Batch 58/235] [D loss: 1.084088, acc: 86.52%] [G loss: 1.108520]\n",
      "[Epoch 27/50] [Batch 59/235] [D loss: 1.138263, acc: 86.52%] [G loss: 1.123861]\n",
      "[Epoch 27/50] [Batch 60/235] [D loss: 1.160158, acc: 86.72%] [G loss: 1.259269]\n",
      "[Epoch 27/50] [Batch 61/235] [D loss: 1.113039, acc: 86.91%] [G loss: 1.086396]\n",
      "[Epoch 27/50] [Batch 62/235] [D loss: 1.105139, acc: 87.89%] [G loss: 1.193845]\n",
      "[Epoch 27/50] [Batch 63/235] [D loss: 1.136745, acc: 84.77%] [G loss: 1.110044]\n",
      "[Epoch 27/50] [Batch 64/235] [D loss: 1.105319, acc: 86.72%] [G loss: 1.098567]\n",
      "[Epoch 27/50] [Batch 65/235] [D loss: 1.163342, acc: 85.74%] [G loss: 1.117997]\n",
      "[Epoch 27/50] [Batch 66/235] [D loss: 1.119170, acc: 86.72%] [G loss: 1.180680]\n",
      "[Epoch 27/50] [Batch 67/235] [D loss: 1.131050, acc: 88.67%] [G loss: 1.111393]\n",
      "[Epoch 27/50] [Batch 68/235] [D loss: 1.137273, acc: 86.13%] [G loss: 1.123904]\n",
      "[Epoch 27/50] [Batch 69/235] [D loss: 1.103019, acc: 86.33%] [G loss: 1.260423]\n",
      "[Epoch 27/50] [Batch 70/235] [D loss: 1.084586, acc: 85.74%] [G loss: 1.216534]\n",
      "[Epoch 27/50] [Batch 71/235] [D loss: 1.084739, acc: 87.50%] [G loss: 1.167669]\n",
      "[Epoch 27/50] [Batch 72/235] [D loss: 1.137322, acc: 88.67%] [G loss: 1.127488]\n",
      "[Epoch 27/50] [Batch 73/235] [D loss: 1.162252, acc: 85.94%] [G loss: 1.189777]\n",
      "[Epoch 27/50] [Batch 74/235] [D loss: 1.109338, acc: 87.50%] [G loss: 1.069305]\n",
      "[Epoch 27/50] [Batch 75/235] [D loss: 1.155598, acc: 85.94%] [G loss: 1.126279]\n",
      "[Epoch 27/50] [Batch 76/235] [D loss: 1.127011, acc: 85.35%] [G loss: 1.050833]\n",
      "[Epoch 27/50] [Batch 77/235] [D loss: 1.188971, acc: 86.13%] [G loss: 1.144312]\n",
      "[Epoch 27/50] [Batch 78/235] [D loss: 1.121608, acc: 87.30%] [G loss: 1.091289]\n",
      "[Epoch 27/50] [Batch 79/235] [D loss: 1.111548, acc: 87.89%] [G loss: 1.197252]\n",
      "[Epoch 27/50] [Batch 80/235] [D loss: 1.117386, acc: 87.11%] [G loss: 1.212846]\n",
      "[Epoch 27/50] [Batch 81/235] [D loss: 1.161404, acc: 86.91%] [G loss: 1.152368]\n",
      "[Epoch 27/50] [Batch 82/235] [D loss: 1.117212, acc: 87.70%] [G loss: 1.334193]\n",
      "[Epoch 27/50] [Batch 83/235] [D loss: 1.086816, acc: 85.35%] [G loss: 1.118429]\n",
      "[Epoch 27/50] [Batch 84/235] [D loss: 1.104364, acc: 86.72%] [G loss: 1.102746]\n",
      "[Epoch 27/50] [Batch 85/235] [D loss: 1.097818, acc: 86.33%] [G loss: 1.314220]\n",
      "[Epoch 27/50] [Batch 86/235] [D loss: 1.115214, acc: 88.28%] [G loss: 1.177711]\n",
      "[Epoch 27/50] [Batch 87/235] [D loss: 1.081718, acc: 89.84%] [G loss: 1.172963]\n",
      "[Epoch 27/50] [Batch 88/235] [D loss: 1.086657, acc: 87.11%] [G loss: 1.121487]\n",
      "[Epoch 27/50] [Batch 89/235] [D loss: 1.143521, acc: 85.16%] [G loss: 1.168184]\n",
      "[Epoch 27/50] [Batch 90/235] [D loss: 1.074229, acc: 88.28%] [G loss: 1.139562]\n",
      "[Epoch 27/50] [Batch 91/235] [D loss: 1.117764, acc: 85.94%] [G loss: 1.036646]\n",
      "[Epoch 27/50] [Batch 92/235] [D loss: 1.134739, acc: 84.38%] [G loss: 1.216501]\n",
      "[Epoch 27/50] [Batch 93/235] [D loss: 1.118957, acc: 86.13%] [G loss: 1.198812]\n",
      "[Epoch 27/50] [Batch 94/235] [D loss: 1.174673, acc: 87.11%] [G loss: 1.187798]\n",
      "[Epoch 27/50] [Batch 95/235] [D loss: 1.131966, acc: 88.09%] [G loss: 1.033373]\n",
      "[Epoch 27/50] [Batch 96/235] [D loss: 1.090029, acc: 89.06%] [G loss: 1.133741]\n",
      "[Epoch 27/50] [Batch 97/235] [D loss: 1.136993, acc: 85.16%] [G loss: 1.196078]\n",
      "[Epoch 27/50] [Batch 98/235] [D loss: 1.113548, acc: 89.65%] [G loss: 1.182781]\n",
      "[Epoch 27/50] [Batch 99/235] [D loss: 1.132928, acc: 87.50%] [G loss: 1.050088]\n",
      "[Epoch 27/50] [Batch 100/235] [D loss: 1.142462, acc: 87.89%] [G loss: 1.100642]\n",
      "[Epoch 27/50] [Batch 101/235] [D loss: 1.131701, acc: 84.38%] [G loss: 1.326515]\n",
      "[Epoch 27/50] [Batch 102/235] [D loss: 1.175909, acc: 84.77%] [G loss: 1.133417]\n",
      "[Epoch 27/50] [Batch 103/235] [D loss: 1.112828, acc: 86.13%] [G loss: 1.146764]\n",
      "[Epoch 27/50] [Batch 104/235] [D loss: 1.155585, acc: 88.87%] [G loss: 1.189043]\n",
      "[Epoch 27/50] [Batch 105/235] [D loss: 1.108621, acc: 84.57%] [G loss: 1.200680]\n",
      "[Epoch 27/50] [Batch 106/235] [D loss: 1.099156, acc: 86.13%] [G loss: 1.125161]\n",
      "[Epoch 27/50] [Batch 107/235] [D loss: 1.088004, acc: 86.33%] [G loss: 1.158671]\n",
      "[Epoch 27/50] [Batch 108/235] [D loss: 1.090649, acc: 88.87%] [G loss: 1.089911]\n",
      "[Epoch 27/50] [Batch 109/235] [D loss: 1.115154, acc: 87.11%] [G loss: 1.160017]\n",
      "[Epoch 27/50] [Batch 110/235] [D loss: 1.087805, acc: 88.48%] [G loss: 1.123222]\n",
      "[Epoch 27/50] [Batch 111/235] [D loss: 1.091553, acc: 87.89%] [G loss: 1.213759]\n",
      "[Epoch 27/50] [Batch 112/235] [D loss: 1.086993, acc: 88.09%] [G loss: 1.091842]\n",
      "[Epoch 27/50] [Batch 113/235] [D loss: 1.099427, acc: 86.52%] [G loss: 1.149479]\n",
      "[Epoch 27/50] [Batch 114/235] [D loss: 1.105887, acc: 85.94%] [G loss: 1.316978]\n",
      "[Epoch 27/50] [Batch 115/235] [D loss: 1.094336, acc: 85.74%] [G loss: 1.185094]\n",
      "[Epoch 27/50] [Batch 116/235] [D loss: 1.089545, acc: 87.11%] [G loss: 1.242524]\n",
      "[Epoch 27/50] [Batch 117/235] [D loss: 1.106526, acc: 86.91%] [G loss: 1.147245]\n",
      "[Epoch 27/50] [Batch 118/235] [D loss: 1.095315, acc: 88.48%] [G loss: 1.122829]\n",
      "[Epoch 27/50] [Batch 119/235] [D loss: 1.124645, acc: 87.89%] [G loss: 1.230993]\n",
      "[Epoch 27/50] [Batch 120/235] [D loss: 1.133556, acc: 86.13%] [G loss: 1.177002]\n",
      "[Epoch 27/50] [Batch 121/235] [D loss: 1.092233, acc: 86.13%] [G loss: 1.222726]\n",
      "[Epoch 27/50] [Batch 122/235] [D loss: 1.101218, acc: 86.33%] [G loss: 1.130269]\n",
      "[Epoch 27/50] [Batch 123/235] [D loss: 1.094856, acc: 88.09%] [G loss: 1.173705]\n",
      "[Epoch 27/50] [Batch 124/235] [D loss: 1.119429, acc: 87.50%] [G loss: 1.239115]\n",
      "[Epoch 27/50] [Batch 125/235] [D loss: 1.092560, acc: 89.06%] [G loss: 1.179603]\n",
      "[Epoch 27/50] [Batch 126/235] [D loss: 1.175287, acc: 86.91%] [G loss: 0.993943]\n",
      "[Epoch 27/50] [Batch 127/235] [D loss: 1.058774, acc: 86.72%] [G loss: 1.196810]\n",
      "[Epoch 27/50] [Batch 128/235] [D loss: 1.096818, acc: 85.16%] [G loss: 1.203261]\n",
      "[Epoch 27/50] [Batch 129/235] [D loss: 1.142161, acc: 86.52%] [G loss: 1.168210]\n",
      "[Epoch 27/50] [Batch 130/235] [D loss: 1.137791, acc: 85.35%] [G loss: 1.116662]\n",
      "[Epoch 27/50] [Batch 131/235] [D loss: 1.138867, acc: 87.30%] [G loss: 1.044783]\n",
      "[Epoch 27/50] [Batch 132/235] [D loss: 1.106226, acc: 87.50%] [G loss: 1.123515]\n",
      "[Epoch 27/50] [Batch 133/235] [D loss: 1.151184, acc: 87.30%] [G loss: 1.207856]\n",
      "[Epoch 27/50] [Batch 134/235] [D loss: 1.090716, acc: 87.11%] [G loss: 1.099474]\n",
      "[Epoch 27/50] [Batch 135/235] [D loss: 1.084657, acc: 86.13%] [G loss: 1.118048]\n",
      "[Epoch 27/50] [Batch 136/235] [D loss: 1.106475, acc: 84.96%] [G loss: 1.102257]\n",
      "[Epoch 27/50] [Batch 137/235] [D loss: 1.128875, acc: 88.48%] [G loss: 1.207566]\n",
      "[Epoch 27/50] [Batch 138/235] [D loss: 1.107441, acc: 84.18%] [G loss: 1.163707]\n",
      "[Epoch 27/50] [Batch 139/235] [D loss: 1.124599, acc: 86.52%] [G loss: 1.191140]\n",
      "[Epoch 27/50] [Batch 140/235] [D loss: 1.106268, acc: 86.52%] [G loss: 1.099474]\n",
      "[Epoch 27/50] [Batch 141/235] [D loss: 1.128175, acc: 86.13%] [G loss: 1.214975]\n",
      "[Epoch 27/50] [Batch 142/235] [D loss: 1.106744, acc: 87.11%] [G loss: 1.286660]\n",
      "[Epoch 27/50] [Batch 143/235] [D loss: 1.112141, acc: 86.13%] [G loss: 1.173314]\n",
      "[Epoch 27/50] [Batch 144/235] [D loss: 1.115553, acc: 85.16%] [G loss: 1.062769]\n",
      "[Epoch 27/50] [Batch 145/235] [D loss: 1.139910, acc: 85.16%] [G loss: 0.993692]\n",
      "[Epoch 27/50] [Batch 146/235] [D loss: 1.172391, acc: 85.94%] [G loss: 1.067586]\n",
      "[Epoch 27/50] [Batch 147/235] [D loss: 1.124324, acc: 86.33%] [G loss: 1.243452]\n",
      "[Epoch 27/50] [Batch 148/235] [D loss: 1.154986, acc: 84.57%] [G loss: 1.147391]\n",
      "[Epoch 27/50] [Batch 149/235] [D loss: 1.094296, acc: 84.77%] [G loss: 1.118580]\n",
      "[Epoch 27/50] [Batch 150/235] [D loss: 1.085836, acc: 88.28%] [G loss: 1.145204]\n",
      "[Epoch 27/50] [Batch 151/235] [D loss: 1.119931, acc: 85.74%] [G loss: 1.243408]\n",
      "[Epoch 27/50] [Batch 152/235] [D loss: 1.132391, acc: 88.67%] [G loss: 1.151037]\n",
      "[Epoch 27/50] [Batch 153/235] [D loss: 1.111698, acc: 86.13%] [G loss: 1.047614]\n",
      "[Epoch 27/50] [Batch 154/235] [D loss: 1.129926, acc: 85.35%] [G loss: 1.142255]\n",
      "[Epoch 27/50] [Batch 155/235] [D loss: 1.151644, acc: 84.96%] [G loss: 1.032911]\n",
      "[Epoch 27/50] [Batch 156/235] [D loss: 1.098521, acc: 87.70%] [G loss: 1.291933]\n",
      "[Epoch 27/50] [Batch 157/235] [D loss: 1.155128, acc: 87.30%] [G loss: 1.230005]\n",
      "[Epoch 27/50] [Batch 158/235] [D loss: 1.121914, acc: 85.35%] [G loss: 1.073609]\n",
      "[Epoch 27/50] [Batch 159/235] [D loss: 1.095477, acc: 88.09%] [G loss: 1.145407]\n",
      "[Epoch 27/50] [Batch 160/235] [D loss: 1.121222, acc: 87.70%] [G loss: 1.311890]\n",
      "[Epoch 27/50] [Batch 161/235] [D loss: 1.085706, acc: 86.52%] [G loss: 1.150702]\n",
      "[Epoch 27/50] [Batch 162/235] [D loss: 1.085675, acc: 88.28%] [G loss: 1.139304]\n",
      "[Epoch 27/50] [Batch 163/235] [D loss: 1.182004, acc: 86.72%] [G loss: 1.355046]\n",
      "[Epoch 27/50] [Batch 164/235] [D loss: 1.186943, acc: 87.89%] [G loss: 1.237573]\n",
      "[Epoch 27/50] [Batch 165/235] [D loss: 1.159150, acc: 86.91%] [G loss: 1.084790]\n",
      "[Epoch 27/50] [Batch 166/235] [D loss: 1.082658, acc: 87.11%] [G loss: 1.240177]\n",
      "[Epoch 27/50] [Batch 167/235] [D loss: 1.146836, acc: 83.79%] [G loss: 1.287976]\n",
      "[Epoch 27/50] [Batch 168/235] [D loss: 1.141275, acc: 87.50%] [G loss: 1.319161]\n",
      "[Epoch 27/50] [Batch 169/235] [D loss: 1.128220, acc: 86.72%] [G loss: 1.084430]\n",
      "[Epoch 27/50] [Batch 170/235] [D loss: 1.128889, acc: 87.70%] [G loss: 1.150167]\n",
      "[Epoch 27/50] [Batch 171/235] [D loss: 1.196438, acc: 85.55%] [G loss: 1.071001]\n",
      "[Epoch 27/50] [Batch 172/235] [D loss: 1.106940, acc: 84.77%] [G loss: 1.277215]\n",
      "[Epoch 27/50] [Batch 173/235] [D loss: 1.092886, acc: 87.89%] [G loss: 1.168298]\n",
      "[Epoch 27/50] [Batch 174/235] [D loss: 1.062792, acc: 86.72%] [G loss: 1.019565]\n",
      "[Epoch 27/50] [Batch 175/235] [D loss: 1.138462, acc: 87.70%] [G loss: 1.108167]\n",
      "[Epoch 27/50] [Batch 176/235] [D loss: 1.089270, acc: 85.74%] [G loss: 1.198345]\n",
      "[Epoch 27/50] [Batch 177/235] [D loss: 1.061065, acc: 87.11%] [G loss: 1.069127]\n",
      "[Epoch 27/50] [Batch 178/235] [D loss: 1.112436, acc: 84.57%] [G loss: 1.134681]\n",
      "[Epoch 27/50] [Batch 179/235] [D loss: 1.167253, acc: 88.28%] [G loss: 1.173401]\n",
      "[Epoch 27/50] [Batch 180/235] [D loss: 1.107886, acc: 86.91%] [G loss: 1.186320]\n",
      "[Epoch 27/50] [Batch 181/235] [D loss: 1.123279, acc: 85.55%] [G loss: 1.153414]\n",
      "[Epoch 27/50] [Batch 182/235] [D loss: 1.067799, acc: 87.11%] [G loss: 1.189128]\n",
      "[Epoch 27/50] [Batch 183/235] [D loss: 1.121516, acc: 86.13%] [G loss: 1.247171]\n",
      "[Epoch 27/50] [Batch 184/235] [D loss: 1.096457, acc: 86.72%] [G loss: 1.059152]\n",
      "[Epoch 27/50] [Batch 185/235] [D loss: 1.092313, acc: 89.26%] [G loss: 1.105283]\n",
      "[Epoch 27/50] [Batch 186/235] [D loss: 1.107078, acc: 87.11%] [G loss: 1.242404]\n",
      "[Epoch 27/50] [Batch 187/235] [D loss: 1.094067, acc: 87.70%] [G loss: 1.207206]\n",
      "[Epoch 27/50] [Batch 188/235] [D loss: 1.180893, acc: 86.72%] [G loss: 1.030636]\n",
      "[Epoch 27/50] [Batch 189/235] [D loss: 1.091460, acc: 85.94%] [G loss: 1.069208]\n",
      "[Epoch 27/50] [Batch 190/235] [D loss: 1.160310, acc: 86.72%] [G loss: 1.264414]\n",
      "[Epoch 27/50] [Batch 191/235] [D loss: 1.101742, acc: 86.13%] [G loss: 1.124769]\n",
      "[Epoch 27/50] [Batch 192/235] [D loss: 1.115449, acc: 86.52%] [G loss: 1.197957]\n",
      "[Epoch 27/50] [Batch 193/235] [D loss: 1.138786, acc: 87.11%] [G loss: 1.106535]\n",
      "[Epoch 27/50] [Batch 194/235] [D loss: 1.125722, acc: 86.33%] [G loss: 1.149034]\n",
      "[Epoch 27/50] [Batch 195/235] [D loss: 1.167235, acc: 83.98%] [G loss: 1.327001]\n",
      "[Epoch 27/50] [Batch 196/235] [D loss: 1.150324, acc: 86.52%] [G loss: 1.209254]\n",
      "[Epoch 27/50] [Batch 197/235] [D loss: 1.127826, acc: 84.96%] [G loss: 1.151032]\n",
      "[Epoch 27/50] [Batch 198/235] [D loss: 1.115690, acc: 89.26%] [G loss: 1.208032]\n",
      "[Epoch 27/50] [Batch 199/235] [D loss: 1.096206, acc: 87.50%] [G loss: 1.142725]\n",
      "[Epoch 27/50] [Batch 200/235] [D loss: 1.186881, acc: 88.09%] [G loss: 1.138485]\n",
      "[Epoch 27/50] [Batch 201/235] [D loss: 1.142500, acc: 85.35%] [G loss: 1.238917]\n",
      "[Epoch 27/50] [Batch 202/235] [D loss: 1.102775, acc: 86.52%] [G loss: 1.221052]\n",
      "[Epoch 27/50] [Batch 203/235] [D loss: 1.096973, acc: 88.28%] [G loss: 1.199638]\n",
      "[Epoch 27/50] [Batch 204/235] [D loss: 1.125267, acc: 85.16%] [G loss: 1.056524]\n",
      "[Epoch 27/50] [Batch 205/235] [D loss: 1.112010, acc: 85.94%] [G loss: 1.180624]\n",
      "[Epoch 27/50] [Batch 206/235] [D loss: 1.157729, acc: 89.45%] [G loss: 1.228083]\n",
      "[Epoch 27/50] [Batch 207/235] [D loss: 1.127172, acc: 87.30%] [G loss: 1.097534]\n",
      "[Epoch 27/50] [Batch 208/235] [D loss: 1.106536, acc: 85.74%] [G loss: 1.192730]\n",
      "[Epoch 27/50] [Batch 209/235] [D loss: 1.072648, acc: 89.65%] [G loss: 1.223014]\n",
      "[Epoch 27/50] [Batch 210/235] [D loss: 1.142781, acc: 90.23%] [G loss: 1.141326]\n",
      "[Epoch 27/50] [Batch 211/235] [D loss: 1.118228, acc: 88.87%] [G loss: 1.191097]\n",
      "[Epoch 27/50] [Batch 212/235] [D loss: 1.105001, acc: 86.52%] [G loss: 1.150820]\n",
      "[Epoch 27/50] [Batch 213/235] [D loss: 1.131944, acc: 86.33%] [G loss: 1.171715]\n",
      "[Epoch 27/50] [Batch 214/235] [D loss: 1.087117, acc: 87.11%] [G loss: 1.206005]\n",
      "[Epoch 27/50] [Batch 215/235] [D loss: 1.094397, acc: 88.87%] [G loss: 1.100463]\n",
      "[Epoch 27/50] [Batch 216/235] [D loss: 1.115749, acc: 84.77%] [G loss: 1.069844]\n",
      "[Epoch 27/50] [Batch 217/235] [D loss: 1.071565, acc: 87.89%] [G loss: 1.167502]\n",
      "[Epoch 27/50] [Batch 218/235] [D loss: 1.111042, acc: 87.30%] [G loss: 1.153199]\n",
      "[Epoch 27/50] [Batch 219/235] [D loss: 1.119587, acc: 87.30%] [G loss: 1.181817]\n",
      "[Epoch 27/50] [Batch 220/235] [D loss: 1.105994, acc: 86.33%] [G loss: 1.131214]\n",
      "[Epoch 27/50] [Batch 221/235] [D loss: 1.096678, acc: 87.11%] [G loss: 1.240085]\n",
      "[Epoch 27/50] [Batch 222/235] [D loss: 1.123629, acc: 84.77%] [G loss: 1.182060]\n",
      "[Epoch 27/50] [Batch 223/235] [D loss: 1.127655, acc: 87.70%] [G loss: 1.240839]\n",
      "[Epoch 27/50] [Batch 224/235] [D loss: 1.156427, acc: 88.48%] [G loss: 1.099150]\n",
      "[Epoch 27/50] [Batch 225/235] [D loss: 1.084996, acc: 86.91%] [G loss: 1.301849]\n",
      "[Epoch 27/50] [Batch 226/235] [D loss: 1.146238, acc: 85.16%] [G loss: 1.223708]\n",
      "[Epoch 27/50] [Batch 227/235] [D loss: 1.083149, acc: 86.72%] [G loss: 1.124924]\n",
      "[Epoch 27/50] [Batch 228/235] [D loss: 1.127670, acc: 86.33%] [G loss: 1.115163]\n",
      "[Epoch 27/50] [Batch 229/235] [D loss: 1.108771, acc: 86.91%] [G loss: 1.121723]\n",
      "[Epoch 27/50] [Batch 230/235] [D loss: 1.095617, acc: 86.33%] [G loss: 1.068022]\n",
      "[Epoch 27/50] [Batch 231/235] [D loss: 1.202723, acc: 84.77%] [G loss: 1.113391]\n",
      "[Epoch 27/50] [Batch 232/235] [D loss: 1.089666, acc: 85.55%] [G loss: 1.120500]\n",
      "[Epoch 27/50] [Batch 233/235] [D loss: 1.090024, acc: 87.70%] [G loss: 1.207880]\n",
      "[Epoch 27/50] [Batch 234/235] [D loss: 1.105610, acc: 84.38%] [G loss: 1.118295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/50] [Batch 0/235] [D loss: 1.117728, acc: 87.50%] [G loss: 1.211658]\n",
      "[Epoch 28/50] [Batch 1/235] [D loss: 1.120044, acc: 85.35%] [G loss: 1.180161]\n",
      "[Epoch 28/50] [Batch 2/235] [D loss: 1.145768, acc: 89.84%] [G loss: 1.084493]\n",
      "[Epoch 28/50] [Batch 3/235] [D loss: 1.096234, acc: 85.35%] [G loss: 1.097838]\n",
      "[Epoch 28/50] [Batch 4/235] [D loss: 1.088759, acc: 88.67%] [G loss: 1.263440]\n",
      "[Epoch 28/50] [Batch 5/235] [D loss: 1.121818, acc: 85.35%] [G loss: 1.231377]\n",
      "[Epoch 28/50] [Batch 6/235] [D loss: 1.159687, acc: 87.30%] [G loss: 1.303525]\n",
      "[Epoch 28/50] [Batch 7/235] [D loss: 1.096128, acc: 88.28%] [G loss: 1.051071]\n",
      "[Epoch 28/50] [Batch 8/235] [D loss: 1.051456, acc: 86.72%] [G loss: 1.353528]\n",
      "[Epoch 28/50] [Batch 9/235] [D loss: 1.127328, acc: 87.30%] [G loss: 1.159806]\n",
      "[Epoch 28/50] [Batch 10/235] [D loss: 1.084221, acc: 85.55%] [G loss: 1.056557]\n",
      "[Epoch 28/50] [Batch 11/235] [D loss: 1.124440, acc: 86.52%] [G loss: 1.263514]\n",
      "[Epoch 28/50] [Batch 12/235] [D loss: 1.091109, acc: 85.74%] [G loss: 1.205078]\n",
      "[Epoch 28/50] [Batch 13/235] [D loss: 1.103528, acc: 83.98%] [G loss: 1.123051]\n",
      "[Epoch 28/50] [Batch 14/235] [D loss: 1.126498, acc: 86.72%] [G loss: 1.072467]\n",
      "[Epoch 28/50] [Batch 15/235] [D loss: 1.114211, acc: 87.30%] [G loss: 1.032043]\n",
      "[Epoch 28/50] [Batch 16/235] [D loss: 1.130856, acc: 83.79%] [G loss: 1.174511]\n",
      "[Epoch 28/50] [Batch 17/235] [D loss: 1.130502, acc: 84.57%] [G loss: 1.185651]\n",
      "[Epoch 28/50] [Batch 18/235] [D loss: 1.098189, acc: 85.55%] [G loss: 1.112162]\n",
      "[Epoch 28/50] [Batch 19/235] [D loss: 1.143880, acc: 88.87%] [G loss: 1.188501]\n",
      "[Epoch 28/50] [Batch 20/235] [D loss: 1.144051, acc: 86.52%] [G loss: 1.193475]\n",
      "[Epoch 28/50] [Batch 21/235] [D loss: 1.116670, acc: 88.28%] [G loss: 1.072355]\n",
      "[Epoch 28/50] [Batch 22/235] [D loss: 1.146699, acc: 86.52%] [G loss: 1.114401]\n",
      "[Epoch 28/50] [Batch 23/235] [D loss: 1.192208, acc: 85.94%] [G loss: 1.150247]\n",
      "[Epoch 28/50] [Batch 24/235] [D loss: 1.148542, acc: 84.57%] [G loss: 1.196236]\n",
      "[Epoch 28/50] [Batch 25/235] [D loss: 1.089531, acc: 86.52%] [G loss: 1.173244]\n",
      "[Epoch 28/50] [Batch 26/235] [D loss: 1.123875, acc: 84.77%] [G loss: 0.990284]\n",
      "[Epoch 28/50] [Batch 27/235] [D loss: 1.079883, acc: 87.30%] [G loss: 1.072623]\n",
      "[Epoch 28/50] [Batch 28/235] [D loss: 1.106196, acc: 87.50%] [G loss: 1.322116]\n",
      "[Epoch 28/50] [Batch 29/235] [D loss: 1.128112, acc: 87.50%] [G loss: 1.265005]\n",
      "[Epoch 28/50] [Batch 30/235] [D loss: 1.176632, acc: 86.52%] [G loss: 1.198762]\n",
      "[Epoch 28/50] [Batch 31/235] [D loss: 1.105405, acc: 86.91%] [G loss: 1.121141]\n",
      "[Epoch 28/50] [Batch 32/235] [D loss: 1.127333, acc: 85.74%] [G loss: 1.045616]\n",
      "[Epoch 28/50] [Batch 33/235] [D loss: 1.147865, acc: 86.52%] [G loss: 1.255104]\n",
      "[Epoch 28/50] [Batch 34/235] [D loss: 1.095163, acc: 87.50%] [G loss: 1.143347]\n",
      "[Epoch 28/50] [Batch 35/235] [D loss: 1.162355, acc: 88.09%] [G loss: 1.085563]\n",
      "[Epoch 28/50] [Batch 36/235] [D loss: 1.096632, acc: 85.35%] [G loss: 1.163990]\n",
      "[Epoch 28/50] [Batch 37/235] [D loss: 1.122254, acc: 84.57%] [G loss: 1.161711]\n",
      "[Epoch 28/50] [Batch 38/235] [D loss: 1.116605, acc: 86.33%] [G loss: 1.245639]\n",
      "[Epoch 28/50] [Batch 39/235] [D loss: 1.169221, acc: 87.89%] [G loss: 1.054379]\n",
      "[Epoch 28/50] [Batch 40/235] [D loss: 1.092761, acc: 87.11%] [G loss: 1.103149]\n",
      "[Epoch 28/50] [Batch 41/235] [D loss: 1.168220, acc: 82.23%] [G loss: 1.192353]\n",
      "[Epoch 28/50] [Batch 42/235] [D loss: 1.124054, acc: 87.50%] [G loss: 1.153916]\n",
      "[Epoch 28/50] [Batch 43/235] [D loss: 1.102347, acc: 87.89%] [G loss: 1.158998]\n",
      "[Epoch 28/50] [Batch 44/235] [D loss: 1.135799, acc: 86.72%] [G loss: 1.180699]\n",
      "[Epoch 28/50] [Batch 45/235] [D loss: 1.085069, acc: 87.89%] [G loss: 1.194600]\n",
      "[Epoch 28/50] [Batch 46/235] [D loss: 1.174483, acc: 86.13%] [G loss: 1.169828]\n",
      "[Epoch 28/50] [Batch 47/235] [D loss: 1.096277, acc: 85.55%] [G loss: 1.174686]\n",
      "[Epoch 28/50] [Batch 48/235] [D loss: 1.237481, acc: 88.28%] [G loss: 1.192165]\n",
      "[Epoch 28/50] [Batch 49/235] [D loss: 1.116839, acc: 88.28%] [G loss: 1.283254]\n",
      "[Epoch 28/50] [Batch 50/235] [D loss: 1.107973, acc: 87.89%] [G loss: 1.188233]\n",
      "[Epoch 28/50] [Batch 51/235] [D loss: 1.144919, acc: 86.33%] [G loss: 1.208427]\n",
      "[Epoch 28/50] [Batch 52/235] [D loss: 1.131683, acc: 87.30%] [G loss: 1.080707]\n",
      "[Epoch 28/50] [Batch 53/235] [D loss: 1.118376, acc: 85.74%] [G loss: 1.229584]\n",
      "[Epoch 28/50] [Batch 54/235] [D loss: 1.111511, acc: 85.74%] [G loss: 1.226692]\n",
      "[Epoch 28/50] [Batch 55/235] [D loss: 1.107386, acc: 88.09%] [G loss: 1.098453]\n",
      "[Epoch 28/50] [Batch 56/235] [D loss: 1.098183, acc: 86.13%] [G loss: 1.151797]\n",
      "[Epoch 28/50] [Batch 57/235] [D loss: 1.050486, acc: 86.33%] [G loss: 1.219065]\n",
      "[Epoch 28/50] [Batch 58/235] [D loss: 1.160948, acc: 87.50%] [G loss: 1.152064]\n",
      "[Epoch 28/50] [Batch 59/235] [D loss: 1.120657, acc: 87.50%] [G loss: 1.157079]\n",
      "[Epoch 28/50] [Batch 60/235] [D loss: 1.117070, acc: 87.11%] [G loss: 1.185107]\n",
      "[Epoch 28/50] [Batch 61/235] [D loss: 1.095602, acc: 87.50%] [G loss: 1.187024]\n",
      "[Epoch 28/50] [Batch 62/235] [D loss: 1.105117, acc: 86.13%] [G loss: 1.220674]\n",
      "[Epoch 28/50] [Batch 63/235] [D loss: 1.139655, acc: 86.52%] [G loss: 1.099356]\n",
      "[Epoch 28/50] [Batch 64/235] [D loss: 1.114466, acc: 89.06%] [G loss: 1.111337]\n",
      "[Epoch 28/50] [Batch 65/235] [D loss: 1.085942, acc: 87.50%] [G loss: 1.254960]\n",
      "[Epoch 28/50] [Batch 66/235] [D loss: 1.103533, acc: 85.55%] [G loss: 1.125226]\n",
      "[Epoch 28/50] [Batch 67/235] [D loss: 1.090578, acc: 86.52%] [G loss: 1.210590]\n",
      "[Epoch 28/50] [Batch 68/235] [D loss: 1.093439, acc: 86.52%] [G loss: 1.084522]\n",
      "[Epoch 28/50] [Batch 69/235] [D loss: 1.184608, acc: 85.74%] [G loss: 1.155379]\n",
      "[Epoch 28/50] [Batch 70/235] [D loss: 1.142741, acc: 86.33%] [G loss: 1.046636]\n",
      "[Epoch 28/50] [Batch 71/235] [D loss: 1.065773, acc: 87.70%] [G loss: 1.178756]\n",
      "[Epoch 28/50] [Batch 72/235] [D loss: 1.143721, acc: 86.33%] [G loss: 1.155193]\n",
      "[Epoch 28/50] [Batch 73/235] [D loss: 1.069457, acc: 86.33%] [G loss: 1.171501]\n",
      "[Epoch 28/50] [Batch 74/235] [D loss: 1.106370, acc: 86.13%] [G loss: 1.211334]\n",
      "[Epoch 28/50] [Batch 75/235] [D loss: 1.128331, acc: 84.96%] [G loss: 1.168568]\n",
      "[Epoch 28/50] [Batch 76/235] [D loss: 1.113380, acc: 87.30%] [G loss: 1.093760]\n",
      "[Epoch 28/50] [Batch 77/235] [D loss: 1.085846, acc: 84.57%] [G loss: 1.120623]\n",
      "[Epoch 28/50] [Batch 78/235] [D loss: 1.151107, acc: 86.52%] [G loss: 1.393205]\n",
      "[Epoch 28/50] [Batch 79/235] [D loss: 1.100594, acc: 88.28%] [G loss: 1.071288]\n",
      "[Epoch 28/50] [Batch 80/235] [D loss: 1.174502, acc: 86.13%] [G loss: 1.284171]\n",
      "[Epoch 28/50] [Batch 81/235] [D loss: 1.152794, acc: 83.59%] [G loss: 1.156639]\n",
      "[Epoch 28/50] [Batch 82/235] [D loss: 1.103543, acc: 87.89%] [G loss: 1.218246]\n",
      "[Epoch 28/50] [Batch 83/235] [D loss: 1.107346, acc: 88.48%] [G loss: 1.107189]\n",
      "[Epoch 28/50] [Batch 84/235] [D loss: 1.161175, acc: 84.18%] [G loss: 1.116168]\n",
      "[Epoch 28/50] [Batch 85/235] [D loss: 1.147076, acc: 88.48%] [G loss: 1.151616]\n",
      "[Epoch 28/50] [Batch 86/235] [D loss: 1.187611, acc: 86.91%] [G loss: 1.260687]\n",
      "[Epoch 28/50] [Batch 87/235] [D loss: 1.119697, acc: 88.48%] [G loss: 1.351101]\n",
      "[Epoch 28/50] [Batch 88/235] [D loss: 1.096211, acc: 87.11%] [G loss: 1.224845]\n",
      "[Epoch 28/50] [Batch 89/235] [D loss: 1.104864, acc: 84.38%] [G loss: 1.097892]\n",
      "[Epoch 28/50] [Batch 90/235] [D loss: 1.089673, acc: 88.28%] [G loss: 1.111957]\n",
      "[Epoch 28/50] [Batch 91/235] [D loss: 1.179370, acc: 85.35%] [G loss: 1.036441]\n",
      "[Epoch 28/50] [Batch 92/235] [D loss: 1.143148, acc: 85.74%] [G loss: 1.105875]\n",
      "[Epoch 28/50] [Batch 93/235] [D loss: 1.114032, acc: 85.74%] [G loss: 1.426843]\n",
      "[Epoch 28/50] [Batch 94/235] [D loss: 1.099236, acc: 85.55%] [G loss: 1.192557]\n",
      "[Epoch 28/50] [Batch 95/235] [D loss: 1.074442, acc: 87.11%] [G loss: 1.087024]\n",
      "[Epoch 28/50] [Batch 96/235] [D loss: 1.183802, acc: 88.48%] [G loss: 1.216241]\n",
      "[Epoch 28/50] [Batch 97/235] [D loss: 1.099300, acc: 88.09%] [G loss: 1.091095]\n",
      "[Epoch 28/50] [Batch 98/235] [D loss: 1.097779, acc: 88.87%] [G loss: 1.086524]\n",
      "[Epoch 28/50] [Batch 99/235] [D loss: 1.120278, acc: 86.91%] [G loss: 1.107592]\n",
      "[Epoch 28/50] [Batch 100/235] [D loss: 1.088524, acc: 85.55%] [G loss: 1.171584]\n",
      "[Epoch 28/50] [Batch 101/235] [D loss: 1.167985, acc: 85.55%] [G loss: 1.095685]\n",
      "[Epoch 28/50] [Batch 102/235] [D loss: 1.106822, acc: 87.50%] [G loss: 1.206098]\n",
      "[Epoch 28/50] [Batch 103/235] [D loss: 1.107402, acc: 88.87%] [G loss: 1.160970]\n",
      "[Epoch 28/50] [Batch 104/235] [D loss: 1.106262, acc: 86.13%] [G loss: 1.197114]\n",
      "[Epoch 28/50] [Batch 105/235] [D loss: 1.109555, acc: 85.74%] [G loss: 1.228882]\n",
      "[Epoch 28/50] [Batch 106/235] [D loss: 1.143289, acc: 85.74%] [G loss: 1.089483]\n",
      "[Epoch 28/50] [Batch 107/235] [D loss: 1.122934, acc: 84.57%] [G loss: 1.064690]\n",
      "[Epoch 28/50] [Batch 108/235] [D loss: 1.096747, acc: 85.94%] [G loss: 1.099981]\n",
      "[Epoch 28/50] [Batch 109/235] [D loss: 1.112876, acc: 85.55%] [G loss: 1.125378]\n",
      "[Epoch 28/50] [Batch 110/235] [D loss: 1.132235, acc: 88.87%] [G loss: 1.178407]\n",
      "[Epoch 28/50] [Batch 111/235] [D loss: 1.116885, acc: 86.72%] [G loss: 1.149409]\n",
      "[Epoch 28/50] [Batch 112/235] [D loss: 1.105048, acc: 88.48%] [G loss: 1.122018]\n",
      "[Epoch 28/50] [Batch 113/235] [D loss: 1.122536, acc: 87.50%] [G loss: 1.086977]\n",
      "[Epoch 28/50] [Batch 114/235] [D loss: 1.158224, acc: 87.70%] [G loss: 1.102742]\n",
      "[Epoch 28/50] [Batch 115/235] [D loss: 1.133004, acc: 88.48%] [G loss: 1.160278]\n",
      "[Epoch 28/50] [Batch 116/235] [D loss: 1.095091, acc: 84.96%] [G loss: 1.120947]\n",
      "[Epoch 28/50] [Batch 117/235] [D loss: 1.153268, acc: 86.13%] [G loss: 1.062370]\n",
      "[Epoch 28/50] [Batch 118/235] [D loss: 1.100601, acc: 89.26%] [G loss: 1.259084]\n",
      "[Epoch 28/50] [Batch 119/235] [D loss: 1.123322, acc: 87.11%] [G loss: 1.217427]\n",
      "[Epoch 28/50] [Batch 120/235] [D loss: 1.075069, acc: 87.89%] [G loss: 1.199616]\n",
      "[Epoch 28/50] [Batch 121/235] [D loss: 1.091567, acc: 85.94%] [G loss: 1.048840]\n",
      "[Epoch 28/50] [Batch 122/235] [D loss: 1.115858, acc: 87.11%] [G loss: 1.219316]\n",
      "[Epoch 28/50] [Batch 123/235] [D loss: 1.049111, acc: 85.94%] [G loss: 1.180709]\n",
      "[Epoch 28/50] [Batch 124/235] [D loss: 1.102564, acc: 87.11%] [G loss: 1.253012]\n",
      "[Epoch 28/50] [Batch 125/235] [D loss: 1.114497, acc: 88.87%] [G loss: 1.170606]\n",
      "[Epoch 28/50] [Batch 126/235] [D loss: 1.095677, acc: 86.13%] [G loss: 1.190731]\n",
      "[Epoch 28/50] [Batch 127/235] [D loss: 1.138408, acc: 88.87%] [G loss: 1.032131]\n",
      "[Epoch 28/50] [Batch 128/235] [D loss: 1.141373, acc: 87.89%] [G loss: 1.295402]\n",
      "[Epoch 28/50] [Batch 129/235] [D loss: 1.106174, acc: 85.74%] [G loss: 1.187859]\n",
      "[Epoch 28/50] [Batch 130/235] [D loss: 1.157110, acc: 86.52%] [G loss: 1.120164]\n",
      "[Epoch 28/50] [Batch 131/235] [D loss: 1.119205, acc: 83.79%] [G loss: 1.146440]\n",
      "[Epoch 28/50] [Batch 132/235] [D loss: 1.137697, acc: 86.52%] [G loss: 1.191994]\n",
      "[Epoch 28/50] [Batch 133/235] [D loss: 1.081798, acc: 89.26%] [G loss: 1.231370]\n",
      "[Epoch 28/50] [Batch 134/235] [D loss: 1.137735, acc: 86.72%] [G loss: 1.126707]\n",
      "[Epoch 28/50] [Batch 135/235] [D loss: 1.171735, acc: 85.94%] [G loss: 1.154932]\n",
      "[Epoch 28/50] [Batch 136/235] [D loss: 1.103598, acc: 84.38%] [G loss: 1.150315]\n",
      "[Epoch 28/50] [Batch 137/235] [D loss: 1.098858, acc: 84.96%] [G loss: 1.183494]\n",
      "[Epoch 28/50] [Batch 138/235] [D loss: 1.112714, acc: 87.30%] [G loss: 1.144832]\n",
      "[Epoch 28/50] [Batch 139/235] [D loss: 1.144322, acc: 89.26%] [G loss: 1.123127]\n",
      "[Epoch 28/50] [Batch 140/235] [D loss: 1.070352, acc: 89.06%] [G loss: 1.172704]\n",
      "[Epoch 28/50] [Batch 141/235] [D loss: 1.107123, acc: 89.84%] [G loss: 1.114570]\n",
      "[Epoch 28/50] [Batch 142/235] [D loss: 1.170349, acc: 84.57%] [G loss: 1.285207]\n",
      "[Epoch 28/50] [Batch 143/235] [D loss: 1.096799, acc: 88.28%] [G loss: 1.201044]\n",
      "[Epoch 28/50] [Batch 144/235] [D loss: 1.147638, acc: 86.72%] [G loss: 1.111727]\n",
      "[Epoch 28/50] [Batch 145/235] [D loss: 1.141108, acc: 84.18%] [G loss: 1.108664]\n",
      "[Epoch 28/50] [Batch 146/235] [D loss: 1.117167, acc: 88.09%] [G loss: 1.081788]\n",
      "[Epoch 28/50] [Batch 147/235] [D loss: 1.081471, acc: 88.28%] [G loss: 1.108094]\n",
      "[Epoch 28/50] [Batch 148/235] [D loss: 1.083343, acc: 87.11%] [G loss: 1.214076]\n",
      "[Epoch 28/50] [Batch 149/235] [D loss: 1.058611, acc: 85.16%] [G loss: 1.150233]\n",
      "[Epoch 28/50] [Batch 150/235] [D loss: 1.091724, acc: 87.70%] [G loss: 1.237633]\n",
      "[Epoch 28/50] [Batch 151/235] [D loss: 1.105715, acc: 88.87%] [G loss: 1.049481]\n",
      "[Epoch 28/50] [Batch 152/235] [D loss: 1.192531, acc: 85.16%] [G loss: 1.116047]\n",
      "[Epoch 28/50] [Batch 153/235] [D loss: 1.173427, acc: 85.55%] [G loss: 1.139235]\n",
      "[Epoch 28/50] [Batch 154/235] [D loss: 1.071887, acc: 85.55%] [G loss: 1.189009]\n",
      "[Epoch 28/50] [Batch 155/235] [D loss: 1.068999, acc: 87.50%] [G loss: 1.150196]\n",
      "[Epoch 28/50] [Batch 156/235] [D loss: 1.100939, acc: 88.67%] [G loss: 1.236190]\n",
      "[Epoch 28/50] [Batch 157/235] [D loss: 1.121271, acc: 86.72%] [G loss: 1.286024]\n",
      "[Epoch 28/50] [Batch 158/235] [D loss: 1.125038, acc: 89.65%] [G loss: 1.260882]\n",
      "[Epoch 28/50] [Batch 159/235] [D loss: 1.033137, acc: 87.11%] [G loss: 1.265696]\n",
      "[Epoch 28/50] [Batch 160/235] [D loss: 1.176153, acc: 87.50%] [G loss: 1.069148]\n",
      "[Epoch 28/50] [Batch 161/235] [D loss: 1.070722, acc: 86.52%] [G loss: 1.172762]\n",
      "[Epoch 28/50] [Batch 162/235] [D loss: 1.075339, acc: 88.48%] [G loss: 1.244808]\n",
      "[Epoch 28/50] [Batch 163/235] [D loss: 1.117104, acc: 87.30%] [G loss: 1.130321]\n",
      "[Epoch 28/50] [Batch 164/235] [D loss: 1.100964, acc: 87.30%] [G loss: 1.219925]\n",
      "[Epoch 28/50] [Batch 165/235] [D loss: 1.117438, acc: 87.89%] [G loss: 1.236410]\n",
      "[Epoch 28/50] [Batch 166/235] [D loss: 1.077823, acc: 87.50%] [G loss: 1.183233]\n",
      "[Epoch 28/50] [Batch 167/235] [D loss: 1.164356, acc: 85.35%] [G loss: 1.228898]\n",
      "[Epoch 28/50] [Batch 168/235] [D loss: 1.124896, acc: 87.30%] [G loss: 1.072607]\n",
      "[Epoch 28/50] [Batch 169/235] [D loss: 1.115676, acc: 88.48%] [G loss: 1.255342]\n",
      "[Epoch 28/50] [Batch 170/235] [D loss: 1.058502, acc: 87.50%] [G loss: 1.115462]\n",
      "[Epoch 28/50] [Batch 171/235] [D loss: 1.049327, acc: 86.33%] [G loss: 1.151546]\n",
      "[Epoch 28/50] [Batch 172/235] [D loss: 1.148225, acc: 87.11%] [G loss: 1.306718]\n",
      "[Epoch 28/50] [Batch 173/235] [D loss: 1.128361, acc: 85.74%] [G loss: 1.147691]\n",
      "[Epoch 28/50] [Batch 174/235] [D loss: 1.134750, acc: 86.91%] [G loss: 1.061182]\n",
      "[Epoch 28/50] [Batch 175/235] [D loss: 1.124732, acc: 87.11%] [G loss: 1.075351]\n",
      "[Epoch 28/50] [Batch 176/235] [D loss: 1.076224, acc: 87.50%] [G loss: 1.212339]\n",
      "[Epoch 28/50] [Batch 177/235] [D loss: 1.090582, acc: 85.16%] [G loss: 1.111805]\n",
      "[Epoch 28/50] [Batch 178/235] [D loss: 1.142813, acc: 86.13%] [G loss: 1.090806]\n",
      "[Epoch 28/50] [Batch 179/235] [D loss: 1.108022, acc: 85.94%] [G loss: 1.084687]\n",
      "[Epoch 28/50] [Batch 180/235] [D loss: 1.139590, acc: 86.91%] [G loss: 1.210614]\n",
      "[Epoch 28/50] [Batch 181/235] [D loss: 1.103796, acc: 86.13%] [G loss: 1.356016]\n",
      "[Epoch 28/50] [Batch 182/235] [D loss: 1.131114, acc: 84.77%] [G loss: 1.090860]\n",
      "[Epoch 28/50] [Batch 183/235] [D loss: 1.166464, acc: 86.52%] [G loss: 1.130407]\n",
      "[Epoch 28/50] [Batch 184/235] [D loss: 1.070498, acc: 86.91%] [G loss: 1.104025]\n",
      "[Epoch 28/50] [Batch 185/235] [D loss: 1.134145, acc: 89.06%] [G loss: 1.081660]\n",
      "[Epoch 28/50] [Batch 186/235] [D loss: 1.089198, acc: 85.55%] [G loss: 1.132163]\n",
      "[Epoch 28/50] [Batch 187/235] [D loss: 1.072190, acc: 88.09%] [G loss: 1.234245]\n",
      "[Epoch 28/50] [Batch 188/235] [D loss: 1.088397, acc: 83.59%] [G loss: 1.148457]\n",
      "[Epoch 28/50] [Batch 189/235] [D loss: 1.077066, acc: 86.33%] [G loss: 1.166821]\n",
      "[Epoch 28/50] [Batch 190/235] [D loss: 1.113523, acc: 89.65%] [G loss: 1.069775]\n",
      "[Epoch 28/50] [Batch 191/235] [D loss: 1.081942, acc: 88.09%] [G loss: 1.157144]\n",
      "[Epoch 28/50] [Batch 192/235] [D loss: 1.086032, acc: 86.72%] [G loss: 1.040501]\n",
      "[Epoch 28/50] [Batch 193/235] [D loss: 1.075235, acc: 85.74%] [G loss: 1.152290]\n",
      "[Epoch 28/50] [Batch 194/235] [D loss: 1.120134, acc: 87.89%] [G loss: 1.085832]\n",
      "[Epoch 28/50] [Batch 195/235] [D loss: 1.108434, acc: 88.48%] [G loss: 1.179642]\n",
      "[Epoch 28/50] [Batch 196/235] [D loss: 1.083690, acc: 86.91%] [G loss: 1.210028]\n",
      "[Epoch 28/50] [Batch 197/235] [D loss: 1.119579, acc: 87.50%] [G loss: 1.112021]\n",
      "[Epoch 28/50] [Batch 198/235] [D loss: 1.092868, acc: 88.09%] [G loss: 1.214238]\n",
      "[Epoch 28/50] [Batch 199/235] [D loss: 1.169632, acc: 87.30%] [G loss: 1.075101]\n",
      "[Epoch 28/50] [Batch 200/235] [D loss: 1.144793, acc: 83.40%] [G loss: 1.068660]\n",
      "[Epoch 28/50] [Batch 201/235] [D loss: 1.119552, acc: 90.62%] [G loss: 1.104057]\n",
      "[Epoch 28/50] [Batch 202/235] [D loss: 1.143807, acc: 86.33%] [G loss: 1.393785]\n",
      "[Epoch 28/50] [Batch 203/235] [D loss: 1.191067, acc: 84.77%] [G loss: 1.282299]\n",
      "[Epoch 28/50] [Batch 204/235] [D loss: 1.091805, acc: 87.70%] [G loss: 1.067671]\n",
      "[Epoch 28/50] [Batch 205/235] [D loss: 1.125296, acc: 86.33%] [G loss: 1.114838]\n",
      "[Epoch 28/50] [Batch 206/235] [D loss: 1.131291, acc: 83.20%] [G loss: 1.231701]\n",
      "[Epoch 28/50] [Batch 207/235] [D loss: 1.133071, acc: 85.16%] [G loss: 1.111031]\n",
      "[Epoch 28/50] [Batch 208/235] [D loss: 1.116828, acc: 86.52%] [G loss: 1.186422]\n",
      "[Epoch 28/50] [Batch 209/235] [D loss: 1.067349, acc: 86.52%] [G loss: 1.241320]\n",
      "[Epoch 28/50] [Batch 210/235] [D loss: 1.127035, acc: 84.57%] [G loss: 1.286622]\n",
      "[Epoch 28/50] [Batch 211/235] [D loss: 1.113137, acc: 85.55%] [G loss: 1.225986]\n",
      "[Epoch 28/50] [Batch 212/235] [D loss: 1.084168, acc: 86.72%] [G loss: 1.175861]\n",
      "[Epoch 28/50] [Batch 213/235] [D loss: 1.063999, acc: 86.52%] [G loss: 1.159208]\n",
      "[Epoch 28/50] [Batch 214/235] [D loss: 1.092494, acc: 86.33%] [G loss: 1.304994]\n",
      "[Epoch 28/50] [Batch 215/235] [D loss: 1.042437, acc: 87.50%] [G loss: 1.112527]\n",
      "[Epoch 28/50] [Batch 216/235] [D loss: 1.071454, acc: 87.50%] [G loss: 1.152536]\n",
      "[Epoch 28/50] [Batch 217/235] [D loss: 1.077866, acc: 85.74%] [G loss: 1.170693]\n",
      "[Epoch 28/50] [Batch 218/235] [D loss: 1.086589, acc: 87.11%] [G loss: 1.196779]\n",
      "[Epoch 28/50] [Batch 219/235] [D loss: 1.091812, acc: 88.67%] [G loss: 1.080448]\n",
      "[Epoch 28/50] [Batch 220/235] [D loss: 1.093440, acc: 88.67%] [G loss: 1.192655]\n",
      "[Epoch 28/50] [Batch 221/235] [D loss: 1.120913, acc: 83.59%] [G loss: 1.265753]\n",
      "[Epoch 28/50] [Batch 222/235] [D loss: 1.086947, acc: 84.96%] [G loss: 1.151508]\n",
      "[Epoch 28/50] [Batch 223/235] [D loss: 1.110889, acc: 85.16%] [G loss: 1.188033]\n",
      "[Epoch 28/50] [Batch 224/235] [D loss: 1.066666, acc: 88.87%] [G loss: 1.106071]\n",
      "[Epoch 28/50] [Batch 225/235] [D loss: 1.084412, acc: 86.91%] [G loss: 1.249686]\n",
      "[Epoch 28/50] [Batch 226/235] [D loss: 1.092029, acc: 86.72%] [G loss: 1.177241]\n",
      "[Epoch 28/50] [Batch 227/235] [D loss: 1.100268, acc: 87.70%] [G loss: 1.168548]\n",
      "[Epoch 28/50] [Batch 228/235] [D loss: 1.162441, acc: 85.55%] [G loss: 1.154058]\n",
      "[Epoch 28/50] [Batch 229/235] [D loss: 1.142713, acc: 86.91%] [G loss: 1.147623]\n",
      "[Epoch 28/50] [Batch 230/235] [D loss: 1.063189, acc: 90.62%] [G loss: 1.155735]\n",
      "[Epoch 28/50] [Batch 231/235] [D loss: 1.089524, acc: 85.35%] [G loss: 1.114609]\n",
      "[Epoch 28/50] [Batch 232/235] [D loss: 1.119365, acc: 85.16%] [G loss: 1.173057]\n",
      "[Epoch 28/50] [Batch 233/235] [D loss: 1.085439, acc: 86.33%] [G loss: 1.109004]\n",
      "[Epoch 28/50] [Batch 234/235] [D loss: 1.159898, acc: 86.46%] [G loss: 1.053852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/50] [Batch 0/235] [D loss: 1.136958, acc: 86.13%] [G loss: 1.462824]\n",
      "[Epoch 29/50] [Batch 1/235] [D loss: 1.079027, acc: 88.09%] [G loss: 1.154165]\n",
      "[Epoch 29/50] [Batch 2/235] [D loss: 1.127815, acc: 84.38%] [G loss: 0.986647]\n",
      "[Epoch 29/50] [Batch 3/235] [D loss: 1.118211, acc: 85.35%] [G loss: 1.071082]\n",
      "[Epoch 29/50] [Batch 4/235] [D loss: 1.192604, acc: 85.74%] [G loss: 1.324424]\n",
      "[Epoch 29/50] [Batch 5/235] [D loss: 1.129095, acc: 91.02%] [G loss: 1.188610]\n",
      "[Epoch 29/50] [Batch 6/235] [D loss: 1.139642, acc: 87.50%] [G loss: 1.096545]\n",
      "[Epoch 29/50] [Batch 7/235] [D loss: 1.144108, acc: 84.77%] [G loss: 1.108242]\n",
      "[Epoch 29/50] [Batch 8/235] [D loss: 1.127309, acc: 87.70%] [G loss: 1.093957]\n",
      "[Epoch 29/50] [Batch 9/235] [D loss: 1.084829, acc: 87.70%] [G loss: 1.110786]\n",
      "[Epoch 29/50] [Batch 10/235] [D loss: 1.110079, acc: 85.74%] [G loss: 1.207311]\n",
      "[Epoch 29/50] [Batch 11/235] [D loss: 1.139337, acc: 84.96%] [G loss: 1.063853]\n",
      "[Epoch 29/50] [Batch 12/235] [D loss: 1.128380, acc: 88.28%] [G loss: 1.104821]\n",
      "[Epoch 29/50] [Batch 13/235] [D loss: 1.087312, acc: 86.72%] [G loss: 1.023790]\n",
      "[Epoch 29/50] [Batch 14/235] [D loss: 1.086272, acc: 84.77%] [G loss: 1.175656]\n",
      "[Epoch 29/50] [Batch 15/235] [D loss: 1.107763, acc: 88.28%] [G loss: 1.232179]\n",
      "[Epoch 29/50] [Batch 16/235] [D loss: 1.102159, acc: 87.70%] [G loss: 1.148435]\n",
      "[Epoch 29/50] [Batch 17/235] [D loss: 1.101618, acc: 85.74%] [G loss: 1.116854]\n",
      "[Epoch 29/50] [Batch 18/235] [D loss: 1.076150, acc: 86.52%] [G loss: 1.112846]\n",
      "[Epoch 29/50] [Batch 19/235] [D loss: 1.109175, acc: 85.94%] [G loss: 1.205037]\n",
      "[Epoch 29/50] [Batch 20/235] [D loss: 1.088259, acc: 86.91%] [G loss: 1.274234]\n",
      "[Epoch 29/50] [Batch 21/235] [D loss: 1.143650, acc: 86.13%] [G loss: 1.190956]\n",
      "[Epoch 29/50] [Batch 22/235] [D loss: 1.089229, acc: 87.50%] [G loss: 1.152177]\n",
      "[Epoch 29/50] [Batch 23/235] [D loss: 1.091466, acc: 87.30%] [G loss: 1.247813]\n",
      "[Epoch 29/50] [Batch 24/235] [D loss: 1.125335, acc: 86.72%] [G loss: 1.247745]\n",
      "[Epoch 29/50] [Batch 25/235] [D loss: 1.108503, acc: 87.70%] [G loss: 1.175670]\n",
      "[Epoch 29/50] [Batch 26/235] [D loss: 1.089338, acc: 90.04%] [G loss: 1.167555]\n",
      "[Epoch 29/50] [Batch 27/235] [D loss: 1.139317, acc: 87.89%] [G loss: 1.161155]\n",
      "[Epoch 29/50] [Batch 28/235] [D loss: 1.115750, acc: 87.89%] [G loss: 1.117580]\n",
      "[Epoch 29/50] [Batch 29/235] [D loss: 1.162665, acc: 85.55%] [G loss: 1.157264]\n",
      "[Epoch 29/50] [Batch 30/235] [D loss: 1.100742, acc: 86.91%] [G loss: 1.281641]\n",
      "[Epoch 29/50] [Batch 31/235] [D loss: 1.114495, acc: 84.96%] [G loss: 1.213408]\n",
      "[Epoch 29/50] [Batch 32/235] [D loss: 1.177619, acc: 86.33%] [G loss: 1.105684]\n",
      "[Epoch 29/50] [Batch 33/235] [D loss: 1.058475, acc: 88.87%] [G loss: 1.121996]\n",
      "[Epoch 29/50] [Batch 34/235] [D loss: 1.122243, acc: 85.55%] [G loss: 1.076924]\n",
      "[Epoch 29/50] [Batch 35/235] [D loss: 1.124291, acc: 85.74%] [G loss: 1.197514]\n",
      "[Epoch 29/50] [Batch 36/235] [D loss: 1.184476, acc: 85.94%] [G loss: 1.320258]\n",
      "[Epoch 29/50] [Batch 37/235] [D loss: 1.108244, acc: 88.09%] [G loss: 1.047890]\n",
      "[Epoch 29/50] [Batch 38/235] [D loss: 1.141057, acc: 87.70%] [G loss: 1.060104]\n",
      "[Epoch 29/50] [Batch 39/235] [D loss: 1.145890, acc: 86.13%] [G loss: 1.186511]\n",
      "[Epoch 29/50] [Batch 40/235] [D loss: 1.097399, acc: 89.45%] [G loss: 1.085625]\n",
      "[Epoch 29/50] [Batch 41/235] [D loss: 1.140811, acc: 87.11%] [G loss: 1.189269]\n",
      "[Epoch 29/50] [Batch 42/235] [D loss: 1.137904, acc: 87.70%] [G loss: 1.049023]\n",
      "[Epoch 29/50] [Batch 43/235] [D loss: 1.108216, acc: 86.91%] [G loss: 1.106736]\n",
      "[Epoch 29/50] [Batch 44/235] [D loss: 1.062899, acc: 86.52%] [G loss: 1.112325]\n",
      "[Epoch 29/50] [Batch 45/235] [D loss: 1.097387, acc: 86.52%] [G loss: 1.195184]\n",
      "[Epoch 29/50] [Batch 46/235] [D loss: 1.122249, acc: 85.16%] [G loss: 1.225743]\n",
      "[Epoch 29/50] [Batch 47/235] [D loss: 1.159191, acc: 83.98%] [G loss: 1.250395]\n",
      "[Epoch 29/50] [Batch 48/235] [D loss: 1.078366, acc: 89.45%] [G loss: 1.122535]\n",
      "[Epoch 29/50] [Batch 49/235] [D loss: 1.099294, acc: 86.13%] [G loss: 1.160122]\n",
      "[Epoch 29/50] [Batch 50/235] [D loss: 1.080244, acc: 87.89%] [G loss: 1.204274]\n",
      "[Epoch 29/50] [Batch 51/235] [D loss: 1.097270, acc: 86.13%] [G loss: 1.225340]\n",
      "[Epoch 29/50] [Batch 52/235] [D loss: 1.173677, acc: 85.16%] [G loss: 1.055406]\n",
      "[Epoch 29/50] [Batch 53/235] [D loss: 1.181353, acc: 87.50%] [G loss: 1.135269]\n",
      "[Epoch 29/50] [Batch 54/235] [D loss: 1.111519, acc: 83.40%] [G loss: 1.218424]\n",
      "[Epoch 29/50] [Batch 55/235] [D loss: 1.214001, acc: 85.35%] [G loss: 1.194205]\n",
      "[Epoch 29/50] [Batch 56/235] [D loss: 1.100249, acc: 88.87%] [G loss: 1.146969]\n",
      "[Epoch 29/50] [Batch 57/235] [D loss: 1.124368, acc: 85.16%] [G loss: 1.026036]\n",
      "[Epoch 29/50] [Batch 58/235] [D loss: 1.106210, acc: 89.26%] [G loss: 1.091321]\n",
      "[Epoch 29/50] [Batch 59/235] [D loss: 1.086820, acc: 87.11%] [G loss: 1.230238]\n",
      "[Epoch 29/50] [Batch 60/235] [D loss: 1.096050, acc: 87.89%] [G loss: 1.170153]\n",
      "[Epoch 29/50] [Batch 61/235] [D loss: 1.102239, acc: 86.52%] [G loss: 1.090250]\n",
      "[Epoch 29/50] [Batch 62/235] [D loss: 1.121194, acc: 87.30%] [G loss: 1.144345]\n",
      "[Epoch 29/50] [Batch 63/235] [D loss: 1.049036, acc: 89.26%] [G loss: 1.150502]\n",
      "[Epoch 29/50] [Batch 64/235] [D loss: 1.100855, acc: 86.91%] [G loss: 1.045956]\n",
      "[Epoch 29/50] [Batch 65/235] [D loss: 1.080773, acc: 85.94%] [G loss: 1.042596]\n",
      "[Epoch 29/50] [Batch 66/235] [D loss: 1.168555, acc: 85.16%] [G loss: 1.214502]\n",
      "[Epoch 29/50] [Batch 67/235] [D loss: 1.174935, acc: 87.30%] [G loss: 1.241762]\n",
      "[Epoch 29/50] [Batch 68/235] [D loss: 1.098567, acc: 88.28%] [G loss: 1.185377]\n",
      "[Epoch 29/50] [Batch 69/235] [D loss: 1.110256, acc: 84.96%] [G loss: 1.028345]\n",
      "[Epoch 29/50] [Batch 70/235] [D loss: 1.113544, acc: 85.74%] [G loss: 1.146434]\n",
      "[Epoch 29/50] [Batch 71/235] [D loss: 1.052403, acc: 87.11%] [G loss: 1.195292]\n",
      "[Epoch 29/50] [Batch 72/235] [D loss: 1.157505, acc: 85.74%] [G loss: 1.310230]\n",
      "[Epoch 29/50] [Batch 73/235] [D loss: 1.086085, acc: 85.74%] [G loss: 1.062642]\n",
      "[Epoch 29/50] [Batch 74/235] [D loss: 1.122812, acc: 88.09%] [G loss: 1.115190]\n",
      "[Epoch 29/50] [Batch 75/235] [D loss: 1.148965, acc: 88.09%] [G loss: 1.238281]\n",
      "[Epoch 29/50] [Batch 76/235] [D loss: 1.052254, acc: 87.89%] [G loss: 1.155683]\n",
      "[Epoch 29/50] [Batch 77/235] [D loss: 1.178954, acc: 86.91%] [G loss: 1.187272]\n",
      "[Epoch 29/50] [Batch 78/235] [D loss: 1.101015, acc: 85.35%] [G loss: 1.127574]\n",
      "[Epoch 29/50] [Batch 79/235] [D loss: 1.136045, acc: 86.91%] [G loss: 1.161825]\n",
      "[Epoch 29/50] [Batch 80/235] [D loss: 1.125276, acc: 85.94%] [G loss: 1.216940]\n",
      "[Epoch 29/50] [Batch 81/235] [D loss: 1.172957, acc: 86.33%] [G loss: 1.075653]\n",
      "[Epoch 29/50] [Batch 82/235] [D loss: 1.086999, acc: 90.62%] [G loss: 1.207230]\n",
      "[Epoch 29/50] [Batch 83/235] [D loss: 1.126907, acc: 86.72%] [G loss: 1.050907]\n",
      "[Epoch 29/50] [Batch 84/235] [D loss: 1.172197, acc: 88.09%] [G loss: 1.055427]\n",
      "[Epoch 29/50] [Batch 85/235] [D loss: 1.093616, acc: 86.72%] [G loss: 1.200528]\n",
      "[Epoch 29/50] [Batch 86/235] [D loss: 1.118856, acc: 89.06%] [G loss: 1.184263]\n",
      "[Epoch 29/50] [Batch 87/235] [D loss: 1.083316, acc: 85.94%] [G loss: 1.119364]\n",
      "[Epoch 29/50] [Batch 88/235] [D loss: 1.138224, acc: 87.30%] [G loss: 1.217960]\n",
      "[Epoch 29/50] [Batch 89/235] [D loss: 1.093805, acc: 89.26%] [G loss: 1.232852]\n",
      "[Epoch 29/50] [Batch 90/235] [D loss: 1.162007, acc: 85.94%] [G loss: 1.069811]\n",
      "[Epoch 29/50] [Batch 91/235] [D loss: 1.097642, acc: 86.52%] [G loss: 1.083063]\n",
      "[Epoch 29/50] [Batch 92/235] [D loss: 1.104430, acc: 86.13%] [G loss: 1.112792]\n",
      "[Epoch 29/50] [Batch 93/235] [D loss: 1.138336, acc: 84.18%] [G loss: 1.354780]\n",
      "[Epoch 29/50] [Batch 94/235] [D loss: 1.096413, acc: 85.16%] [G loss: 1.241342]\n",
      "[Epoch 29/50] [Batch 95/235] [D loss: 1.061782, acc: 88.48%] [G loss: 1.124636]\n",
      "[Epoch 29/50] [Batch 96/235] [D loss: 1.039439, acc: 87.11%] [G loss: 1.139794]\n",
      "[Epoch 29/50] [Batch 97/235] [D loss: 1.120070, acc: 87.70%] [G loss: 1.256381]\n",
      "[Epoch 29/50] [Batch 98/235] [D loss: 1.152779, acc: 88.09%] [G loss: 1.179523]\n",
      "[Epoch 29/50] [Batch 99/235] [D loss: 1.079456, acc: 86.13%] [G loss: 1.093428]\n",
      "[Epoch 29/50] [Batch 100/235] [D loss: 1.025369, acc: 86.72%] [G loss: 1.113479]\n",
      "[Epoch 29/50] [Batch 101/235] [D loss: 1.104487, acc: 86.91%] [G loss: 1.173431]\n",
      "[Epoch 29/50] [Batch 102/235] [D loss: 1.115496, acc: 88.09%] [G loss: 1.201607]\n",
      "[Epoch 29/50] [Batch 103/235] [D loss: 1.130371, acc: 86.72%] [G loss: 1.000294]\n",
      "[Epoch 29/50] [Batch 104/235] [D loss: 1.199964, acc: 89.45%] [G loss: 1.134595]\n",
      "[Epoch 29/50] [Batch 105/235] [D loss: 1.121069, acc: 87.89%] [G loss: 1.239535]\n",
      "[Epoch 29/50] [Batch 106/235] [D loss: 1.175118, acc: 84.77%] [G loss: 1.205793]\n",
      "[Epoch 29/50] [Batch 107/235] [D loss: 1.121874, acc: 87.70%] [G loss: 1.053398]\n",
      "[Epoch 29/50] [Batch 108/235] [D loss: 1.124644, acc: 86.33%] [G loss: 1.075776]\n",
      "[Epoch 29/50] [Batch 109/235] [D loss: 1.160851, acc: 86.13%] [G loss: 1.293441]\n",
      "[Epoch 29/50] [Batch 110/235] [D loss: 1.057732, acc: 89.06%] [G loss: 1.130370]\n",
      "[Epoch 29/50] [Batch 111/235] [D loss: 1.157264, acc: 86.33%] [G loss: 1.135228]\n",
      "[Epoch 29/50] [Batch 112/235] [D loss: 1.103924, acc: 88.09%] [G loss: 1.065834]\n",
      "[Epoch 29/50] [Batch 113/235] [D loss: 1.085247, acc: 89.06%] [G loss: 1.339530]\n",
      "[Epoch 29/50] [Batch 114/235] [D loss: 1.085268, acc: 85.35%] [G loss: 1.098656]\n",
      "[Epoch 29/50] [Batch 115/235] [D loss: 1.133276, acc: 87.50%] [G loss: 1.109011]\n",
      "[Epoch 29/50] [Batch 116/235] [D loss: 1.092400, acc: 87.70%] [G loss: 1.207464]\n",
      "[Epoch 29/50] [Batch 117/235] [D loss: 1.113564, acc: 86.33%] [G loss: 1.134349]\n",
      "[Epoch 29/50] [Batch 118/235] [D loss: 1.143771, acc: 86.13%] [G loss: 1.153718]\n",
      "[Epoch 29/50] [Batch 119/235] [D loss: 1.118432, acc: 86.52%] [G loss: 1.253011]\n",
      "[Epoch 29/50] [Batch 120/235] [D loss: 1.121785, acc: 86.33%] [G loss: 1.174198]\n",
      "[Epoch 29/50] [Batch 121/235] [D loss: 1.052826, acc: 86.13%] [G loss: 1.092810]\n",
      "[Epoch 29/50] [Batch 122/235] [D loss: 1.132882, acc: 87.11%] [G loss: 1.044630]\n",
      "[Epoch 29/50] [Batch 123/235] [D loss: 1.100620, acc: 87.70%] [G loss: 1.082592]\n",
      "[Epoch 29/50] [Batch 124/235] [D loss: 1.127703, acc: 85.55%] [G loss: 1.160346]\n",
      "[Epoch 29/50] [Batch 125/235] [D loss: 1.182493, acc: 88.28%] [G loss: 1.253776]\n",
      "[Epoch 29/50] [Batch 126/235] [D loss: 1.082986, acc: 89.45%] [G loss: 1.136248]\n",
      "[Epoch 29/50] [Batch 127/235] [D loss: 1.075164, acc: 85.94%] [G loss: 1.091853]\n",
      "[Epoch 29/50] [Batch 128/235] [D loss: 1.109842, acc: 88.28%] [G loss: 1.115076]\n",
      "[Epoch 29/50] [Batch 129/235] [D loss: 1.132308, acc: 88.09%] [G loss: 1.233604]\n",
      "[Epoch 29/50] [Batch 130/235] [D loss: 1.084553, acc: 85.35%] [G loss: 1.126917]\n",
      "[Epoch 29/50] [Batch 131/235] [D loss: 1.123422, acc: 86.91%] [G loss: 1.294152]\n",
      "[Epoch 29/50] [Batch 132/235] [D loss: 1.094382, acc: 90.43%] [G loss: 1.224672]\n",
      "[Epoch 29/50] [Batch 133/235] [D loss: 1.141520, acc: 86.91%] [G loss: 1.148903]\n",
      "[Epoch 29/50] [Batch 134/235] [D loss: 1.110173, acc: 85.94%] [G loss: 1.264249]\n",
      "[Epoch 29/50] [Batch 135/235] [D loss: 1.143585, acc: 87.70%] [G loss: 1.286824]\n",
      "[Epoch 29/50] [Batch 136/235] [D loss: 1.164027, acc: 85.55%] [G loss: 1.038689]\n",
      "[Epoch 29/50] [Batch 137/235] [D loss: 1.146719, acc: 86.33%] [G loss: 1.244941]\n",
      "[Epoch 29/50] [Batch 138/235] [D loss: 1.132812, acc: 87.11%] [G loss: 1.124130]\n",
      "[Epoch 29/50] [Batch 139/235] [D loss: 1.153097, acc: 86.52%] [G loss: 1.126334]\n",
      "[Epoch 29/50] [Batch 140/235] [D loss: 1.117540, acc: 84.77%] [G loss: 1.158014]\n",
      "[Epoch 29/50] [Batch 141/235] [D loss: 1.080853, acc: 87.11%] [G loss: 1.097353]\n",
      "[Epoch 29/50] [Batch 142/235] [D loss: 1.070874, acc: 87.89%] [G loss: 1.104818]\n",
      "[Epoch 29/50] [Batch 143/235] [D loss: 1.109523, acc: 86.52%] [G loss: 1.063486]\n",
      "[Epoch 29/50] [Batch 144/235] [D loss: 1.117840, acc: 88.09%] [G loss: 1.207364]\n",
      "[Epoch 29/50] [Batch 145/235] [D loss: 1.130255, acc: 86.91%] [G loss: 1.100866]\n",
      "[Epoch 29/50] [Batch 146/235] [D loss: 1.117582, acc: 86.72%] [G loss: 1.228146]\n",
      "[Epoch 29/50] [Batch 147/235] [D loss: 1.119329, acc: 87.11%] [G loss: 1.163350]\n",
      "[Epoch 29/50] [Batch 148/235] [D loss: 1.076596, acc: 87.89%] [G loss: 1.082829]\n",
      "[Epoch 29/50] [Batch 149/235] [D loss: 1.073976, acc: 85.94%] [G loss: 1.085008]\n",
      "[Epoch 29/50] [Batch 150/235] [D loss: 1.145910, acc: 86.13%] [G loss: 1.044390]\n",
      "[Epoch 29/50] [Batch 151/235] [D loss: 1.189534, acc: 87.30%] [G loss: 1.267105]\n",
      "[Epoch 29/50] [Batch 152/235] [D loss: 1.132772, acc: 85.94%] [G loss: 1.456406]\n",
      "[Epoch 29/50] [Batch 153/235] [D loss: 1.121171, acc: 85.55%] [G loss: 1.236899]\n",
      "[Epoch 29/50] [Batch 154/235] [D loss: 1.096828, acc: 87.30%] [G loss: 1.092874]\n",
      "[Epoch 29/50] [Batch 155/235] [D loss: 1.130014, acc: 85.94%] [G loss: 1.103090]\n",
      "[Epoch 29/50] [Batch 156/235] [D loss: 1.145221, acc: 89.06%] [G loss: 1.151907]\n",
      "[Epoch 29/50] [Batch 157/235] [D loss: 1.149308, acc: 88.09%] [G loss: 1.104766]\n",
      "[Epoch 29/50] [Batch 158/235] [D loss: 1.196402, acc: 84.38%] [G loss: 1.235490]\n",
      "[Epoch 29/50] [Batch 159/235] [D loss: 1.097067, acc: 87.50%] [G loss: 1.040361]\n",
      "[Epoch 29/50] [Batch 160/235] [D loss: 1.131616, acc: 89.26%] [G loss: 1.105261]\n",
      "[Epoch 29/50] [Batch 161/235] [D loss: 1.164310, acc: 88.48%] [G loss: 1.243486]\n",
      "[Epoch 29/50] [Batch 162/235] [D loss: 1.121855, acc: 89.06%] [G loss: 1.209010]\n",
      "[Epoch 29/50] [Batch 163/235] [D loss: 1.125783, acc: 85.55%] [G loss: 1.098167]\n",
      "[Epoch 29/50] [Batch 164/235] [D loss: 1.187418, acc: 85.74%] [G loss: 0.981906]\n",
      "[Epoch 29/50] [Batch 165/235] [D loss: 1.059582, acc: 84.96%] [G loss: 1.240748]\n",
      "[Epoch 29/50] [Batch 166/235] [D loss: 1.208333, acc: 82.62%] [G loss: 1.071541]\n",
      "[Epoch 29/50] [Batch 167/235] [D loss: 1.147901, acc: 85.16%] [G loss: 1.075415]\n",
      "[Epoch 29/50] [Batch 168/235] [D loss: 1.118470, acc: 88.48%] [G loss: 1.154584]\n",
      "[Epoch 29/50] [Batch 169/235] [D loss: 1.089661, acc: 86.72%] [G loss: 1.207158]\n",
      "[Epoch 29/50] [Batch 170/235] [D loss: 1.155881, acc: 88.87%] [G loss: 1.088504]\n",
      "[Epoch 29/50] [Batch 171/235] [D loss: 1.128985, acc: 85.55%] [G loss: 1.042130]\n",
      "[Epoch 29/50] [Batch 172/235] [D loss: 1.152394, acc: 88.87%] [G loss: 1.241022]\n",
      "[Epoch 29/50] [Batch 173/235] [D loss: 1.116389, acc: 85.55%] [G loss: 1.174876]\n",
      "[Epoch 29/50] [Batch 174/235] [D loss: 1.063272, acc: 87.89%] [G loss: 1.072060]\n",
      "[Epoch 29/50] [Batch 175/235] [D loss: 1.093197, acc: 84.96%] [G loss: 1.132364]\n",
      "[Epoch 29/50] [Batch 176/235] [D loss: 1.064851, acc: 87.50%] [G loss: 1.153814]\n",
      "[Epoch 29/50] [Batch 177/235] [D loss: 1.126885, acc: 86.52%] [G loss: 1.262126]\n",
      "[Epoch 29/50] [Batch 178/235] [D loss: 1.138242, acc: 86.91%] [G loss: 1.206542]\n",
      "[Epoch 29/50] [Batch 179/235] [D loss: 1.118027, acc: 90.23%] [G loss: 1.084108]\n",
      "[Epoch 29/50] [Batch 180/235] [D loss: 1.130079, acc: 86.91%] [G loss: 1.155344]\n",
      "[Epoch 29/50] [Batch 181/235] [D loss: 1.121624, acc: 86.33%] [G loss: 1.172053]\n",
      "[Epoch 29/50] [Batch 182/235] [D loss: 1.122365, acc: 85.16%] [G loss: 1.215422]\n",
      "[Epoch 29/50] [Batch 183/235] [D loss: 1.199857, acc: 86.33%] [G loss: 1.157141]\n",
      "[Epoch 29/50] [Batch 184/235] [D loss: 1.118782, acc: 84.77%] [G loss: 1.234920]\n",
      "[Epoch 29/50] [Batch 185/235] [D loss: 1.139028, acc: 85.16%] [G loss: 1.273423]\n",
      "[Epoch 29/50] [Batch 186/235] [D loss: 1.096308, acc: 87.30%] [G loss: 0.992178]\n",
      "[Epoch 29/50] [Batch 187/235] [D loss: 1.147084, acc: 87.30%] [G loss: 1.118448]\n",
      "[Epoch 29/50] [Batch 188/235] [D loss: 1.042056, acc: 86.72%] [G loss: 1.276800]\n",
      "[Epoch 29/50] [Batch 189/235] [D loss: 1.108877, acc: 86.91%] [G loss: 1.167625]\n",
      "[Epoch 29/50] [Batch 190/235] [D loss: 1.066847, acc: 90.04%] [G loss: 1.134848]\n",
      "[Epoch 29/50] [Batch 191/235] [D loss: 1.183323, acc: 86.33%] [G loss: 1.181984]\n",
      "[Epoch 29/50] [Batch 192/235] [D loss: 1.133384, acc: 85.74%] [G loss: 1.149386]\n",
      "[Epoch 29/50] [Batch 193/235] [D loss: 1.130654, acc: 85.16%] [G loss: 1.065574]\n",
      "[Epoch 29/50] [Batch 194/235] [D loss: 1.037331, acc: 88.28%] [G loss: 1.013941]\n",
      "[Epoch 29/50] [Batch 195/235] [D loss: 1.123264, acc: 87.30%] [G loss: 1.261574]\n",
      "[Epoch 29/50] [Batch 196/235] [D loss: 1.113483, acc: 84.96%] [G loss: 1.164982]\n",
      "[Epoch 29/50] [Batch 197/235] [D loss: 1.076731, acc: 87.50%] [G loss: 1.263565]\n",
      "[Epoch 29/50] [Batch 198/235] [D loss: 1.081358, acc: 89.06%] [G loss: 1.185385]\n",
      "[Epoch 29/50] [Batch 199/235] [D loss: 1.090800, acc: 85.94%] [G loss: 1.181689]\n",
      "[Epoch 29/50] [Batch 200/235] [D loss: 1.119354, acc: 86.91%] [G loss: 1.070495]\n",
      "[Epoch 29/50] [Batch 201/235] [D loss: 1.125516, acc: 83.59%] [G loss: 1.152497]\n",
      "[Epoch 29/50] [Batch 202/235] [D loss: 1.103780, acc: 84.96%] [G loss: 1.149922]\n",
      "[Epoch 29/50] [Batch 203/235] [D loss: 1.128791, acc: 88.87%] [G loss: 1.128392]\n",
      "[Epoch 29/50] [Batch 204/235] [D loss: 1.146811, acc: 83.59%] [G loss: 1.084589]\n",
      "[Epoch 29/50] [Batch 205/235] [D loss: 1.100171, acc: 84.96%] [G loss: 1.184146]\n",
      "[Epoch 29/50] [Batch 206/235] [D loss: 1.165592, acc: 88.28%] [G loss: 1.124928]\n",
      "[Epoch 29/50] [Batch 207/235] [D loss: 1.066848, acc: 86.91%] [G loss: 1.219109]\n",
      "[Epoch 29/50] [Batch 208/235] [D loss: 1.139024, acc: 86.91%] [G loss: 1.174667]\n",
      "[Epoch 29/50] [Batch 209/235] [D loss: 1.117584, acc: 87.50%] [G loss: 1.168828]\n",
      "[Epoch 29/50] [Batch 210/235] [D loss: 1.129425, acc: 88.09%] [G loss: 1.094727]\n",
      "[Epoch 29/50] [Batch 211/235] [D loss: 1.146913, acc: 87.70%] [G loss: 1.264088]\n",
      "[Epoch 29/50] [Batch 212/235] [D loss: 1.109526, acc: 86.33%] [G loss: 1.294306]\n",
      "[Epoch 29/50] [Batch 213/235] [D loss: 1.093398, acc: 88.67%] [G loss: 1.103718]\n",
      "[Epoch 29/50] [Batch 214/235] [D loss: 1.142893, acc: 87.11%] [G loss: 1.158219]\n",
      "[Epoch 29/50] [Batch 215/235] [D loss: 1.121206, acc: 86.91%] [G loss: 1.125189]\n",
      "[Epoch 29/50] [Batch 216/235] [D loss: 1.091393, acc: 89.26%] [G loss: 1.106806]\n",
      "[Epoch 29/50] [Batch 217/235] [D loss: 1.126430, acc: 86.33%] [G loss: 1.141317]\n",
      "[Epoch 29/50] [Batch 218/235] [D loss: 1.103514, acc: 88.67%] [G loss: 1.189065]\n",
      "[Epoch 29/50] [Batch 219/235] [D loss: 1.081735, acc: 84.96%] [G loss: 1.290119]\n",
      "[Epoch 29/50] [Batch 220/235] [D loss: 1.142011, acc: 87.30%] [G loss: 1.018312]\n",
      "[Epoch 29/50] [Batch 221/235] [D loss: 1.095205, acc: 87.70%] [G loss: 1.202471]\n",
      "[Epoch 29/50] [Batch 222/235] [D loss: 1.131679, acc: 88.09%] [G loss: 1.249240]\n",
      "[Epoch 29/50] [Batch 223/235] [D loss: 1.104770, acc: 86.13%] [G loss: 1.224676]\n",
      "[Epoch 29/50] [Batch 224/235] [D loss: 1.150409, acc: 87.50%] [G loss: 1.139345]\n",
      "[Epoch 29/50] [Batch 225/235] [D loss: 1.134128, acc: 85.94%] [G loss: 1.221132]\n",
      "[Epoch 29/50] [Batch 226/235] [D loss: 1.067052, acc: 86.72%] [G loss: 1.249515]\n",
      "[Epoch 29/50] [Batch 227/235] [D loss: 1.096565, acc: 85.16%] [G loss: 1.097856]\n",
      "[Epoch 29/50] [Batch 228/235] [D loss: 1.073880, acc: 86.13%] [G loss: 1.187707]\n",
      "[Epoch 29/50] [Batch 229/235] [D loss: 1.102163, acc: 87.70%] [G loss: 1.184630]\n",
      "[Epoch 29/50] [Batch 230/235] [D loss: 1.098456, acc: 89.06%] [G loss: 1.163659]\n",
      "[Epoch 29/50] [Batch 231/235] [D loss: 1.149504, acc: 85.94%] [G loss: 1.226422]\n",
      "[Epoch 29/50] [Batch 232/235] [D loss: 1.095414, acc: 87.50%] [G loss: 1.109280]\n",
      "[Epoch 29/50] [Batch 233/235] [D loss: 1.038297, acc: 88.09%] [G loss: 1.257204]\n",
      "[Epoch 29/50] [Batch 234/235] [D loss: 1.151665, acc: 88.02%] [G loss: 1.093790]\n",
      "[Epoch 30/50] [Batch 0/235] [D loss: 1.199728, acc: 89.06%] [G loss: 1.203117]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/50] [Batch 1/235] [D loss: 1.078805, acc: 86.72%] [G loss: 1.146499]\n",
      "[Epoch 30/50] [Batch 2/235] [D loss: 1.114657, acc: 85.16%] [G loss: 1.150714]\n",
      "[Epoch 30/50] [Batch 3/235] [D loss: 1.103404, acc: 86.91%] [G loss: 1.231855]\n",
      "[Epoch 30/50] [Batch 4/235] [D loss: 1.140521, acc: 86.52%] [G loss: 1.133222]\n",
      "[Epoch 30/50] [Batch 5/235] [D loss: 1.074423, acc: 89.26%] [G loss: 1.152261]\n",
      "[Epoch 30/50] [Batch 6/235] [D loss: 1.136796, acc: 89.45%] [G loss: 1.090857]\n",
      "[Epoch 30/50] [Batch 7/235] [D loss: 1.073630, acc: 85.55%] [G loss: 1.193455]\n",
      "[Epoch 30/50] [Batch 8/235] [D loss: 1.096290, acc: 89.26%] [G loss: 1.198653]\n",
      "[Epoch 30/50] [Batch 9/235] [D loss: 1.154921, acc: 84.96%] [G loss: 1.181197]\n",
      "[Epoch 30/50] [Batch 10/235] [D loss: 1.103083, acc: 85.94%] [G loss: 1.335144]\n",
      "[Epoch 30/50] [Batch 11/235] [D loss: 1.097310, acc: 86.13%] [G loss: 1.087907]\n",
      "[Epoch 30/50] [Batch 12/235] [D loss: 1.118784, acc: 88.67%] [G loss: 1.043435]\n",
      "[Epoch 30/50] [Batch 13/235] [D loss: 1.124824, acc: 87.89%] [G loss: 1.140744]\n",
      "[Epoch 30/50] [Batch 14/235] [D loss: 1.104591, acc: 89.45%] [G loss: 1.234748]\n",
      "[Epoch 30/50] [Batch 15/235] [D loss: 1.028130, acc: 86.91%] [G loss: 1.264458]\n",
      "[Epoch 30/50] [Batch 16/235] [D loss: 1.115357, acc: 87.70%] [G loss: 1.306881]\n",
      "[Epoch 30/50] [Batch 17/235] [D loss: 1.118572, acc: 87.50%] [G loss: 1.094510]\n",
      "[Epoch 30/50] [Batch 18/235] [D loss: 1.144079, acc: 85.55%] [G loss: 1.274664]\n",
      "[Epoch 30/50] [Batch 19/235] [D loss: 1.093031, acc: 88.09%] [G loss: 1.064458]\n",
      "[Epoch 30/50] [Batch 20/235] [D loss: 1.111775, acc: 85.74%] [G loss: 1.012671]\n",
      "[Epoch 30/50] [Batch 21/235] [D loss: 1.145027, acc: 87.50%] [G loss: 1.214610]\n",
      "[Epoch 30/50] [Batch 22/235] [D loss: 1.097717, acc: 87.11%] [G loss: 1.346086]\n",
      "[Epoch 30/50] [Batch 23/235] [D loss: 1.134936, acc: 86.33%] [G loss: 1.169925]\n",
      "[Epoch 30/50] [Batch 24/235] [D loss: 1.085340, acc: 87.70%] [G loss: 1.030926]\n",
      "[Epoch 30/50] [Batch 25/235] [D loss: 1.089489, acc: 86.52%] [G loss: 1.177653]\n",
      "[Epoch 30/50] [Batch 26/235] [D loss: 1.101850, acc: 86.72%] [G loss: 1.135408]\n",
      "[Epoch 30/50] [Batch 27/235] [D loss: 1.186904, acc: 87.11%] [G loss: 1.199644]\n",
      "[Epoch 30/50] [Batch 28/235] [D loss: 1.072845, acc: 85.55%] [G loss: 1.078216]\n",
      "[Epoch 30/50] [Batch 29/235] [D loss: 1.080799, acc: 87.50%] [G loss: 1.135120]\n",
      "[Epoch 30/50] [Batch 30/235] [D loss: 1.116307, acc: 87.70%] [G loss: 1.195357]\n",
      "[Epoch 30/50] [Batch 31/235] [D loss: 1.140886, acc: 85.74%] [G loss: 1.189695]\n",
      "[Epoch 30/50] [Batch 32/235] [D loss: 1.124443, acc: 87.30%] [G loss: 1.093544]\n",
      "[Epoch 30/50] [Batch 33/235] [D loss: 1.092439, acc: 89.06%] [G loss: 1.051198]\n",
      "[Epoch 30/50] [Batch 34/235] [D loss: 1.075440, acc: 85.55%] [G loss: 1.118406]\n",
      "[Epoch 30/50] [Batch 35/235] [D loss: 1.181795, acc: 84.57%] [G loss: 1.252500]\n",
      "[Epoch 30/50] [Batch 36/235] [D loss: 1.134134, acc: 89.06%] [G loss: 1.274990]\n",
      "[Epoch 30/50] [Batch 37/235] [D loss: 1.083631, acc: 86.91%] [G loss: 1.094916]\n",
      "[Epoch 30/50] [Batch 38/235] [D loss: 1.054122, acc: 87.30%] [G loss: 1.170622]\n",
      "[Epoch 30/50] [Batch 39/235] [D loss: 1.110047, acc: 86.33%] [G loss: 1.170783]\n",
      "[Epoch 30/50] [Batch 40/235] [D loss: 1.085669, acc: 89.06%] [G loss: 1.066903]\n",
      "[Epoch 30/50] [Batch 41/235] [D loss: 1.025851, acc: 86.72%] [G loss: 1.086974]\n",
      "[Epoch 30/50] [Batch 42/235] [D loss: 1.128930, acc: 85.16%] [G loss: 1.058919]\n",
      "[Epoch 30/50] [Batch 43/235] [D loss: 1.117443, acc: 86.52%] [G loss: 1.109249]\n",
      "[Epoch 30/50] [Batch 44/235] [D loss: 1.123928, acc: 87.50%] [G loss: 1.222714]\n",
      "[Epoch 30/50] [Batch 45/235] [D loss: 1.119566, acc: 86.13%] [G loss: 1.147988]\n",
      "[Epoch 30/50] [Batch 46/235] [D loss: 1.088231, acc: 87.30%] [G loss: 1.067308]\n",
      "[Epoch 30/50] [Batch 47/235] [D loss: 1.113822, acc: 88.67%] [G loss: 1.157528]\n",
      "[Epoch 30/50] [Batch 48/235] [D loss: 1.131922, acc: 87.30%] [G loss: 1.163908]\n",
      "[Epoch 30/50] [Batch 49/235] [D loss: 1.098970, acc: 87.89%] [G loss: 1.194738]\n",
      "[Epoch 30/50] [Batch 50/235] [D loss: 1.111635, acc: 87.11%] [G loss: 1.145960]\n",
      "[Epoch 30/50] [Batch 51/235] [D loss: 1.143597, acc: 83.40%] [G loss: 1.180415]\n",
      "[Epoch 30/50] [Batch 52/235] [D loss: 1.137931, acc: 86.52%] [G loss: 1.103574]\n",
      "[Epoch 30/50] [Batch 53/235] [D loss: 1.071389, acc: 87.89%] [G loss: 1.214509]\n",
      "[Epoch 30/50] [Batch 54/235] [D loss: 1.094737, acc: 87.89%] [G loss: 1.222910]\n",
      "[Epoch 30/50] [Batch 55/235] [D loss: 1.128172, acc: 87.50%] [G loss: 1.013774]\n",
      "[Epoch 30/50] [Batch 56/235] [D loss: 1.177210, acc: 86.13%] [G loss: 1.041699]\n",
      "[Epoch 30/50] [Batch 57/235] [D loss: 1.121483, acc: 87.50%] [G loss: 1.126730]\n",
      "[Epoch 30/50] [Batch 58/235] [D loss: 1.108894, acc: 86.91%] [G loss: 1.350559]\n",
      "[Epoch 30/50] [Batch 59/235] [D loss: 1.114904, acc: 87.30%] [G loss: 1.198448]\n",
      "[Epoch 30/50] [Batch 60/235] [D loss: 1.149474, acc: 85.16%] [G loss: 1.059574]\n",
      "[Epoch 30/50] [Batch 61/235] [D loss: 1.077262, acc: 86.91%] [G loss: 1.146894]\n",
      "[Epoch 30/50] [Batch 62/235] [D loss: 1.153814, acc: 87.70%] [G loss: 1.111475]\n",
      "[Epoch 30/50] [Batch 63/235] [D loss: 1.103243, acc: 85.35%] [G loss: 1.206362]\n",
      "[Epoch 30/50] [Batch 64/235] [D loss: 1.053827, acc: 88.67%] [G loss: 1.230076]\n",
      "[Epoch 30/50] [Batch 65/235] [D loss: 1.112164, acc: 88.09%] [G loss: 1.163738]\n",
      "[Epoch 30/50] [Batch 66/235] [D loss: 1.176189, acc: 86.91%] [G loss: 1.153027]\n",
      "[Epoch 30/50] [Batch 67/235] [D loss: 1.149825, acc: 88.48%] [G loss: 1.283699]\n",
      "[Epoch 30/50] [Batch 68/235] [D loss: 1.111392, acc: 88.28%] [G loss: 1.210315]\n",
      "[Epoch 30/50] [Batch 69/235] [D loss: 1.071728, acc: 86.52%] [G loss: 1.051421]\n",
      "[Epoch 30/50] [Batch 70/235] [D loss: 1.134522, acc: 87.30%] [G loss: 1.105378]\n",
      "[Epoch 30/50] [Batch 71/235] [D loss: 1.074376, acc: 87.89%] [G loss: 1.223380]\n",
      "[Epoch 30/50] [Batch 72/235] [D loss: 1.133846, acc: 85.55%] [G loss: 1.132003]\n",
      "[Epoch 30/50] [Batch 73/235] [D loss: 1.115758, acc: 85.55%] [G loss: 1.087787]\n",
      "[Epoch 30/50] [Batch 74/235] [D loss: 1.091638, acc: 84.77%] [G loss: 1.233698]\n",
      "[Epoch 30/50] [Batch 75/235] [D loss: 1.141399, acc: 88.48%] [G loss: 1.100006]\n",
      "[Epoch 30/50] [Batch 76/235] [D loss: 1.076606, acc: 86.91%] [G loss: 1.345421]\n",
      "[Epoch 30/50] [Batch 77/235] [D loss: 1.099864, acc: 86.91%] [G loss: 1.165410]\n",
      "[Epoch 30/50] [Batch 78/235] [D loss: 1.163290, acc: 85.94%] [G loss: 1.131053]\n",
      "[Epoch 30/50] [Batch 79/235] [D loss: 1.122934, acc: 84.57%] [G loss: 1.048414]\n",
      "[Epoch 30/50] [Batch 80/235] [D loss: 1.208278, acc: 84.18%] [G loss: 1.136492]\n",
      "[Epoch 30/50] [Batch 81/235] [D loss: 1.140277, acc: 86.91%] [G loss: 1.167889]\n",
      "[Epoch 30/50] [Batch 82/235] [D loss: 1.171583, acc: 87.70%] [G loss: 1.208429]\n",
      "[Epoch 30/50] [Batch 83/235] [D loss: 1.136963, acc: 86.72%] [G loss: 1.131572]\n",
      "[Epoch 30/50] [Batch 84/235] [D loss: 1.164416, acc: 84.77%] [G loss: 1.069745]\n",
      "[Epoch 30/50] [Batch 85/235] [D loss: 1.121329, acc: 86.13%] [G loss: 1.113599]\n",
      "[Epoch 30/50] [Batch 86/235] [D loss: 1.084121, acc: 89.06%] [G loss: 1.180233]\n",
      "[Epoch 30/50] [Batch 87/235] [D loss: 1.142839, acc: 84.96%] [G loss: 1.131796]\n",
      "[Epoch 30/50] [Batch 88/235] [D loss: 1.140293, acc: 83.98%] [G loss: 1.222710]\n",
      "[Epoch 30/50] [Batch 89/235] [D loss: 1.129383, acc: 85.55%] [G loss: 1.106648]\n",
      "[Epoch 30/50] [Batch 90/235] [D loss: 1.152192, acc: 85.35%] [G loss: 1.168458]\n",
      "[Epoch 30/50] [Batch 91/235] [D loss: 1.100111, acc: 87.11%] [G loss: 1.367094]\n",
      "[Epoch 30/50] [Batch 92/235] [D loss: 1.113109, acc: 88.28%] [G loss: 1.119589]\n",
      "[Epoch 30/50] [Batch 93/235] [D loss: 1.086138, acc: 86.33%] [G loss: 1.065712]\n",
      "[Epoch 30/50] [Batch 94/235] [D loss: 1.107031, acc: 86.91%] [G loss: 1.232588]\n",
      "[Epoch 30/50] [Batch 95/235] [D loss: 1.136782, acc: 86.52%] [G loss: 1.138173]\n",
      "[Epoch 30/50] [Batch 96/235] [D loss: 1.058804, acc: 87.89%] [G loss: 1.221264]\n",
      "[Epoch 30/50] [Batch 97/235] [D loss: 1.111439, acc: 86.72%] [G loss: 1.232761]\n",
      "[Epoch 30/50] [Batch 98/235] [D loss: 1.123147, acc: 86.91%] [G loss: 1.121023]\n",
      "[Epoch 30/50] [Batch 99/235] [D loss: 1.101550, acc: 87.89%] [G loss: 1.005832]\n",
      "[Epoch 30/50] [Batch 100/235] [D loss: 1.065862, acc: 87.30%] [G loss: 1.221936]\n",
      "[Epoch 30/50] [Batch 101/235] [D loss: 1.096108, acc: 85.74%] [G loss: 1.236086]\n",
      "[Epoch 30/50] [Batch 102/235] [D loss: 1.219847, acc: 87.11%] [G loss: 1.096637]\n",
      "[Epoch 30/50] [Batch 103/235] [D loss: 1.162698, acc: 87.50%] [G loss: 1.183339]\n",
      "[Epoch 30/50] [Batch 104/235] [D loss: 1.165639, acc: 85.55%] [G loss: 1.157893]\n",
      "[Epoch 30/50] [Batch 105/235] [D loss: 1.152917, acc: 88.48%] [G loss: 1.037811]\n",
      "[Epoch 30/50] [Batch 106/235] [D loss: 1.145002, acc: 88.67%] [G loss: 1.131578]\n",
      "[Epoch 30/50] [Batch 107/235] [D loss: 1.124223, acc: 86.13%] [G loss: 1.038839]\n",
      "[Epoch 30/50] [Batch 108/235] [D loss: 1.060658, acc: 86.91%] [G loss: 1.236620]\n",
      "[Epoch 30/50] [Batch 109/235] [D loss: 1.161222, acc: 89.26%] [G loss: 1.039146]\n",
      "[Epoch 30/50] [Batch 110/235] [D loss: 1.120916, acc: 84.96%] [G loss: 1.317905]\n",
      "[Epoch 30/50] [Batch 111/235] [D loss: 1.117748, acc: 90.43%] [G loss: 1.135886]\n",
      "[Epoch 30/50] [Batch 112/235] [D loss: 1.086194, acc: 86.72%] [G loss: 1.258668]\n",
      "[Epoch 30/50] [Batch 113/235] [D loss: 1.098196, acc: 86.33%] [G loss: 1.037759]\n",
      "[Epoch 30/50] [Batch 114/235] [D loss: 1.111370, acc: 85.55%] [G loss: 1.207894]\n",
      "[Epoch 30/50] [Batch 115/235] [D loss: 1.076458, acc: 86.72%] [G loss: 1.065033]\n",
      "[Epoch 30/50] [Batch 116/235] [D loss: 1.117279, acc: 86.52%] [G loss: 1.072445]\n",
      "[Epoch 30/50] [Batch 117/235] [D loss: 1.124320, acc: 87.50%] [G loss: 1.166693]\n",
      "[Epoch 30/50] [Batch 118/235] [D loss: 1.097993, acc: 86.52%] [G loss: 1.307427]\n",
      "[Epoch 30/50] [Batch 119/235] [D loss: 1.121122, acc: 84.57%] [G loss: 1.204544]\n",
      "[Epoch 30/50] [Batch 120/235] [D loss: 1.081454, acc: 85.55%] [G loss: 1.091585]\n",
      "[Epoch 30/50] [Batch 121/235] [D loss: 1.155083, acc: 84.96%] [G loss: 0.976878]\n",
      "[Epoch 30/50] [Batch 122/235] [D loss: 1.108123, acc: 84.77%] [G loss: 1.319007]\n",
      "[Epoch 30/50] [Batch 123/235] [D loss: 1.124991, acc: 87.11%] [G loss: 1.190006]\n",
      "[Epoch 30/50] [Batch 124/235] [D loss: 1.102377, acc: 87.30%] [G loss: 1.155314]\n",
      "[Epoch 30/50] [Batch 125/235] [D loss: 1.082476, acc: 86.91%] [G loss: 1.229627]\n",
      "[Epoch 30/50] [Batch 126/235] [D loss: 1.087843, acc: 86.52%] [G loss: 1.096642]\n",
      "[Epoch 30/50] [Batch 127/235] [D loss: 1.105970, acc: 88.09%] [G loss: 1.099403]\n",
      "[Epoch 30/50] [Batch 128/235] [D loss: 1.141255, acc: 86.72%] [G loss: 1.035539]\n",
      "[Epoch 30/50] [Batch 129/235] [D loss: 1.155457, acc: 86.13%] [G loss: 1.158286]\n",
      "[Epoch 30/50] [Batch 130/235] [D loss: 1.139960, acc: 86.91%] [G loss: 1.073200]\n",
      "[Epoch 30/50] [Batch 131/235] [D loss: 1.146029, acc: 87.30%] [G loss: 1.132746]\n",
      "[Epoch 30/50] [Batch 132/235] [D loss: 1.117547, acc: 88.67%] [G loss: 1.221723]\n",
      "[Epoch 30/50] [Batch 133/235] [D loss: 1.134436, acc: 86.72%] [G loss: 1.216535]\n",
      "[Epoch 30/50] [Batch 134/235] [D loss: 1.108981, acc: 88.87%] [G loss: 1.221414]\n",
      "[Epoch 30/50] [Batch 135/235] [D loss: 1.125612, acc: 85.74%] [G loss: 1.125060]\n",
      "[Epoch 30/50] [Batch 136/235] [D loss: 1.113389, acc: 86.52%] [G loss: 1.231353]\n",
      "[Epoch 30/50] [Batch 137/235] [D loss: 1.088989, acc: 88.28%] [G loss: 1.196857]\n",
      "[Epoch 30/50] [Batch 138/235] [D loss: 1.095071, acc: 87.30%] [G loss: 1.242156]\n",
      "[Epoch 30/50] [Batch 139/235] [D loss: 1.144476, acc: 88.67%] [G loss: 1.141196]\n",
      "[Epoch 30/50] [Batch 140/235] [D loss: 1.128666, acc: 87.11%] [G loss: 1.261881]\n",
      "[Epoch 30/50] [Batch 141/235] [D loss: 1.177412, acc: 89.84%] [G loss: 1.082377]\n",
      "[Epoch 30/50] [Batch 142/235] [D loss: 1.146223, acc: 87.30%] [G loss: 1.072797]\n",
      "[Epoch 30/50] [Batch 143/235] [D loss: 1.047141, acc: 88.09%] [G loss: 1.167604]\n",
      "[Epoch 30/50] [Batch 144/235] [D loss: 1.145856, acc: 85.74%] [G loss: 1.234107]\n",
      "[Epoch 30/50] [Batch 145/235] [D loss: 1.066690, acc: 88.09%] [G loss: 1.182669]\n",
      "[Epoch 30/50] [Batch 146/235] [D loss: 1.065278, acc: 87.70%] [G loss: 1.107438]\n",
      "[Epoch 30/50] [Batch 147/235] [D loss: 1.257981, acc: 88.28%] [G loss: 1.108746]\n",
      "[Epoch 30/50] [Batch 148/235] [D loss: 1.156515, acc: 85.94%] [G loss: 1.189508]\n",
      "[Epoch 30/50] [Batch 149/235] [D loss: 1.061219, acc: 86.72%] [G loss: 1.176373]\n",
      "[Epoch 30/50] [Batch 150/235] [D loss: 1.110692, acc: 88.67%] [G loss: 1.075407]\n",
      "[Epoch 30/50] [Batch 151/235] [D loss: 1.175096, acc: 86.13%] [G loss: 1.085114]\n",
      "[Epoch 30/50] [Batch 152/235] [D loss: 1.081228, acc: 88.09%] [G loss: 1.230479]\n",
      "[Epoch 30/50] [Batch 153/235] [D loss: 1.135075, acc: 88.67%] [G loss: 1.233631]\n",
      "[Epoch 30/50] [Batch 154/235] [D loss: 1.142347, acc: 83.79%] [G loss: 1.198174]\n",
      "[Epoch 30/50] [Batch 155/235] [D loss: 1.090616, acc: 87.50%] [G loss: 1.080666]\n",
      "[Epoch 30/50] [Batch 156/235] [D loss: 1.079216, acc: 85.35%] [G loss: 1.132035]\n",
      "[Epoch 30/50] [Batch 157/235] [D loss: 1.045086, acc: 88.28%] [G loss: 1.220888]\n",
      "[Epoch 30/50] [Batch 158/235] [D loss: 1.098420, acc: 87.30%] [G loss: 1.203068]\n",
      "[Epoch 30/50] [Batch 159/235] [D loss: 1.101816, acc: 88.28%] [G loss: 1.209415]\n",
      "[Epoch 30/50] [Batch 160/235] [D loss: 1.140973, acc: 86.91%] [G loss: 1.112260]\n",
      "[Epoch 30/50] [Batch 161/235] [D loss: 1.124723, acc: 86.52%] [G loss: 1.171375]\n",
      "[Epoch 30/50] [Batch 162/235] [D loss: 1.132117, acc: 85.55%] [G loss: 1.196024]\n",
      "[Epoch 30/50] [Batch 163/235] [D loss: 1.111459, acc: 88.87%] [G loss: 1.190070]\n",
      "[Epoch 30/50] [Batch 164/235] [D loss: 1.109093, acc: 87.70%] [G loss: 1.236647]\n",
      "[Epoch 30/50] [Batch 165/235] [D loss: 1.176382, acc: 86.72%] [G loss: 1.053534]\n",
      "[Epoch 30/50] [Batch 166/235] [D loss: 1.144602, acc: 87.50%] [G loss: 1.122946]\n",
      "[Epoch 30/50] [Batch 167/235] [D loss: 1.119205, acc: 88.09%] [G loss: 1.093770]\n",
      "[Epoch 30/50] [Batch 168/235] [D loss: 1.202637, acc: 89.26%] [G loss: 1.117034]\n",
      "[Epoch 30/50] [Batch 169/235] [D loss: 1.098229, acc: 86.13%] [G loss: 1.177486]\n",
      "[Epoch 30/50] [Batch 170/235] [D loss: 1.121879, acc: 86.91%] [G loss: 1.198714]\n",
      "[Epoch 30/50] [Batch 171/235] [D loss: 1.104791, acc: 86.52%] [G loss: 1.133710]\n",
      "[Epoch 30/50] [Batch 172/235] [D loss: 1.078610, acc: 86.91%] [G loss: 1.251122]\n",
      "[Epoch 30/50] [Batch 173/235] [D loss: 1.126423, acc: 86.13%] [G loss: 1.337703]\n",
      "[Epoch 30/50] [Batch 174/235] [D loss: 1.132640, acc: 85.74%] [G loss: 1.197364]\n",
      "[Epoch 30/50] [Batch 175/235] [D loss: 1.178967, acc: 87.89%] [G loss: 1.123815]\n",
      "[Epoch 30/50] [Batch 176/235] [D loss: 1.217123, acc: 85.35%] [G loss: 1.050929]\n",
      "[Epoch 30/50] [Batch 177/235] [D loss: 1.100990, acc: 87.89%] [G loss: 1.323650]\n",
      "[Epoch 30/50] [Batch 178/235] [D loss: 1.102076, acc: 87.50%] [G loss: 1.285926]\n",
      "[Epoch 30/50] [Batch 179/235] [D loss: 1.098083, acc: 91.60%] [G loss: 1.177706]\n",
      "[Epoch 30/50] [Batch 180/235] [D loss: 1.184774, acc: 85.94%] [G loss: 1.110935]\n",
      "[Epoch 30/50] [Batch 181/235] [D loss: 1.231469, acc: 86.72%] [G loss: 1.160587]\n",
      "[Epoch 30/50] [Batch 182/235] [D loss: 1.155447, acc: 86.91%] [G loss: 1.222187]\n",
      "[Epoch 30/50] [Batch 183/235] [D loss: 1.088713, acc: 89.06%] [G loss: 1.119962]\n",
      "[Epoch 30/50] [Batch 184/235] [D loss: 1.074411, acc: 89.06%] [G loss: 1.169176]\n",
      "[Epoch 30/50] [Batch 185/235] [D loss: 1.141914, acc: 87.70%] [G loss: 1.081883]\n",
      "[Epoch 30/50] [Batch 186/235] [D loss: 1.110959, acc: 87.70%] [G loss: 1.109472]\n",
      "[Epoch 30/50] [Batch 187/235] [D loss: 1.095969, acc: 87.30%] [G loss: 1.140077]\n",
      "[Epoch 30/50] [Batch 188/235] [D loss: 1.171872, acc: 85.16%] [G loss: 1.106327]\n",
      "[Epoch 30/50] [Batch 189/235] [D loss: 1.135130, acc: 88.48%] [G loss: 1.106198]\n",
      "[Epoch 30/50] [Batch 190/235] [D loss: 1.093175, acc: 87.50%] [G loss: 1.046384]\n",
      "[Epoch 30/50] [Batch 191/235] [D loss: 1.071464, acc: 89.65%] [G loss: 1.036942]\n",
      "[Epoch 30/50] [Batch 192/235] [D loss: 1.096516, acc: 87.30%] [G loss: 1.176460]\n",
      "[Epoch 30/50] [Batch 193/235] [D loss: 1.098502, acc: 87.50%] [G loss: 1.179547]\n",
      "[Epoch 30/50] [Batch 194/235] [D loss: 1.111964, acc: 87.50%] [G loss: 1.078251]\n",
      "[Epoch 30/50] [Batch 195/235] [D loss: 1.158114, acc: 86.91%] [G loss: 1.149496]\n",
      "[Epoch 30/50] [Batch 196/235] [D loss: 1.143486, acc: 89.65%] [G loss: 1.298743]\n",
      "[Epoch 30/50] [Batch 197/235] [D loss: 1.049773, acc: 88.87%] [G loss: 1.254934]\n",
      "[Epoch 30/50] [Batch 198/235] [D loss: 1.147679, acc: 87.50%] [G loss: 1.140684]\n",
      "[Epoch 30/50] [Batch 199/235] [D loss: 1.112466, acc: 89.06%] [G loss: 1.300651]\n",
      "[Epoch 30/50] [Batch 200/235] [D loss: 1.102695, acc: 86.13%] [G loss: 1.138377]\n",
      "[Epoch 30/50] [Batch 201/235] [D loss: 1.063784, acc: 87.70%] [G loss: 1.228210]\n",
      "[Epoch 30/50] [Batch 202/235] [D loss: 1.092041, acc: 84.57%] [G loss: 1.174904]\n",
      "[Epoch 30/50] [Batch 203/235] [D loss: 1.035692, acc: 87.11%] [G loss: 1.157282]\n",
      "[Epoch 30/50] [Batch 204/235] [D loss: 1.071244, acc: 86.91%] [G loss: 1.115392]\n",
      "[Epoch 30/50] [Batch 205/235] [D loss: 1.209702, acc: 88.48%] [G loss: 1.192845]\n",
      "[Epoch 30/50] [Batch 206/235] [D loss: 1.067809, acc: 85.74%] [G loss: 1.134071]\n",
      "[Epoch 30/50] [Batch 207/235] [D loss: 1.124126, acc: 85.94%] [G loss: 1.057530]\n",
      "[Epoch 30/50] [Batch 208/235] [D loss: 1.169802, acc: 85.35%] [G loss: 1.059117]\n",
      "[Epoch 30/50] [Batch 209/235] [D loss: 1.109126, acc: 86.13%] [G loss: 1.217242]\n",
      "[Epoch 30/50] [Batch 210/235] [D loss: 1.167165, acc: 86.52%] [G loss: 1.109323]\n",
      "[Epoch 30/50] [Batch 211/235] [D loss: 1.109825, acc: 85.94%] [G loss: 1.052160]\n",
      "[Epoch 30/50] [Batch 212/235] [D loss: 1.173311, acc: 87.11%] [G loss: 1.168620]\n",
      "[Epoch 30/50] [Batch 213/235] [D loss: 1.089489, acc: 86.33%] [G loss: 1.382196]\n",
      "[Epoch 30/50] [Batch 214/235] [D loss: 1.136076, acc: 87.11%] [G loss: 1.138445]\n",
      "[Epoch 30/50] [Batch 215/235] [D loss: 1.095934, acc: 87.70%] [G loss: 1.085838]\n",
      "[Epoch 30/50] [Batch 216/235] [D loss: 1.076682, acc: 85.55%] [G loss: 1.271132]\n",
      "[Epoch 30/50] [Batch 217/235] [D loss: 1.114385, acc: 85.35%] [G loss: 1.083531]\n",
      "[Epoch 30/50] [Batch 218/235] [D loss: 1.090237, acc: 88.09%] [G loss: 1.181478]\n",
      "[Epoch 30/50] [Batch 219/235] [D loss: 1.106175, acc: 87.30%] [G loss: 1.221236]\n",
      "[Epoch 30/50] [Batch 220/235] [D loss: 1.121075, acc: 86.52%] [G loss: 1.169742]\n",
      "[Epoch 30/50] [Batch 221/235] [D loss: 1.117262, acc: 87.89%] [G loss: 1.095297]\n",
      "[Epoch 30/50] [Batch 222/235] [D loss: 1.135493, acc: 85.74%] [G loss: 1.179001]\n",
      "[Epoch 30/50] [Batch 223/235] [D loss: 1.143682, acc: 84.38%] [G loss: 1.069681]\n",
      "[Epoch 30/50] [Batch 224/235] [D loss: 1.158077, acc: 84.38%] [G loss: 1.087641]\n",
      "[Epoch 30/50] [Batch 225/235] [D loss: 1.136940, acc: 87.70%] [G loss: 1.160832]\n",
      "[Epoch 30/50] [Batch 226/235] [D loss: 1.119671, acc: 86.33%] [G loss: 1.225838]\n",
      "[Epoch 30/50] [Batch 227/235] [D loss: 1.196402, acc: 85.74%] [G loss: 1.116421]\n",
      "[Epoch 30/50] [Batch 228/235] [D loss: 1.118774, acc: 87.50%] [G loss: 1.176734]\n",
      "[Epoch 30/50] [Batch 229/235] [D loss: 1.096734, acc: 87.50%] [G loss: 1.075333]\n",
      "[Epoch 30/50] [Batch 230/235] [D loss: 1.147808, acc: 89.45%] [G loss: 1.132469]\n",
      "[Epoch 30/50] [Batch 231/235] [D loss: 1.085299, acc: 87.50%] [G loss: 1.120681]\n",
      "[Epoch 30/50] [Batch 232/235] [D loss: 1.117596, acc: 88.09%] [G loss: 1.111204]\n",
      "[Epoch 30/50] [Batch 233/235] [D loss: 1.127938, acc: 85.16%] [G loss: 1.161350]\n",
      "[Epoch 30/50] [Batch 234/235] [D loss: 1.155098, acc: 88.54%] [G loss: 1.093989]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/50] [Batch 0/235] [D loss: 1.130125, acc: 86.91%] [G loss: 1.037452]\n",
      "[Epoch 31/50] [Batch 1/235] [D loss: 1.049824, acc: 89.65%] [G loss: 1.227923]\n",
      "[Epoch 31/50] [Batch 2/235] [D loss: 1.150390, acc: 88.48%] [G loss: 1.217340]\n",
      "[Epoch 31/50] [Batch 3/235] [D loss: 1.135881, acc: 87.89%] [G loss: 1.130237]\n",
      "[Epoch 31/50] [Batch 4/235] [D loss: 1.126974, acc: 84.57%] [G loss: 1.221601]\n",
      "[Epoch 31/50] [Batch 5/235] [D loss: 1.164732, acc: 84.38%] [G loss: 1.004031]\n",
      "[Epoch 31/50] [Batch 6/235] [D loss: 1.106988, acc: 87.30%] [G loss: 1.159307]\n",
      "[Epoch 31/50] [Batch 7/235] [D loss: 1.098142, acc: 87.70%] [G loss: 1.105333]\n",
      "[Epoch 31/50] [Batch 8/235] [D loss: 1.098525, acc: 88.67%] [G loss: 1.127072]\n",
      "[Epoch 31/50] [Batch 9/235] [D loss: 1.149145, acc: 88.28%] [G loss: 1.011192]\n",
      "[Epoch 31/50] [Batch 10/235] [D loss: 1.133989, acc: 86.13%] [G loss: 1.143631]\n",
      "[Epoch 31/50] [Batch 11/235] [D loss: 1.104268, acc: 87.50%] [G loss: 1.306137]\n",
      "[Epoch 31/50] [Batch 12/235] [D loss: 1.105320, acc: 88.67%] [G loss: 1.171496]\n",
      "[Epoch 31/50] [Batch 13/235] [D loss: 1.117441, acc: 85.55%] [G loss: 1.204000]\n",
      "[Epoch 31/50] [Batch 14/235] [D loss: 1.112300, acc: 87.89%] [G loss: 1.145066]\n",
      "[Epoch 31/50] [Batch 15/235] [D loss: 1.114714, acc: 86.72%] [G loss: 1.052953]\n",
      "[Epoch 31/50] [Batch 16/235] [D loss: 1.138502, acc: 89.84%] [G loss: 1.103989]\n",
      "[Epoch 31/50] [Batch 17/235] [D loss: 1.101714, acc: 87.70%] [G loss: 1.111688]\n",
      "[Epoch 31/50] [Batch 18/235] [D loss: 1.135579, acc: 83.20%] [G loss: 1.180845]\n",
      "[Epoch 31/50] [Batch 19/235] [D loss: 1.077238, acc: 88.48%] [G loss: 1.191479]\n",
      "[Epoch 31/50] [Batch 20/235] [D loss: 1.093680, acc: 87.30%] [G loss: 1.132622]\n",
      "[Epoch 31/50] [Batch 21/235] [D loss: 1.051491, acc: 88.09%] [G loss: 1.189868]\n",
      "[Epoch 31/50] [Batch 22/235] [D loss: 1.200527, acc: 86.91%] [G loss: 1.159522]\n",
      "[Epoch 31/50] [Batch 23/235] [D loss: 1.126837, acc: 88.28%] [G loss: 1.166620]\n",
      "[Epoch 31/50] [Batch 24/235] [D loss: 1.132442, acc: 86.52%] [G loss: 1.146388]\n",
      "[Epoch 31/50] [Batch 25/235] [D loss: 1.132186, acc: 85.94%] [G loss: 1.194376]\n",
      "[Epoch 31/50] [Batch 26/235] [D loss: 1.098997, acc: 88.28%] [G loss: 1.219889]\n",
      "[Epoch 31/50] [Batch 27/235] [D loss: 1.094315, acc: 84.18%] [G loss: 1.272349]\n",
      "[Epoch 31/50] [Batch 28/235] [D loss: 1.138670, acc: 85.35%] [G loss: 1.007848]\n",
      "[Epoch 31/50] [Batch 29/235] [D loss: 1.097492, acc: 89.06%] [G loss: 1.097592]\n",
      "[Epoch 31/50] [Batch 30/235] [D loss: 1.098956, acc: 87.30%] [G loss: 1.256518]\n",
      "[Epoch 31/50] [Batch 31/235] [D loss: 1.095422, acc: 88.28%] [G loss: 1.209342]\n",
      "[Epoch 31/50] [Batch 32/235] [D loss: 1.096534, acc: 87.11%] [G loss: 1.100301]\n",
      "[Epoch 31/50] [Batch 33/235] [D loss: 1.109170, acc: 87.70%] [G loss: 1.102267]\n",
      "[Epoch 31/50] [Batch 34/235] [D loss: 1.045042, acc: 88.67%] [G loss: 1.188001]\n",
      "[Epoch 31/50] [Batch 35/235] [D loss: 1.114322, acc: 87.70%] [G loss: 1.169992]\n",
      "[Epoch 31/50] [Batch 36/235] [D loss: 1.132145, acc: 90.62%] [G loss: 1.077509]\n",
      "[Epoch 31/50] [Batch 37/235] [D loss: 1.168832, acc: 86.13%] [G loss: 1.056678]\n",
      "[Epoch 31/50] [Batch 38/235] [D loss: 1.151178, acc: 86.52%] [G loss: 1.123350]\n",
      "[Epoch 31/50] [Batch 39/235] [D loss: 1.089003, acc: 86.72%] [G loss: 1.236842]\n",
      "[Epoch 31/50] [Batch 40/235] [D loss: 1.099505, acc: 87.50%] [G loss: 1.187308]\n",
      "[Epoch 31/50] [Batch 41/235] [D loss: 1.075677, acc: 89.26%] [G loss: 1.071326]\n",
      "[Epoch 31/50] [Batch 42/235] [D loss: 1.074254, acc: 88.09%] [G loss: 1.194475]\n",
      "[Epoch 31/50] [Batch 43/235] [D loss: 1.114838, acc: 86.33%] [G loss: 1.144637]\n",
      "[Epoch 31/50] [Batch 44/235] [D loss: 1.142103, acc: 87.11%] [G loss: 1.268975]\n",
      "[Epoch 31/50] [Batch 45/235] [D loss: 1.118860, acc: 87.11%] [G loss: 1.125422]\n",
      "[Epoch 31/50] [Batch 46/235] [D loss: 1.125587, acc: 87.30%] [G loss: 1.082507]\n",
      "[Epoch 31/50] [Batch 47/235] [D loss: 1.115521, acc: 88.28%] [G loss: 1.032329]\n",
      "[Epoch 31/50] [Batch 48/235] [D loss: 1.147529, acc: 88.67%] [G loss: 1.152080]\n",
      "[Epoch 31/50] [Batch 49/235] [D loss: 1.133343, acc: 89.06%] [G loss: 1.090364]\n",
      "[Epoch 31/50] [Batch 50/235] [D loss: 1.135414, acc: 87.11%] [G loss: 1.013436]\n",
      "[Epoch 31/50] [Batch 51/235] [D loss: 1.109564, acc: 85.94%] [G loss: 1.263909]\n",
      "[Epoch 31/50] [Batch 52/235] [D loss: 1.114282, acc: 88.87%] [G loss: 1.128634]\n",
      "[Epoch 31/50] [Batch 53/235] [D loss: 1.127854, acc: 85.94%] [G loss: 1.066834]\n",
      "[Epoch 31/50] [Batch 54/235] [D loss: 1.148836, acc: 86.13%] [G loss: 1.224172]\n",
      "[Epoch 31/50] [Batch 55/235] [D loss: 1.177242, acc: 87.11%] [G loss: 1.282889]\n",
      "[Epoch 31/50] [Batch 56/235] [D loss: 1.130635, acc: 84.38%] [G loss: 1.299499]\n",
      "[Epoch 31/50] [Batch 57/235] [D loss: 1.156576, acc: 86.52%] [G loss: 1.126867]\n",
      "[Epoch 31/50] [Batch 58/235] [D loss: 1.144809, acc: 84.77%] [G loss: 1.152359]\n",
      "[Epoch 31/50] [Batch 59/235] [D loss: 1.111650, acc: 88.87%] [G loss: 1.164794]\n",
      "[Epoch 31/50] [Batch 60/235] [D loss: 1.178816, acc: 85.74%] [G loss: 1.230923]\n",
      "[Epoch 31/50] [Batch 61/235] [D loss: 1.075341, acc: 87.89%] [G loss: 1.297086]\n",
      "[Epoch 31/50] [Batch 62/235] [D loss: 1.158417, acc: 84.96%] [G loss: 1.253600]\n",
      "[Epoch 31/50] [Batch 63/235] [D loss: 1.103429, acc: 86.72%] [G loss: 1.105791]\n",
      "[Epoch 31/50] [Batch 64/235] [D loss: 1.077662, acc: 86.72%] [G loss: 1.109001]\n",
      "[Epoch 31/50] [Batch 65/235] [D loss: 1.118887, acc: 86.33%] [G loss: 1.286082]\n",
      "[Epoch 31/50] [Batch 66/235] [D loss: 1.173970, acc: 86.13%] [G loss: 1.389538]\n",
      "[Epoch 31/50] [Batch 67/235] [D loss: 1.091858, acc: 86.52%] [G loss: 1.139214]\n",
      "[Epoch 31/50] [Batch 68/235] [D loss: 1.128613, acc: 87.11%] [G loss: 1.082837]\n",
      "[Epoch 31/50] [Batch 69/235] [D loss: 1.067652, acc: 87.11%] [G loss: 1.182328]\n",
      "[Epoch 31/50] [Batch 70/235] [D loss: 1.186318, acc: 87.89%] [G loss: 1.203106]\n",
      "[Epoch 31/50] [Batch 71/235] [D loss: 1.121940, acc: 88.48%] [G loss: 1.175595]\n",
      "[Epoch 31/50] [Batch 72/235] [D loss: 1.074158, acc: 88.67%] [G loss: 1.050860]\n",
      "[Epoch 31/50] [Batch 73/235] [D loss: 1.087850, acc: 86.13%] [G loss: 1.142545]\n",
      "[Epoch 31/50] [Batch 74/235] [D loss: 1.111924, acc: 85.74%] [G loss: 1.109880]\n",
      "[Epoch 31/50] [Batch 75/235] [D loss: 1.117407, acc: 88.67%] [G loss: 1.082986]\n",
      "[Epoch 31/50] [Batch 76/235] [D loss: 1.082715, acc: 87.50%] [G loss: 1.189936]\n",
      "[Epoch 31/50] [Batch 77/235] [D loss: 1.140085, acc: 89.06%] [G loss: 1.178586]\n",
      "[Epoch 31/50] [Batch 78/235] [D loss: 1.102645, acc: 86.52%] [G loss: 1.198595]\n",
      "[Epoch 31/50] [Batch 79/235] [D loss: 1.149305, acc: 85.16%] [G loss: 1.113047]\n",
      "[Epoch 31/50] [Batch 80/235] [D loss: 1.144539, acc: 84.96%] [G loss: 1.111523]\n",
      "[Epoch 31/50] [Batch 81/235] [D loss: 1.079343, acc: 85.35%] [G loss: 1.265808]\n",
      "[Epoch 31/50] [Batch 82/235] [D loss: 1.147929, acc: 86.33%] [G loss: 1.075156]\n",
      "[Epoch 31/50] [Batch 83/235] [D loss: 1.138432, acc: 88.09%] [G loss: 1.063900]\n",
      "[Epoch 31/50] [Batch 84/235] [D loss: 1.114768, acc: 86.52%] [G loss: 1.092353]\n",
      "[Epoch 31/50] [Batch 85/235] [D loss: 1.094404, acc: 86.52%] [G loss: 1.189362]\n",
      "[Epoch 31/50] [Batch 86/235] [D loss: 1.150016, acc: 83.01%] [G loss: 1.085802]\n",
      "[Epoch 31/50] [Batch 87/235] [D loss: 1.128113, acc: 89.65%] [G loss: 1.170779]\n",
      "[Epoch 31/50] [Batch 88/235] [D loss: 1.132191, acc: 86.13%] [G loss: 1.107520]\n",
      "[Epoch 31/50] [Batch 89/235] [D loss: 1.145338, acc: 84.96%] [G loss: 1.118674]\n",
      "[Epoch 31/50] [Batch 90/235] [D loss: 1.128728, acc: 88.09%] [G loss: 1.095880]\n",
      "[Epoch 31/50] [Batch 91/235] [D loss: 1.123524, acc: 87.70%] [G loss: 1.129136]\n",
      "[Epoch 31/50] [Batch 92/235] [D loss: 1.129780, acc: 85.74%] [G loss: 1.203456]\n",
      "[Epoch 31/50] [Batch 93/235] [D loss: 1.150548, acc: 86.33%] [G loss: 1.208414]\n",
      "[Epoch 31/50] [Batch 94/235] [D loss: 1.119949, acc: 89.26%] [G loss: 1.088175]\n",
      "[Epoch 31/50] [Batch 95/235] [D loss: 1.113652, acc: 88.67%] [G loss: 1.079984]\n",
      "[Epoch 31/50] [Batch 96/235] [D loss: 1.133387, acc: 85.35%] [G loss: 1.119041]\n",
      "[Epoch 31/50] [Batch 97/235] [D loss: 1.112333, acc: 86.52%] [G loss: 1.160492]\n",
      "[Epoch 31/50] [Batch 98/235] [D loss: 1.143435, acc: 87.70%] [G loss: 1.188051]\n",
      "[Epoch 31/50] [Batch 99/235] [D loss: 1.129584, acc: 87.11%] [G loss: 1.008990]\n",
      "[Epoch 31/50] [Batch 100/235] [D loss: 1.170777, acc: 86.52%] [G loss: 1.130446]\n",
      "[Epoch 31/50] [Batch 101/235] [D loss: 1.115887, acc: 86.52%] [G loss: 1.273153]\n",
      "[Epoch 31/50] [Batch 102/235] [D loss: 1.147230, acc: 90.23%] [G loss: 1.138232]\n",
      "[Epoch 31/50] [Batch 103/235] [D loss: 1.069488, acc: 86.91%] [G loss: 1.032999]\n",
      "[Epoch 31/50] [Batch 104/235] [D loss: 1.094491, acc: 87.50%] [G loss: 1.112013]\n",
      "[Epoch 31/50] [Batch 105/235] [D loss: 1.104982, acc: 88.87%] [G loss: 1.150230]\n",
      "[Epoch 31/50] [Batch 106/235] [D loss: 1.126590, acc: 88.28%] [G loss: 1.131705]\n",
      "[Epoch 31/50] [Batch 107/235] [D loss: 1.148882, acc: 86.91%] [G loss: 1.056244]\n",
      "[Epoch 31/50] [Batch 108/235] [D loss: 1.173610, acc: 86.13%] [G loss: 1.093462]\n",
      "[Epoch 31/50] [Batch 109/235] [D loss: 1.111372, acc: 90.43%] [G loss: 1.261059]\n",
      "[Epoch 31/50] [Batch 110/235] [D loss: 1.039070, acc: 89.45%] [G loss: 1.135841]\n",
      "[Epoch 31/50] [Batch 111/235] [D loss: 1.125532, acc: 87.30%] [G loss: 1.069043]\n",
      "[Epoch 31/50] [Batch 112/235] [D loss: 1.116756, acc: 87.70%] [G loss: 1.259763]\n",
      "[Epoch 31/50] [Batch 113/235] [D loss: 1.142906, acc: 86.91%] [G loss: 1.300576]\n",
      "[Epoch 31/50] [Batch 114/235] [D loss: 1.150832, acc: 85.94%] [G loss: 1.105818]\n",
      "[Epoch 31/50] [Batch 115/235] [D loss: 1.082464, acc: 87.50%] [G loss: 1.079668]\n",
      "[Epoch 31/50] [Batch 116/235] [D loss: 1.097893, acc: 86.33%] [G loss: 1.042388]\n",
      "[Epoch 31/50] [Batch 117/235] [D loss: 1.065319, acc: 89.65%] [G loss: 1.155041]\n",
      "[Epoch 31/50] [Batch 118/235] [D loss: 1.119672, acc: 85.94%] [G loss: 1.094755]\n",
      "[Epoch 31/50] [Batch 119/235] [D loss: 1.091732, acc: 85.16%] [G loss: 1.115442]\n",
      "[Epoch 31/50] [Batch 120/235] [D loss: 1.090309, acc: 85.16%] [G loss: 1.268107]\n",
      "[Epoch 31/50] [Batch 121/235] [D loss: 1.101271, acc: 85.16%] [G loss: 1.212184]\n",
      "[Epoch 31/50] [Batch 122/235] [D loss: 1.119579, acc: 87.89%] [G loss: 1.240987]\n",
      "[Epoch 31/50] [Batch 123/235] [D loss: 1.167777, acc: 85.94%] [G loss: 1.211914]\n",
      "[Epoch 31/50] [Batch 124/235] [D loss: 1.150840, acc: 85.55%] [G loss: 1.019621]\n",
      "[Epoch 31/50] [Batch 125/235] [D loss: 1.079470, acc: 86.13%] [G loss: 1.164889]\n",
      "[Epoch 31/50] [Batch 126/235] [D loss: 1.159897, acc: 89.06%] [G loss: 1.148029]\n",
      "[Epoch 31/50] [Batch 127/235] [D loss: 1.128303, acc: 86.91%] [G loss: 1.302654]\n",
      "[Epoch 31/50] [Batch 128/235] [D loss: 1.114429, acc: 86.13%] [G loss: 1.161603]\n",
      "[Epoch 31/50] [Batch 129/235] [D loss: 1.177737, acc: 84.96%] [G loss: 1.140427]\n",
      "[Epoch 31/50] [Batch 130/235] [D loss: 1.138666, acc: 86.33%] [G loss: 1.295178]\n",
      "[Epoch 31/50] [Batch 131/235] [D loss: 1.135324, acc: 86.33%] [G loss: 1.315358]\n",
      "[Epoch 31/50] [Batch 132/235] [D loss: 1.076891, acc: 89.45%] [G loss: 1.150469]\n",
      "[Epoch 31/50] [Batch 133/235] [D loss: 1.151189, acc: 84.77%] [G loss: 1.089162]\n",
      "[Epoch 31/50] [Batch 134/235] [D loss: 1.114387, acc: 85.55%] [G loss: 1.336129]\n",
      "[Epoch 31/50] [Batch 135/235] [D loss: 1.140714, acc: 86.13%] [G loss: 1.124435]\n",
      "[Epoch 31/50] [Batch 136/235] [D loss: 1.100731, acc: 86.72%] [G loss: 1.127354]\n",
      "[Epoch 31/50] [Batch 137/235] [D loss: 1.073875, acc: 86.91%] [G loss: 1.245001]\n",
      "[Epoch 31/50] [Batch 138/235] [D loss: 1.136254, acc: 87.89%] [G loss: 1.225182]\n",
      "[Epoch 31/50] [Batch 139/235] [D loss: 1.108921, acc: 88.09%] [G loss: 1.240341]\n",
      "[Epoch 31/50] [Batch 140/235] [D loss: 1.092658, acc: 87.50%] [G loss: 1.142067]\n",
      "[Epoch 31/50] [Batch 141/235] [D loss: 1.067383, acc: 89.26%] [G loss: 1.093646]\n",
      "[Epoch 31/50] [Batch 142/235] [D loss: 1.114218, acc: 84.77%] [G loss: 1.188346]\n",
      "[Epoch 31/50] [Batch 143/235] [D loss: 1.071580, acc: 88.09%] [G loss: 1.090557]\n",
      "[Epoch 31/50] [Batch 144/235] [D loss: 1.076373, acc: 89.45%] [G loss: 1.218083]\n",
      "[Epoch 31/50] [Batch 145/235] [D loss: 1.143278, acc: 87.89%] [G loss: 1.256677]\n",
      "[Epoch 31/50] [Batch 146/235] [D loss: 1.133358, acc: 86.33%] [G loss: 1.170529]\n",
      "[Epoch 31/50] [Batch 147/235] [D loss: 1.132831, acc: 84.96%] [G loss: 1.349329]\n",
      "[Epoch 31/50] [Batch 148/235] [D loss: 1.158470, acc: 85.94%] [G loss: 1.205140]\n",
      "[Epoch 31/50] [Batch 149/235] [D loss: 1.087011, acc: 87.70%] [G loss: 1.072028]\n",
      "[Epoch 31/50] [Batch 150/235] [D loss: 1.094903, acc: 87.70%] [G loss: 1.075837]\n",
      "[Epoch 31/50] [Batch 151/235] [D loss: 1.077212, acc: 87.50%] [G loss: 1.183409]\n",
      "[Epoch 31/50] [Batch 152/235] [D loss: 1.126916, acc: 87.89%] [G loss: 1.170947]\n",
      "[Epoch 31/50] [Batch 153/235] [D loss: 1.141781, acc: 86.91%] [G loss: 1.198180]\n",
      "[Epoch 31/50] [Batch 154/235] [D loss: 1.148840, acc: 86.13%] [G loss: 1.107368]\n",
      "[Epoch 31/50] [Batch 155/235] [D loss: 1.135470, acc: 86.33%] [G loss: 1.231473]\n",
      "[Epoch 31/50] [Batch 156/235] [D loss: 1.183307, acc: 85.74%] [G loss: 1.306947]\n",
      "[Epoch 31/50] [Batch 157/235] [D loss: 1.122926, acc: 88.48%] [G loss: 1.154069]\n",
      "[Epoch 31/50] [Batch 158/235] [D loss: 1.117719, acc: 89.06%] [G loss: 1.160851]\n",
      "[Epoch 31/50] [Batch 159/235] [D loss: 1.141966, acc: 86.72%] [G loss: 1.173413]\n",
      "[Epoch 31/50] [Batch 160/235] [D loss: 1.105728, acc: 87.50%] [G loss: 1.251444]\n",
      "[Epoch 31/50] [Batch 161/235] [D loss: 1.134511, acc: 87.30%] [G loss: 1.013433]\n",
      "[Epoch 31/50] [Batch 162/235] [D loss: 1.093787, acc: 86.13%] [G loss: 1.100576]\n",
      "[Epoch 31/50] [Batch 163/235] [D loss: 1.153095, acc: 86.13%] [G loss: 1.145034]\n",
      "[Epoch 31/50] [Batch 164/235] [D loss: 1.066705, acc: 89.06%] [G loss: 1.167932]\n",
      "[Epoch 31/50] [Batch 165/235] [D loss: 1.110397, acc: 86.72%] [G loss: 1.154030]\n",
      "[Epoch 31/50] [Batch 166/235] [D loss: 1.123751, acc: 91.21%] [G loss: 1.047756]\n",
      "[Epoch 31/50] [Batch 167/235] [D loss: 1.128940, acc: 84.57%] [G loss: 1.043369]\n",
      "[Epoch 31/50] [Batch 168/235] [D loss: 1.102618, acc: 86.91%] [G loss: 1.074919]\n",
      "[Epoch 31/50] [Batch 169/235] [D loss: 1.105205, acc: 87.50%] [G loss: 1.223767]\n",
      "[Epoch 31/50] [Batch 170/235] [D loss: 1.074728, acc: 86.72%] [G loss: 1.209894]\n",
      "[Epoch 31/50] [Batch 171/235] [D loss: 1.173316, acc: 85.94%] [G loss: 1.158977]\n",
      "[Epoch 31/50] [Batch 172/235] [D loss: 1.195537, acc: 85.94%] [G loss: 1.102238]\n",
      "[Epoch 31/50] [Batch 173/235] [D loss: 1.151200, acc: 87.30%] [G loss: 1.089419]\n",
      "[Epoch 31/50] [Batch 174/235] [D loss: 1.119248, acc: 85.74%] [G loss: 1.023801]\n",
      "[Epoch 31/50] [Batch 175/235] [D loss: 1.111864, acc: 87.11%] [G loss: 1.264867]\n",
      "[Epoch 31/50] [Batch 176/235] [D loss: 1.101309, acc: 86.13%] [G loss: 1.143775]\n",
      "[Epoch 31/50] [Batch 177/235] [D loss: 1.084645, acc: 87.50%] [G loss: 1.146038]\n",
      "[Epoch 31/50] [Batch 178/235] [D loss: 1.097824, acc: 85.94%] [G loss: 1.221766]\n",
      "[Epoch 31/50] [Batch 179/235] [D loss: 1.166893, acc: 85.94%] [G loss: 1.102388]\n",
      "[Epoch 31/50] [Batch 180/235] [D loss: 1.130713, acc: 84.57%] [G loss: 1.052992]\n",
      "[Epoch 31/50] [Batch 181/235] [D loss: 1.136833, acc: 87.70%] [G loss: 1.097622]\n",
      "[Epoch 31/50] [Batch 182/235] [D loss: 1.135056, acc: 87.50%] [G loss: 1.107266]\n",
      "[Epoch 31/50] [Batch 183/235] [D loss: 1.089280, acc: 87.50%] [G loss: 1.183086]\n",
      "[Epoch 31/50] [Batch 184/235] [D loss: 1.135751, acc: 88.28%] [G loss: 1.221439]\n",
      "[Epoch 31/50] [Batch 185/235] [D loss: 1.100413, acc: 88.48%] [G loss: 1.018819]\n",
      "[Epoch 31/50] [Batch 186/235] [D loss: 1.072318, acc: 87.11%] [G loss: 1.183634]\n",
      "[Epoch 31/50] [Batch 187/235] [D loss: 1.090566, acc: 90.23%] [G loss: 1.242540]\n",
      "[Epoch 31/50] [Batch 188/235] [D loss: 1.094893, acc: 86.52%] [G loss: 1.231152]\n",
      "[Epoch 31/50] [Batch 189/235] [D loss: 1.094453, acc: 87.70%] [G loss: 1.293502]\n",
      "[Epoch 31/50] [Batch 190/235] [D loss: 1.166557, acc: 87.89%] [G loss: 1.216375]\n",
      "[Epoch 31/50] [Batch 191/235] [D loss: 1.112126, acc: 86.52%] [G loss: 1.119658]\n",
      "[Epoch 31/50] [Batch 192/235] [D loss: 1.190897, acc: 84.57%] [G loss: 1.118250]\n",
      "[Epoch 31/50] [Batch 193/235] [D loss: 1.164595, acc: 86.91%] [G loss: 1.027800]\n",
      "[Epoch 31/50] [Batch 194/235] [D loss: 1.061428, acc: 86.52%] [G loss: 1.043889]\n",
      "[Epoch 31/50] [Batch 195/235] [D loss: 1.083944, acc: 86.72%] [G loss: 1.271374]\n",
      "[Epoch 31/50] [Batch 196/235] [D loss: 1.139391, acc: 88.87%] [G loss: 1.118374]\n",
      "[Epoch 31/50] [Batch 197/235] [D loss: 1.081998, acc: 87.50%] [G loss: 1.140124]\n",
      "[Epoch 31/50] [Batch 198/235] [D loss: 1.121917, acc: 85.74%] [G loss: 1.093464]\n",
      "[Epoch 31/50] [Batch 199/235] [D loss: 1.120049, acc: 86.72%] [G loss: 1.282998]\n",
      "[Epoch 31/50] [Batch 200/235] [D loss: 1.107847, acc: 87.30%] [G loss: 1.287274]\n",
      "[Epoch 31/50] [Batch 201/235] [D loss: 1.105740, acc: 86.52%] [G loss: 1.007193]\n",
      "[Epoch 31/50] [Batch 202/235] [D loss: 1.114124, acc: 88.28%] [G loss: 1.003630]\n",
      "[Epoch 31/50] [Batch 203/235] [D loss: 1.067275, acc: 86.91%] [G loss: 1.122617]\n",
      "[Epoch 31/50] [Batch 204/235] [D loss: 1.087622, acc: 84.96%] [G loss: 1.208172]\n",
      "[Epoch 31/50] [Batch 205/235] [D loss: 1.138220, acc: 86.72%] [G loss: 1.164799]\n",
      "[Epoch 31/50] [Batch 206/235] [D loss: 1.150331, acc: 88.48%] [G loss: 1.278606]\n",
      "[Epoch 31/50] [Batch 207/235] [D loss: 1.179454, acc: 88.28%] [G loss: 0.975856]\n",
      "[Epoch 31/50] [Batch 208/235] [D loss: 1.121055, acc: 85.55%] [G loss: 1.049228]\n",
      "[Epoch 31/50] [Batch 209/235] [D loss: 1.200672, acc: 86.91%] [G loss: 1.165684]\n",
      "[Epoch 31/50] [Batch 210/235] [D loss: 1.125128, acc: 90.04%] [G loss: 1.337055]\n",
      "[Epoch 31/50] [Batch 211/235] [D loss: 1.072082, acc: 85.74%] [G loss: 1.189033]\n",
      "[Epoch 31/50] [Batch 212/235] [D loss: 1.180198, acc: 88.48%] [G loss: 1.013680]\n",
      "[Epoch 31/50] [Batch 213/235] [D loss: 1.107559, acc: 87.70%] [G loss: 0.995734]\n",
      "[Epoch 31/50] [Batch 214/235] [D loss: 1.121910, acc: 86.33%] [G loss: 1.118434]\n",
      "[Epoch 31/50] [Batch 215/235] [D loss: 1.125373, acc: 87.50%] [G loss: 1.299690]\n",
      "[Epoch 31/50] [Batch 216/235] [D loss: 1.114109, acc: 87.11%] [G loss: 1.205202]\n",
      "[Epoch 31/50] [Batch 217/235] [D loss: 1.092568, acc: 84.18%] [G loss: 1.097153]\n",
      "[Epoch 31/50] [Batch 218/235] [D loss: 1.092782, acc: 87.89%] [G loss: 1.109180]\n",
      "[Epoch 31/50] [Batch 219/235] [D loss: 1.156149, acc: 86.72%] [G loss: 1.109118]\n",
      "[Epoch 31/50] [Batch 220/235] [D loss: 1.135504, acc: 88.28%] [G loss: 1.214124]\n",
      "[Epoch 31/50] [Batch 221/235] [D loss: 1.129529, acc: 85.94%] [G loss: 1.269442]\n",
      "[Epoch 31/50] [Batch 222/235] [D loss: 1.121571, acc: 87.50%] [G loss: 1.265425]\n",
      "[Epoch 31/50] [Batch 223/235] [D loss: 1.123457, acc: 84.38%] [G loss: 1.188086]\n",
      "[Epoch 31/50] [Batch 224/235] [D loss: 1.134606, acc: 85.16%] [G loss: 1.044254]\n",
      "[Epoch 31/50] [Batch 225/235] [D loss: 1.084401, acc: 87.30%] [G loss: 1.268797]\n",
      "[Epoch 31/50] [Batch 226/235] [D loss: 1.065405, acc: 87.50%] [G loss: 1.205401]\n",
      "[Epoch 31/50] [Batch 227/235] [D loss: 1.141228, acc: 86.13%] [G loss: 1.151772]\n",
      "[Epoch 31/50] [Batch 228/235] [D loss: 1.148972, acc: 85.94%] [G loss: 1.076167]\n",
      "[Epoch 31/50] [Batch 229/235] [D loss: 1.180942, acc: 87.30%] [G loss: 1.115494]\n",
      "[Epoch 31/50] [Batch 230/235] [D loss: 1.145879, acc: 87.70%] [G loss: 1.156300]\n",
      "[Epoch 31/50] [Batch 231/235] [D loss: 1.168127, acc: 84.38%] [G loss: 1.291323]\n",
      "[Epoch 31/50] [Batch 232/235] [D loss: 1.088922, acc: 87.30%] [G loss: 1.171694]\n",
      "[Epoch 31/50] [Batch 233/235] [D loss: 1.093949, acc: 86.33%] [G loss: 1.187405]\n",
      "[Epoch 31/50] [Batch 234/235] [D loss: 1.153841, acc: 85.42%] [G loss: 1.089320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/50] [Batch 0/235] [D loss: 1.126040, acc: 87.30%] [G loss: 1.252347]\n",
      "[Epoch 32/50] [Batch 1/235] [D loss: 1.153748, acc: 88.28%] [G loss: 1.308281]\n",
      "[Epoch 32/50] [Batch 2/235] [D loss: 1.068510, acc: 86.13%] [G loss: 1.130438]\n",
      "[Epoch 32/50] [Batch 3/235] [D loss: 1.111233, acc: 86.72%] [G loss: 1.150092]\n",
      "[Epoch 32/50] [Batch 4/235] [D loss: 1.122274, acc: 86.33%] [G loss: 1.082283]\n",
      "[Epoch 32/50] [Batch 5/235] [D loss: 1.124903, acc: 85.55%] [G loss: 1.179242]\n",
      "[Epoch 32/50] [Batch 6/235] [D loss: 1.113572, acc: 86.91%] [G loss: 1.159722]\n",
      "[Epoch 32/50] [Batch 7/235] [D loss: 1.153054, acc: 83.98%] [G loss: 1.105770]\n",
      "[Epoch 32/50] [Batch 8/235] [D loss: 1.124570, acc: 89.26%] [G loss: 1.111279]\n",
      "[Epoch 32/50] [Batch 9/235] [D loss: 1.115139, acc: 87.89%] [G loss: 1.123641]\n",
      "[Epoch 32/50] [Batch 10/235] [D loss: 1.107298, acc: 84.96%] [G loss: 1.144343]\n",
      "[Epoch 32/50] [Batch 11/235] [D loss: 1.071478, acc: 88.28%] [G loss: 1.159613]\n",
      "[Epoch 32/50] [Batch 12/235] [D loss: 1.086021, acc: 85.74%] [G loss: 1.162260]\n",
      "[Epoch 32/50] [Batch 13/235] [D loss: 1.140636, acc: 87.11%] [G loss: 1.039827]\n",
      "[Epoch 32/50] [Batch 14/235] [D loss: 1.108189, acc: 87.11%] [G loss: 1.122672]\n",
      "[Epoch 32/50] [Batch 15/235] [D loss: 1.127614, acc: 87.30%] [G loss: 1.025099]\n",
      "[Epoch 32/50] [Batch 16/235] [D loss: 1.026118, acc: 87.30%] [G loss: 1.183325]\n",
      "[Epoch 32/50] [Batch 17/235] [D loss: 1.147584, acc: 88.48%] [G loss: 1.193159]\n",
      "[Epoch 32/50] [Batch 18/235] [D loss: 1.090154, acc: 88.28%] [G loss: 1.083197]\n",
      "[Epoch 32/50] [Batch 19/235] [D loss: 1.141320, acc: 88.48%] [G loss: 1.138982]\n",
      "[Epoch 32/50] [Batch 20/235] [D loss: 1.066939, acc: 87.50%] [G loss: 1.222784]\n",
      "[Epoch 32/50] [Batch 21/235] [D loss: 1.072341, acc: 88.48%] [G loss: 1.135959]\n",
      "[Epoch 32/50] [Batch 22/235] [D loss: 1.090065, acc: 89.45%] [G loss: 1.088076]\n",
      "[Epoch 32/50] [Batch 23/235] [D loss: 1.072150, acc: 86.91%] [G loss: 1.099664]\n",
      "[Epoch 32/50] [Batch 24/235] [D loss: 1.166312, acc: 88.28%] [G loss: 1.076056]\n",
      "[Epoch 32/50] [Batch 25/235] [D loss: 1.039479, acc: 88.48%] [G loss: 1.246640]\n",
      "[Epoch 32/50] [Batch 26/235] [D loss: 1.143239, acc: 85.16%] [G loss: 1.059881]\n",
      "[Epoch 32/50] [Batch 27/235] [D loss: 1.131365, acc: 86.52%] [G loss: 1.020189]\n",
      "[Epoch 32/50] [Batch 28/235] [D loss: 1.115053, acc: 87.89%] [G loss: 1.225478]\n",
      "[Epoch 32/50] [Batch 29/235] [D loss: 1.137145, acc: 86.52%] [G loss: 1.198034]\n",
      "[Epoch 32/50] [Batch 30/235] [D loss: 1.108544, acc: 87.30%] [G loss: 1.214393]\n",
      "[Epoch 32/50] [Batch 31/235] [D loss: 1.138855, acc: 84.96%] [G loss: 1.131846]\n",
      "[Epoch 32/50] [Batch 32/235] [D loss: 1.085886, acc: 87.89%] [G loss: 1.114757]\n",
      "[Epoch 32/50] [Batch 33/235] [D loss: 1.153824, acc: 87.70%] [G loss: 1.118845]\n",
      "[Epoch 32/50] [Batch 34/235] [D loss: 1.132358, acc: 87.11%] [G loss: 1.078318]\n",
      "[Epoch 32/50] [Batch 35/235] [D loss: 1.126379, acc: 88.09%] [G loss: 1.174596]\n",
      "[Epoch 32/50] [Batch 36/235] [D loss: 1.125828, acc: 88.28%] [G loss: 1.115776]\n",
      "[Epoch 32/50] [Batch 37/235] [D loss: 1.164482, acc: 86.52%] [G loss: 1.160620]\n",
      "[Epoch 32/50] [Batch 38/235] [D loss: 1.146518, acc: 88.67%] [G loss: 1.180218]\n",
      "[Epoch 32/50] [Batch 39/235] [D loss: 1.131934, acc: 88.09%] [G loss: 1.083949]\n",
      "[Epoch 32/50] [Batch 40/235] [D loss: 1.100937, acc: 88.87%] [G loss: 1.134865]\n",
      "[Epoch 32/50] [Batch 41/235] [D loss: 1.165960, acc: 85.35%] [G loss: 1.238240]\n",
      "[Epoch 32/50] [Batch 42/235] [D loss: 1.129639, acc: 87.89%] [G loss: 1.182966]\n",
      "[Epoch 32/50] [Batch 43/235] [D loss: 1.173927, acc: 85.16%] [G loss: 1.112626]\n",
      "[Epoch 32/50] [Batch 44/235] [D loss: 1.100643, acc: 86.52%] [G loss: 1.123258]\n",
      "[Epoch 32/50] [Batch 45/235] [D loss: 1.141019, acc: 84.77%] [G loss: 1.130182]\n",
      "[Epoch 32/50] [Batch 46/235] [D loss: 1.132207, acc: 87.11%] [G loss: 1.136568]\n",
      "[Epoch 32/50] [Batch 47/235] [D loss: 1.102993, acc: 86.91%] [G loss: 1.178580]\n",
      "[Epoch 32/50] [Batch 48/235] [D loss: 1.088568, acc: 87.89%] [G loss: 1.364041]\n",
      "[Epoch 32/50] [Batch 49/235] [D loss: 1.167582, acc: 85.74%] [G loss: 1.138097]\n",
      "[Epoch 32/50] [Batch 50/235] [D loss: 1.093107, acc: 88.87%] [G loss: 1.165515]\n",
      "[Epoch 32/50] [Batch 51/235] [D loss: 1.154715, acc: 85.16%] [G loss: 1.061225]\n",
      "[Epoch 32/50] [Batch 52/235] [D loss: 1.122950, acc: 87.89%] [G loss: 1.127669]\n",
      "[Epoch 32/50] [Batch 53/235] [D loss: 1.123454, acc: 86.91%] [G loss: 1.166876]\n",
      "[Epoch 32/50] [Batch 54/235] [D loss: 1.098899, acc: 88.87%] [G loss: 1.128237]\n",
      "[Epoch 32/50] [Batch 55/235] [D loss: 1.143604, acc: 88.48%] [G loss: 1.210929]\n",
      "[Epoch 32/50] [Batch 56/235] [D loss: 1.111879, acc: 87.11%] [G loss: 1.087515]\n",
      "[Epoch 32/50] [Batch 57/235] [D loss: 1.098989, acc: 90.82%] [G loss: 1.091904]\n",
      "[Epoch 32/50] [Batch 58/235] [D loss: 1.128963, acc: 86.52%] [G loss: 1.077258]\n",
      "[Epoch 32/50] [Batch 59/235] [D loss: 1.069062, acc: 88.28%] [G loss: 1.074478]\n",
      "[Epoch 32/50] [Batch 60/235] [D loss: 1.106941, acc: 85.35%] [G loss: 1.250692]\n",
      "[Epoch 32/50] [Batch 61/235] [D loss: 1.143319, acc: 87.50%] [G loss: 1.174417]\n",
      "[Epoch 32/50] [Batch 62/235] [D loss: 1.113826, acc: 90.23%] [G loss: 1.115489]\n",
      "[Epoch 32/50] [Batch 63/235] [D loss: 1.116448, acc: 87.11%] [G loss: 1.114955]\n",
      "[Epoch 32/50] [Batch 64/235] [D loss: 1.131624, acc: 86.33%] [G loss: 1.078079]\n",
      "[Epoch 32/50] [Batch 65/235] [D loss: 1.138735, acc: 88.67%] [G loss: 1.183239]\n",
      "[Epoch 32/50] [Batch 66/235] [D loss: 1.131275, acc: 88.67%] [G loss: 1.154968]\n",
      "[Epoch 32/50] [Batch 67/235] [D loss: 1.104829, acc: 85.94%] [G loss: 1.089319]\n",
      "[Epoch 32/50] [Batch 68/235] [D loss: 1.057332, acc: 87.50%] [G loss: 1.165463]\n",
      "[Epoch 32/50] [Batch 69/235] [D loss: 1.096835, acc: 86.33%] [G loss: 1.227748]\n",
      "[Epoch 32/50] [Batch 70/235] [D loss: 1.138850, acc: 84.96%] [G loss: 1.154332]\n",
      "[Epoch 32/50] [Batch 71/235] [D loss: 1.151515, acc: 90.23%] [G loss: 1.141704]\n",
      "[Epoch 32/50] [Batch 72/235] [D loss: 1.122373, acc: 87.50%] [G loss: 1.029889]\n",
      "[Epoch 32/50] [Batch 73/235] [D loss: 1.074859, acc: 88.09%] [G loss: 1.193939]\n",
      "[Epoch 32/50] [Batch 74/235] [D loss: 1.173117, acc: 86.72%] [G loss: 1.097609]\n",
      "[Epoch 32/50] [Batch 75/235] [D loss: 1.187577, acc: 88.28%] [G loss: 1.105630]\n",
      "[Epoch 32/50] [Batch 76/235] [D loss: 1.105693, acc: 87.89%] [G loss: 1.128992]\n",
      "[Epoch 32/50] [Batch 77/235] [D loss: 1.145037, acc: 86.72%] [G loss: 1.122587]\n",
      "[Epoch 32/50] [Batch 78/235] [D loss: 1.140152, acc: 87.70%] [G loss: 1.154010]\n",
      "[Epoch 32/50] [Batch 79/235] [D loss: 1.070198, acc: 89.06%] [G loss: 1.201140]\n",
      "[Epoch 32/50] [Batch 80/235] [D loss: 1.071238, acc: 87.89%] [G loss: 1.075771]\n",
      "[Epoch 32/50] [Batch 81/235] [D loss: 1.143283, acc: 86.33%] [G loss: 1.087349]\n",
      "[Epoch 32/50] [Batch 82/235] [D loss: 1.084128, acc: 85.55%] [G loss: 1.186120]\n",
      "[Epoch 32/50] [Batch 83/235] [D loss: 1.101910, acc: 86.33%] [G loss: 1.222250]\n",
      "[Epoch 32/50] [Batch 84/235] [D loss: 1.148120, acc: 89.65%] [G loss: 1.240153]\n",
      "[Epoch 32/50] [Batch 85/235] [D loss: 1.131962, acc: 86.33%] [G loss: 1.122386]\n",
      "[Epoch 32/50] [Batch 86/235] [D loss: 1.136064, acc: 87.70%] [G loss: 1.121721]\n",
      "[Epoch 32/50] [Batch 87/235] [D loss: 1.134362, acc: 87.50%] [G loss: 1.108696]\n",
      "[Epoch 32/50] [Batch 88/235] [D loss: 1.103997, acc: 84.57%] [G loss: 1.290216]\n",
      "[Epoch 32/50] [Batch 89/235] [D loss: 1.128137, acc: 90.04%] [G loss: 1.109774]\n",
      "[Epoch 32/50] [Batch 90/235] [D loss: 1.126381, acc: 86.72%] [G loss: 1.156503]\n",
      "[Epoch 32/50] [Batch 91/235] [D loss: 1.109056, acc: 88.67%] [G loss: 1.217960]\n",
      "[Epoch 32/50] [Batch 92/235] [D loss: 1.122014, acc: 85.74%] [G loss: 1.187405]\n",
      "[Epoch 32/50] [Batch 93/235] [D loss: 1.106557, acc: 87.30%] [G loss: 1.142063]\n",
      "[Epoch 32/50] [Batch 94/235] [D loss: 1.148775, acc: 87.11%] [G loss: 1.167696]\n",
      "[Epoch 32/50] [Batch 95/235] [D loss: 1.148886, acc: 84.77%] [G loss: 1.151719]\n",
      "[Epoch 32/50] [Batch 96/235] [D loss: 1.075209, acc: 88.09%] [G loss: 1.112917]\n",
      "[Epoch 32/50] [Batch 97/235] [D loss: 1.118856, acc: 86.33%] [G loss: 1.144204]\n",
      "[Epoch 32/50] [Batch 98/235] [D loss: 1.118327, acc: 87.30%] [G loss: 1.009707]\n",
      "[Epoch 32/50] [Batch 99/235] [D loss: 1.139359, acc: 84.96%] [G loss: 1.213689]\n",
      "[Epoch 32/50] [Batch 100/235] [D loss: 1.089820, acc: 87.89%] [G loss: 1.263829]\n",
      "[Epoch 32/50] [Batch 101/235] [D loss: 1.132951, acc: 86.33%] [G loss: 1.248052]\n",
      "[Epoch 32/50] [Batch 102/235] [D loss: 1.136114, acc: 86.33%] [G loss: 1.123911]\n",
      "[Epoch 32/50] [Batch 103/235] [D loss: 1.126701, acc: 87.70%] [G loss: 1.160859]\n",
      "[Epoch 32/50] [Batch 104/235] [D loss: 1.111078, acc: 87.70%] [G loss: 1.138134]\n",
      "[Epoch 32/50] [Batch 105/235] [D loss: 1.131634, acc: 86.52%] [G loss: 1.217159]\n",
      "[Epoch 32/50] [Batch 106/235] [D loss: 1.122893, acc: 86.91%] [G loss: 1.193542]\n",
      "[Epoch 32/50] [Batch 107/235] [D loss: 1.116475, acc: 88.09%] [G loss: 1.219609]\n",
      "[Epoch 32/50] [Batch 108/235] [D loss: 1.134025, acc: 87.70%] [G loss: 1.178609]\n",
      "[Epoch 32/50] [Batch 109/235] [D loss: 1.049746, acc: 85.35%] [G loss: 1.180264]\n",
      "[Epoch 32/50] [Batch 110/235] [D loss: 1.098462, acc: 87.70%] [G loss: 1.112525]\n",
      "[Epoch 32/50] [Batch 111/235] [D loss: 1.089421, acc: 87.70%] [G loss: 1.075833]\n",
      "[Epoch 32/50] [Batch 112/235] [D loss: 1.150584, acc: 85.16%] [G loss: 1.217113]\n",
      "[Epoch 32/50] [Batch 113/235] [D loss: 1.150454, acc: 85.74%] [G loss: 1.037113]\n",
      "[Epoch 32/50] [Batch 114/235] [D loss: 1.112513, acc: 87.70%] [G loss: 1.163344]\n",
      "[Epoch 32/50] [Batch 115/235] [D loss: 1.154149, acc: 87.30%] [G loss: 1.092410]\n",
      "[Epoch 32/50] [Batch 116/235] [D loss: 1.138940, acc: 85.94%] [G loss: 1.088820]\n",
      "[Epoch 32/50] [Batch 117/235] [D loss: 1.162580, acc: 85.94%] [G loss: 1.065363]\n",
      "[Epoch 32/50] [Batch 118/235] [D loss: 1.076774, acc: 86.72%] [G loss: 1.255774]\n",
      "[Epoch 32/50] [Batch 119/235] [D loss: 1.122803, acc: 86.72%] [G loss: 1.325522]\n",
      "[Epoch 32/50] [Batch 120/235] [D loss: 1.121069, acc: 88.09%] [G loss: 1.116506]\n",
      "[Epoch 32/50] [Batch 121/235] [D loss: 1.126022, acc: 89.65%] [G loss: 1.104599]\n",
      "[Epoch 32/50] [Batch 122/235] [D loss: 1.123905, acc: 85.74%] [G loss: 1.095767]\n",
      "[Epoch 32/50] [Batch 123/235] [D loss: 1.095952, acc: 86.91%] [G loss: 1.246206]\n",
      "[Epoch 32/50] [Batch 124/235] [D loss: 1.107476, acc: 86.72%] [G loss: 1.197948]\n",
      "[Epoch 32/50] [Batch 125/235] [D loss: 1.103550, acc: 88.28%] [G loss: 1.093553]\n",
      "[Epoch 32/50] [Batch 126/235] [D loss: 1.094550, acc: 88.87%] [G loss: 1.171985]\n",
      "[Epoch 32/50] [Batch 127/235] [D loss: 1.078932, acc: 85.94%] [G loss: 1.201906]\n",
      "[Epoch 32/50] [Batch 128/235] [D loss: 1.115834, acc: 86.72%] [G loss: 0.991086]\n",
      "[Epoch 32/50] [Batch 129/235] [D loss: 1.134832, acc: 86.52%] [G loss: 1.114400]\n",
      "[Epoch 32/50] [Batch 130/235] [D loss: 1.129613, acc: 85.55%] [G loss: 1.308822]\n",
      "[Epoch 32/50] [Batch 131/235] [D loss: 1.158880, acc: 87.30%] [G loss: 1.169269]\n",
      "[Epoch 32/50] [Batch 132/235] [D loss: 1.146781, acc: 85.55%] [G loss: 1.222322]\n",
      "[Epoch 32/50] [Batch 133/235] [D loss: 1.071467, acc: 87.11%] [G loss: 1.277546]\n",
      "[Epoch 32/50] [Batch 134/235] [D loss: 1.149310, acc: 87.70%] [G loss: 1.249563]\n",
      "[Epoch 32/50] [Batch 135/235] [D loss: 1.124106, acc: 85.16%] [G loss: 1.302283]\n",
      "[Epoch 32/50] [Batch 136/235] [D loss: 1.134369, acc: 87.30%] [G loss: 1.132220]\n",
      "[Epoch 32/50] [Batch 137/235] [D loss: 1.131953, acc: 85.55%] [G loss: 1.017708]\n",
      "[Epoch 32/50] [Batch 138/235] [D loss: 1.087170, acc: 88.48%] [G loss: 1.105287]\n",
      "[Epoch 32/50] [Batch 139/235] [D loss: 1.085489, acc: 86.13%] [G loss: 1.140678]\n",
      "[Epoch 32/50] [Batch 140/235] [D loss: 1.091779, acc: 85.74%] [G loss: 1.043506]\n",
      "[Epoch 32/50] [Batch 141/235] [D loss: 1.092651, acc: 87.89%] [G loss: 1.186985]\n",
      "[Epoch 32/50] [Batch 142/235] [D loss: 1.159605, acc: 86.91%] [G loss: 1.218938]\n",
      "[Epoch 32/50] [Batch 143/235] [D loss: 1.153339, acc: 87.50%] [G loss: 1.103811]\n",
      "[Epoch 32/50] [Batch 144/235] [D loss: 1.062132, acc: 89.06%] [G loss: 1.148791]\n",
      "[Epoch 32/50] [Batch 145/235] [D loss: 1.178986, acc: 86.33%] [G loss: 1.073402]\n",
      "[Epoch 32/50] [Batch 146/235] [D loss: 1.120588, acc: 82.81%] [G loss: 1.049921]\n",
      "[Epoch 32/50] [Batch 147/235] [D loss: 1.077780, acc: 86.33%] [G loss: 1.148232]\n",
      "[Epoch 32/50] [Batch 148/235] [D loss: 1.103439, acc: 84.38%] [G loss: 1.195381]\n",
      "[Epoch 32/50] [Batch 149/235] [D loss: 1.118443, acc: 85.94%] [G loss: 1.146221]\n",
      "[Epoch 32/50] [Batch 150/235] [D loss: 1.113108, acc: 86.52%] [G loss: 1.165836]\n",
      "[Epoch 32/50] [Batch 151/235] [D loss: 1.129857, acc: 88.48%] [G loss: 1.215160]\n",
      "[Epoch 32/50] [Batch 152/235] [D loss: 1.172249, acc: 87.70%] [G loss: 1.370321]\n",
      "[Epoch 32/50] [Batch 153/235] [D loss: 1.095119, acc: 88.09%] [G loss: 1.091410]\n",
      "[Epoch 32/50] [Batch 154/235] [D loss: 1.073427, acc: 86.52%] [G loss: 1.137169]\n",
      "[Epoch 32/50] [Batch 155/235] [D loss: 1.071828, acc: 88.67%] [G loss: 1.009537]\n",
      "[Epoch 32/50] [Batch 156/235] [D loss: 1.094074, acc: 88.09%] [G loss: 1.111073]\n",
      "[Epoch 32/50] [Batch 157/235] [D loss: 1.120031, acc: 85.16%] [G loss: 1.203749]\n",
      "[Epoch 32/50] [Batch 158/235] [D loss: 1.147676, acc: 86.33%] [G loss: 1.291380]\n",
      "[Epoch 32/50] [Batch 159/235] [D loss: 1.085365, acc: 86.91%] [G loss: 1.074911]\n",
      "[Epoch 32/50] [Batch 160/235] [D loss: 1.093726, acc: 84.57%] [G loss: 1.098195]\n",
      "[Epoch 32/50] [Batch 161/235] [D loss: 1.077851, acc: 88.67%] [G loss: 1.167284]\n",
      "[Epoch 32/50] [Batch 162/235] [D loss: 1.160804, acc: 85.94%] [G loss: 1.401369]\n",
      "[Epoch 32/50] [Batch 163/235] [D loss: 1.125143, acc: 87.70%] [G loss: 1.148388]\n",
      "[Epoch 32/50] [Batch 164/235] [D loss: 1.118040, acc: 85.35%] [G loss: 1.087196]\n",
      "[Epoch 32/50] [Batch 165/235] [D loss: 1.118200, acc: 87.30%] [G loss: 1.155341]\n",
      "[Epoch 32/50] [Batch 166/235] [D loss: 1.143881, acc: 86.91%] [G loss: 1.117158]\n",
      "[Epoch 32/50] [Batch 167/235] [D loss: 1.202935, acc: 88.48%] [G loss: 1.060628]\n",
      "[Epoch 32/50] [Batch 168/235] [D loss: 1.114393, acc: 83.98%] [G loss: 1.102802]\n",
      "[Epoch 32/50] [Batch 169/235] [D loss: 1.105262, acc: 87.11%] [G loss: 1.352554]\n",
      "[Epoch 32/50] [Batch 170/235] [D loss: 1.188981, acc: 84.96%] [G loss: 1.143169]\n",
      "[Epoch 32/50] [Batch 171/235] [D loss: 1.089048, acc: 87.30%] [G loss: 1.114228]\n",
      "[Epoch 32/50] [Batch 172/235] [D loss: 1.120701, acc: 86.91%] [G loss: 1.233700]\n",
      "[Epoch 32/50] [Batch 173/235] [D loss: 1.078668, acc: 88.28%] [G loss: 1.082203]\n",
      "[Epoch 32/50] [Batch 174/235] [D loss: 1.181179, acc: 84.57%] [G loss: 1.131054]\n",
      "[Epoch 32/50] [Batch 175/235] [D loss: 1.109587, acc: 88.48%] [G loss: 1.155200]\n",
      "[Epoch 32/50] [Batch 176/235] [D loss: 1.159880, acc: 87.70%] [G loss: 1.020970]\n",
      "[Epoch 32/50] [Batch 177/235] [D loss: 1.093887, acc: 86.91%] [G loss: 1.094686]\n",
      "[Epoch 32/50] [Batch 178/235] [D loss: 1.102169, acc: 86.72%] [G loss: 1.203115]\n",
      "[Epoch 32/50] [Batch 179/235] [D loss: 1.154528, acc: 86.91%] [G loss: 1.246093]\n",
      "[Epoch 32/50] [Batch 180/235] [D loss: 1.188011, acc: 88.28%] [G loss: 1.203634]\n",
      "[Epoch 32/50] [Batch 181/235] [D loss: 1.085223, acc: 87.50%] [G loss: 1.307414]\n",
      "[Epoch 32/50] [Batch 182/235] [D loss: 1.111262, acc: 87.30%] [G loss: 1.105206]\n",
      "[Epoch 32/50] [Batch 183/235] [D loss: 1.106345, acc: 86.91%] [G loss: 1.070329]\n",
      "[Epoch 32/50] [Batch 184/235] [D loss: 1.083317, acc: 85.94%] [G loss: 1.108792]\n",
      "[Epoch 32/50] [Batch 185/235] [D loss: 1.168461, acc: 87.89%] [G loss: 1.155145]\n",
      "[Epoch 32/50] [Batch 186/235] [D loss: 1.124684, acc: 88.28%] [G loss: 1.212942]\n",
      "[Epoch 32/50] [Batch 187/235] [D loss: 1.078959, acc: 88.67%] [G loss: 1.143709]\n",
      "[Epoch 32/50] [Batch 188/235] [D loss: 1.172880, acc: 86.72%] [G loss: 1.036878]\n",
      "[Epoch 32/50] [Batch 189/235] [D loss: 1.189355, acc: 87.11%] [G loss: 1.097990]\n",
      "[Epoch 32/50] [Batch 190/235] [D loss: 1.140840, acc: 88.48%] [G loss: 1.298397]\n",
      "[Epoch 32/50] [Batch 191/235] [D loss: 1.146039, acc: 85.94%] [G loss: 1.129784]\n",
      "[Epoch 32/50] [Batch 192/235] [D loss: 1.153123, acc: 86.13%] [G loss: 1.074627]\n",
      "[Epoch 32/50] [Batch 193/235] [D loss: 1.162980, acc: 87.30%] [G loss: 1.322958]\n",
      "[Epoch 32/50] [Batch 194/235] [D loss: 1.093321, acc: 86.72%] [G loss: 1.180751]\n",
      "[Epoch 32/50] [Batch 195/235] [D loss: 1.076969, acc: 89.06%] [G loss: 1.125584]\n",
      "[Epoch 32/50] [Batch 196/235] [D loss: 1.114835, acc: 87.70%] [G loss: 1.042570]\n",
      "[Epoch 32/50] [Batch 197/235] [D loss: 1.055252, acc: 86.72%] [G loss: 1.116892]\n",
      "[Epoch 32/50] [Batch 198/235] [D loss: 1.141486, acc: 86.13%] [G loss: 1.273480]\n",
      "[Epoch 32/50] [Batch 199/235] [D loss: 1.135370, acc: 87.11%] [G loss: 1.107319]\n",
      "[Epoch 32/50] [Batch 200/235] [D loss: 1.197344, acc: 86.72%] [G loss: 1.099396]\n",
      "[Epoch 32/50] [Batch 201/235] [D loss: 1.091505, acc: 87.70%] [G loss: 1.075067]\n",
      "[Epoch 32/50] [Batch 202/235] [D loss: 1.125275, acc: 86.13%] [G loss: 1.310064]\n",
      "[Epoch 32/50] [Batch 203/235] [D loss: 1.111045, acc: 88.28%] [G loss: 1.224495]\n",
      "[Epoch 32/50] [Batch 204/235] [D loss: 1.090657, acc: 87.30%] [G loss: 1.211812]\n",
      "[Epoch 32/50] [Batch 205/235] [D loss: 1.120449, acc: 87.30%] [G loss: 1.215041]\n",
      "[Epoch 32/50] [Batch 206/235] [D loss: 1.172111, acc: 86.13%] [G loss: 1.032963]\n",
      "[Epoch 32/50] [Batch 207/235] [D loss: 1.129957, acc: 86.33%] [G loss: 1.122956]\n",
      "[Epoch 32/50] [Batch 208/235] [D loss: 1.124088, acc: 86.72%] [G loss: 1.290801]\n",
      "[Epoch 32/50] [Batch 209/235] [D loss: 1.132320, acc: 86.72%] [G loss: 1.246187]\n",
      "[Epoch 32/50] [Batch 210/235] [D loss: 1.135320, acc: 86.91%] [G loss: 1.070005]\n",
      "[Epoch 32/50] [Batch 211/235] [D loss: 1.134855, acc: 87.11%] [G loss: 1.101943]\n",
      "[Epoch 32/50] [Batch 212/235] [D loss: 1.114832, acc: 85.74%] [G loss: 1.086413]\n",
      "[Epoch 32/50] [Batch 213/235] [D loss: 1.091725, acc: 86.72%] [G loss: 1.190976]\n",
      "[Epoch 32/50] [Batch 214/235] [D loss: 1.123260, acc: 87.70%] [G loss: 1.126680]\n",
      "[Epoch 32/50] [Batch 215/235] [D loss: 1.112056, acc: 85.74%] [G loss: 1.185926]\n",
      "[Epoch 32/50] [Batch 216/235] [D loss: 1.036719, acc: 87.11%] [G loss: 1.181949]\n",
      "[Epoch 32/50] [Batch 217/235] [D loss: 1.100866, acc: 88.87%] [G loss: 1.108259]\n",
      "[Epoch 32/50] [Batch 218/235] [D loss: 1.112215, acc: 89.26%] [G loss: 1.039977]\n",
      "[Epoch 32/50] [Batch 219/235] [D loss: 1.057960, acc: 86.72%] [G loss: 1.218535]\n",
      "[Epoch 32/50] [Batch 220/235] [D loss: 1.101198, acc: 86.52%] [G loss: 1.215360]\n",
      "[Epoch 32/50] [Batch 221/235] [D loss: 1.142564, acc: 85.55%] [G loss: 1.112857]\n",
      "[Epoch 32/50] [Batch 222/235] [D loss: 1.084798, acc: 87.30%] [G loss: 1.141319]\n",
      "[Epoch 32/50] [Batch 223/235] [D loss: 1.111143, acc: 86.13%] [G loss: 1.104757]\n",
      "[Epoch 32/50] [Batch 224/235] [D loss: 1.135804, acc: 87.50%] [G loss: 1.211444]\n",
      "[Epoch 32/50] [Batch 225/235] [D loss: 1.165937, acc: 86.72%] [G loss: 1.142417]\n",
      "[Epoch 32/50] [Batch 226/235] [D loss: 1.081440, acc: 86.52%] [G loss: 1.196427]\n",
      "[Epoch 32/50] [Batch 227/235] [D loss: 1.085168, acc: 84.38%] [G loss: 1.133507]\n",
      "[Epoch 32/50] [Batch 228/235] [D loss: 1.103435, acc: 85.94%] [G loss: 1.091234]\n",
      "[Epoch 32/50] [Batch 229/235] [D loss: 1.101035, acc: 89.84%] [G loss: 1.069245]\n",
      "[Epoch 32/50] [Batch 230/235] [D loss: 1.112497, acc: 89.65%] [G loss: 1.173259]\n",
      "[Epoch 32/50] [Batch 231/235] [D loss: 1.097034, acc: 85.35%] [G loss: 1.221837]\n",
      "[Epoch 32/50] [Batch 232/235] [D loss: 1.107286, acc: 88.48%] [G loss: 1.161679]\n",
      "[Epoch 32/50] [Batch 233/235] [D loss: 1.155845, acc: 89.06%] [G loss: 1.032346]\n",
      "[Epoch 32/50] [Batch 234/235] [D loss: 1.165468, acc: 86.98%] [G loss: 1.143475]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/50] [Batch 0/235] [D loss: 1.094974, acc: 88.28%] [G loss: 1.242118]\n",
      "[Epoch 33/50] [Batch 1/235] [D loss: 1.129036, acc: 89.06%] [G loss: 1.153843]\n",
      "[Epoch 33/50] [Batch 2/235] [D loss: 1.153032, acc: 85.94%] [G loss: 1.061154]\n",
      "[Epoch 33/50] [Batch 3/235] [D loss: 1.141136, acc: 85.94%] [G loss: 1.171375]\n",
      "[Epoch 33/50] [Batch 4/235] [D loss: 1.134250, acc: 88.87%] [G loss: 1.306318]\n",
      "[Epoch 33/50] [Batch 5/235] [D loss: 1.105591, acc: 88.09%] [G loss: 1.239981]\n",
      "[Epoch 33/50] [Batch 6/235] [D loss: 1.194847, acc: 86.91%] [G loss: 1.157034]\n",
      "[Epoch 33/50] [Batch 7/235] [D loss: 1.078960, acc: 89.26%] [G loss: 1.136820]\n",
      "[Epoch 33/50] [Batch 8/235] [D loss: 1.122112, acc: 86.13%] [G loss: 1.128932]\n",
      "[Epoch 33/50] [Batch 9/235] [D loss: 1.131641, acc: 86.33%] [G loss: 1.109025]\n",
      "[Epoch 33/50] [Batch 10/235] [D loss: 1.075000, acc: 89.06%] [G loss: 1.210426]\n",
      "[Epoch 33/50] [Batch 11/235] [D loss: 1.128761, acc: 87.30%] [G loss: 1.253848]\n",
      "[Epoch 33/50] [Batch 12/235] [D loss: 1.130776, acc: 89.84%] [G loss: 1.101368]\n",
      "[Epoch 33/50] [Batch 13/235] [D loss: 1.143437, acc: 86.13%] [G loss: 1.212031]\n",
      "[Epoch 33/50] [Batch 14/235] [D loss: 1.120329, acc: 86.72%] [G loss: 1.228397]\n",
      "[Epoch 33/50] [Batch 15/235] [D loss: 1.122940, acc: 87.11%] [G loss: 1.139161]\n",
      "[Epoch 33/50] [Batch 16/235] [D loss: 1.192189, acc: 86.52%] [G loss: 1.128222]\n",
      "[Epoch 33/50] [Batch 17/235] [D loss: 1.120081, acc: 85.74%] [G loss: 1.106308]\n",
      "[Epoch 33/50] [Batch 18/235] [D loss: 1.066633, acc: 85.35%] [G loss: 1.183055]\n",
      "[Epoch 33/50] [Batch 19/235] [D loss: 1.168197, acc: 87.70%] [G loss: 1.279377]\n",
      "[Epoch 33/50] [Batch 20/235] [D loss: 1.115894, acc: 87.30%] [G loss: 1.088550]\n",
      "[Epoch 33/50] [Batch 21/235] [D loss: 1.126923, acc: 84.77%] [G loss: 1.234118]\n",
      "[Epoch 33/50] [Batch 22/235] [D loss: 1.161450, acc: 86.13%] [G loss: 1.311992]\n",
      "[Epoch 33/50] [Batch 23/235] [D loss: 1.125750, acc: 87.89%] [G loss: 1.195126]\n",
      "[Epoch 33/50] [Batch 24/235] [D loss: 1.100842, acc: 90.43%] [G loss: 1.158976]\n",
      "[Epoch 33/50] [Batch 25/235] [D loss: 1.148377, acc: 86.33%] [G loss: 1.253317]\n",
      "[Epoch 33/50] [Batch 26/235] [D loss: 1.088810, acc: 86.13%] [G loss: 1.096575]\n",
      "[Epoch 33/50] [Batch 27/235] [D loss: 1.089354, acc: 88.67%] [G loss: 1.045075]\n",
      "[Epoch 33/50] [Batch 28/235] [D loss: 1.120559, acc: 87.11%] [G loss: 1.085176]\n",
      "[Epoch 33/50] [Batch 29/235] [D loss: 1.162612, acc: 87.11%] [G loss: 1.269432]\n",
      "[Epoch 33/50] [Batch 30/235] [D loss: 1.126085, acc: 86.52%] [G loss: 1.189428]\n",
      "[Epoch 33/50] [Batch 31/235] [D loss: 1.091122, acc: 86.33%] [G loss: 1.116502]\n",
      "[Epoch 33/50] [Batch 32/235] [D loss: 1.115181, acc: 86.91%] [G loss: 1.019552]\n",
      "[Epoch 33/50] [Batch 33/235] [D loss: 1.087117, acc: 86.72%] [G loss: 1.155871]\n",
      "[Epoch 33/50] [Batch 34/235] [D loss: 1.125648, acc: 87.11%] [G loss: 1.124437]\n",
      "[Epoch 33/50] [Batch 35/235] [D loss: 1.111941, acc: 85.94%] [G loss: 1.045864]\n",
      "[Epoch 33/50] [Batch 36/235] [D loss: 1.134650, acc: 86.52%] [G loss: 1.151595]\n",
      "[Epoch 33/50] [Batch 37/235] [D loss: 1.122886, acc: 86.13%] [G loss: 1.211682]\n",
      "[Epoch 33/50] [Batch 38/235] [D loss: 1.173572, acc: 87.11%] [G loss: 1.263744]\n",
      "[Epoch 33/50] [Batch 39/235] [D loss: 1.079157, acc: 90.23%] [G loss: 1.191788]\n",
      "[Epoch 33/50] [Batch 40/235] [D loss: 1.102384, acc: 89.26%] [G loss: 1.122329]\n",
      "[Epoch 33/50] [Batch 41/235] [D loss: 1.085744, acc: 86.13%] [G loss: 1.115614]\n",
      "[Epoch 33/50] [Batch 42/235] [D loss: 1.099275, acc: 87.70%] [G loss: 1.098167]\n",
      "[Epoch 33/50] [Batch 43/235] [D loss: 1.188948, acc: 87.70%] [G loss: 1.130804]\n",
      "[Epoch 33/50] [Batch 44/235] [D loss: 1.098882, acc: 89.06%] [G loss: 1.075562]\n",
      "[Epoch 33/50] [Batch 45/235] [D loss: 1.105581, acc: 87.89%] [G loss: 1.156010]\n",
      "[Epoch 33/50] [Batch 46/235] [D loss: 1.171518, acc: 87.11%] [G loss: 1.185716]\n",
      "[Epoch 33/50] [Batch 47/235] [D loss: 1.058430, acc: 86.52%] [G loss: 1.158006]\n",
      "[Epoch 33/50] [Batch 48/235] [D loss: 1.124055, acc: 84.96%] [G loss: 1.091789]\n",
      "[Epoch 33/50] [Batch 49/235] [D loss: 1.116512, acc: 89.06%] [G loss: 1.183467]\n",
      "[Epoch 33/50] [Batch 50/235] [D loss: 1.113579, acc: 85.74%] [G loss: 1.211878]\n",
      "[Epoch 33/50] [Batch 51/235] [D loss: 1.127270, acc: 84.96%] [G loss: 1.157668]\n",
      "[Epoch 33/50] [Batch 52/235] [D loss: 1.108566, acc: 87.11%] [G loss: 1.157435]\n",
      "[Epoch 33/50] [Batch 53/235] [D loss: 1.142989, acc: 86.52%] [G loss: 1.237219]\n",
      "[Epoch 33/50] [Batch 54/235] [D loss: 1.085661, acc: 86.33%] [G loss: 1.093046]\n",
      "[Epoch 33/50] [Batch 55/235] [D loss: 1.123460, acc: 86.52%] [G loss: 1.039912]\n",
      "[Epoch 33/50] [Batch 56/235] [D loss: 1.092074, acc: 85.94%] [G loss: 1.177147]\n",
      "[Epoch 33/50] [Batch 57/235] [D loss: 1.039227, acc: 87.11%] [G loss: 1.258982]\n",
      "[Epoch 33/50] [Batch 58/235] [D loss: 1.121746, acc: 87.11%] [G loss: 1.145800]\n",
      "[Epoch 33/50] [Batch 59/235] [D loss: 1.183922, acc: 86.33%] [G loss: 0.966236]\n",
      "[Epoch 33/50] [Batch 60/235] [D loss: 1.070693, acc: 85.16%] [G loss: 1.031721]\n",
      "[Epoch 33/50] [Batch 61/235] [D loss: 1.145759, acc: 88.28%] [G loss: 1.122936]\n",
      "[Epoch 33/50] [Batch 62/235] [D loss: 1.123918, acc: 88.28%] [G loss: 1.271027]\n",
      "[Epoch 33/50] [Batch 63/235] [D loss: 1.103967, acc: 86.52%] [G loss: 1.161921]\n",
      "[Epoch 33/50] [Batch 64/235] [D loss: 1.129974, acc: 87.70%] [G loss: 1.035806]\n",
      "[Epoch 33/50] [Batch 65/235] [D loss: 1.058258, acc: 87.11%] [G loss: 1.158335]\n",
      "[Epoch 33/50] [Batch 66/235] [D loss: 1.125676, acc: 85.55%] [G loss: 1.241318]\n",
      "[Epoch 33/50] [Batch 67/235] [D loss: 1.087864, acc: 86.91%] [G loss: 1.387829]\n",
      "[Epoch 33/50] [Batch 68/235] [D loss: 1.130297, acc: 88.48%] [G loss: 1.104147]\n",
      "[Epoch 33/50] [Batch 69/235] [D loss: 1.079610, acc: 88.48%] [G loss: 1.170997]\n",
      "[Epoch 33/50] [Batch 70/235] [D loss: 1.146320, acc: 87.30%] [G loss: 1.161397]\n",
      "[Epoch 33/50] [Batch 71/235] [D loss: 1.060120, acc: 87.70%] [G loss: 1.218188]\n",
      "[Epoch 33/50] [Batch 72/235] [D loss: 1.089860, acc: 89.06%] [G loss: 1.187693]\n",
      "[Epoch 33/50] [Batch 73/235] [D loss: 1.119529, acc: 84.96%] [G loss: 1.203067]\n",
      "[Epoch 33/50] [Batch 74/235] [D loss: 1.100591, acc: 85.55%] [G loss: 1.188511]\n",
      "[Epoch 33/50] [Batch 75/235] [D loss: 1.148175, acc: 86.13%] [G loss: 1.235659]\n",
      "[Epoch 33/50] [Batch 76/235] [D loss: 1.125054, acc: 86.13%] [G loss: 1.101498]\n",
      "[Epoch 33/50] [Batch 77/235] [D loss: 1.117537, acc: 86.91%] [G loss: 1.163816]\n",
      "[Epoch 33/50] [Batch 78/235] [D loss: 1.168726, acc: 85.35%] [G loss: 1.084486]\n",
      "[Epoch 33/50] [Batch 79/235] [D loss: 1.169949, acc: 86.72%] [G loss: 1.310236]\n",
      "[Epoch 33/50] [Batch 80/235] [D loss: 1.118299, acc: 88.48%] [G loss: 1.145020]\n",
      "[Epoch 33/50] [Batch 81/235] [D loss: 1.134154, acc: 86.52%] [G loss: 1.216092]\n",
      "[Epoch 33/50] [Batch 82/235] [D loss: 1.109102, acc: 86.91%] [G loss: 1.090423]\n",
      "[Epoch 33/50] [Batch 83/235] [D loss: 1.146082, acc: 87.50%] [G loss: 1.239232]\n",
      "[Epoch 33/50] [Batch 84/235] [D loss: 1.154719, acc: 88.48%] [G loss: 1.181813]\n",
      "[Epoch 33/50] [Batch 85/235] [D loss: 1.077578, acc: 86.52%] [G loss: 1.211574]\n",
      "[Epoch 33/50] [Batch 86/235] [D loss: 1.068254, acc: 88.28%] [G loss: 1.222611]\n",
      "[Epoch 33/50] [Batch 87/235] [D loss: 1.131422, acc: 87.70%] [G loss: 1.207503]\n",
      "[Epoch 33/50] [Batch 88/235] [D loss: 1.143073, acc: 85.94%] [G loss: 1.159051]\n",
      "[Epoch 33/50] [Batch 89/235] [D loss: 1.092572, acc: 86.13%] [G loss: 1.071165]\n",
      "[Epoch 33/50] [Batch 90/235] [D loss: 1.086338, acc: 88.28%] [G loss: 1.165479]\n",
      "[Epoch 33/50] [Batch 91/235] [D loss: 1.115743, acc: 90.04%] [G loss: 1.248845]\n",
      "[Epoch 33/50] [Batch 92/235] [D loss: 1.112733, acc: 87.11%] [G loss: 1.228019]\n",
      "[Epoch 33/50] [Batch 93/235] [D loss: 1.135838, acc: 86.52%] [G loss: 1.154506]\n",
      "[Epoch 33/50] [Batch 94/235] [D loss: 1.091013, acc: 86.72%] [G loss: 1.099458]\n",
      "[Epoch 33/50] [Batch 95/235] [D loss: 1.096498, acc: 88.09%] [G loss: 1.042731]\n",
      "[Epoch 33/50] [Batch 96/235] [D loss: 1.060127, acc: 88.09%] [G loss: 1.124882]\n",
      "[Epoch 33/50] [Batch 97/235] [D loss: 1.075481, acc: 89.26%] [G loss: 1.211096]\n",
      "[Epoch 33/50] [Batch 98/235] [D loss: 1.190484, acc: 83.01%] [G loss: 1.112023]\n",
      "[Epoch 33/50] [Batch 99/235] [D loss: 1.118631, acc: 84.96%] [G loss: 1.093642]\n",
      "[Epoch 33/50] [Batch 100/235] [D loss: 1.062618, acc: 84.18%] [G loss: 1.150934]\n",
      "[Epoch 33/50] [Batch 101/235] [D loss: 1.059112, acc: 87.89%] [G loss: 1.200655]\n",
      "[Epoch 33/50] [Batch 102/235] [D loss: 1.102271, acc: 88.67%] [G loss: 1.173219]\n",
      "[Epoch 33/50] [Batch 103/235] [D loss: 1.120280, acc: 87.70%] [G loss: 1.107280]\n",
      "[Epoch 33/50] [Batch 104/235] [D loss: 1.077564, acc: 86.91%] [G loss: 1.291513]\n",
      "[Epoch 33/50] [Batch 105/235] [D loss: 1.094570, acc: 86.13%] [G loss: 1.073746]\n",
      "[Epoch 33/50] [Batch 106/235] [D loss: 1.101706, acc: 87.70%] [G loss: 1.266257]\n",
      "[Epoch 33/50] [Batch 107/235] [D loss: 1.102726, acc: 86.33%] [G loss: 1.070143]\n",
      "[Epoch 33/50] [Batch 108/235] [D loss: 1.076137, acc: 87.30%] [G loss: 1.109692]\n",
      "[Epoch 33/50] [Batch 109/235] [D loss: 1.092002, acc: 88.09%] [G loss: 1.182598]\n",
      "[Epoch 33/50] [Batch 110/235] [D loss: 1.118402, acc: 88.09%] [G loss: 1.292720]\n",
      "[Epoch 33/50] [Batch 111/235] [D loss: 1.124942, acc: 86.91%] [G loss: 1.272221]\n",
      "[Epoch 33/50] [Batch 112/235] [D loss: 1.138852, acc: 84.77%] [G loss: 1.178606]\n",
      "[Epoch 33/50] [Batch 113/235] [D loss: 1.073012, acc: 89.06%] [G loss: 1.146211]\n",
      "[Epoch 33/50] [Batch 114/235] [D loss: 1.113952, acc: 87.11%] [G loss: 1.247504]\n",
      "[Epoch 33/50] [Batch 115/235] [D loss: 1.178581, acc: 87.50%] [G loss: 1.056028]\n",
      "[Epoch 33/50] [Batch 116/235] [D loss: 1.139245, acc: 88.09%] [G loss: 1.158962]\n",
      "[Epoch 33/50] [Batch 117/235] [D loss: 1.172398, acc: 86.91%] [G loss: 1.070294]\n",
      "[Epoch 33/50] [Batch 118/235] [D loss: 1.081909, acc: 88.09%] [G loss: 1.211828]\n",
      "[Epoch 33/50] [Batch 119/235] [D loss: 1.114388, acc: 86.52%] [G loss: 1.294343]\n",
      "[Epoch 33/50] [Batch 120/235] [D loss: 1.114266, acc: 87.89%] [G loss: 1.204168]\n",
      "[Epoch 33/50] [Batch 121/235] [D loss: 1.067965, acc: 87.89%] [G loss: 1.145854]\n",
      "[Epoch 33/50] [Batch 122/235] [D loss: 1.079314, acc: 85.74%] [G loss: 1.186977]\n",
      "[Epoch 33/50] [Batch 123/235] [D loss: 1.172728, acc: 87.11%] [G loss: 1.207870]\n",
      "[Epoch 33/50] [Batch 124/235] [D loss: 1.158976, acc: 87.70%] [G loss: 1.123694]\n",
      "[Epoch 33/50] [Batch 125/235] [D loss: 1.106247, acc: 87.11%] [G loss: 1.123272]\n",
      "[Epoch 33/50] [Batch 126/235] [D loss: 1.096968, acc: 86.13%] [G loss: 1.042005]\n",
      "[Epoch 33/50] [Batch 127/235] [D loss: 1.107624, acc: 88.28%] [G loss: 1.102025]\n",
      "[Epoch 33/50] [Batch 128/235] [D loss: 1.203453, acc: 85.94%] [G loss: 1.217537]\n",
      "[Epoch 33/50] [Batch 129/235] [D loss: 1.091599, acc: 87.70%] [G loss: 1.189946]\n",
      "[Epoch 33/50] [Batch 130/235] [D loss: 1.130931, acc: 83.20%] [G loss: 1.158972]\n",
      "[Epoch 33/50] [Batch 131/235] [D loss: 1.144342, acc: 86.33%] [G loss: 1.187398]\n",
      "[Epoch 33/50] [Batch 132/235] [D loss: 1.110418, acc: 88.87%] [G loss: 1.159766]\n",
      "[Epoch 33/50] [Batch 133/235] [D loss: 1.132633, acc: 87.50%] [G loss: 1.140089]\n",
      "[Epoch 33/50] [Batch 134/235] [D loss: 1.083970, acc: 87.89%] [G loss: 1.091849]\n",
      "[Epoch 33/50] [Batch 135/235] [D loss: 1.143447, acc: 86.72%] [G loss: 1.309152]\n",
      "[Epoch 33/50] [Batch 136/235] [D loss: 1.095370, acc: 87.70%] [G loss: 1.094112]\n",
      "[Epoch 33/50] [Batch 137/235] [D loss: 1.155415, acc: 87.50%] [G loss: 0.988221]\n",
      "[Epoch 33/50] [Batch 138/235] [D loss: 1.099570, acc: 86.72%] [G loss: 1.026001]\n",
      "[Epoch 33/50] [Batch 139/235] [D loss: 1.174766, acc: 89.26%] [G loss: 1.164738]\n",
      "[Epoch 33/50] [Batch 140/235] [D loss: 1.172035, acc: 89.65%] [G loss: 1.379514]\n",
      "[Epoch 33/50] [Batch 141/235] [D loss: 1.085452, acc: 90.82%] [G loss: 1.200291]\n",
      "[Epoch 33/50] [Batch 142/235] [D loss: 1.120200, acc: 87.11%] [G loss: 1.079889]\n",
      "[Epoch 33/50] [Batch 143/235] [D loss: 1.102450, acc: 86.33%] [G loss: 1.122977]\n",
      "[Epoch 33/50] [Batch 144/235] [D loss: 1.049497, acc: 86.33%] [G loss: 1.186770]\n",
      "[Epoch 33/50] [Batch 145/235] [D loss: 1.156117, acc: 86.72%] [G loss: 1.194973]\n",
      "[Epoch 33/50] [Batch 146/235] [D loss: 1.157511, acc: 84.96%] [G loss: 1.196499]\n",
      "[Epoch 33/50] [Batch 147/235] [D loss: 1.123597, acc: 86.72%] [G loss: 1.129205]\n",
      "[Epoch 33/50] [Batch 148/235] [D loss: 1.166610, acc: 86.33%] [G loss: 1.241428]\n",
      "[Epoch 33/50] [Batch 149/235] [D loss: 1.164582, acc: 84.38%] [G loss: 1.122187]\n",
      "[Epoch 33/50] [Batch 150/235] [D loss: 1.138764, acc: 86.33%] [G loss: 1.178895]\n",
      "[Epoch 33/50] [Batch 151/235] [D loss: 1.137800, acc: 88.67%] [G loss: 1.156293]\n",
      "[Epoch 33/50] [Batch 152/235] [D loss: 1.145925, acc: 85.55%] [G loss: 1.211102]\n",
      "[Epoch 33/50] [Batch 153/235] [D loss: 1.140612, acc: 86.52%] [G loss: 1.145330]\n",
      "[Epoch 33/50] [Batch 154/235] [D loss: 1.104292, acc: 86.72%] [G loss: 1.226850]\n",
      "[Epoch 33/50] [Batch 155/235] [D loss: 1.112518, acc: 85.35%] [G loss: 1.180025]\n",
      "[Epoch 33/50] [Batch 156/235] [D loss: 1.138714, acc: 86.33%] [G loss: 1.090050]\n",
      "[Epoch 33/50] [Batch 157/235] [D loss: 1.102372, acc: 89.06%] [G loss: 1.085317]\n",
      "[Epoch 33/50] [Batch 158/235] [D loss: 1.127003, acc: 87.50%] [G loss: 1.139167]\n",
      "[Epoch 33/50] [Batch 159/235] [D loss: 1.055213, acc: 85.74%] [G loss: 1.193611]\n",
      "[Epoch 33/50] [Batch 160/235] [D loss: 1.157076, acc: 90.43%] [G loss: 1.098994]\n",
      "[Epoch 33/50] [Batch 161/235] [D loss: 1.092846, acc: 87.70%] [G loss: 1.163298]\n",
      "[Epoch 33/50] [Batch 162/235] [D loss: 1.088231, acc: 86.72%] [G loss: 1.132725]\n",
      "[Epoch 33/50] [Batch 163/235] [D loss: 1.114283, acc: 88.09%] [G loss: 1.095246]\n",
      "[Epoch 33/50] [Batch 164/235] [D loss: 1.087274, acc: 87.50%] [G loss: 1.250451]\n",
      "[Epoch 33/50] [Batch 165/235] [D loss: 1.230371, acc: 85.74%] [G loss: 1.162370]\n",
      "[Epoch 33/50] [Batch 166/235] [D loss: 1.109507, acc: 84.96%] [G loss: 1.269106]\n",
      "[Epoch 33/50] [Batch 167/235] [D loss: 1.086080, acc: 85.55%] [G loss: 1.124246]\n",
      "[Epoch 33/50] [Batch 168/235] [D loss: 1.099199, acc: 86.72%] [G loss: 1.206350]\n",
      "[Epoch 33/50] [Batch 169/235] [D loss: 1.081411, acc: 85.16%] [G loss: 1.139181]\n",
      "[Epoch 33/50] [Batch 170/235] [D loss: 1.106100, acc: 87.89%] [G loss: 1.255058]\n",
      "[Epoch 33/50] [Batch 171/235] [D loss: 1.077789, acc: 89.65%] [G loss: 1.087001]\n",
      "[Epoch 33/50] [Batch 172/235] [D loss: 1.144416, acc: 85.94%] [G loss: 1.172508]\n",
      "[Epoch 33/50] [Batch 173/235] [D loss: 1.121018, acc: 85.35%] [G loss: 1.172352]\n",
      "[Epoch 33/50] [Batch 174/235] [D loss: 1.091681, acc: 87.11%] [G loss: 1.277261]\n",
      "[Epoch 33/50] [Batch 175/235] [D loss: 1.114677, acc: 87.70%] [G loss: 1.183104]\n",
      "[Epoch 33/50] [Batch 176/235] [D loss: 1.162010, acc: 87.70%] [G loss: 1.077496]\n",
      "[Epoch 33/50] [Batch 177/235] [D loss: 1.181186, acc: 87.50%] [G loss: 1.171954]\n",
      "[Epoch 33/50] [Batch 178/235] [D loss: 1.114197, acc: 85.35%] [G loss: 1.178675]\n",
      "[Epoch 33/50] [Batch 179/235] [D loss: 1.121342, acc: 85.94%] [G loss: 1.004963]\n",
      "[Epoch 33/50] [Batch 180/235] [D loss: 1.081997, acc: 87.70%] [G loss: 1.047054]\n",
      "[Epoch 33/50] [Batch 181/235] [D loss: 1.066376, acc: 87.11%] [G loss: 1.079000]\n",
      "[Epoch 33/50] [Batch 182/235] [D loss: 1.125363, acc: 86.52%] [G loss: 1.148657]\n",
      "[Epoch 33/50] [Batch 183/235] [D loss: 1.121554, acc: 87.70%] [G loss: 1.213504]\n",
      "[Epoch 33/50] [Batch 184/235] [D loss: 1.124376, acc: 87.30%] [G loss: 1.233930]\n",
      "[Epoch 33/50] [Batch 185/235] [D loss: 1.150601, acc: 89.26%] [G loss: 1.195999]\n",
      "[Epoch 33/50] [Batch 186/235] [D loss: 1.078058, acc: 88.87%] [G loss: 1.046891]\n",
      "[Epoch 33/50] [Batch 187/235] [D loss: 1.148337, acc: 85.94%] [G loss: 1.088150]\n",
      "[Epoch 33/50] [Batch 188/235] [D loss: 1.115337, acc: 88.09%] [G loss: 1.145116]\n",
      "[Epoch 33/50] [Batch 189/235] [D loss: 1.049061, acc: 87.89%] [G loss: 1.200040]\n",
      "[Epoch 33/50] [Batch 190/235] [D loss: 1.053929, acc: 89.45%] [G loss: 1.164407]\n",
      "[Epoch 33/50] [Batch 191/235] [D loss: 1.118723, acc: 87.89%] [G loss: 1.137476]\n",
      "[Epoch 33/50] [Batch 192/235] [D loss: 1.154483, acc: 85.94%] [G loss: 1.097165]\n",
      "[Epoch 33/50] [Batch 193/235] [D loss: 1.106408, acc: 85.55%] [G loss: 1.293851]\n",
      "[Epoch 33/50] [Batch 194/235] [D loss: 1.124895, acc: 87.11%] [G loss: 1.218780]\n",
      "[Epoch 33/50] [Batch 195/235] [D loss: 1.196333, acc: 85.55%] [G loss: 1.113272]\n",
      "[Epoch 33/50] [Batch 196/235] [D loss: 1.091018, acc: 84.77%] [G loss: 1.276344]\n",
      "[Epoch 33/50] [Batch 197/235] [D loss: 1.129325, acc: 86.33%] [G loss: 1.156611]\n",
      "[Epoch 33/50] [Batch 198/235] [D loss: 1.143498, acc: 86.13%] [G loss: 1.204275]\n",
      "[Epoch 33/50] [Batch 199/235] [D loss: 1.120103, acc: 87.30%] [G loss: 1.088525]\n",
      "[Epoch 33/50] [Batch 200/235] [D loss: 1.130393, acc: 85.55%] [G loss: 1.110048]\n",
      "[Epoch 33/50] [Batch 201/235] [D loss: 1.095791, acc: 85.94%] [G loss: 1.131552]\n",
      "[Epoch 33/50] [Batch 202/235] [D loss: 1.063787, acc: 88.67%] [G loss: 1.071486]\n",
      "[Epoch 33/50] [Batch 203/235] [D loss: 1.092219, acc: 85.35%] [G loss: 1.087513]\n",
      "[Epoch 33/50] [Batch 204/235] [D loss: 1.120423, acc: 88.28%] [G loss: 1.224655]\n",
      "[Epoch 33/50] [Batch 205/235] [D loss: 1.031495, acc: 88.48%] [G loss: 1.224282]\n",
      "[Epoch 33/50] [Batch 206/235] [D loss: 1.054746, acc: 87.89%] [G loss: 1.094806]\n",
      "[Epoch 33/50] [Batch 207/235] [D loss: 1.141016, acc: 85.94%] [G loss: 1.177312]\n",
      "[Epoch 33/50] [Batch 208/235] [D loss: 1.103514, acc: 88.09%] [G loss: 1.232692]\n",
      "[Epoch 33/50] [Batch 209/235] [D loss: 1.184525, acc: 88.48%] [G loss: 1.091166]\n",
      "[Epoch 33/50] [Batch 210/235] [D loss: 1.121127, acc: 86.13%] [G loss: 1.047952]\n",
      "[Epoch 33/50] [Batch 211/235] [D loss: 1.085917, acc: 88.28%] [G loss: 1.155449]\n",
      "[Epoch 33/50] [Batch 212/235] [D loss: 1.156006, acc: 88.09%] [G loss: 1.159642]\n",
      "[Epoch 33/50] [Batch 213/235] [D loss: 1.079353, acc: 87.50%] [G loss: 1.119809]\n",
      "[Epoch 33/50] [Batch 214/235] [D loss: 1.180830, acc: 89.45%] [G loss: 1.101817]\n",
      "[Epoch 33/50] [Batch 215/235] [D loss: 1.122762, acc: 88.67%] [G loss: 1.175621]\n",
      "[Epoch 33/50] [Batch 216/235] [D loss: 1.129566, acc: 88.87%] [G loss: 1.224087]\n",
      "[Epoch 33/50] [Batch 217/235] [D loss: 1.034739, acc: 89.65%] [G loss: 1.213432]\n",
      "[Epoch 33/50] [Batch 218/235] [D loss: 1.188073, acc: 87.11%] [G loss: 1.009956]\n",
      "[Epoch 33/50] [Batch 219/235] [D loss: 1.090160, acc: 87.11%] [G loss: 1.158493]\n",
      "[Epoch 33/50] [Batch 220/235] [D loss: 1.122863, acc: 87.70%] [G loss: 1.328082]\n",
      "[Epoch 33/50] [Batch 221/235] [D loss: 1.097057, acc: 88.48%] [G loss: 1.180030]\n",
      "[Epoch 33/50] [Batch 222/235] [D loss: 1.097134, acc: 86.52%] [G loss: 1.133709]\n",
      "[Epoch 33/50] [Batch 223/235] [D loss: 1.105408, acc: 87.11%] [G loss: 1.195469]\n",
      "[Epoch 33/50] [Batch 224/235] [D loss: 1.098799, acc: 86.52%] [G loss: 1.074444]\n",
      "[Epoch 33/50] [Batch 225/235] [D loss: 1.094233, acc: 86.72%] [G loss: 1.094557]\n",
      "[Epoch 33/50] [Batch 226/235] [D loss: 1.135258, acc: 87.30%] [G loss: 1.166570]\n",
      "[Epoch 33/50] [Batch 227/235] [D loss: 1.121976, acc: 87.50%] [G loss: 1.266811]\n",
      "[Epoch 33/50] [Batch 228/235] [D loss: 1.085452, acc: 86.52%] [G loss: 1.216417]\n",
      "[Epoch 33/50] [Batch 229/235] [D loss: 1.124137, acc: 85.35%] [G loss: 1.083891]\n",
      "[Epoch 33/50] [Batch 230/235] [D loss: 1.092913, acc: 88.28%] [G loss: 1.215253]\n",
      "[Epoch 33/50] [Batch 231/235] [D loss: 1.113872, acc: 85.55%] [G loss: 1.150946]\n",
      "[Epoch 33/50] [Batch 232/235] [D loss: 1.113426, acc: 87.89%] [G loss: 1.273562]\n",
      "[Epoch 33/50] [Batch 233/235] [D loss: 1.103957, acc: 87.11%] [G loss: 1.106904]\n",
      "[Epoch 33/50] [Batch 234/235] [D loss: 1.117554, acc: 88.02%] [G loss: 1.123515]\n",
      "[Epoch 34/50] [Batch 0/235] [D loss: 1.058753, acc: 87.89%] [G loss: 1.171102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/50] [Batch 1/235] [D loss: 1.099268, acc: 88.48%] [G loss: 1.132805]\n",
      "[Epoch 34/50] [Batch 2/235] [D loss: 1.076794, acc: 88.09%] [G loss: 1.118906]\n",
      "[Epoch 34/50] [Batch 3/235] [D loss: 1.146583, acc: 87.89%] [G loss: 1.142453]\n",
      "[Epoch 34/50] [Batch 4/235] [D loss: 1.158193, acc: 86.52%] [G loss: 1.134280]\n",
      "[Epoch 34/50] [Batch 5/235] [D loss: 1.112532, acc: 86.52%] [G loss: 1.072259]\n",
      "[Epoch 34/50] [Batch 6/235] [D loss: 1.132414, acc: 86.72%] [G loss: 1.194353]\n",
      "[Epoch 34/50] [Batch 7/235] [D loss: 1.075418, acc: 86.72%] [G loss: 1.182762]\n",
      "[Epoch 34/50] [Batch 8/235] [D loss: 1.078177, acc: 89.65%] [G loss: 1.099554]\n",
      "[Epoch 34/50] [Batch 9/235] [D loss: 1.127224, acc: 87.70%] [G loss: 1.060494]\n",
      "[Epoch 34/50] [Batch 10/235] [D loss: 1.068965, acc: 88.09%] [G loss: 1.099182]\n",
      "[Epoch 34/50] [Batch 11/235] [D loss: 1.165105, acc: 85.35%] [G loss: 1.049161]\n",
      "[Epoch 34/50] [Batch 12/235] [D loss: 1.120669, acc: 87.11%] [G loss: 1.242534]\n",
      "[Epoch 34/50] [Batch 13/235] [D loss: 1.110597, acc: 87.89%] [G loss: 1.123931]\n",
      "[Epoch 34/50] [Batch 14/235] [D loss: 1.102417, acc: 83.59%] [G loss: 1.161325]\n",
      "[Epoch 34/50] [Batch 15/235] [D loss: 1.157775, acc: 88.48%] [G loss: 1.099623]\n",
      "[Epoch 34/50] [Batch 16/235] [D loss: 1.092690, acc: 86.91%] [G loss: 1.267938]\n",
      "[Epoch 34/50] [Batch 17/235] [D loss: 1.185325, acc: 88.48%] [G loss: 1.375535]\n",
      "[Epoch 34/50] [Batch 18/235] [D loss: 1.093155, acc: 88.28%] [G loss: 1.136102]\n",
      "[Epoch 34/50] [Batch 19/235] [D loss: 1.129512, acc: 89.06%] [G loss: 0.990234]\n",
      "[Epoch 34/50] [Batch 20/235] [D loss: 1.127307, acc: 87.11%] [G loss: 1.089803]\n",
      "[Epoch 34/50] [Batch 21/235] [D loss: 1.133780, acc: 87.89%] [G loss: 1.356436]\n",
      "[Epoch 34/50] [Batch 22/235] [D loss: 1.086051, acc: 86.13%] [G loss: 1.291794]\n",
      "[Epoch 34/50] [Batch 23/235] [D loss: 1.094367, acc: 86.52%] [G loss: 1.138437]\n",
      "[Epoch 34/50] [Batch 24/235] [D loss: 1.149178, acc: 86.91%] [G loss: 1.122195]\n",
      "[Epoch 34/50] [Batch 25/235] [D loss: 1.125284, acc: 87.70%] [G loss: 1.090474]\n",
      "[Epoch 34/50] [Batch 26/235] [D loss: 1.127542, acc: 86.33%] [G loss: 1.253220]\n",
      "[Epoch 34/50] [Batch 27/235] [D loss: 1.113773, acc: 88.67%] [G loss: 1.246927]\n",
      "[Epoch 34/50] [Batch 28/235] [D loss: 1.135692, acc: 84.18%] [G loss: 1.101905]\n",
      "[Epoch 34/50] [Batch 29/235] [D loss: 1.155569, acc: 84.96%] [G loss: 0.975699]\n",
      "[Epoch 34/50] [Batch 30/235] [D loss: 1.099645, acc: 86.52%] [G loss: 1.070060]\n",
      "[Epoch 34/50] [Batch 31/235] [D loss: 1.164033, acc: 86.52%] [G loss: 1.230767]\n",
      "[Epoch 34/50] [Batch 32/235] [D loss: 1.092787, acc: 87.11%] [G loss: 1.184496]\n",
      "[Epoch 34/50] [Batch 33/235] [D loss: 1.065456, acc: 86.13%] [G loss: 1.189737]\n",
      "[Epoch 34/50] [Batch 34/235] [D loss: 1.109077, acc: 86.13%] [G loss: 1.127574]\n",
      "[Epoch 34/50] [Batch 35/235] [D loss: 1.166475, acc: 87.50%] [G loss: 1.127767]\n",
      "[Epoch 34/50] [Batch 36/235] [D loss: 1.041483, acc: 86.91%] [G loss: 1.125829]\n",
      "[Epoch 34/50] [Batch 37/235] [D loss: 1.118646, acc: 87.11%] [G loss: 1.169411]\n",
      "[Epoch 34/50] [Batch 38/235] [D loss: 1.062507, acc: 87.50%] [G loss: 1.238358]\n",
      "[Epoch 34/50] [Batch 39/235] [D loss: 1.113357, acc: 86.52%] [G loss: 1.129029]\n",
      "[Epoch 34/50] [Batch 40/235] [D loss: 1.118698, acc: 84.96%] [G loss: 1.136340]\n",
      "[Epoch 34/50] [Batch 41/235] [D loss: 1.074447, acc: 88.48%] [G loss: 1.185817]\n",
      "[Epoch 34/50] [Batch 42/235] [D loss: 1.116647, acc: 87.89%] [G loss: 1.113058]\n",
      "[Epoch 34/50] [Batch 43/235] [D loss: 1.135546, acc: 88.28%] [G loss: 1.101924]\n",
      "[Epoch 34/50] [Batch 44/235] [D loss: 1.157924, acc: 87.70%] [G loss: 1.085216]\n",
      "[Epoch 34/50] [Batch 45/235] [D loss: 1.107695, acc: 87.30%] [G loss: 1.136825]\n",
      "[Epoch 34/50] [Batch 46/235] [D loss: 1.165716, acc: 88.67%] [G loss: 1.347374]\n",
      "[Epoch 34/50] [Batch 47/235] [D loss: 1.091274, acc: 85.94%] [G loss: 1.289406]\n",
      "[Epoch 34/50] [Batch 48/235] [D loss: 1.148308, acc: 85.55%] [G loss: 1.225541]\n",
      "[Epoch 34/50] [Batch 49/235] [D loss: 1.084217, acc: 88.28%] [G loss: 1.196180]\n",
      "[Epoch 34/50] [Batch 50/235] [D loss: 1.143286, acc: 84.57%] [G loss: 1.117947]\n",
      "[Epoch 34/50] [Batch 51/235] [D loss: 1.110212, acc: 87.70%] [G loss: 1.121319]\n",
      "[Epoch 34/50] [Batch 52/235] [D loss: 1.161505, acc: 85.94%] [G loss: 1.351609]\n",
      "[Epoch 34/50] [Batch 53/235] [D loss: 1.052165, acc: 89.26%] [G loss: 1.213471]\n",
      "[Epoch 34/50] [Batch 54/235] [D loss: 1.138624, acc: 86.91%] [G loss: 1.138307]\n",
      "[Epoch 34/50] [Batch 55/235] [D loss: 1.070625, acc: 89.65%] [G loss: 1.189934]\n",
      "[Epoch 34/50] [Batch 56/235] [D loss: 1.150538, acc: 85.35%] [G loss: 1.201599]\n",
      "[Epoch 34/50] [Batch 57/235] [D loss: 1.179615, acc: 86.33%] [G loss: 1.194541]\n",
      "[Epoch 34/50] [Batch 58/235] [D loss: 1.132022, acc: 84.57%] [G loss: 1.125719]\n",
      "[Epoch 34/50] [Batch 59/235] [D loss: 1.107400, acc: 87.30%] [G loss: 1.192634]\n",
      "[Epoch 34/50] [Batch 60/235] [D loss: 1.164074, acc: 88.28%] [G loss: 0.963026]\n",
      "[Epoch 34/50] [Batch 61/235] [D loss: 1.130346, acc: 84.38%] [G loss: 1.196694]\n",
      "[Epoch 34/50] [Batch 62/235] [D loss: 1.115558, acc: 89.26%] [G loss: 1.175188]\n",
      "[Epoch 34/50] [Batch 63/235] [D loss: 1.125656, acc: 87.50%] [G loss: 1.169721]\n",
      "[Epoch 34/50] [Batch 64/235] [D loss: 1.178883, acc: 85.55%] [G loss: 1.184325]\n",
      "[Epoch 34/50] [Batch 65/235] [D loss: 1.108119, acc: 87.89%] [G loss: 1.093270]\n",
      "[Epoch 34/50] [Batch 66/235] [D loss: 1.110707, acc: 88.09%] [G loss: 1.112553]\n",
      "[Epoch 34/50] [Batch 67/235] [D loss: 1.106161, acc: 90.82%] [G loss: 1.218256]\n",
      "[Epoch 34/50] [Batch 68/235] [D loss: 1.122433, acc: 90.43%] [G loss: 1.252617]\n",
      "[Epoch 34/50] [Batch 69/235] [D loss: 1.076634, acc: 87.50%] [G loss: 1.192343]\n",
      "[Epoch 34/50] [Batch 70/235] [D loss: 1.089135, acc: 87.70%] [G loss: 1.209879]\n",
      "[Epoch 34/50] [Batch 71/235] [D loss: 1.150521, acc: 86.91%] [G loss: 1.138509]\n",
      "[Epoch 34/50] [Batch 72/235] [D loss: 1.138661, acc: 86.13%] [G loss: 1.144218]\n",
      "[Epoch 34/50] [Batch 73/235] [D loss: 1.191486, acc: 89.26%] [G loss: 1.251734]\n",
      "[Epoch 34/50] [Batch 74/235] [D loss: 1.081868, acc: 88.48%] [G loss: 1.232040]\n",
      "[Epoch 34/50] [Batch 75/235] [D loss: 1.082052, acc: 86.91%] [G loss: 1.228759]\n",
      "[Epoch 34/50] [Batch 76/235] [D loss: 1.157910, acc: 86.13%] [G loss: 1.125952]\n",
      "[Epoch 34/50] [Batch 77/235] [D loss: 1.139624, acc: 87.30%] [G loss: 1.249045]\n",
      "[Epoch 34/50] [Batch 78/235] [D loss: 1.108233, acc: 88.09%] [G loss: 1.189071]\n",
      "[Epoch 34/50] [Batch 79/235] [D loss: 1.098760, acc: 90.23%] [G loss: 1.199726]\n",
      "[Epoch 34/50] [Batch 80/235] [D loss: 1.138763, acc: 88.09%] [G loss: 1.178925]\n",
      "[Epoch 34/50] [Batch 81/235] [D loss: 1.099144, acc: 85.16%] [G loss: 1.132923]\n",
      "[Epoch 34/50] [Batch 82/235] [D loss: 1.123679, acc: 85.16%] [G loss: 1.169964]\n",
      "[Epoch 34/50] [Batch 83/235] [D loss: 1.060663, acc: 87.11%] [G loss: 1.090775]\n",
      "[Epoch 34/50] [Batch 84/235] [D loss: 1.203570, acc: 85.16%] [G loss: 1.099576]\n",
      "[Epoch 34/50] [Batch 85/235] [D loss: 1.118743, acc: 85.74%] [G loss: 1.185887]\n",
      "[Epoch 34/50] [Batch 86/235] [D loss: 1.125816, acc: 86.91%] [G loss: 1.149344]\n",
      "[Epoch 34/50] [Batch 87/235] [D loss: 1.118216, acc: 86.91%] [G loss: 1.125558]\n",
      "[Epoch 34/50] [Batch 88/235] [D loss: 1.151713, acc: 87.11%] [G loss: 1.175370]\n",
      "[Epoch 34/50] [Batch 89/235] [D loss: 1.087950, acc: 90.82%] [G loss: 1.113139]\n",
      "[Epoch 34/50] [Batch 90/235] [D loss: 1.143615, acc: 85.16%] [G loss: 1.225718]\n",
      "[Epoch 34/50] [Batch 91/235] [D loss: 1.093592, acc: 87.11%] [G loss: 1.137072]\n",
      "[Epoch 34/50] [Batch 92/235] [D loss: 1.127510, acc: 86.52%] [G loss: 1.124950]\n",
      "[Epoch 34/50] [Batch 93/235] [D loss: 1.110417, acc: 86.13%] [G loss: 1.258408]\n",
      "[Epoch 34/50] [Batch 94/235] [D loss: 1.092926, acc: 87.70%] [G loss: 1.092338]\n",
      "[Epoch 34/50] [Batch 95/235] [D loss: 1.065570, acc: 88.67%] [G loss: 1.316945]\n",
      "[Epoch 34/50] [Batch 96/235] [D loss: 1.087021, acc: 88.87%] [G loss: 1.077078]\n",
      "[Epoch 34/50] [Batch 97/235] [D loss: 1.114005, acc: 86.33%] [G loss: 1.084682]\n",
      "[Epoch 34/50] [Batch 98/235] [D loss: 1.043669, acc: 86.91%] [G loss: 1.089860]\n",
      "[Epoch 34/50] [Batch 99/235] [D loss: 1.118747, acc: 87.70%] [G loss: 1.056556]\n",
      "[Epoch 34/50] [Batch 100/235] [D loss: 1.134048, acc: 87.89%] [G loss: 1.257040]\n",
      "[Epoch 34/50] [Batch 101/235] [D loss: 1.145890, acc: 87.30%] [G loss: 1.198427]\n",
      "[Epoch 34/50] [Batch 102/235] [D loss: 1.128490, acc: 88.67%] [G loss: 1.296322]\n",
      "[Epoch 34/50] [Batch 103/235] [D loss: 1.156482, acc: 86.91%] [G loss: 1.291033]\n",
      "[Epoch 34/50] [Batch 104/235] [D loss: 1.138663, acc: 85.94%] [G loss: 1.041487]\n",
      "[Epoch 34/50] [Batch 105/235] [D loss: 1.110887, acc: 87.50%] [G loss: 1.107447]\n",
      "[Epoch 34/50] [Batch 106/235] [D loss: 1.167040, acc: 87.30%] [G loss: 1.237364]\n",
      "[Epoch 34/50] [Batch 107/235] [D loss: 1.063976, acc: 89.06%] [G loss: 1.139209]\n",
      "[Epoch 34/50] [Batch 108/235] [D loss: 1.158493, acc: 87.70%] [G loss: 1.155484]\n",
      "[Epoch 34/50] [Batch 109/235] [D loss: 1.119591, acc: 87.30%] [G loss: 1.012634]\n",
      "[Epoch 34/50] [Batch 110/235] [D loss: 1.098916, acc: 86.91%] [G loss: 1.146703]\n",
      "[Epoch 34/50] [Batch 111/235] [D loss: 1.091888, acc: 86.52%] [G loss: 1.226812]\n",
      "[Epoch 34/50] [Batch 112/235] [D loss: 1.144041, acc: 88.28%] [G loss: 1.233131]\n",
      "[Epoch 34/50] [Batch 113/235] [D loss: 1.171775, acc: 86.52%] [G loss: 1.096306]\n",
      "[Epoch 34/50] [Batch 114/235] [D loss: 1.136819, acc: 87.50%] [G loss: 1.025862]\n",
      "[Epoch 34/50] [Batch 115/235] [D loss: 1.110370, acc: 89.65%] [G loss: 1.081175]\n",
      "[Epoch 34/50] [Batch 116/235] [D loss: 1.117498, acc: 87.50%] [G loss: 1.318374]\n",
      "[Epoch 34/50] [Batch 117/235] [D loss: 1.104212, acc: 84.96%] [G loss: 1.238492]\n",
      "[Epoch 34/50] [Batch 118/235] [D loss: 1.120509, acc: 84.38%] [G loss: 1.178040]\n",
      "[Epoch 34/50] [Batch 119/235] [D loss: 1.141353, acc: 88.67%] [G loss: 1.031665]\n",
      "[Epoch 34/50] [Batch 120/235] [D loss: 1.085953, acc: 84.57%] [G loss: 1.147141]\n",
      "[Epoch 34/50] [Batch 121/235] [D loss: 1.113426, acc: 86.33%] [G loss: 1.231630]\n",
      "[Epoch 34/50] [Batch 122/235] [D loss: 1.097886, acc: 86.91%] [G loss: 1.087804]\n",
      "[Epoch 34/50] [Batch 123/235] [D loss: 1.060374, acc: 87.70%] [G loss: 1.173326]\n",
      "[Epoch 34/50] [Batch 124/235] [D loss: 1.099924, acc: 88.09%] [G loss: 1.151772]\n",
      "[Epoch 34/50] [Batch 125/235] [D loss: 1.125673, acc: 87.11%] [G loss: 1.226356]\n",
      "[Epoch 34/50] [Batch 126/235] [D loss: 1.046950, acc: 89.06%] [G loss: 1.245015]\n",
      "[Epoch 34/50] [Batch 127/235] [D loss: 1.161469, acc: 85.94%] [G loss: 1.146326]\n",
      "[Epoch 34/50] [Batch 128/235] [D loss: 1.088943, acc: 86.52%] [G loss: 1.112456]\n",
      "[Epoch 34/50] [Batch 129/235] [D loss: 1.135074, acc: 85.74%] [G loss: 1.212624]\n",
      "[Epoch 34/50] [Batch 130/235] [D loss: 1.067245, acc: 89.45%] [G loss: 1.166317]\n",
      "[Epoch 34/50] [Batch 131/235] [D loss: 1.109846, acc: 85.35%] [G loss: 1.258561]\n",
      "[Epoch 34/50] [Batch 132/235] [D loss: 1.083397, acc: 86.13%] [G loss: 1.136681]\n",
      "[Epoch 34/50] [Batch 133/235] [D loss: 1.120545, acc: 84.38%] [G loss: 1.121663]\n",
      "[Epoch 34/50] [Batch 134/235] [D loss: 1.112307, acc: 87.11%] [G loss: 1.219205]\n",
      "[Epoch 34/50] [Batch 135/235] [D loss: 1.086080, acc: 87.50%] [G loss: 1.151482]\n",
      "[Epoch 34/50] [Batch 136/235] [D loss: 1.131688, acc: 87.50%] [G loss: 1.203313]\n",
      "[Epoch 34/50] [Batch 137/235] [D loss: 1.077133, acc: 88.09%] [G loss: 1.083865]\n",
      "[Epoch 34/50] [Batch 138/235] [D loss: 1.136818, acc: 86.72%] [G loss: 1.073365]\n",
      "[Epoch 34/50] [Batch 139/235] [D loss: 1.097456, acc: 90.04%] [G loss: 1.102411]\n",
      "[Epoch 34/50] [Batch 140/235] [D loss: 1.174085, acc: 85.55%] [G loss: 1.158849]\n",
      "[Epoch 34/50] [Batch 141/235] [D loss: 1.127257, acc: 86.91%] [G loss: 1.108930]\n",
      "[Epoch 34/50] [Batch 142/235] [D loss: 1.117170, acc: 87.30%] [G loss: 1.167614]\n",
      "[Epoch 34/50] [Batch 143/235] [D loss: 1.059932, acc: 86.33%] [G loss: 1.251546]\n",
      "[Epoch 34/50] [Batch 144/235] [D loss: 1.124687, acc: 87.11%] [G loss: 1.179625]\n",
      "[Epoch 34/50] [Batch 145/235] [D loss: 1.079895, acc: 86.72%] [G loss: 1.236062]\n",
      "[Epoch 34/50] [Batch 146/235] [D loss: 1.102125, acc: 85.35%] [G loss: 1.192898]\n",
      "[Epoch 34/50] [Batch 147/235] [D loss: 1.096694, acc: 88.48%] [G loss: 1.176187]\n",
      "[Epoch 34/50] [Batch 148/235] [D loss: 1.181417, acc: 87.50%] [G loss: 1.114781]\n",
      "[Epoch 34/50] [Batch 149/235] [D loss: 1.111642, acc: 87.70%] [G loss: 1.175523]\n",
      "[Epoch 34/50] [Batch 150/235] [D loss: 1.125633, acc: 87.89%] [G loss: 1.148787]\n",
      "[Epoch 34/50] [Batch 151/235] [D loss: 1.179848, acc: 87.50%] [G loss: 1.250456]\n",
      "[Epoch 34/50] [Batch 152/235] [D loss: 1.153525, acc: 87.11%] [G loss: 1.159125]\n",
      "[Epoch 34/50] [Batch 153/235] [D loss: 1.107711, acc: 86.91%] [G loss: 1.008399]\n",
      "[Epoch 34/50] [Batch 154/235] [D loss: 1.087511, acc: 85.35%] [G loss: 1.187863]\n",
      "[Epoch 34/50] [Batch 155/235] [D loss: 1.124136, acc: 87.70%] [G loss: 1.324048]\n",
      "[Epoch 34/50] [Batch 156/235] [D loss: 1.123898, acc: 87.89%] [G loss: 1.127780]\n",
      "[Epoch 34/50] [Batch 157/235] [D loss: 1.121236, acc: 88.28%] [G loss: 1.124508]\n",
      "[Epoch 34/50] [Batch 158/235] [D loss: 1.080921, acc: 87.50%] [G loss: 1.086091]\n",
      "[Epoch 34/50] [Batch 159/235] [D loss: 1.119844, acc: 85.94%] [G loss: 1.327778]\n",
      "[Epoch 34/50] [Batch 160/235] [D loss: 1.130273, acc: 85.94%] [G loss: 1.132646]\n",
      "[Epoch 34/50] [Batch 161/235] [D loss: 1.080700, acc: 86.72%] [G loss: 1.298188]\n",
      "[Epoch 34/50] [Batch 162/235] [D loss: 1.111299, acc: 88.09%] [G loss: 1.151284]\n",
      "[Epoch 34/50] [Batch 163/235] [D loss: 1.137131, acc: 88.87%] [G loss: 1.216085]\n",
      "[Epoch 34/50] [Batch 164/235] [D loss: 1.099443, acc: 90.04%] [G loss: 1.112202]\n",
      "[Epoch 34/50] [Batch 165/235] [D loss: 1.078716, acc: 89.06%] [G loss: 1.090909]\n",
      "[Epoch 34/50] [Batch 166/235] [D loss: 1.170570, acc: 88.28%] [G loss: 1.195735]\n",
      "[Epoch 34/50] [Batch 167/235] [D loss: 1.204867, acc: 86.91%] [G loss: 0.956804]\n",
      "[Epoch 34/50] [Batch 168/235] [D loss: 1.116053, acc: 87.89%] [G loss: 1.123623]\n",
      "[Epoch 34/50] [Batch 169/235] [D loss: 1.071225, acc: 88.09%] [G loss: 1.251798]\n",
      "[Epoch 34/50] [Batch 170/235] [D loss: 1.139314, acc: 87.11%] [G loss: 1.325802]\n",
      "[Epoch 34/50] [Batch 171/235] [D loss: 1.115678, acc: 87.30%] [G loss: 1.047878]\n",
      "[Epoch 34/50] [Batch 172/235] [D loss: 1.088817, acc: 86.72%] [G loss: 1.101089]\n",
      "[Epoch 34/50] [Batch 173/235] [D loss: 1.166581, acc: 85.74%] [G loss: 1.235414]\n",
      "[Epoch 34/50] [Batch 174/235] [D loss: 1.166721, acc: 86.72%] [G loss: 1.190331]\n",
      "[Epoch 34/50] [Batch 175/235] [D loss: 1.032562, acc: 87.70%] [G loss: 1.169458]\n",
      "[Epoch 34/50] [Batch 176/235] [D loss: 1.145640, acc: 86.72%] [G loss: 1.239158]\n",
      "[Epoch 34/50] [Batch 177/235] [D loss: 1.138377, acc: 87.30%] [G loss: 1.149595]\n",
      "[Epoch 34/50] [Batch 178/235] [D loss: 1.122047, acc: 87.89%] [G loss: 1.183984]\n",
      "[Epoch 34/50] [Batch 179/235] [D loss: 1.119431, acc: 86.52%] [G loss: 1.150432]\n",
      "[Epoch 34/50] [Batch 180/235] [D loss: 1.145611, acc: 85.94%] [G loss: 1.219345]\n",
      "[Epoch 34/50] [Batch 181/235] [D loss: 1.204909, acc: 84.57%] [G loss: 1.233419]\n",
      "[Epoch 34/50] [Batch 182/235] [D loss: 1.118258, acc: 82.81%] [G loss: 1.167735]\n",
      "[Epoch 34/50] [Batch 183/235] [D loss: 1.107632, acc: 89.26%] [G loss: 1.092302]\n",
      "[Epoch 34/50] [Batch 184/235] [D loss: 1.077634, acc: 87.11%] [G loss: 1.176226]\n",
      "[Epoch 34/50] [Batch 185/235] [D loss: 1.125422, acc: 87.70%] [G loss: 1.113609]\n",
      "[Epoch 34/50] [Batch 186/235] [D loss: 1.085585, acc: 90.82%] [G loss: 1.252033]\n",
      "[Epoch 34/50] [Batch 187/235] [D loss: 1.063583, acc: 88.09%] [G loss: 1.175147]\n",
      "[Epoch 34/50] [Batch 188/235] [D loss: 1.113144, acc: 86.91%] [G loss: 1.112541]\n",
      "[Epoch 34/50] [Batch 189/235] [D loss: 1.129384, acc: 88.87%] [G loss: 1.129464]\n",
      "[Epoch 34/50] [Batch 190/235] [D loss: 1.105690, acc: 86.91%] [G loss: 1.137564]\n",
      "[Epoch 34/50] [Batch 191/235] [D loss: 1.080215, acc: 85.94%] [G loss: 1.090194]\n",
      "[Epoch 34/50] [Batch 192/235] [D loss: 1.182907, acc: 84.77%] [G loss: 1.173372]\n",
      "[Epoch 34/50] [Batch 193/235] [D loss: 1.110312, acc: 85.16%] [G loss: 1.213419]\n",
      "[Epoch 34/50] [Batch 194/235] [D loss: 1.092719, acc: 89.65%] [G loss: 1.194376]\n",
      "[Epoch 34/50] [Batch 195/235] [D loss: 1.049156, acc: 87.70%] [G loss: 1.145068]\n",
      "[Epoch 34/50] [Batch 196/235] [D loss: 1.175342, acc: 88.87%] [G loss: 1.099416]\n",
      "[Epoch 34/50] [Batch 197/235] [D loss: 1.121833, acc: 84.77%] [G loss: 1.229415]\n",
      "[Epoch 34/50] [Batch 198/235] [D loss: 1.131423, acc: 86.72%] [G loss: 1.108315]\n",
      "[Epoch 34/50] [Batch 199/235] [D loss: 1.157367, acc: 86.52%] [G loss: 1.134901]\n",
      "[Epoch 34/50] [Batch 200/235] [D loss: 1.116814, acc: 85.94%] [G loss: 1.243831]\n",
      "[Epoch 34/50] [Batch 201/235] [D loss: 1.066826, acc: 86.72%] [G loss: 1.158474]\n",
      "[Epoch 34/50] [Batch 202/235] [D loss: 1.059225, acc: 86.91%] [G loss: 1.116436]\n",
      "[Epoch 34/50] [Batch 203/235] [D loss: 1.115063, acc: 88.28%] [G loss: 1.136250]\n",
      "[Epoch 34/50] [Batch 204/235] [D loss: 1.138598, acc: 86.33%] [G loss: 1.144158]\n",
      "[Epoch 34/50] [Batch 205/235] [D loss: 1.110376, acc: 86.33%] [G loss: 1.181904]\n",
      "[Epoch 34/50] [Batch 206/235] [D loss: 1.173407, acc: 87.11%] [G loss: 1.102040]\n",
      "[Epoch 34/50] [Batch 207/235] [D loss: 1.052774, acc: 86.52%] [G loss: 1.154103]\n",
      "[Epoch 34/50] [Batch 208/235] [D loss: 1.081795, acc: 87.50%] [G loss: 1.126484]\n",
      "[Epoch 34/50] [Batch 209/235] [D loss: 1.172243, acc: 88.48%] [G loss: 1.045334]\n",
      "[Epoch 34/50] [Batch 210/235] [D loss: 1.123423, acc: 89.26%] [G loss: 1.315034]\n",
      "[Epoch 34/50] [Batch 211/235] [D loss: 1.125614, acc: 88.87%] [G loss: 1.303774]\n",
      "[Epoch 34/50] [Batch 212/235] [D loss: 1.192158, acc: 84.77%] [G loss: 1.107124]\n",
      "[Epoch 34/50] [Batch 213/235] [D loss: 1.160224, acc: 83.40%] [G loss: 1.137737]\n",
      "[Epoch 34/50] [Batch 214/235] [D loss: 1.152089, acc: 87.89%] [G loss: 1.225095]\n",
      "[Epoch 34/50] [Batch 215/235] [D loss: 1.151133, acc: 85.35%] [G loss: 1.257923]\n",
      "[Epoch 34/50] [Batch 216/235] [D loss: 1.096814, acc: 89.26%] [G loss: 1.143568]\n",
      "[Epoch 34/50] [Batch 217/235] [D loss: 1.093240, acc: 89.45%] [G loss: 1.139063]\n",
      "[Epoch 34/50] [Batch 218/235] [D loss: 1.080921, acc: 87.50%] [G loss: 1.037833]\n",
      "[Epoch 34/50] [Batch 219/235] [D loss: 1.101995, acc: 87.89%] [G loss: 1.185525]\n",
      "[Epoch 34/50] [Batch 220/235] [D loss: 1.143810, acc: 84.38%] [G loss: 1.217368]\n",
      "[Epoch 34/50] [Batch 221/235] [D loss: 1.087442, acc: 87.70%] [G loss: 1.122028]\n",
      "[Epoch 34/50] [Batch 222/235] [D loss: 1.129322, acc: 86.13%] [G loss: 1.088492]\n",
      "[Epoch 34/50] [Batch 223/235] [D loss: 1.086271, acc: 89.26%] [G loss: 1.230851]\n",
      "[Epoch 34/50] [Batch 224/235] [D loss: 1.161257, acc: 87.11%] [G loss: 1.173903]\n",
      "[Epoch 34/50] [Batch 225/235] [D loss: 1.123390, acc: 85.16%] [G loss: 1.176981]\n",
      "[Epoch 34/50] [Batch 226/235] [D loss: 1.164948, acc: 89.06%] [G loss: 1.000319]\n",
      "[Epoch 34/50] [Batch 227/235] [D loss: 1.103580, acc: 87.11%] [G loss: 1.077044]\n",
      "[Epoch 34/50] [Batch 228/235] [D loss: 1.057850, acc: 87.70%] [G loss: 1.196089]\n",
      "[Epoch 34/50] [Batch 229/235] [D loss: 1.125369, acc: 87.50%] [G loss: 1.073913]\n",
      "[Epoch 34/50] [Batch 230/235] [D loss: 1.120533, acc: 85.55%] [G loss: 1.177059]\n",
      "[Epoch 34/50] [Batch 231/235] [D loss: 1.077649, acc: 85.74%] [G loss: 1.129839]\n",
      "[Epoch 34/50] [Batch 232/235] [D loss: 1.136505, acc: 89.45%] [G loss: 1.091562]\n",
      "[Epoch 34/50] [Batch 233/235] [D loss: 1.139168, acc: 89.26%] [G loss: 1.065917]\n",
      "[Epoch 34/50] [Batch 234/235] [D loss: 1.089751, acc: 86.98%] [G loss: 1.181492]\n",
      "[Epoch 35/50] [Batch 0/235] [D loss: 1.129975, acc: 87.30%] [G loss: 1.236186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/50] [Batch 1/235] [D loss: 1.080442, acc: 86.72%] [G loss: 1.113500]\n",
      "[Epoch 35/50] [Batch 2/235] [D loss: 1.125752, acc: 86.91%] [G loss: 1.238305]\n",
      "[Epoch 35/50] [Batch 3/235] [D loss: 1.133943, acc: 88.09%] [G loss: 1.192142]\n",
      "[Epoch 35/50] [Batch 4/235] [D loss: 1.156751, acc: 88.09%] [G loss: 1.185419]\n",
      "[Epoch 35/50] [Batch 5/235] [D loss: 1.173827, acc: 89.06%] [G loss: 1.421652]\n",
      "[Epoch 35/50] [Batch 6/235] [D loss: 1.114917, acc: 87.11%] [G loss: 1.106332]\n",
      "[Epoch 35/50] [Batch 7/235] [D loss: 1.140181, acc: 87.89%] [G loss: 1.077317]\n",
      "[Epoch 35/50] [Batch 8/235] [D loss: 1.061817, acc: 88.09%] [G loss: 1.095719]\n",
      "[Epoch 35/50] [Batch 9/235] [D loss: 1.077299, acc: 87.11%] [G loss: 1.087941]\n",
      "[Epoch 35/50] [Batch 10/235] [D loss: 1.098329, acc: 87.50%] [G loss: 1.100618]\n",
      "[Epoch 35/50] [Batch 11/235] [D loss: 1.129883, acc: 83.40%] [G loss: 1.164875]\n",
      "[Epoch 35/50] [Batch 12/235] [D loss: 1.115987, acc: 84.96%] [G loss: 1.226258]\n",
      "[Epoch 35/50] [Batch 13/235] [D loss: 1.117189, acc: 84.57%] [G loss: 1.097928]\n",
      "[Epoch 35/50] [Batch 14/235] [D loss: 1.111045, acc: 88.09%] [G loss: 1.114850]\n",
      "[Epoch 35/50] [Batch 15/235] [D loss: 1.087620, acc: 87.50%] [G loss: 1.094644]\n",
      "[Epoch 35/50] [Batch 16/235] [D loss: 1.148468, acc: 86.33%] [G loss: 1.042514]\n",
      "[Epoch 35/50] [Batch 17/235] [D loss: 1.046253, acc: 87.89%] [G loss: 1.082958]\n",
      "[Epoch 35/50] [Batch 18/235] [D loss: 1.032432, acc: 87.30%] [G loss: 1.248085]\n",
      "[Epoch 35/50] [Batch 19/235] [D loss: 1.107732, acc: 87.89%] [G loss: 1.105512]\n",
      "[Epoch 35/50] [Batch 20/235] [D loss: 1.076528, acc: 87.89%] [G loss: 1.083075]\n",
      "[Epoch 35/50] [Batch 21/235] [D loss: 1.131869, acc: 88.28%] [G loss: 1.236476]\n",
      "[Epoch 35/50] [Batch 22/235] [D loss: 1.088455, acc: 85.55%] [G loss: 1.049269]\n",
      "[Epoch 35/50] [Batch 23/235] [D loss: 1.124366, acc: 86.72%] [G loss: 1.106260]\n",
      "[Epoch 35/50] [Batch 24/235] [D loss: 1.061363, acc: 89.65%] [G loss: 1.126848]\n",
      "[Epoch 35/50] [Batch 25/235] [D loss: 1.085710, acc: 86.33%] [G loss: 1.163087]\n",
      "[Epoch 35/50] [Batch 26/235] [D loss: 1.032053, acc: 88.87%] [G loss: 1.300179]\n",
      "[Epoch 35/50] [Batch 27/235] [D loss: 1.067333, acc: 87.11%] [G loss: 1.198205]\n",
      "[Epoch 35/50] [Batch 28/235] [D loss: 1.046943, acc: 87.50%] [G loss: 1.268705]\n",
      "[Epoch 35/50] [Batch 29/235] [D loss: 1.132221, acc: 86.91%] [G loss: 1.078936]\n",
      "[Epoch 35/50] [Batch 30/235] [D loss: 1.107144, acc: 87.89%] [G loss: 1.146183]\n",
      "[Epoch 35/50] [Batch 31/235] [D loss: 1.052448, acc: 87.30%] [G loss: 1.059045]\n",
      "[Epoch 35/50] [Batch 32/235] [D loss: 1.135371, acc: 86.13%] [G loss: 1.183021]\n",
      "[Epoch 35/50] [Batch 33/235] [D loss: 1.089710, acc: 87.50%] [G loss: 1.233475]\n",
      "[Epoch 35/50] [Batch 34/235] [D loss: 1.098868, acc: 87.50%] [G loss: 1.123640]\n",
      "[Epoch 35/50] [Batch 35/235] [D loss: 1.081495, acc: 87.50%] [G loss: 1.188298]\n",
      "[Epoch 35/50] [Batch 36/235] [D loss: 1.150695, acc: 85.74%] [G loss: 1.213752]\n",
      "[Epoch 35/50] [Batch 37/235] [D loss: 1.092366, acc: 89.06%] [G loss: 1.173239]\n",
      "[Epoch 35/50] [Batch 38/235] [D loss: 1.074919, acc: 87.89%] [G loss: 1.111398]\n",
      "[Epoch 35/50] [Batch 39/235] [D loss: 1.100856, acc: 87.89%] [G loss: 1.202899]\n",
      "[Epoch 35/50] [Batch 40/235] [D loss: 1.128033, acc: 87.70%] [G loss: 1.193697]\n",
      "[Epoch 35/50] [Batch 41/235] [D loss: 1.106751, acc: 86.72%] [G loss: 1.131495]\n",
      "[Epoch 35/50] [Batch 42/235] [D loss: 1.120395, acc: 85.74%] [G loss: 1.175908]\n",
      "[Epoch 35/50] [Batch 43/235] [D loss: 1.082658, acc: 85.16%] [G loss: 1.250596]\n",
      "[Epoch 35/50] [Batch 44/235] [D loss: 1.093099, acc: 89.06%] [G loss: 1.219245]\n",
      "[Epoch 35/50] [Batch 45/235] [D loss: 1.079478, acc: 87.70%] [G loss: 1.209156]\n",
      "[Epoch 35/50] [Batch 46/235] [D loss: 1.167788, acc: 88.48%] [G loss: 1.069285]\n",
      "[Epoch 35/50] [Batch 47/235] [D loss: 1.164345, acc: 88.87%] [G loss: 1.193395]\n",
      "[Epoch 35/50] [Batch 48/235] [D loss: 1.091013, acc: 89.84%] [G loss: 1.150303]\n",
      "[Epoch 35/50] [Batch 49/235] [D loss: 1.065523, acc: 88.87%] [G loss: 1.218907]\n",
      "[Epoch 35/50] [Batch 50/235] [D loss: 1.179648, acc: 86.91%] [G loss: 1.044535]\n",
      "[Epoch 35/50] [Batch 51/235] [D loss: 1.110275, acc: 87.50%] [G loss: 1.102938]\n",
      "[Epoch 35/50] [Batch 52/235] [D loss: 1.158673, acc: 88.09%] [G loss: 1.298643]\n",
      "[Epoch 35/50] [Batch 53/235] [D loss: 1.207354, acc: 84.57%] [G loss: 1.197311]\n",
      "[Epoch 35/50] [Batch 54/235] [D loss: 1.125719, acc: 85.55%] [G loss: 1.145235]\n",
      "[Epoch 35/50] [Batch 55/235] [D loss: 1.228712, acc: 83.79%] [G loss: 1.146235]\n",
      "[Epoch 35/50] [Batch 56/235] [D loss: 1.127264, acc: 87.11%] [G loss: 1.165120]\n",
      "[Epoch 35/50] [Batch 57/235] [D loss: 1.130375, acc: 87.11%] [G loss: 1.085983]\n",
      "[Epoch 35/50] [Batch 58/235] [D loss: 1.154594, acc: 85.74%] [G loss: 1.103775]\n",
      "[Epoch 35/50] [Batch 59/235] [D loss: 1.146201, acc: 87.11%] [G loss: 1.070939]\n",
      "[Epoch 35/50] [Batch 60/235] [D loss: 1.105478, acc: 89.26%] [G loss: 1.046301]\n",
      "[Epoch 35/50] [Batch 61/235] [D loss: 1.114819, acc: 87.50%] [G loss: 1.381359]\n",
      "[Epoch 35/50] [Batch 62/235] [D loss: 1.116141, acc: 88.28%] [G loss: 1.205706]\n",
      "[Epoch 35/50] [Batch 63/235] [D loss: 1.139444, acc: 85.94%] [G loss: 1.137656]\n",
      "[Epoch 35/50] [Batch 64/235] [D loss: 1.109839, acc: 89.45%] [G loss: 1.129815]\n",
      "[Epoch 35/50] [Batch 65/235] [D loss: 1.097542, acc: 86.33%] [G loss: 1.233615]\n",
      "[Epoch 35/50] [Batch 66/235] [D loss: 1.144010, acc: 86.91%] [G loss: 1.100705]\n",
      "[Epoch 35/50] [Batch 67/235] [D loss: 1.094140, acc: 85.94%] [G loss: 1.109344]\n",
      "[Epoch 35/50] [Batch 68/235] [D loss: 1.133500, acc: 87.70%] [G loss: 1.187984]\n",
      "[Epoch 35/50] [Batch 69/235] [D loss: 1.125062, acc: 89.65%] [G loss: 1.238177]\n",
      "[Epoch 35/50] [Batch 70/235] [D loss: 1.159616, acc: 87.50%] [G loss: 1.170105]\n",
      "[Epoch 35/50] [Batch 71/235] [D loss: 1.182848, acc: 86.91%] [G loss: 1.083039]\n",
      "[Epoch 35/50] [Batch 72/235] [D loss: 1.091008, acc: 86.91%] [G loss: 1.131665]\n",
      "[Epoch 35/50] [Batch 73/235] [D loss: 1.090491, acc: 84.96%] [G loss: 1.394242]\n",
      "[Epoch 35/50] [Batch 74/235] [D loss: 1.078000, acc: 86.72%] [G loss: 1.139835]\n",
      "[Epoch 35/50] [Batch 75/235] [D loss: 1.125396, acc: 86.72%] [G loss: 1.104264]\n",
      "[Epoch 35/50] [Batch 76/235] [D loss: 1.108824, acc: 86.52%] [G loss: 1.143490]\n",
      "[Epoch 35/50] [Batch 77/235] [D loss: 1.023522, acc: 86.91%] [G loss: 1.180167]\n",
      "[Epoch 35/50] [Batch 78/235] [D loss: 1.108079, acc: 87.89%] [G loss: 1.052131]\n",
      "[Epoch 35/50] [Batch 79/235] [D loss: 1.139752, acc: 86.91%] [G loss: 1.052876]\n",
      "[Epoch 35/50] [Batch 80/235] [D loss: 1.088267, acc: 86.72%] [G loss: 1.101189]\n",
      "[Epoch 35/50] [Batch 81/235] [D loss: 1.074833, acc: 88.28%] [G loss: 1.250020]\n",
      "[Epoch 35/50] [Batch 82/235] [D loss: 1.113935, acc: 87.30%] [G loss: 1.279289]\n",
      "[Epoch 35/50] [Batch 83/235] [D loss: 1.052692, acc: 88.28%] [G loss: 1.085208]\n",
      "[Epoch 35/50] [Batch 84/235] [D loss: 1.087364, acc: 89.06%] [G loss: 1.039154]\n",
      "[Epoch 35/50] [Batch 85/235] [D loss: 1.163905, acc: 87.30%] [G loss: 1.179733]\n",
      "[Epoch 35/50] [Batch 86/235] [D loss: 1.140761, acc: 85.55%] [G loss: 1.211239]\n",
      "[Epoch 35/50] [Batch 87/235] [D loss: 1.169174, acc: 87.50%] [G loss: 1.140939]\n",
      "[Epoch 35/50] [Batch 88/235] [D loss: 1.186278, acc: 87.11%] [G loss: 1.279741]\n",
      "[Epoch 35/50] [Batch 89/235] [D loss: 1.094857, acc: 87.11%] [G loss: 1.168337]\n",
      "[Epoch 35/50] [Batch 90/235] [D loss: 1.122381, acc: 87.50%] [G loss: 1.290847]\n",
      "[Epoch 35/50] [Batch 91/235] [D loss: 1.142902, acc: 86.72%] [G loss: 1.153394]\n",
      "[Epoch 35/50] [Batch 92/235] [D loss: 1.104028, acc: 88.28%] [G loss: 1.196536]\n",
      "[Epoch 35/50] [Batch 93/235] [D loss: 1.117562, acc: 87.30%] [G loss: 1.008127]\n",
      "[Epoch 35/50] [Batch 94/235] [D loss: 1.070526, acc: 87.89%] [G loss: 1.205909]\n",
      "[Epoch 35/50] [Batch 95/235] [D loss: 1.129634, acc: 86.33%] [G loss: 1.108762]\n",
      "[Epoch 35/50] [Batch 96/235] [D loss: 1.102284, acc: 86.91%] [G loss: 1.112312]\n",
      "[Epoch 35/50] [Batch 97/235] [D loss: 1.108904, acc: 87.30%] [G loss: 1.139502]\n",
      "[Epoch 35/50] [Batch 98/235] [D loss: 1.109061, acc: 85.94%] [G loss: 1.106137]\n",
      "[Epoch 35/50] [Batch 99/235] [D loss: 1.105418, acc: 88.28%] [G loss: 1.081879]\n",
      "[Epoch 35/50] [Batch 100/235] [D loss: 1.132538, acc: 87.11%] [G loss: 1.056360]\n",
      "[Epoch 35/50] [Batch 101/235] [D loss: 1.134533, acc: 88.67%] [G loss: 1.052117]\n",
      "[Epoch 35/50] [Batch 102/235] [D loss: 1.113677, acc: 88.67%] [G loss: 1.128700]\n",
      "[Epoch 35/50] [Batch 103/235] [D loss: 1.116024, acc: 85.94%] [G loss: 1.149648]\n",
      "[Epoch 35/50] [Batch 104/235] [D loss: 1.096754, acc: 90.23%] [G loss: 1.225701]\n",
      "[Epoch 35/50] [Batch 105/235] [D loss: 1.115459, acc: 87.70%] [G loss: 1.121202]\n",
      "[Epoch 35/50] [Batch 106/235] [D loss: 1.184159, acc: 85.35%] [G loss: 1.090521]\n",
      "[Epoch 35/50] [Batch 107/235] [D loss: 1.128095, acc: 88.09%] [G loss: 1.158918]\n",
      "[Epoch 35/50] [Batch 108/235] [D loss: 1.074450, acc: 85.55%] [G loss: 1.129136]\n",
      "[Epoch 35/50] [Batch 109/235] [D loss: 1.129402, acc: 85.74%] [G loss: 1.105520]\n",
      "[Epoch 35/50] [Batch 110/235] [D loss: 1.146465, acc: 89.45%] [G loss: 1.079032]\n",
      "[Epoch 35/50] [Batch 111/235] [D loss: 1.103994, acc: 86.33%] [G loss: 1.103176]\n",
      "[Epoch 35/50] [Batch 112/235] [D loss: 1.134206, acc: 87.70%] [G loss: 1.218491]\n",
      "[Epoch 35/50] [Batch 113/235] [D loss: 1.111531, acc: 86.33%] [G loss: 1.216045]\n",
      "[Epoch 35/50] [Batch 114/235] [D loss: 1.132861, acc: 87.70%] [G loss: 1.145092]\n",
      "[Epoch 35/50] [Batch 115/235] [D loss: 1.153844, acc: 85.55%] [G loss: 1.064992]\n",
      "[Epoch 35/50] [Batch 116/235] [D loss: 1.101202, acc: 89.65%] [G loss: 1.160022]\n",
      "[Epoch 35/50] [Batch 117/235] [D loss: 1.139633, acc: 89.06%] [G loss: 1.085473]\n",
      "[Epoch 35/50] [Batch 118/235] [D loss: 1.108174, acc: 89.65%] [G loss: 1.171002]\n",
      "[Epoch 35/50] [Batch 119/235] [D loss: 1.096175, acc: 87.89%] [G loss: 1.137703]\n",
      "[Epoch 35/50] [Batch 120/235] [D loss: 1.073692, acc: 87.30%] [G loss: 1.245855]\n",
      "[Epoch 35/50] [Batch 121/235] [D loss: 1.172071, acc: 85.35%] [G loss: 1.273896]\n",
      "[Epoch 35/50] [Batch 122/235] [D loss: 1.123351, acc: 86.13%] [G loss: 1.150933]\n",
      "[Epoch 35/50] [Batch 123/235] [D loss: 1.085770, acc: 87.11%] [G loss: 1.077863]\n",
      "[Epoch 35/50] [Batch 124/235] [D loss: 1.096980, acc: 86.91%] [G loss: 1.314995]\n",
      "[Epoch 35/50] [Batch 125/235] [D loss: 1.111307, acc: 88.09%] [G loss: 1.180775]\n",
      "[Epoch 35/50] [Batch 126/235] [D loss: 1.103459, acc: 88.09%] [G loss: 1.192882]\n",
      "[Epoch 35/50] [Batch 127/235] [D loss: 1.173173, acc: 85.16%] [G loss: 1.122501]\n",
      "[Epoch 35/50] [Batch 128/235] [D loss: 1.108403, acc: 85.55%] [G loss: 1.175383]\n",
      "[Epoch 35/50] [Batch 129/235] [D loss: 1.140737, acc: 89.84%] [G loss: 1.379499]\n",
      "[Epoch 35/50] [Batch 130/235] [D loss: 1.133124, acc: 86.72%] [G loss: 1.219587]\n",
      "[Epoch 35/50] [Batch 131/235] [D loss: 1.129429, acc: 87.70%] [G loss: 1.065613]\n",
      "[Epoch 35/50] [Batch 132/235] [D loss: 1.031039, acc: 88.67%] [G loss: 1.134299]\n",
      "[Epoch 35/50] [Batch 133/235] [D loss: 1.163130, acc: 86.33%] [G loss: 1.034863]\n",
      "[Epoch 35/50] [Batch 134/235] [D loss: 1.095847, acc: 86.52%] [G loss: 1.167588]\n",
      "[Epoch 35/50] [Batch 135/235] [D loss: 1.073803, acc: 88.67%] [G loss: 1.296735]\n",
      "[Epoch 35/50] [Batch 136/235] [D loss: 1.125081, acc: 85.16%] [G loss: 1.086631]\n",
      "[Epoch 35/50] [Batch 137/235] [D loss: 1.075948, acc: 87.50%] [G loss: 1.257133]\n",
      "[Epoch 35/50] [Batch 138/235] [D loss: 1.100616, acc: 87.70%] [G loss: 1.162258]\n",
      "[Epoch 35/50] [Batch 139/235] [D loss: 1.086268, acc: 86.72%] [G loss: 1.194918]\n",
      "[Epoch 35/50] [Batch 140/235] [D loss: 1.107348, acc: 89.45%] [G loss: 1.175290]\n",
      "[Epoch 35/50] [Batch 141/235] [D loss: 1.119016, acc: 86.13%] [G loss: 1.006016]\n",
      "[Epoch 35/50] [Batch 142/235] [D loss: 1.109011, acc: 86.33%] [G loss: 1.069951]\n",
      "[Epoch 35/50] [Batch 143/235] [D loss: 1.141818, acc: 85.55%] [G loss: 1.225915]\n",
      "[Epoch 35/50] [Batch 144/235] [D loss: 1.163076, acc: 85.16%] [G loss: 1.245662]\n",
      "[Epoch 35/50] [Batch 145/235] [D loss: 1.102630, acc: 86.91%] [G loss: 1.292979]\n",
      "[Epoch 35/50] [Batch 146/235] [D loss: 1.104038, acc: 85.55%] [G loss: 1.062104]\n",
      "[Epoch 35/50] [Batch 147/235] [D loss: 1.066458, acc: 87.70%] [G loss: 0.991573]\n",
      "[Epoch 35/50] [Batch 148/235] [D loss: 1.067510, acc: 86.72%] [G loss: 1.130425]\n",
      "[Epoch 35/50] [Batch 149/235] [D loss: 1.113864, acc: 88.09%] [G loss: 1.244387]\n",
      "[Epoch 35/50] [Batch 150/235] [D loss: 1.088925, acc: 84.38%] [G loss: 1.071547]\n",
      "[Epoch 35/50] [Batch 151/235] [D loss: 1.124549, acc: 84.57%] [G loss: 1.081603]\n",
      "[Epoch 35/50] [Batch 152/235] [D loss: 1.095817, acc: 87.50%] [G loss: 1.146526]\n",
      "[Epoch 35/50] [Batch 153/235] [D loss: 1.136500, acc: 85.35%] [G loss: 1.233107]\n",
      "[Epoch 35/50] [Batch 154/235] [D loss: 1.119576, acc: 85.16%] [G loss: 1.087735]\n",
      "[Epoch 35/50] [Batch 155/235] [D loss: 1.133709, acc: 89.26%] [G loss: 1.002638]\n",
      "[Epoch 35/50] [Batch 156/235] [D loss: 1.135088, acc: 87.11%] [G loss: 1.135718]\n",
      "[Epoch 35/50] [Batch 157/235] [D loss: 1.129907, acc: 88.48%] [G loss: 1.201404]\n",
      "[Epoch 35/50] [Batch 158/235] [D loss: 1.121754, acc: 87.30%] [G loss: 1.143757]\n",
      "[Epoch 35/50] [Batch 159/235] [D loss: 1.127128, acc: 87.70%] [G loss: 1.056243]\n",
      "[Epoch 35/50] [Batch 160/235] [D loss: 1.086638, acc: 88.67%] [G loss: 1.203741]\n",
      "[Epoch 35/50] [Batch 161/235] [D loss: 1.126573, acc: 84.18%] [G loss: 1.150510]\n",
      "[Epoch 35/50] [Batch 162/235] [D loss: 1.145248, acc: 86.91%] [G loss: 1.122927]\n",
      "[Epoch 35/50] [Batch 163/235] [D loss: 1.164293, acc: 87.70%] [G loss: 1.156781]\n",
      "[Epoch 35/50] [Batch 164/235] [D loss: 1.131483, acc: 86.91%] [G loss: 1.078740]\n",
      "[Epoch 35/50] [Batch 165/235] [D loss: 1.120924, acc: 85.16%] [G loss: 1.063942]\n",
      "[Epoch 35/50] [Batch 166/235] [D loss: 1.092657, acc: 85.94%] [G loss: 1.145718]\n",
      "[Epoch 35/50] [Batch 167/235] [D loss: 1.123993, acc: 88.28%] [G loss: 1.233960]\n",
      "[Epoch 35/50] [Batch 168/235] [D loss: 1.116263, acc: 87.89%] [G loss: 1.231651]\n",
      "[Epoch 35/50] [Batch 169/235] [D loss: 1.128447, acc: 85.16%] [G loss: 1.213320]\n",
      "[Epoch 35/50] [Batch 170/235] [D loss: 1.155837, acc: 86.33%] [G loss: 1.126946]\n",
      "[Epoch 35/50] [Batch 171/235] [D loss: 1.103695, acc: 86.33%] [G loss: 1.176213]\n",
      "[Epoch 35/50] [Batch 172/235] [D loss: 1.129416, acc: 89.45%] [G loss: 1.155661]\n",
      "[Epoch 35/50] [Batch 173/235] [D loss: 1.095293, acc: 88.28%] [G loss: 1.123307]\n",
      "[Epoch 35/50] [Batch 174/235] [D loss: 1.089577, acc: 89.06%] [G loss: 1.202941]\n",
      "[Epoch 35/50] [Batch 175/235] [D loss: 1.122071, acc: 86.13%] [G loss: 1.125494]\n",
      "[Epoch 35/50] [Batch 176/235] [D loss: 1.073340, acc: 88.87%] [G loss: 1.031671]\n",
      "[Epoch 35/50] [Batch 177/235] [D loss: 1.072974, acc: 87.70%] [G loss: 1.223031]\n",
      "[Epoch 35/50] [Batch 178/235] [D loss: 1.133564, acc: 85.74%] [G loss: 1.142057]\n",
      "[Epoch 35/50] [Batch 179/235] [D loss: 1.100820, acc: 85.55%] [G loss: 1.125241]\n",
      "[Epoch 35/50] [Batch 180/235] [D loss: 1.147633, acc: 86.13%] [G loss: 1.323683]\n",
      "[Epoch 35/50] [Batch 181/235] [D loss: 1.087562, acc: 88.87%] [G loss: 1.238311]\n",
      "[Epoch 35/50] [Batch 182/235] [D loss: 1.190156, acc: 85.74%] [G loss: 1.124711]\n",
      "[Epoch 35/50] [Batch 183/235] [D loss: 1.121449, acc: 88.48%] [G loss: 1.339740]\n",
      "[Epoch 35/50] [Batch 184/235] [D loss: 1.055594, acc: 87.11%] [G loss: 1.421856]\n",
      "[Epoch 35/50] [Batch 185/235] [D loss: 1.192624, acc: 88.09%] [G loss: 1.197550]\n",
      "[Epoch 35/50] [Batch 186/235] [D loss: 1.095828, acc: 84.57%] [G loss: 1.164951]\n",
      "[Epoch 35/50] [Batch 187/235] [D loss: 1.083709, acc: 89.65%] [G loss: 1.072221]\n",
      "[Epoch 35/50] [Batch 188/235] [D loss: 1.149630, acc: 87.89%] [G loss: 1.078169]\n",
      "[Epoch 35/50] [Batch 189/235] [D loss: 1.114000, acc: 84.57%] [G loss: 1.118584]\n",
      "[Epoch 35/50] [Batch 190/235] [D loss: 1.135795, acc: 86.72%] [G loss: 1.265723]\n",
      "[Epoch 35/50] [Batch 191/235] [D loss: 1.091688, acc: 87.89%] [G loss: 1.255452]\n",
      "[Epoch 35/50] [Batch 192/235] [D loss: 1.114891, acc: 83.79%] [G loss: 1.176733]\n",
      "[Epoch 35/50] [Batch 193/235] [D loss: 1.088814, acc: 85.55%] [G loss: 1.034973]\n",
      "[Epoch 35/50] [Batch 194/235] [D loss: 1.120574, acc: 87.11%] [G loss: 1.147666]\n",
      "[Epoch 35/50] [Batch 195/235] [D loss: 1.124592, acc: 85.16%] [G loss: 1.184016]\n",
      "[Epoch 35/50] [Batch 196/235] [D loss: 1.094324, acc: 90.23%] [G loss: 1.076974]\n",
      "[Epoch 35/50] [Batch 197/235] [D loss: 1.114966, acc: 88.67%] [G loss: 1.071919]\n",
      "[Epoch 35/50] [Batch 198/235] [D loss: 1.084762, acc: 86.91%] [G loss: 1.144126]\n",
      "[Epoch 35/50] [Batch 199/235] [D loss: 1.142283, acc: 88.67%] [G loss: 1.102606]\n",
      "[Epoch 35/50] [Batch 200/235] [D loss: 1.053835, acc: 87.50%] [G loss: 1.217354]\n",
      "[Epoch 35/50] [Batch 201/235] [D loss: 1.098554, acc: 86.33%] [G loss: 1.088826]\n",
      "[Epoch 35/50] [Batch 202/235] [D loss: 1.148637, acc: 84.77%] [G loss: 1.191190]\n",
      "[Epoch 35/50] [Batch 203/235] [D loss: 1.092175, acc: 85.16%] [G loss: 1.168333]\n",
      "[Epoch 35/50] [Batch 204/235] [D loss: 1.156279, acc: 83.98%] [G loss: 1.147517]\n",
      "[Epoch 35/50] [Batch 205/235] [D loss: 1.057112, acc: 88.48%] [G loss: 1.134841]\n",
      "[Epoch 35/50] [Batch 206/235] [D loss: 1.110748, acc: 86.13%] [G loss: 1.186031]\n",
      "[Epoch 35/50] [Batch 207/235] [D loss: 1.153380, acc: 88.09%] [G loss: 1.145025]\n",
      "[Epoch 35/50] [Batch 208/235] [D loss: 1.166395, acc: 84.77%] [G loss: 1.308827]\n",
      "[Epoch 35/50] [Batch 209/235] [D loss: 1.104008, acc: 86.52%] [G loss: 1.362628]\n",
      "[Epoch 35/50] [Batch 210/235] [D loss: 1.128373, acc: 88.67%] [G loss: 1.079357]\n",
      "[Epoch 35/50] [Batch 211/235] [D loss: 1.148862, acc: 85.16%] [G loss: 1.079867]\n",
      "[Epoch 35/50] [Batch 212/235] [D loss: 1.089155, acc: 87.89%] [G loss: 1.142746]\n",
      "[Epoch 35/50] [Batch 213/235] [D loss: 1.119829, acc: 89.65%] [G loss: 1.261796]\n",
      "[Epoch 35/50] [Batch 214/235] [D loss: 1.152665, acc: 87.11%] [G loss: 1.102702]\n",
      "[Epoch 35/50] [Batch 215/235] [D loss: 1.124752, acc: 86.33%] [G loss: 1.063809]\n",
      "[Epoch 35/50] [Batch 216/235] [D loss: 1.121110, acc: 87.11%] [G loss: 1.116351]\n",
      "[Epoch 35/50] [Batch 217/235] [D loss: 1.127399, acc: 86.52%] [G loss: 1.087505]\n",
      "[Epoch 35/50] [Batch 218/235] [D loss: 1.139176, acc: 87.50%] [G loss: 1.168100]\n",
      "[Epoch 35/50] [Batch 219/235] [D loss: 1.136433, acc: 85.74%] [G loss: 1.273255]\n",
      "[Epoch 35/50] [Batch 220/235] [D loss: 1.101969, acc: 88.87%] [G loss: 1.266655]\n",
      "[Epoch 35/50] [Batch 221/235] [D loss: 1.048211, acc: 88.48%] [G loss: 1.200309]\n",
      "[Epoch 35/50] [Batch 222/235] [D loss: 1.110801, acc: 86.13%] [G loss: 1.070540]\n",
      "[Epoch 35/50] [Batch 223/235] [D loss: 1.047646, acc: 86.91%] [G loss: 1.086887]\n",
      "[Epoch 35/50] [Batch 224/235] [D loss: 1.172816, acc: 86.52%] [G loss: 1.229587]\n",
      "[Epoch 35/50] [Batch 225/235] [D loss: 1.097070, acc: 86.52%] [G loss: 1.306472]\n",
      "[Epoch 35/50] [Batch 226/235] [D loss: 1.126192, acc: 87.11%] [G loss: 1.173104]\n",
      "[Epoch 35/50] [Batch 227/235] [D loss: 1.146466, acc: 86.91%] [G loss: 1.237603]\n",
      "[Epoch 35/50] [Batch 228/235] [D loss: 1.074794, acc: 90.43%] [G loss: 1.118284]\n",
      "[Epoch 35/50] [Batch 229/235] [D loss: 1.101696, acc: 87.11%] [G loss: 1.021273]\n",
      "[Epoch 35/50] [Batch 230/235] [D loss: 1.103324, acc: 88.28%] [G loss: 1.086430]\n",
      "[Epoch 35/50] [Batch 231/235] [D loss: 1.109042, acc: 89.45%] [G loss: 1.196175]\n",
      "[Epoch 35/50] [Batch 232/235] [D loss: 1.105633, acc: 87.30%] [G loss: 1.251006]\n",
      "[Epoch 35/50] [Batch 233/235] [D loss: 1.129519, acc: 86.13%] [G loss: 1.103513]\n",
      "[Epoch 35/50] [Batch 234/235] [D loss: 1.122838, acc: 83.33%] [G loss: 1.066389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/50] [Batch 0/235] [D loss: 1.142893, acc: 88.48%] [G loss: 1.203488]\n",
      "[Epoch 36/50] [Batch 1/235] [D loss: 1.153197, acc: 87.89%] [G loss: 1.101770]\n",
      "[Epoch 36/50] [Batch 2/235] [D loss: 1.089373, acc: 86.52%] [G loss: 1.118547]\n",
      "[Epoch 36/50] [Batch 3/235] [D loss: 1.094679, acc: 87.50%] [G loss: 1.135360]\n",
      "[Epoch 36/50] [Batch 4/235] [D loss: 1.200755, acc: 86.33%] [G loss: 1.104504]\n",
      "[Epoch 36/50] [Batch 5/235] [D loss: 1.138180, acc: 88.67%] [G loss: 1.078027]\n",
      "[Epoch 36/50] [Batch 6/235] [D loss: 1.149150, acc: 86.72%] [G loss: 1.210229]\n",
      "[Epoch 36/50] [Batch 7/235] [D loss: 1.085729, acc: 88.09%] [G loss: 1.394431]\n",
      "[Epoch 36/50] [Batch 8/235] [D loss: 1.148816, acc: 84.38%] [G loss: 1.090823]\n",
      "[Epoch 36/50] [Batch 9/235] [D loss: 1.073795, acc: 87.70%] [G loss: 1.154747]\n",
      "[Epoch 36/50] [Batch 10/235] [D loss: 1.104377, acc: 86.33%] [G loss: 1.196419]\n",
      "[Epoch 36/50] [Batch 11/235] [D loss: 1.083799, acc: 88.09%] [G loss: 1.145007]\n",
      "[Epoch 36/50] [Batch 12/235] [D loss: 1.107865, acc: 86.52%] [G loss: 1.081835]\n",
      "[Epoch 36/50] [Batch 13/235] [D loss: 1.137669, acc: 84.18%] [G loss: 1.197472]\n",
      "[Epoch 36/50] [Batch 14/235] [D loss: 1.133103, acc: 87.30%] [G loss: 1.187659]\n",
      "[Epoch 36/50] [Batch 15/235] [D loss: 1.080676, acc: 89.06%] [G loss: 1.159606]\n",
      "[Epoch 36/50] [Batch 16/235] [D loss: 1.200069, acc: 87.70%] [G loss: 1.062521]\n",
      "[Epoch 36/50] [Batch 17/235] [D loss: 1.160602, acc: 85.74%] [G loss: 1.172723]\n",
      "[Epoch 36/50] [Batch 18/235] [D loss: 1.123698, acc: 88.67%] [G loss: 1.159942]\n",
      "[Epoch 36/50] [Batch 19/235] [D loss: 1.120835, acc: 85.74%] [G loss: 1.074910]\n",
      "[Epoch 36/50] [Batch 20/235] [D loss: 1.105518, acc: 87.89%] [G loss: 1.040915]\n",
      "[Epoch 36/50] [Batch 21/235] [D loss: 1.097230, acc: 86.91%] [G loss: 1.169516]\n",
      "[Epoch 36/50] [Batch 22/235] [D loss: 1.193824, acc: 89.84%] [G loss: 1.374560]\n",
      "[Epoch 36/50] [Batch 23/235] [D loss: 1.145787, acc: 86.13%] [G loss: 1.257413]\n",
      "[Epoch 36/50] [Batch 24/235] [D loss: 1.110642, acc: 86.33%] [G loss: 1.110246]\n",
      "[Epoch 36/50] [Batch 25/235] [D loss: 1.160929, acc: 87.50%] [G loss: 1.123024]\n",
      "[Epoch 36/50] [Batch 26/235] [D loss: 1.107813, acc: 86.52%] [G loss: 1.137223]\n",
      "[Epoch 36/50] [Batch 27/235] [D loss: 1.088795, acc: 88.67%] [G loss: 1.259698]\n",
      "[Epoch 36/50] [Batch 28/235] [D loss: 1.183230, acc: 85.35%] [G loss: 1.341457]\n",
      "[Epoch 36/50] [Batch 29/235] [D loss: 1.106273, acc: 84.57%] [G loss: 1.142613]\n",
      "[Epoch 36/50] [Batch 30/235] [D loss: 1.157009, acc: 86.72%] [G loss: 1.066973]\n",
      "[Epoch 36/50] [Batch 31/235] [D loss: 1.119922, acc: 86.72%] [G loss: 1.284783]\n",
      "[Epoch 36/50] [Batch 32/235] [D loss: 1.166860, acc: 88.48%] [G loss: 1.296584]\n",
      "[Epoch 36/50] [Batch 33/235] [D loss: 1.051930, acc: 86.72%] [G loss: 1.106665]\n",
      "[Epoch 36/50] [Batch 34/235] [D loss: 1.183861, acc: 86.72%] [G loss: 1.010037]\n",
      "[Epoch 36/50] [Batch 35/235] [D loss: 1.134158, acc: 84.57%] [G loss: 1.346067]\n",
      "[Epoch 36/50] [Batch 36/235] [D loss: 1.128486, acc: 85.94%] [G loss: 1.427665]\n",
      "[Epoch 36/50] [Batch 37/235] [D loss: 1.085850, acc: 86.52%] [G loss: 1.223404]\n",
      "[Epoch 36/50] [Batch 38/235] [D loss: 1.085852, acc: 89.26%] [G loss: 0.988559]\n",
      "[Epoch 36/50] [Batch 39/235] [D loss: 1.142594, acc: 90.04%] [G loss: 1.069610]\n",
      "[Epoch 36/50] [Batch 40/235] [D loss: 1.191788, acc: 84.57%] [G loss: 1.255286]\n",
      "[Epoch 36/50] [Batch 41/235] [D loss: 1.152577, acc: 89.26%] [G loss: 1.186733]\n",
      "[Epoch 36/50] [Batch 42/235] [D loss: 1.099765, acc: 87.30%] [G loss: 1.032074]\n",
      "[Epoch 36/50] [Batch 43/235] [D loss: 1.063438, acc: 88.87%] [G loss: 1.084064]\n",
      "[Epoch 36/50] [Batch 44/235] [D loss: 1.123231, acc: 86.72%] [G loss: 1.230013]\n",
      "[Epoch 36/50] [Batch 45/235] [D loss: 1.124306, acc: 87.70%] [G loss: 1.207606]\n",
      "[Epoch 36/50] [Batch 46/235] [D loss: 1.166554, acc: 85.55%] [G loss: 0.999958]\n",
      "[Epoch 36/50] [Batch 47/235] [D loss: 1.104428, acc: 85.74%] [G loss: 1.184776]\n",
      "[Epoch 36/50] [Batch 48/235] [D loss: 1.141845, acc: 87.89%] [G loss: 1.093512]\n",
      "[Epoch 36/50] [Batch 49/235] [D loss: 1.171310, acc: 87.50%] [G loss: 1.272107]\n",
      "[Epoch 36/50] [Batch 50/235] [D loss: 1.130574, acc: 84.96%] [G loss: 0.954502]\n",
      "[Epoch 36/50] [Batch 51/235] [D loss: 1.081000, acc: 85.94%] [G loss: 1.108751]\n",
      "[Epoch 36/50] [Batch 52/235] [D loss: 1.080670, acc: 87.30%] [G loss: 1.151685]\n",
      "[Epoch 36/50] [Batch 53/235] [D loss: 1.153448, acc: 87.89%] [G loss: 1.159050]\n",
      "[Epoch 36/50] [Batch 54/235] [D loss: 1.097865, acc: 89.45%] [G loss: 1.075866]\n",
      "[Epoch 36/50] [Batch 55/235] [D loss: 1.112325, acc: 90.23%] [G loss: 1.160907]\n",
      "[Epoch 36/50] [Batch 56/235] [D loss: 1.154695, acc: 89.06%] [G loss: 1.212298]\n",
      "[Epoch 36/50] [Batch 57/235] [D loss: 1.134052, acc: 87.50%] [G loss: 1.248622]\n",
      "[Epoch 36/50] [Batch 58/235] [D loss: 1.052657, acc: 89.84%] [G loss: 1.017703]\n",
      "[Epoch 36/50] [Batch 59/235] [D loss: 1.092605, acc: 86.91%] [G loss: 1.080633]\n",
      "[Epoch 36/50] [Batch 60/235] [D loss: 1.141555, acc: 84.96%] [G loss: 1.174632]\n",
      "[Epoch 36/50] [Batch 61/235] [D loss: 1.146862, acc: 90.62%] [G loss: 1.024510]\n",
      "[Epoch 36/50] [Batch 62/235] [D loss: 1.139607, acc: 86.91%] [G loss: 1.146339]\n",
      "[Epoch 36/50] [Batch 63/235] [D loss: 1.154322, acc: 87.30%] [G loss: 1.184931]\n",
      "[Epoch 36/50] [Batch 64/235] [D loss: 1.137956, acc: 88.28%] [G loss: 1.036189]\n",
      "[Epoch 36/50] [Batch 65/235] [D loss: 1.138865, acc: 86.13%] [G loss: 1.061067]\n",
      "[Epoch 36/50] [Batch 66/235] [D loss: 1.192377, acc: 87.11%] [G loss: 1.178340]\n",
      "[Epoch 36/50] [Batch 67/235] [D loss: 1.099551, acc: 85.55%] [G loss: 1.177846]\n",
      "[Epoch 36/50] [Batch 68/235] [D loss: 1.092591, acc: 87.70%] [G loss: 1.087481]\n",
      "[Epoch 36/50] [Batch 69/235] [D loss: 1.123031, acc: 86.91%] [G loss: 1.202062]\n",
      "[Epoch 36/50] [Batch 70/235] [D loss: 1.144241, acc: 88.28%] [G loss: 1.141279]\n",
      "[Epoch 36/50] [Batch 71/235] [D loss: 1.112951, acc: 87.70%] [G loss: 1.222996]\n",
      "[Epoch 36/50] [Batch 72/235] [D loss: 1.104259, acc: 89.26%] [G loss: 1.307209]\n",
      "[Epoch 36/50] [Batch 73/235] [D loss: 1.110955, acc: 86.91%] [G loss: 1.030076]\n",
      "[Epoch 36/50] [Batch 74/235] [D loss: 1.086466, acc: 88.67%] [G loss: 1.292227]\n",
      "[Epoch 36/50] [Batch 75/235] [D loss: 1.139742, acc: 85.55%] [G loss: 1.079642]\n",
      "[Epoch 36/50] [Batch 76/235] [D loss: 1.121491, acc: 86.91%] [G loss: 1.006696]\n",
      "[Epoch 36/50] [Batch 77/235] [D loss: 1.112103, acc: 89.06%] [G loss: 1.154687]\n",
      "[Epoch 36/50] [Batch 78/235] [D loss: 1.147190, acc: 84.77%] [G loss: 1.247831]\n",
      "[Epoch 36/50] [Batch 79/235] [D loss: 1.113621, acc: 87.30%] [G loss: 1.160079]\n",
      "[Epoch 36/50] [Batch 80/235] [D loss: 1.137678, acc: 88.09%] [G loss: 1.091430]\n",
      "[Epoch 36/50] [Batch 81/235] [D loss: 1.103652, acc: 86.91%] [G loss: 1.216241]\n",
      "[Epoch 36/50] [Batch 82/235] [D loss: 1.108336, acc: 85.94%] [G loss: 1.131325]\n",
      "[Epoch 36/50] [Batch 83/235] [D loss: 1.107262, acc: 88.48%] [G loss: 1.275546]\n",
      "[Epoch 36/50] [Batch 84/235] [D loss: 1.119373, acc: 87.89%] [G loss: 1.163279]\n",
      "[Epoch 36/50] [Batch 85/235] [D loss: 1.144274, acc: 84.77%] [G loss: 1.036512]\n",
      "[Epoch 36/50] [Batch 86/235] [D loss: 1.057022, acc: 87.30%] [G loss: 1.113879]\n",
      "[Epoch 36/50] [Batch 87/235] [D loss: 1.144893, acc: 88.67%] [G loss: 1.048233]\n",
      "[Epoch 36/50] [Batch 88/235] [D loss: 1.113821, acc: 88.09%] [G loss: 1.129502]\n",
      "[Epoch 36/50] [Batch 89/235] [D loss: 1.148269, acc: 86.13%] [G loss: 1.119444]\n",
      "[Epoch 36/50] [Batch 90/235] [D loss: 1.070633, acc: 87.89%] [G loss: 1.132083]\n",
      "[Epoch 36/50] [Batch 91/235] [D loss: 1.133789, acc: 86.72%] [G loss: 1.153818]\n",
      "[Epoch 36/50] [Batch 92/235] [D loss: 1.117878, acc: 87.70%] [G loss: 1.093283]\n",
      "[Epoch 36/50] [Batch 93/235] [D loss: 1.126961, acc: 86.13%] [G loss: 1.144108]\n",
      "[Epoch 36/50] [Batch 94/235] [D loss: 1.110184, acc: 88.28%] [G loss: 1.321197]\n",
      "[Epoch 36/50] [Batch 95/235] [D loss: 1.079805, acc: 88.28%] [G loss: 1.093728]\n",
      "[Epoch 36/50] [Batch 96/235] [D loss: 1.092179, acc: 86.33%] [G loss: 0.998266]\n",
      "[Epoch 36/50] [Batch 97/235] [D loss: 1.106420, acc: 85.74%] [G loss: 1.279286]\n",
      "[Epoch 36/50] [Batch 98/235] [D loss: 1.112676, acc: 86.91%] [G loss: 1.102690]\n",
      "[Epoch 36/50] [Batch 99/235] [D loss: 1.121888, acc: 88.28%] [G loss: 1.139870]\n",
      "[Epoch 36/50] [Batch 100/235] [D loss: 1.119771, acc: 85.94%] [G loss: 1.032981]\n",
      "[Epoch 36/50] [Batch 101/235] [D loss: 1.119466, acc: 87.11%] [G loss: 1.301765]\n",
      "[Epoch 36/50] [Batch 102/235] [D loss: 1.136132, acc: 86.52%] [G loss: 1.298473]\n",
      "[Epoch 36/50] [Batch 103/235] [D loss: 1.106011, acc: 86.52%] [G loss: 1.176206]\n",
      "[Epoch 36/50] [Batch 104/235] [D loss: 1.056636, acc: 86.33%] [G loss: 1.218179]\n",
      "[Epoch 36/50] [Batch 105/235] [D loss: 1.134786, acc: 84.57%] [G loss: 1.056034]\n",
      "[Epoch 36/50] [Batch 106/235] [D loss: 1.101880, acc: 91.41%] [G loss: 1.113679]\n",
      "[Epoch 36/50] [Batch 107/235] [D loss: 1.065860, acc: 85.94%] [G loss: 1.113631]\n",
      "[Epoch 36/50] [Batch 108/235] [D loss: 1.103068, acc: 86.52%] [G loss: 1.094472]\n",
      "[Epoch 36/50] [Batch 109/235] [D loss: 1.159764, acc: 86.13%] [G loss: 1.142954]\n",
      "[Epoch 36/50] [Batch 110/235] [D loss: 1.118918, acc: 88.09%] [G loss: 1.229619]\n",
      "[Epoch 36/50] [Batch 111/235] [D loss: 1.120771, acc: 89.65%] [G loss: 1.025251]\n",
      "[Epoch 36/50] [Batch 112/235] [D loss: 1.094395, acc: 89.06%] [G loss: 1.084452]\n",
      "[Epoch 36/50] [Batch 113/235] [D loss: 1.119790, acc: 88.28%] [G loss: 1.123034]\n",
      "[Epoch 36/50] [Batch 114/235] [D loss: 1.073515, acc: 88.28%] [G loss: 1.110130]\n",
      "[Epoch 36/50] [Batch 115/235] [D loss: 1.125244, acc: 85.74%] [G loss: 1.136020]\n",
      "[Epoch 36/50] [Batch 116/235] [D loss: 1.114589, acc: 89.45%] [G loss: 1.115038]\n",
      "[Epoch 36/50] [Batch 117/235] [D loss: 1.151208, acc: 85.35%] [G loss: 1.145082]\n",
      "[Epoch 36/50] [Batch 118/235] [D loss: 1.142524, acc: 84.57%] [G loss: 1.138960]\n",
      "[Epoch 36/50] [Batch 119/235] [D loss: 1.048903, acc: 87.30%] [G loss: 1.146993]\n",
      "[Epoch 36/50] [Batch 120/235] [D loss: 1.073712, acc: 87.11%] [G loss: 1.118892]\n",
      "[Epoch 36/50] [Batch 121/235] [D loss: 1.081588, acc: 87.11%] [G loss: 1.092859]\n",
      "[Epoch 36/50] [Batch 122/235] [D loss: 1.139786, acc: 87.30%] [G loss: 1.204848]\n",
      "[Epoch 36/50] [Batch 123/235] [D loss: 1.117177, acc: 87.30%] [G loss: 1.171623]\n",
      "[Epoch 36/50] [Batch 124/235] [D loss: 1.118527, acc: 85.74%] [G loss: 1.064731]\n",
      "[Epoch 36/50] [Batch 125/235] [D loss: 1.183662, acc: 87.11%] [G loss: 1.180993]\n",
      "[Epoch 36/50] [Batch 126/235] [D loss: 1.134873, acc: 86.72%] [G loss: 1.145449]\n",
      "[Epoch 36/50] [Batch 127/235] [D loss: 1.142950, acc: 84.96%] [G loss: 1.170043]\n",
      "[Epoch 36/50] [Batch 128/235] [D loss: 1.173307, acc: 90.82%] [G loss: 1.026084]\n",
      "[Epoch 36/50] [Batch 129/235] [D loss: 1.150729, acc: 85.94%] [G loss: 1.114474]\n",
      "[Epoch 36/50] [Batch 130/235] [D loss: 1.065601, acc: 89.26%] [G loss: 1.200548]\n",
      "[Epoch 36/50] [Batch 131/235] [D loss: 1.145820, acc: 87.30%] [G loss: 1.221081]\n",
      "[Epoch 36/50] [Batch 132/235] [D loss: 1.112367, acc: 86.13%] [G loss: 1.154323]\n",
      "[Epoch 36/50] [Batch 133/235] [D loss: 1.123157, acc: 87.50%] [G loss: 1.179829]\n",
      "[Epoch 36/50] [Batch 134/235] [D loss: 1.153027, acc: 83.01%] [G loss: 1.146974]\n",
      "[Epoch 36/50] [Batch 135/235] [D loss: 1.136339, acc: 85.16%] [G loss: 1.227007]\n",
      "[Epoch 36/50] [Batch 136/235] [D loss: 1.078678, acc: 88.67%] [G loss: 1.257401]\n",
      "[Epoch 36/50] [Batch 137/235] [D loss: 1.095650, acc: 87.70%] [G loss: 1.131392]\n",
      "[Epoch 36/50] [Batch 138/235] [D loss: 1.057118, acc: 85.74%] [G loss: 1.124740]\n",
      "[Epoch 36/50] [Batch 139/235] [D loss: 1.070720, acc: 89.45%] [G loss: 1.221416]\n",
      "[Epoch 36/50] [Batch 140/235] [D loss: 1.080609, acc: 87.89%] [G loss: 1.129695]\n",
      "[Epoch 36/50] [Batch 141/235] [D loss: 1.145027, acc: 87.89%] [G loss: 1.194434]\n",
      "[Epoch 36/50] [Batch 142/235] [D loss: 1.130466, acc: 88.28%] [G loss: 1.272224]\n",
      "[Epoch 36/50] [Batch 143/235] [D loss: 1.138075, acc: 87.89%] [G loss: 1.325722]\n",
      "[Epoch 36/50] [Batch 144/235] [D loss: 1.129730, acc: 89.84%] [G loss: 1.119979]\n",
      "[Epoch 36/50] [Batch 145/235] [D loss: 1.123718, acc: 86.72%] [G loss: 1.116737]\n",
      "[Epoch 36/50] [Batch 146/235] [D loss: 1.087466, acc: 87.11%] [G loss: 1.264895]\n",
      "[Epoch 36/50] [Batch 147/235] [D loss: 1.142454, acc: 88.28%] [G loss: 1.242117]\n",
      "[Epoch 36/50] [Batch 148/235] [D loss: 1.128472, acc: 88.67%] [G loss: 1.286305]\n",
      "[Epoch 36/50] [Batch 149/235] [D loss: 1.137261, acc: 87.11%] [G loss: 1.283484]\n",
      "[Epoch 36/50] [Batch 150/235] [D loss: 1.104374, acc: 88.28%] [G loss: 1.050455]\n",
      "[Epoch 36/50] [Batch 151/235] [D loss: 1.148924, acc: 88.48%] [G loss: 1.066095]\n",
      "[Epoch 36/50] [Batch 152/235] [D loss: 1.104542, acc: 87.11%] [G loss: 1.229920]\n",
      "[Epoch 36/50] [Batch 153/235] [D loss: 1.157159, acc: 86.91%] [G loss: 1.092442]\n",
      "[Epoch 36/50] [Batch 154/235] [D loss: 1.133084, acc: 86.52%] [G loss: 1.126691]\n",
      "[Epoch 36/50] [Batch 155/235] [D loss: 1.114079, acc: 88.48%] [G loss: 1.154196]\n",
      "[Epoch 36/50] [Batch 156/235] [D loss: 1.069046, acc: 87.50%] [G loss: 1.095252]\n",
      "[Epoch 36/50] [Batch 157/235] [D loss: 1.163775, acc: 85.35%] [G loss: 1.245165]\n",
      "[Epoch 36/50] [Batch 158/235] [D loss: 1.154692, acc: 87.50%] [G loss: 1.230103]\n",
      "[Epoch 36/50] [Batch 159/235] [D loss: 1.122632, acc: 88.67%] [G loss: 1.205813]\n",
      "[Epoch 36/50] [Batch 160/235] [D loss: 1.083147, acc: 88.67%] [G loss: 1.171350]\n",
      "[Epoch 36/50] [Batch 161/235] [D loss: 1.215527, acc: 84.77%] [G loss: 1.133488]\n",
      "[Epoch 36/50] [Batch 162/235] [D loss: 1.147198, acc: 87.89%] [G loss: 1.053325]\n",
      "[Epoch 36/50] [Batch 163/235] [D loss: 1.173245, acc: 86.72%] [G loss: 1.101788]\n",
      "[Epoch 36/50] [Batch 164/235] [D loss: 1.088360, acc: 86.52%] [G loss: 1.181749]\n",
      "[Epoch 36/50] [Batch 165/235] [D loss: 1.171613, acc: 86.13%] [G loss: 1.162234]\n",
      "[Epoch 36/50] [Batch 166/235] [D loss: 1.103536, acc: 88.28%] [G loss: 1.148756]\n",
      "[Epoch 36/50] [Batch 167/235] [D loss: 1.078039, acc: 88.48%] [G loss: 1.134171]\n",
      "[Epoch 36/50] [Batch 168/235] [D loss: 1.142747, acc: 85.74%] [G loss: 1.146599]\n",
      "[Epoch 36/50] [Batch 169/235] [D loss: 1.107560, acc: 86.72%] [G loss: 1.177212]\n",
      "[Epoch 36/50] [Batch 170/235] [D loss: 1.059504, acc: 86.33%] [G loss: 1.147510]\n",
      "[Epoch 36/50] [Batch 171/235] [D loss: 1.133745, acc: 85.55%] [G loss: 1.093871]\n",
      "[Epoch 36/50] [Batch 172/235] [D loss: 1.114891, acc: 89.26%] [G loss: 1.146079]\n",
      "[Epoch 36/50] [Batch 173/235] [D loss: 1.161915, acc: 87.50%] [G loss: 1.133827]\n",
      "[Epoch 36/50] [Batch 174/235] [D loss: 1.097173, acc: 88.67%] [G loss: 1.114923]\n",
      "[Epoch 36/50] [Batch 175/235] [D loss: 1.068133, acc: 89.65%] [G loss: 1.173567]\n",
      "[Epoch 36/50] [Batch 176/235] [D loss: 1.136200, acc: 87.89%] [G loss: 1.262037]\n",
      "[Epoch 36/50] [Batch 177/235] [D loss: 1.204462, acc: 89.06%] [G loss: 1.168395]\n",
      "[Epoch 36/50] [Batch 178/235] [D loss: 1.112903, acc: 85.35%] [G loss: 1.255423]\n",
      "[Epoch 36/50] [Batch 179/235] [D loss: 1.156545, acc: 86.72%] [G loss: 1.190644]\n",
      "[Epoch 36/50] [Batch 180/235] [D loss: 1.107343, acc: 88.28%] [G loss: 1.169198]\n",
      "[Epoch 36/50] [Batch 181/235] [D loss: 1.100070, acc: 87.89%] [G loss: 1.316234]\n",
      "[Epoch 36/50] [Batch 182/235] [D loss: 1.059335, acc: 86.91%] [G loss: 1.204217]\n",
      "[Epoch 36/50] [Batch 183/235] [D loss: 1.106697, acc: 86.13%] [G loss: 1.201036]\n",
      "[Epoch 36/50] [Batch 184/235] [D loss: 1.139180, acc: 89.06%] [G loss: 1.068294]\n",
      "[Epoch 36/50] [Batch 185/235] [D loss: 1.095437, acc: 85.55%] [G loss: 1.181193]\n",
      "[Epoch 36/50] [Batch 186/235] [D loss: 1.098427, acc: 88.09%] [G loss: 1.147591]\n",
      "[Epoch 36/50] [Batch 187/235] [D loss: 1.098464, acc: 88.28%] [G loss: 1.145557]\n",
      "[Epoch 36/50] [Batch 188/235] [D loss: 1.080426, acc: 86.91%] [G loss: 1.382034]\n",
      "[Epoch 36/50] [Batch 189/235] [D loss: 1.209444, acc: 85.94%] [G loss: 1.264199]\n",
      "[Epoch 36/50] [Batch 190/235] [D loss: 1.085606, acc: 86.13%] [G loss: 1.114650]\n",
      "[Epoch 36/50] [Batch 191/235] [D loss: 1.152432, acc: 84.77%] [G loss: 1.011418]\n",
      "[Epoch 36/50] [Batch 192/235] [D loss: 1.148207, acc: 86.33%] [G loss: 1.242465]\n",
      "[Epoch 36/50] [Batch 193/235] [D loss: 1.139572, acc: 85.74%] [G loss: 1.205240]\n",
      "[Epoch 36/50] [Batch 194/235] [D loss: 1.124368, acc: 86.33%] [G loss: 1.059314]\n",
      "[Epoch 36/50] [Batch 195/235] [D loss: 1.068010, acc: 89.06%] [G loss: 1.046558]\n",
      "[Epoch 36/50] [Batch 196/235] [D loss: 1.164827, acc: 88.09%] [G loss: 1.168445]\n",
      "[Epoch 36/50] [Batch 197/235] [D loss: 1.101692, acc: 86.33%] [G loss: 1.123564]\n",
      "[Epoch 36/50] [Batch 198/235] [D loss: 1.147694, acc: 89.06%] [G loss: 1.101139]\n",
      "[Epoch 36/50] [Batch 199/235] [D loss: 1.100807, acc: 88.87%] [G loss: 1.099231]\n",
      "[Epoch 36/50] [Batch 200/235] [D loss: 1.125308, acc: 85.55%] [G loss: 1.184086]\n",
      "[Epoch 36/50] [Batch 201/235] [D loss: 1.063502, acc: 88.09%] [G loss: 1.220810]\n",
      "[Epoch 36/50] [Batch 202/235] [D loss: 1.184656, acc: 88.48%] [G loss: 1.291387]\n",
      "[Epoch 36/50] [Batch 203/235] [D loss: 1.062118, acc: 90.82%] [G loss: 1.157735]\n",
      "[Epoch 36/50] [Batch 204/235] [D loss: 1.096246, acc: 88.67%] [G loss: 1.124703]\n",
      "[Epoch 36/50] [Batch 205/235] [D loss: 1.151946, acc: 85.94%] [G loss: 1.199636]\n",
      "[Epoch 36/50] [Batch 206/235] [D loss: 1.148161, acc: 83.59%] [G loss: 1.172544]\n",
      "[Epoch 36/50] [Batch 207/235] [D loss: 1.215043, acc: 88.48%] [G loss: 1.035996]\n",
      "[Epoch 36/50] [Batch 208/235] [D loss: 1.089307, acc: 86.52%] [G loss: 1.187686]\n",
      "[Epoch 36/50] [Batch 209/235] [D loss: 1.080357, acc: 89.65%] [G loss: 1.207097]\n",
      "[Epoch 36/50] [Batch 210/235] [D loss: 1.059869, acc: 87.50%] [G loss: 1.213878]\n",
      "[Epoch 36/50] [Batch 211/235] [D loss: 1.153231, acc: 87.70%] [G loss: 1.145802]\n",
      "[Epoch 36/50] [Batch 212/235] [D loss: 1.140516, acc: 86.33%] [G loss: 1.108448]\n",
      "[Epoch 36/50] [Batch 213/235] [D loss: 1.110343, acc: 84.77%] [G loss: 1.155083]\n",
      "[Epoch 36/50] [Batch 214/235] [D loss: 1.054226, acc: 86.33%] [G loss: 1.268572]\n",
      "[Epoch 36/50] [Batch 215/235] [D loss: 1.052850, acc: 88.48%] [G loss: 1.213953]\n",
      "[Epoch 36/50] [Batch 216/235] [D loss: 1.187867, acc: 84.38%] [G loss: 1.156960]\n",
      "[Epoch 36/50] [Batch 217/235] [D loss: 1.084026, acc: 87.50%] [G loss: 1.155289]\n",
      "[Epoch 36/50] [Batch 218/235] [D loss: 1.114991, acc: 86.72%] [G loss: 1.264676]\n",
      "[Epoch 36/50] [Batch 219/235] [D loss: 1.128950, acc: 83.59%] [G loss: 1.121199]\n",
      "[Epoch 36/50] [Batch 220/235] [D loss: 1.097531, acc: 87.70%] [G loss: 1.074885]\n",
      "[Epoch 36/50] [Batch 221/235] [D loss: 1.063276, acc: 90.04%] [G loss: 1.098900]\n",
      "[Epoch 36/50] [Batch 222/235] [D loss: 1.079206, acc: 88.09%] [G loss: 1.100876]\n",
      "[Epoch 36/50] [Batch 223/235] [D loss: 1.079526, acc: 86.13%] [G loss: 1.237157]\n",
      "[Epoch 36/50] [Batch 224/235] [D loss: 1.155476, acc: 86.13%] [G loss: 1.190672]\n",
      "[Epoch 36/50] [Batch 225/235] [D loss: 1.023707, acc: 86.52%] [G loss: 1.236963]\n",
      "[Epoch 36/50] [Batch 226/235] [D loss: 1.080529, acc: 87.70%] [G loss: 1.060951]\n",
      "[Epoch 36/50] [Batch 227/235] [D loss: 1.140396, acc: 87.89%] [G loss: 1.015293]\n",
      "[Epoch 36/50] [Batch 228/235] [D loss: 1.126357, acc: 88.28%] [G loss: 1.106607]\n",
      "[Epoch 36/50] [Batch 229/235] [D loss: 1.107073, acc: 88.09%] [G loss: 1.124415]\n",
      "[Epoch 36/50] [Batch 230/235] [D loss: 1.135265, acc: 90.04%] [G loss: 1.068799]\n",
      "[Epoch 36/50] [Batch 231/235] [D loss: 1.072753, acc: 89.26%] [G loss: 1.158294]\n",
      "[Epoch 36/50] [Batch 232/235] [D loss: 1.155874, acc: 86.72%] [G loss: 1.120465]\n",
      "[Epoch 36/50] [Batch 233/235] [D loss: 1.101833, acc: 86.52%] [G loss: 1.174576]\n",
      "[Epoch 36/50] [Batch 234/235] [D loss: 1.090335, acc: 88.02%] [G loss: 1.213445]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/50] [Batch 0/235] [D loss: 1.088709, acc: 87.89%] [G loss: 1.116051]\n",
      "[Epoch 37/50] [Batch 1/235] [D loss: 1.095039, acc: 85.94%] [G loss: 1.307469]\n",
      "[Epoch 37/50] [Batch 2/235] [D loss: 1.087947, acc: 88.09%] [G loss: 1.113904]\n",
      "[Epoch 37/50] [Batch 3/235] [D loss: 1.115516, acc: 86.13%] [G loss: 1.201989]\n",
      "[Epoch 37/50] [Batch 4/235] [D loss: 1.138656, acc: 87.70%] [G loss: 1.152558]\n",
      "[Epoch 37/50] [Batch 5/235] [D loss: 1.122865, acc: 85.55%] [G loss: 1.296825]\n",
      "[Epoch 37/50] [Batch 6/235] [D loss: 1.102280, acc: 87.30%] [G loss: 1.363702]\n",
      "[Epoch 37/50] [Batch 7/235] [D loss: 1.061476, acc: 85.94%] [G loss: 1.193813]\n",
      "[Epoch 37/50] [Batch 8/235] [D loss: 1.099600, acc: 87.50%] [G loss: 1.066592]\n",
      "[Epoch 37/50] [Batch 9/235] [D loss: 1.138314, acc: 86.33%] [G loss: 1.117009]\n",
      "[Epoch 37/50] [Batch 10/235] [D loss: 1.177682, acc: 85.94%] [G loss: 1.044030]\n",
      "[Epoch 37/50] [Batch 11/235] [D loss: 1.092140, acc: 87.70%] [G loss: 1.116506]\n",
      "[Epoch 37/50] [Batch 12/235] [D loss: 1.095634, acc: 84.18%] [G loss: 1.129241]\n",
      "[Epoch 37/50] [Batch 13/235] [D loss: 1.111518, acc: 87.50%] [G loss: 1.118378]\n",
      "[Epoch 37/50] [Batch 14/235] [D loss: 1.049816, acc: 88.09%] [G loss: 1.124893]\n",
      "[Epoch 37/50] [Batch 15/235] [D loss: 1.095189, acc: 88.67%] [G loss: 1.207962]\n",
      "[Epoch 37/50] [Batch 16/235] [D loss: 1.065236, acc: 89.06%] [G loss: 1.226264]\n",
      "[Epoch 37/50] [Batch 17/235] [D loss: 1.026753, acc: 87.70%] [G loss: 1.135964]\n",
      "[Epoch 37/50] [Batch 18/235] [D loss: 1.135139, acc: 89.06%] [G loss: 1.111568]\n",
      "[Epoch 37/50] [Batch 19/235] [D loss: 1.149098, acc: 86.33%] [G loss: 1.200016]\n",
      "[Epoch 37/50] [Batch 20/235] [D loss: 1.138183, acc: 89.65%] [G loss: 1.159505]\n",
      "[Epoch 37/50] [Batch 21/235] [D loss: 1.057705, acc: 86.91%] [G loss: 1.082792]\n",
      "[Epoch 37/50] [Batch 22/235] [D loss: 1.106468, acc: 88.28%] [G loss: 1.134616]\n",
      "[Epoch 37/50] [Batch 23/235] [D loss: 1.118370, acc: 88.87%] [G loss: 1.130996]\n",
      "[Epoch 37/50] [Batch 24/235] [D loss: 1.139232, acc: 84.18%] [G loss: 1.371180]\n",
      "[Epoch 37/50] [Batch 25/235] [D loss: 1.100498, acc: 86.33%] [G loss: 1.117110]\n",
      "[Epoch 37/50] [Batch 26/235] [D loss: 1.085261, acc: 88.48%] [G loss: 1.195592]\n",
      "[Epoch 37/50] [Batch 27/235] [D loss: 1.067625, acc: 85.74%] [G loss: 1.230807]\n",
      "[Epoch 37/50] [Batch 28/235] [D loss: 1.066662, acc: 89.26%] [G loss: 1.220696]\n",
      "[Epoch 37/50] [Batch 29/235] [D loss: 1.111076, acc: 87.89%] [G loss: 1.158486]\n",
      "[Epoch 37/50] [Batch 30/235] [D loss: 1.063620, acc: 87.30%] [G loss: 1.263092]\n",
      "[Epoch 37/50] [Batch 31/235] [D loss: 1.150352, acc: 85.94%] [G loss: 1.228552]\n",
      "[Epoch 37/50] [Batch 32/235] [D loss: 1.109036, acc: 88.48%] [G loss: 1.109701]\n",
      "[Epoch 37/50] [Batch 33/235] [D loss: 1.112261, acc: 86.91%] [G loss: 1.153170]\n",
      "[Epoch 37/50] [Batch 34/235] [D loss: 1.044830, acc: 88.09%] [G loss: 1.147640]\n",
      "[Epoch 37/50] [Batch 35/235] [D loss: 1.098174, acc: 89.45%] [G loss: 1.025630]\n",
      "[Epoch 37/50] [Batch 36/235] [D loss: 1.117649, acc: 86.33%] [G loss: 1.420299]\n",
      "[Epoch 37/50] [Batch 37/235] [D loss: 1.137428, acc: 87.11%] [G loss: 1.323814]\n",
      "[Epoch 37/50] [Batch 38/235] [D loss: 1.101298, acc: 89.06%] [G loss: 1.163717]\n",
      "[Epoch 37/50] [Batch 39/235] [D loss: 1.141271, acc: 86.33%] [G loss: 1.117391]\n",
      "[Epoch 37/50] [Batch 40/235] [D loss: 1.057987, acc: 86.72%] [G loss: 1.192839]\n",
      "[Epoch 37/50] [Batch 41/235] [D loss: 1.115862, acc: 88.67%] [G loss: 1.143726]\n",
      "[Epoch 37/50] [Batch 42/235] [D loss: 1.084847, acc: 88.09%] [G loss: 1.166691]\n",
      "[Epoch 37/50] [Batch 43/235] [D loss: 1.123306, acc: 87.50%] [G loss: 1.251978]\n",
      "[Epoch 37/50] [Batch 44/235] [D loss: 1.139513, acc: 86.13%] [G loss: 1.087980]\n",
      "[Epoch 37/50] [Batch 45/235] [D loss: 1.148423, acc: 87.30%] [G loss: 1.006271]\n",
      "[Epoch 37/50] [Batch 46/235] [D loss: 1.076409, acc: 86.33%] [G loss: 1.098024]\n",
      "[Epoch 37/50] [Batch 47/235] [D loss: 1.155253, acc: 84.96%] [G loss: 1.161429]\n",
      "[Epoch 37/50] [Batch 48/235] [D loss: 1.108895, acc: 87.30%] [G loss: 1.319867]\n",
      "[Epoch 37/50] [Batch 49/235] [D loss: 1.090106, acc: 89.06%] [G loss: 1.184100]\n",
      "[Epoch 37/50] [Batch 50/235] [D loss: 1.130068, acc: 88.67%] [G loss: 1.248450]\n",
      "[Epoch 37/50] [Batch 51/235] [D loss: 1.072847, acc: 89.26%] [G loss: 0.973720]\n",
      "[Epoch 37/50] [Batch 52/235] [D loss: 1.116558, acc: 88.28%] [G loss: 1.148752]\n",
      "[Epoch 37/50] [Batch 53/235] [D loss: 1.107593, acc: 87.30%] [G loss: 1.058210]\n",
      "[Epoch 37/50] [Batch 54/235] [D loss: 1.144778, acc: 88.28%] [G loss: 1.282628]\n",
      "[Epoch 37/50] [Batch 55/235] [D loss: 1.083275, acc: 88.87%] [G loss: 1.217494]\n",
      "[Epoch 37/50] [Batch 56/235] [D loss: 1.150656, acc: 84.77%] [G loss: 1.161936]\n",
      "[Epoch 37/50] [Batch 57/235] [D loss: 1.105190, acc: 86.91%] [G loss: 1.109719]\n",
      "[Epoch 37/50] [Batch 58/235] [D loss: 1.169279, acc: 88.87%] [G loss: 1.211542]\n",
      "[Epoch 37/50] [Batch 59/235] [D loss: 1.198740, acc: 83.01%] [G loss: 1.214350]\n",
      "[Epoch 37/50] [Batch 60/235] [D loss: 1.087071, acc: 89.45%] [G loss: 1.124956]\n",
      "[Epoch 37/50] [Batch 61/235] [D loss: 1.124289, acc: 86.52%] [G loss: 1.206111]\n",
      "[Epoch 37/50] [Batch 62/235] [D loss: 1.084693, acc: 88.28%] [G loss: 1.192860]\n",
      "[Epoch 37/50] [Batch 63/235] [D loss: 1.068039, acc: 87.50%] [G loss: 1.235572]\n",
      "[Epoch 37/50] [Batch 64/235] [D loss: 1.155238, acc: 87.50%] [G loss: 1.141842]\n",
      "[Epoch 37/50] [Batch 65/235] [D loss: 1.083291, acc: 88.09%] [G loss: 1.202535]\n",
      "[Epoch 37/50] [Batch 66/235] [D loss: 1.119980, acc: 87.70%] [G loss: 1.222961]\n",
      "[Epoch 37/50] [Batch 67/235] [D loss: 1.130412, acc: 87.50%] [G loss: 1.224764]\n",
      "[Epoch 37/50] [Batch 68/235] [D loss: 1.110670, acc: 88.48%] [G loss: 1.118093]\n",
      "[Epoch 37/50] [Batch 69/235] [D loss: 1.112926, acc: 89.45%] [G loss: 1.210432]\n",
      "[Epoch 37/50] [Batch 70/235] [D loss: 1.116196, acc: 87.30%] [G loss: 1.058223]\n",
      "[Epoch 37/50] [Batch 71/235] [D loss: 1.097168, acc: 85.35%] [G loss: 1.153102]\n",
      "[Epoch 37/50] [Batch 72/235] [D loss: 1.107486, acc: 84.57%] [G loss: 1.145875]\n",
      "[Epoch 37/50] [Batch 73/235] [D loss: 1.072032, acc: 89.06%] [G loss: 1.097774]\n",
      "[Epoch 37/50] [Batch 74/235] [D loss: 1.130937, acc: 88.09%] [G loss: 1.302151]\n",
      "[Epoch 37/50] [Batch 75/235] [D loss: 1.103481, acc: 86.91%] [G loss: 1.121026]\n",
      "[Epoch 37/50] [Batch 76/235] [D loss: 1.114663, acc: 84.96%] [G loss: 1.094583]\n",
      "[Epoch 37/50] [Batch 77/235] [D loss: 1.109477, acc: 86.91%] [G loss: 1.088980]\n",
      "[Epoch 37/50] [Batch 78/235] [D loss: 1.029914, acc: 86.91%] [G loss: 1.322577]\n",
      "[Epoch 37/50] [Batch 79/235] [D loss: 1.120044, acc: 88.09%] [G loss: 1.135543]\n",
      "[Epoch 37/50] [Batch 80/235] [D loss: 1.194023, acc: 86.91%] [G loss: 1.050487]\n",
      "[Epoch 37/50] [Batch 81/235] [D loss: 1.115975, acc: 87.70%] [G loss: 1.224301]\n",
      "[Epoch 37/50] [Batch 82/235] [D loss: 1.121240, acc: 88.09%] [G loss: 1.104009]\n",
      "[Epoch 37/50] [Batch 83/235] [D loss: 1.106165, acc: 88.28%] [G loss: 1.144159]\n",
      "[Epoch 37/50] [Batch 84/235] [D loss: 1.173129, acc: 87.11%] [G loss: 1.053931]\n",
      "[Epoch 37/50] [Batch 85/235] [D loss: 1.144409, acc: 86.91%] [G loss: 1.179596]\n",
      "[Epoch 37/50] [Batch 86/235] [D loss: 1.139314, acc: 85.94%] [G loss: 1.242019]\n",
      "[Epoch 37/50] [Batch 87/235] [D loss: 1.154688, acc: 87.70%] [G loss: 1.200502]\n",
      "[Epoch 37/50] [Batch 88/235] [D loss: 1.203011, acc: 86.52%] [G loss: 1.127160]\n",
      "[Epoch 37/50] [Batch 89/235] [D loss: 1.103889, acc: 88.48%] [G loss: 1.058065]\n",
      "[Epoch 37/50] [Batch 90/235] [D loss: 1.120403, acc: 86.72%] [G loss: 1.084549]\n",
      "[Epoch 37/50] [Batch 91/235] [D loss: 1.131185, acc: 86.52%] [G loss: 1.180056]\n",
      "[Epoch 37/50] [Batch 92/235] [D loss: 1.098897, acc: 86.72%] [G loss: 1.236072]\n",
      "[Epoch 37/50] [Batch 93/235] [D loss: 1.111841, acc: 86.91%] [G loss: 1.156706]\n",
      "[Epoch 37/50] [Batch 94/235] [D loss: 1.121101, acc: 86.52%] [G loss: 1.180377]\n",
      "[Epoch 37/50] [Batch 95/235] [D loss: 1.167725, acc: 87.11%] [G loss: 1.042765]\n",
      "[Epoch 37/50] [Batch 96/235] [D loss: 1.080950, acc: 88.67%] [G loss: 1.217057]\n",
      "[Epoch 37/50] [Batch 97/235] [D loss: 1.075970, acc: 88.28%] [G loss: 1.160637]\n",
      "[Epoch 37/50] [Batch 98/235] [D loss: 1.137805, acc: 84.57%] [G loss: 1.259140]\n",
      "[Epoch 37/50] [Batch 99/235] [D loss: 1.103212, acc: 87.89%] [G loss: 1.214493]\n",
      "[Epoch 37/50] [Batch 100/235] [D loss: 1.168246, acc: 87.89%] [G loss: 1.140223]\n",
      "[Epoch 37/50] [Batch 101/235] [D loss: 1.181502, acc: 85.74%] [G loss: 1.007592]\n",
      "[Epoch 37/50] [Batch 102/235] [D loss: 1.126457, acc: 87.89%] [G loss: 1.394701]\n",
      "[Epoch 37/50] [Batch 103/235] [D loss: 1.095925, acc: 86.91%] [G loss: 1.224091]\n",
      "[Epoch 37/50] [Batch 104/235] [D loss: 1.141061, acc: 88.48%] [G loss: 1.068337]\n",
      "[Epoch 37/50] [Batch 105/235] [D loss: 1.072144, acc: 88.48%] [G loss: 1.209033]\n",
      "[Epoch 37/50] [Batch 106/235] [D loss: 1.094993, acc: 84.96%] [G loss: 1.288278]\n",
      "[Epoch 37/50] [Batch 107/235] [D loss: 1.112114, acc: 86.52%] [G loss: 1.182222]\n",
      "[Epoch 37/50] [Batch 108/235] [D loss: 1.122031, acc: 89.65%] [G loss: 1.252994]\n",
      "[Epoch 37/50] [Batch 109/235] [D loss: 1.080655, acc: 89.06%] [G loss: 1.119308]\n",
      "[Epoch 37/50] [Batch 110/235] [D loss: 1.110006, acc: 86.72%] [G loss: 1.214944]\n",
      "[Epoch 37/50] [Batch 111/235] [D loss: 1.075604, acc: 87.50%] [G loss: 1.140185]\n",
      "[Epoch 37/50] [Batch 112/235] [D loss: 1.142311, acc: 86.33%] [G loss: 1.045648]\n",
      "[Epoch 37/50] [Batch 113/235] [D loss: 1.083936, acc: 85.74%] [G loss: 1.118387]\n",
      "[Epoch 37/50] [Batch 114/235] [D loss: 1.067085, acc: 88.48%] [G loss: 1.232538]\n",
      "[Epoch 37/50] [Batch 115/235] [D loss: 1.094698, acc: 87.11%] [G loss: 1.047104]\n",
      "[Epoch 37/50] [Batch 116/235] [D loss: 1.122626, acc: 84.77%] [G loss: 1.259823]\n",
      "[Epoch 37/50] [Batch 117/235] [D loss: 1.039873, acc: 87.11%] [G loss: 1.235461]\n",
      "[Epoch 37/50] [Batch 118/235] [D loss: 1.121721, acc: 86.72%] [G loss: 1.119321]\n",
      "[Epoch 37/50] [Batch 119/235] [D loss: 1.141086, acc: 85.55%] [G loss: 1.137347]\n",
      "[Epoch 37/50] [Batch 120/235] [D loss: 1.145701, acc: 85.74%] [G loss: 1.021747]\n",
      "[Epoch 37/50] [Batch 121/235] [D loss: 1.149843, acc: 88.28%] [G loss: 1.189852]\n",
      "[Epoch 37/50] [Batch 122/235] [D loss: 1.115814, acc: 88.28%] [G loss: 1.073277]\n",
      "[Epoch 37/50] [Batch 123/235] [D loss: 1.106772, acc: 87.89%] [G loss: 1.227698]\n",
      "[Epoch 37/50] [Batch 124/235] [D loss: 1.093647, acc: 86.13%] [G loss: 1.125870]\n",
      "[Epoch 37/50] [Batch 125/235] [D loss: 1.113123, acc: 88.48%] [G loss: 1.177651]\n",
      "[Epoch 37/50] [Batch 126/235] [D loss: 1.118677, acc: 88.28%] [G loss: 1.200187]\n",
      "[Epoch 37/50] [Batch 127/235] [D loss: 1.115186, acc: 86.52%] [G loss: 1.122202]\n",
      "[Epoch 37/50] [Batch 128/235] [D loss: 1.147308, acc: 86.13%] [G loss: 1.114833]\n",
      "[Epoch 37/50] [Batch 129/235] [D loss: 1.094076, acc: 85.35%] [G loss: 1.258988]\n",
      "[Epoch 37/50] [Batch 130/235] [D loss: 1.101741, acc: 88.28%] [G loss: 1.152928]\n",
      "[Epoch 37/50] [Batch 131/235] [D loss: 1.167647, acc: 86.72%] [G loss: 1.066402]\n",
      "[Epoch 37/50] [Batch 132/235] [D loss: 1.101948, acc: 85.55%] [G loss: 1.122752]\n",
      "[Epoch 37/50] [Batch 133/235] [D loss: 1.120399, acc: 87.50%] [G loss: 1.189168]\n",
      "[Epoch 37/50] [Batch 134/235] [D loss: 1.099198, acc: 87.89%] [G loss: 1.164966]\n",
      "[Epoch 37/50] [Batch 135/235] [D loss: 1.088960, acc: 85.35%] [G loss: 1.100657]\n",
      "[Epoch 37/50] [Batch 136/235] [D loss: 1.075654, acc: 88.48%] [G loss: 1.056996]\n",
      "[Epoch 37/50] [Batch 137/235] [D loss: 1.082299, acc: 85.74%] [G loss: 1.232360]\n",
      "[Epoch 37/50] [Batch 138/235] [D loss: 1.113673, acc: 87.11%] [G loss: 1.374219]\n",
      "[Epoch 37/50] [Batch 139/235] [D loss: 1.110644, acc: 86.52%] [G loss: 1.110319]\n",
      "[Epoch 37/50] [Batch 140/235] [D loss: 1.129632, acc: 87.30%] [G loss: 1.045157]\n",
      "[Epoch 37/50] [Batch 141/235] [D loss: 1.072989, acc: 88.48%] [G loss: 1.237099]\n",
      "[Epoch 37/50] [Batch 142/235] [D loss: 1.110506, acc: 88.48%] [G loss: 1.130796]\n",
      "[Epoch 37/50] [Batch 143/235] [D loss: 1.112516, acc: 89.45%] [G loss: 1.131034]\n",
      "[Epoch 37/50] [Batch 144/235] [D loss: 1.156832, acc: 84.96%] [G loss: 1.218815]\n",
      "[Epoch 37/50] [Batch 145/235] [D loss: 1.108219, acc: 87.70%] [G loss: 1.073841]\n",
      "[Epoch 37/50] [Batch 146/235] [D loss: 1.094629, acc: 86.13%] [G loss: 1.188122]\n",
      "[Epoch 37/50] [Batch 147/235] [D loss: 1.123390, acc: 83.01%] [G loss: 1.145005]\n",
      "[Epoch 37/50] [Batch 148/235] [D loss: 1.081472, acc: 86.13%] [G loss: 1.209385]\n",
      "[Epoch 37/50] [Batch 149/235] [D loss: 1.066548, acc: 87.30%] [G loss: 1.209418]\n",
      "[Epoch 37/50] [Batch 150/235] [D loss: 1.131959, acc: 86.72%] [G loss: 1.128765]\n",
      "[Epoch 37/50] [Batch 151/235] [D loss: 1.073834, acc: 88.28%] [G loss: 1.165407]\n",
      "[Epoch 37/50] [Batch 152/235] [D loss: 1.113464, acc: 87.70%] [G loss: 1.063636]\n",
      "[Epoch 37/50] [Batch 153/235] [D loss: 1.117585, acc: 86.52%] [G loss: 1.225268]\n",
      "[Epoch 37/50] [Batch 154/235] [D loss: 1.123359, acc: 87.70%] [G loss: 1.360295]\n",
      "[Epoch 37/50] [Batch 155/235] [D loss: 1.032227, acc: 87.11%] [G loss: 1.218207]\n",
      "[Epoch 37/50] [Batch 156/235] [D loss: 1.123907, acc: 85.74%] [G loss: 1.077276]\n",
      "[Epoch 37/50] [Batch 157/235] [D loss: 1.064544, acc: 87.50%] [G loss: 1.174376]\n",
      "[Epoch 37/50] [Batch 158/235] [D loss: 1.075308, acc: 86.72%] [G loss: 1.230533]\n",
      "[Epoch 37/50] [Batch 159/235] [D loss: 1.151053, acc: 87.50%] [G loss: 1.333852]\n",
      "[Epoch 37/50] [Batch 160/235] [D loss: 1.157990, acc: 87.11%] [G loss: 1.304339]\n",
      "[Epoch 37/50] [Batch 161/235] [D loss: 1.099761, acc: 86.52%] [G loss: 1.072843]\n",
      "[Epoch 37/50] [Batch 162/235] [D loss: 1.115714, acc: 85.35%] [G loss: 1.077374]\n",
      "[Epoch 37/50] [Batch 163/235] [D loss: 1.094633, acc: 89.65%] [G loss: 1.209988]\n",
      "[Epoch 37/50] [Batch 164/235] [D loss: 1.091580, acc: 88.09%] [G loss: 1.167871]\n",
      "[Epoch 37/50] [Batch 165/235] [D loss: 1.087540, acc: 87.30%] [G loss: 1.108003]\n",
      "[Epoch 37/50] [Batch 166/235] [D loss: 1.146704, acc: 87.89%] [G loss: 1.146683]\n",
      "[Epoch 37/50] [Batch 167/235] [D loss: 1.167399, acc: 83.98%] [G loss: 1.067283]\n",
      "[Epoch 37/50] [Batch 168/235] [D loss: 1.118877, acc: 86.52%] [G loss: 1.135640]\n",
      "[Epoch 37/50] [Batch 169/235] [D loss: 1.182399, acc: 85.74%] [G loss: 1.303719]\n",
      "[Epoch 37/50] [Batch 170/235] [D loss: 1.110862, acc: 87.30%] [G loss: 1.074298]\n",
      "[Epoch 37/50] [Batch 171/235] [D loss: 1.174441, acc: 84.77%] [G loss: 1.138572]\n",
      "[Epoch 37/50] [Batch 172/235] [D loss: 1.072122, acc: 88.48%] [G loss: 1.093205]\n",
      "[Epoch 37/50] [Batch 173/235] [D loss: 1.141490, acc: 89.65%] [G loss: 1.045777]\n",
      "[Epoch 37/50] [Batch 174/235] [D loss: 1.123460, acc: 88.67%] [G loss: 1.089916]\n",
      "[Epoch 37/50] [Batch 175/235] [D loss: 1.108070, acc: 87.50%] [G loss: 1.324194]\n",
      "[Epoch 37/50] [Batch 176/235] [D loss: 1.159569, acc: 88.67%] [G loss: 1.108563]\n",
      "[Epoch 37/50] [Batch 177/235] [D loss: 1.071977, acc: 87.70%] [G loss: 1.141835]\n",
      "[Epoch 37/50] [Batch 178/235] [D loss: 1.112411, acc: 85.55%] [G loss: 1.213260]\n",
      "[Epoch 37/50] [Batch 179/235] [D loss: 1.156435, acc: 88.28%] [G loss: 1.143497]\n",
      "[Epoch 37/50] [Batch 180/235] [D loss: 1.094417, acc: 89.84%] [G loss: 1.136500]\n",
      "[Epoch 37/50] [Batch 181/235] [D loss: 1.091564, acc: 87.89%] [G loss: 1.307855]\n",
      "[Epoch 37/50] [Batch 182/235] [D loss: 1.114841, acc: 86.13%] [G loss: 1.203433]\n",
      "[Epoch 37/50] [Batch 183/235] [D loss: 1.068655, acc: 88.09%] [G loss: 1.225906]\n",
      "[Epoch 37/50] [Batch 184/235] [D loss: 1.126784, acc: 88.28%] [G loss: 1.110234]\n",
      "[Epoch 37/50] [Batch 185/235] [D loss: 1.112424, acc: 88.09%] [G loss: 1.194819]\n",
      "[Epoch 37/50] [Batch 186/235] [D loss: 1.104031, acc: 88.09%] [G loss: 1.112911]\n",
      "[Epoch 37/50] [Batch 187/235] [D loss: 1.140318, acc: 86.13%] [G loss: 1.208808]\n",
      "[Epoch 37/50] [Batch 188/235] [D loss: 1.096822, acc: 87.70%] [G loss: 1.008281]\n",
      "[Epoch 37/50] [Batch 189/235] [D loss: 1.093786, acc: 87.50%] [G loss: 1.221771]\n",
      "[Epoch 37/50] [Batch 190/235] [D loss: 1.125328, acc: 86.13%] [G loss: 1.118872]\n",
      "[Epoch 37/50] [Batch 191/235] [D loss: 1.141948, acc: 85.94%] [G loss: 1.155515]\n",
      "[Epoch 37/50] [Batch 192/235] [D loss: 1.105997, acc: 87.70%] [G loss: 1.043500]\n",
      "[Epoch 37/50] [Batch 193/235] [D loss: 1.068472, acc: 86.52%] [G loss: 1.072360]\n",
      "[Epoch 37/50] [Batch 194/235] [D loss: 1.111021, acc: 89.06%] [G loss: 1.027329]\n",
      "[Epoch 37/50] [Batch 195/235] [D loss: 1.043446, acc: 89.26%] [G loss: 1.157836]\n",
      "[Epoch 37/50] [Batch 196/235] [D loss: 1.138207, acc: 88.09%] [G loss: 1.158363]\n",
      "[Epoch 37/50] [Batch 197/235] [D loss: 1.148409, acc: 91.41%] [G loss: 1.173004]\n",
      "[Epoch 37/50] [Batch 198/235] [D loss: 1.109894, acc: 85.35%] [G loss: 1.075842]\n",
      "[Epoch 37/50] [Batch 199/235] [D loss: 1.164765, acc: 86.72%] [G loss: 1.073957]\n",
      "[Epoch 37/50] [Batch 200/235] [D loss: 1.079103, acc: 87.70%] [G loss: 1.284333]\n",
      "[Epoch 37/50] [Batch 201/235] [D loss: 1.083011, acc: 88.09%] [G loss: 1.202371]\n",
      "[Epoch 37/50] [Batch 202/235] [D loss: 1.143226, acc: 88.09%] [G loss: 1.017035]\n",
      "[Epoch 37/50] [Batch 203/235] [D loss: 1.136874, acc: 88.48%] [G loss: 1.077019]\n",
      "[Epoch 37/50] [Batch 204/235] [D loss: 1.140438, acc: 87.70%] [G loss: 1.215362]\n",
      "[Epoch 37/50] [Batch 205/235] [D loss: 1.121962, acc: 86.72%] [G loss: 1.161618]\n",
      "[Epoch 37/50] [Batch 206/235] [D loss: 1.193635, acc: 87.30%] [G loss: 1.187853]\n",
      "[Epoch 37/50] [Batch 207/235] [D loss: 1.067304, acc: 89.65%] [G loss: 1.195712]\n",
      "[Epoch 37/50] [Batch 208/235] [D loss: 1.129402, acc: 85.35%] [G loss: 1.250119]\n",
      "[Epoch 37/50] [Batch 209/235] [D loss: 1.139733, acc: 85.94%] [G loss: 1.142142]\n",
      "[Epoch 37/50] [Batch 210/235] [D loss: 1.066558, acc: 87.50%] [G loss: 1.181931]\n",
      "[Epoch 37/50] [Batch 211/235] [D loss: 1.081910, acc: 87.30%] [G loss: 1.171371]\n",
      "[Epoch 37/50] [Batch 212/235] [D loss: 1.137231, acc: 84.96%] [G loss: 1.136668]\n",
      "[Epoch 37/50] [Batch 213/235] [D loss: 1.111142, acc: 87.50%] [G loss: 1.162443]\n",
      "[Epoch 37/50] [Batch 214/235] [D loss: 1.116223, acc: 88.48%] [G loss: 1.175771]\n",
      "[Epoch 37/50] [Batch 215/235] [D loss: 1.094736, acc: 88.67%] [G loss: 1.116902]\n",
      "[Epoch 37/50] [Batch 216/235] [D loss: 1.091713, acc: 86.52%] [G loss: 1.100128]\n",
      "[Epoch 37/50] [Batch 217/235] [D loss: 1.147587, acc: 89.26%] [G loss: 1.111127]\n",
      "[Epoch 37/50] [Batch 218/235] [D loss: 1.162295, acc: 87.11%] [G loss: 1.256623]\n",
      "[Epoch 37/50] [Batch 219/235] [D loss: 1.082319, acc: 87.50%] [G loss: 1.157358]\n",
      "[Epoch 37/50] [Batch 220/235] [D loss: 1.070604, acc: 86.13%] [G loss: 1.106706]\n",
      "[Epoch 37/50] [Batch 221/235] [D loss: 1.135442, acc: 86.72%] [G loss: 1.105184]\n",
      "[Epoch 37/50] [Batch 222/235] [D loss: 1.087086, acc: 86.33%] [G loss: 1.476225]\n",
      "[Epoch 37/50] [Batch 223/235] [D loss: 1.122149, acc: 87.50%] [G loss: 1.187902]\n",
      "[Epoch 37/50] [Batch 224/235] [D loss: 1.097837, acc: 86.52%] [G loss: 0.975052]\n",
      "[Epoch 37/50] [Batch 225/235] [D loss: 1.114440, acc: 87.50%] [G loss: 1.126511]\n",
      "[Epoch 37/50] [Batch 226/235] [D loss: 1.122425, acc: 86.13%] [G loss: 1.158739]\n",
      "[Epoch 37/50] [Batch 227/235] [D loss: 1.097022, acc: 86.33%] [G loss: 1.188345]\n",
      "[Epoch 37/50] [Batch 228/235] [D loss: 1.115849, acc: 89.06%] [G loss: 1.264868]\n",
      "[Epoch 37/50] [Batch 229/235] [D loss: 1.055108, acc: 88.87%] [G loss: 1.261764]\n",
      "[Epoch 37/50] [Batch 230/235] [D loss: 1.103353, acc: 87.70%] [G loss: 1.069762]\n",
      "[Epoch 37/50] [Batch 231/235] [D loss: 1.127532, acc: 88.48%] [G loss: 1.067423]\n",
      "[Epoch 37/50] [Batch 232/235] [D loss: 1.088883, acc: 88.87%] [G loss: 1.174983]\n",
      "[Epoch 37/50] [Batch 233/235] [D loss: 1.134818, acc: 88.48%] [G loss: 1.243837]\n",
      "[Epoch 37/50] [Batch 234/235] [D loss: 1.220016, acc: 87.50%] [G loss: 1.116458]\n",
      "[Epoch 38/50] [Batch 0/235] [D loss: 1.131528, acc: 86.13%] [G loss: 1.057732]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/50] [Batch 1/235] [D loss: 1.149722, acc: 89.45%] [G loss: 1.055170]\n",
      "[Epoch 38/50] [Batch 2/235] [D loss: 1.085107, acc: 85.16%] [G loss: 1.235823]\n",
      "[Epoch 38/50] [Batch 3/235] [D loss: 1.221587, acc: 86.52%] [G loss: 1.181351]\n",
      "[Epoch 38/50] [Batch 4/235] [D loss: 1.113470, acc: 88.67%] [G loss: 1.032645]\n",
      "[Epoch 38/50] [Batch 5/235] [D loss: 1.099280, acc: 86.52%] [G loss: 1.148108]\n",
      "[Epoch 38/50] [Batch 6/235] [D loss: 1.052782, acc: 88.87%] [G loss: 1.195448]\n",
      "[Epoch 38/50] [Batch 7/235] [D loss: 1.169080, acc: 90.04%] [G loss: 1.053392]\n",
      "[Epoch 38/50] [Batch 8/235] [D loss: 1.172419, acc: 88.67%] [G loss: 1.304140]\n",
      "[Epoch 38/50] [Batch 9/235] [D loss: 1.087560, acc: 88.28%] [G loss: 1.160664]\n",
      "[Epoch 38/50] [Batch 10/235] [D loss: 1.155045, acc: 87.70%] [G loss: 1.164648]\n",
      "[Epoch 38/50] [Batch 11/235] [D loss: 1.082056, acc: 86.33%] [G loss: 1.136828]\n",
      "[Epoch 38/50] [Batch 12/235] [D loss: 1.125019, acc: 86.72%] [G loss: 1.227479]\n",
      "[Epoch 38/50] [Batch 13/235] [D loss: 1.084410, acc: 87.89%] [G loss: 0.994710]\n",
      "[Epoch 38/50] [Batch 14/235] [D loss: 1.126083, acc: 87.11%] [G loss: 1.155111]\n",
      "[Epoch 38/50] [Batch 15/235] [D loss: 1.078934, acc: 87.70%] [G loss: 1.156737]\n",
      "[Epoch 38/50] [Batch 16/235] [D loss: 1.160184, acc: 86.72%] [G loss: 1.031292]\n",
      "[Epoch 38/50] [Batch 17/235] [D loss: 1.097868, acc: 88.28%] [G loss: 1.100630]\n",
      "[Epoch 38/50] [Batch 18/235] [D loss: 1.106142, acc: 87.30%] [G loss: 1.239546]\n",
      "[Epoch 38/50] [Batch 19/235] [D loss: 1.133348, acc: 87.89%] [G loss: 1.191687]\n",
      "[Epoch 38/50] [Batch 20/235] [D loss: 1.070723, acc: 87.11%] [G loss: 1.134567]\n",
      "[Epoch 38/50] [Batch 21/235] [D loss: 1.118153, acc: 90.82%] [G loss: 1.113262]\n",
      "[Epoch 38/50] [Batch 22/235] [D loss: 1.161009, acc: 86.13%] [G loss: 1.227244]\n",
      "[Epoch 38/50] [Batch 23/235] [D loss: 1.106740, acc: 85.55%] [G loss: 1.199281]\n",
      "[Epoch 38/50] [Batch 24/235] [D loss: 1.143170, acc: 86.33%] [G loss: 1.115116]\n",
      "[Epoch 38/50] [Batch 25/235] [D loss: 1.112345, acc: 86.13%] [G loss: 1.275659]\n",
      "[Epoch 38/50] [Batch 26/235] [D loss: 1.045802, acc: 87.30%] [G loss: 1.177574]\n",
      "[Epoch 38/50] [Batch 27/235] [D loss: 1.109990, acc: 87.50%] [G loss: 1.119480]\n",
      "[Epoch 38/50] [Batch 28/235] [D loss: 1.062039, acc: 88.48%] [G loss: 1.098009]\n",
      "[Epoch 38/50] [Batch 29/235] [D loss: 1.023230, acc: 88.48%] [G loss: 1.128461]\n",
      "[Epoch 38/50] [Batch 30/235] [D loss: 1.103502, acc: 87.11%] [G loss: 1.167011]\n",
      "[Epoch 38/50] [Batch 31/235] [D loss: 1.090841, acc: 87.50%] [G loss: 1.281686]\n",
      "[Epoch 38/50] [Batch 32/235] [D loss: 1.096198, acc: 87.89%] [G loss: 1.224020]\n",
      "[Epoch 38/50] [Batch 33/235] [D loss: 1.134600, acc: 89.06%] [G loss: 1.068315]\n",
      "[Epoch 38/50] [Batch 34/235] [D loss: 1.176535, acc: 83.59%] [G loss: 1.074140]\n",
      "[Epoch 38/50] [Batch 35/235] [D loss: 1.129951, acc: 89.26%] [G loss: 1.114220]\n",
      "[Epoch 38/50] [Batch 36/235] [D loss: 1.115304, acc: 86.91%] [G loss: 1.334715]\n",
      "[Epoch 38/50] [Batch 37/235] [D loss: 1.149183, acc: 86.91%] [G loss: 1.207502]\n",
      "[Epoch 38/50] [Batch 38/235] [D loss: 1.119566, acc: 87.50%] [G loss: 1.280807]\n",
      "[Epoch 38/50] [Batch 39/235] [D loss: 1.126265, acc: 86.52%] [G loss: 1.144257]\n",
      "[Epoch 38/50] [Batch 40/235] [D loss: 1.119137, acc: 91.41%] [G loss: 1.064214]\n",
      "[Epoch 38/50] [Batch 41/235] [D loss: 1.146290, acc: 86.33%] [G loss: 1.202341]\n",
      "[Epoch 38/50] [Batch 42/235] [D loss: 1.128373, acc: 87.50%] [G loss: 1.277585]\n",
      "[Epoch 38/50] [Batch 43/235] [D loss: 1.190154, acc: 90.62%] [G loss: 1.103763]\n",
      "[Epoch 38/50] [Batch 44/235] [D loss: 1.098779, acc: 88.48%] [G loss: 1.019195]\n",
      "[Epoch 38/50] [Batch 45/235] [D loss: 1.135032, acc: 88.28%] [G loss: 1.129211]\n",
      "[Epoch 38/50] [Batch 46/235] [D loss: 1.097985, acc: 86.72%] [G loss: 1.111483]\n",
      "[Epoch 38/50] [Batch 47/235] [D loss: 1.184249, acc: 88.09%] [G loss: 1.123347]\n",
      "[Epoch 38/50] [Batch 48/235] [D loss: 1.118693, acc: 85.35%] [G loss: 1.213185]\n",
      "[Epoch 38/50] [Batch 49/235] [D loss: 1.116968, acc: 87.70%] [G loss: 1.159638]\n",
      "[Epoch 38/50] [Batch 50/235] [D loss: 1.146420, acc: 87.11%] [G loss: 1.178301]\n",
      "[Epoch 38/50] [Batch 51/235] [D loss: 1.098362, acc: 87.70%] [G loss: 1.081269]\n",
      "[Epoch 38/50] [Batch 52/235] [D loss: 1.092443, acc: 88.67%] [G loss: 1.053441]\n",
      "[Epoch 38/50] [Batch 53/235] [D loss: 1.103064, acc: 86.33%] [G loss: 1.160532]\n",
      "[Epoch 38/50] [Batch 54/235] [D loss: 1.111444, acc: 86.91%] [G loss: 1.201436]\n",
      "[Epoch 38/50] [Batch 55/235] [D loss: 1.137782, acc: 85.35%] [G loss: 1.301328]\n",
      "[Epoch 38/50] [Batch 56/235] [D loss: 1.162501, acc: 88.48%] [G loss: 1.177224]\n",
      "[Epoch 38/50] [Batch 57/235] [D loss: 1.046815, acc: 87.89%] [G loss: 1.190729]\n",
      "[Epoch 38/50] [Batch 58/235] [D loss: 1.115375, acc: 84.57%] [G loss: 1.087391]\n",
      "[Epoch 38/50] [Batch 59/235] [D loss: 1.082841, acc: 88.87%] [G loss: 1.143110]\n",
      "[Epoch 38/50] [Batch 60/235] [D loss: 1.084614, acc: 87.11%] [G loss: 1.051801]\n",
      "[Epoch 38/50] [Batch 61/235] [D loss: 1.142443, acc: 86.72%] [G loss: 1.130018]\n",
      "[Epoch 38/50] [Batch 62/235] [D loss: 1.092786, acc: 88.48%] [G loss: 1.196864]\n",
      "[Epoch 38/50] [Batch 63/235] [D loss: 1.074291, acc: 87.50%] [G loss: 1.116638]\n",
      "[Epoch 38/50] [Batch 64/235] [D loss: 1.084905, acc: 89.06%] [G loss: 1.177978]\n",
      "[Epoch 38/50] [Batch 65/235] [D loss: 1.075507, acc: 87.30%] [G loss: 1.121903]\n",
      "[Epoch 38/50] [Batch 66/235] [D loss: 1.062069, acc: 88.48%] [G loss: 1.122383]\n",
      "[Epoch 38/50] [Batch 67/235] [D loss: 1.049677, acc: 87.70%] [G loss: 1.266744]\n",
      "[Epoch 38/50] [Batch 68/235] [D loss: 1.137555, acc: 88.48%] [G loss: 1.209616]\n",
      "[Epoch 38/50] [Batch 69/235] [D loss: 1.104953, acc: 87.30%] [G loss: 1.142996]\n",
      "[Epoch 38/50] [Batch 70/235] [D loss: 1.125567, acc: 87.70%] [G loss: 1.028233]\n",
      "[Epoch 38/50] [Batch 71/235] [D loss: 1.098774, acc: 86.52%] [G loss: 1.046842]\n",
      "[Epoch 38/50] [Batch 72/235] [D loss: 1.118638, acc: 87.50%] [G loss: 1.275020]\n",
      "[Epoch 38/50] [Batch 73/235] [D loss: 1.062650, acc: 86.91%] [G loss: 1.271933]\n",
      "[Epoch 38/50] [Batch 74/235] [D loss: 1.115736, acc: 86.91%] [G loss: 1.047109]\n",
      "[Epoch 38/50] [Batch 75/235] [D loss: 1.138231, acc: 86.33%] [G loss: 1.302276]\n",
      "[Epoch 38/50] [Batch 76/235] [D loss: 1.138842, acc: 85.16%] [G loss: 1.133710]\n",
      "[Epoch 38/50] [Batch 77/235] [D loss: 1.079486, acc: 86.72%] [G loss: 1.147357]\n",
      "[Epoch 38/50] [Batch 78/235] [D loss: 1.116136, acc: 86.91%] [G loss: 1.188898]\n",
      "[Epoch 38/50] [Batch 79/235] [D loss: 1.103038, acc: 88.67%] [G loss: 1.194570]\n",
      "[Epoch 38/50] [Batch 80/235] [D loss: 1.048916, acc: 89.65%] [G loss: 1.234192]\n",
      "[Epoch 38/50] [Batch 81/235] [D loss: 1.091478, acc: 87.11%] [G loss: 1.143890]\n",
      "[Epoch 38/50] [Batch 82/235] [D loss: 1.121376, acc: 86.72%] [G loss: 1.184932]\n",
      "[Epoch 38/50] [Batch 83/235] [D loss: 1.037243, acc: 88.67%] [G loss: 1.163849]\n",
      "[Epoch 38/50] [Batch 84/235] [D loss: 1.152701, acc: 87.30%] [G loss: 1.085483]\n",
      "[Epoch 38/50] [Batch 85/235] [D loss: 1.087372, acc: 85.35%] [G loss: 1.293004]\n",
      "[Epoch 38/50] [Batch 86/235] [D loss: 1.093794, acc: 90.04%] [G loss: 1.255632]\n",
      "[Epoch 38/50] [Batch 87/235] [D loss: 1.118775, acc: 87.50%] [G loss: 1.219831]\n",
      "[Epoch 38/50] [Batch 88/235] [D loss: 1.056127, acc: 88.48%] [G loss: 1.084792]\n",
      "[Epoch 38/50] [Batch 89/235] [D loss: 1.130846, acc: 88.48%] [G loss: 1.222985]\n",
      "[Epoch 38/50] [Batch 90/235] [D loss: 1.057467, acc: 88.48%] [G loss: 1.009087]\n",
      "[Epoch 38/50] [Batch 91/235] [D loss: 1.094886, acc: 87.50%] [G loss: 1.203977]\n",
      "[Epoch 38/50] [Batch 92/235] [D loss: 1.072506, acc: 88.48%] [G loss: 1.295837]\n",
      "[Epoch 38/50] [Batch 93/235] [D loss: 1.080405, acc: 87.30%] [G loss: 1.159571]\n",
      "[Epoch 38/50] [Batch 94/235] [D loss: 1.135095, acc: 87.89%] [G loss: 1.093941]\n",
      "[Epoch 38/50] [Batch 95/235] [D loss: 1.132338, acc: 85.74%] [G loss: 1.243953]\n",
      "[Epoch 38/50] [Batch 96/235] [D loss: 1.093926, acc: 87.30%] [G loss: 1.221240]\n",
      "[Epoch 38/50] [Batch 97/235] [D loss: 1.129575, acc: 87.11%] [G loss: 1.098330]\n",
      "[Epoch 38/50] [Batch 98/235] [D loss: 1.109372, acc: 88.09%] [G loss: 1.125552]\n",
      "[Epoch 38/50] [Batch 99/235] [D loss: 1.137703, acc: 87.70%] [G loss: 1.114405]\n",
      "[Epoch 38/50] [Batch 100/235] [D loss: 1.141917, acc: 85.94%] [G loss: 0.985051]\n",
      "[Epoch 38/50] [Batch 101/235] [D loss: 1.114481, acc: 84.96%] [G loss: 1.067348]\n",
      "[Epoch 38/50] [Batch 102/235] [D loss: 1.140878, acc: 86.72%] [G loss: 1.175066]\n",
      "[Epoch 38/50] [Batch 103/235] [D loss: 1.115534, acc: 86.33%] [G loss: 1.257657]\n",
      "[Epoch 38/50] [Batch 104/235] [D loss: 1.163662, acc: 86.33%] [G loss: 1.228924]\n",
      "[Epoch 38/50] [Batch 105/235] [D loss: 1.153450, acc: 88.48%] [G loss: 1.117349]\n",
      "[Epoch 38/50] [Batch 106/235] [D loss: 1.085836, acc: 88.28%] [G loss: 1.246934]\n",
      "[Epoch 38/50] [Batch 107/235] [D loss: 1.028213, acc: 89.45%] [G loss: 1.105009]\n",
      "[Epoch 38/50] [Batch 108/235] [D loss: 1.077933, acc: 87.11%] [G loss: 1.117765]\n",
      "[Epoch 38/50] [Batch 109/235] [D loss: 1.053160, acc: 88.48%] [G loss: 1.173554]\n",
      "[Epoch 38/50] [Batch 110/235] [D loss: 1.122778, acc: 87.89%] [G loss: 1.206316]\n",
      "[Epoch 38/50] [Batch 111/235] [D loss: 1.075854, acc: 86.91%] [G loss: 1.170028]\n",
      "[Epoch 38/50] [Batch 112/235] [D loss: 1.140833, acc: 89.65%] [G loss: 1.214970]\n",
      "[Epoch 38/50] [Batch 113/235] [D loss: 1.116407, acc: 89.65%] [G loss: 1.071253]\n",
      "[Epoch 38/50] [Batch 114/235] [D loss: 1.100732, acc: 86.52%] [G loss: 1.131393]\n",
      "[Epoch 38/50] [Batch 115/235] [D loss: 1.116773, acc: 88.67%] [G loss: 1.158224]\n",
      "[Epoch 38/50] [Batch 116/235] [D loss: 1.160849, acc: 86.33%] [G loss: 1.003127]\n",
      "[Epoch 38/50] [Batch 117/235] [D loss: 1.118967, acc: 89.65%] [G loss: 1.155694]\n",
      "[Epoch 38/50] [Batch 118/235] [D loss: 1.178883, acc: 86.72%] [G loss: 1.237879]\n",
      "[Epoch 38/50] [Batch 119/235] [D loss: 1.116211, acc: 87.89%] [G loss: 1.136052]\n",
      "[Epoch 38/50] [Batch 120/235] [D loss: 1.092568, acc: 86.52%] [G loss: 1.116257]\n",
      "[Epoch 38/50] [Batch 121/235] [D loss: 1.164447, acc: 88.09%] [G loss: 1.057450]\n",
      "[Epoch 38/50] [Batch 122/235] [D loss: 1.132736, acc: 86.52%] [G loss: 1.270425]\n",
      "[Epoch 38/50] [Batch 123/235] [D loss: 1.146943, acc: 87.50%] [G loss: 1.170084]\n",
      "[Epoch 38/50] [Batch 124/235] [D loss: 1.157631, acc: 88.09%] [G loss: 1.003149]\n",
      "[Epoch 38/50] [Batch 125/235] [D loss: 1.083668, acc: 88.28%] [G loss: 1.208198]\n",
      "[Epoch 38/50] [Batch 126/235] [D loss: 1.062076, acc: 88.28%] [G loss: 1.205581]\n",
      "[Epoch 38/50] [Batch 127/235] [D loss: 1.139316, acc: 86.52%] [G loss: 1.272691]\n",
      "[Epoch 38/50] [Batch 128/235] [D loss: 1.095399, acc: 87.11%] [G loss: 1.065991]\n",
      "[Epoch 38/50] [Batch 129/235] [D loss: 1.128698, acc: 87.50%] [G loss: 1.065083]\n",
      "[Epoch 38/50] [Batch 130/235] [D loss: 1.117738, acc: 88.48%] [G loss: 1.349408]\n",
      "[Epoch 38/50] [Batch 131/235] [D loss: 1.140880, acc: 88.48%] [G loss: 1.444790]\n",
      "[Epoch 38/50] [Batch 132/235] [D loss: 1.125114, acc: 86.72%] [G loss: 1.229088]\n",
      "[Epoch 38/50] [Batch 133/235] [D loss: 1.131882, acc: 86.91%] [G loss: 1.116645]\n",
      "[Epoch 38/50] [Batch 134/235] [D loss: 1.081105, acc: 87.50%] [G loss: 1.141192]\n",
      "[Epoch 38/50] [Batch 135/235] [D loss: 1.096996, acc: 86.52%] [G loss: 1.047201]\n",
      "[Epoch 38/50] [Batch 136/235] [D loss: 1.153748, acc: 85.35%] [G loss: 1.053681]\n",
      "[Epoch 38/50] [Batch 137/235] [D loss: 1.062110, acc: 86.52%] [G loss: 1.454757]\n",
      "[Epoch 38/50] [Batch 138/235] [D loss: 1.115344, acc: 88.28%] [G loss: 1.160741]\n",
      "[Epoch 38/50] [Batch 139/235] [D loss: 1.132303, acc: 88.48%] [G loss: 1.094883]\n",
      "[Epoch 38/50] [Batch 140/235] [D loss: 1.111140, acc: 88.09%] [G loss: 1.248744]\n",
      "[Epoch 38/50] [Batch 141/235] [D loss: 1.173555, acc: 87.89%] [G loss: 1.124531]\n",
      "[Epoch 38/50] [Batch 142/235] [D loss: 1.111002, acc: 88.67%] [G loss: 1.089389]\n",
      "[Epoch 38/50] [Batch 143/235] [D loss: 1.068811, acc: 86.13%] [G loss: 1.219933]\n",
      "[Epoch 38/50] [Batch 144/235] [D loss: 1.025653, acc: 87.89%] [G loss: 1.308940]\n",
      "[Epoch 38/50] [Batch 145/235] [D loss: 1.067921, acc: 86.33%] [G loss: 1.197246]\n",
      "[Epoch 38/50] [Batch 146/235] [D loss: 1.106288, acc: 84.96%] [G loss: 1.083410]\n",
      "[Epoch 38/50] [Batch 147/235] [D loss: 1.129381, acc: 89.45%] [G loss: 1.254206]\n",
      "[Epoch 38/50] [Batch 148/235] [D loss: 1.115456, acc: 88.87%] [G loss: 1.267268]\n",
      "[Epoch 38/50] [Batch 149/235] [D loss: 1.120512, acc: 85.94%] [G loss: 1.126783]\n",
      "[Epoch 38/50] [Batch 150/235] [D loss: 1.122588, acc: 90.04%] [G loss: 1.110233]\n",
      "[Epoch 38/50] [Batch 151/235] [D loss: 1.126933, acc: 84.96%] [G loss: 1.223052]\n",
      "[Epoch 38/50] [Batch 152/235] [D loss: 1.065589, acc: 88.28%] [G loss: 1.213494]\n",
      "[Epoch 38/50] [Batch 153/235] [D loss: 1.164311, acc: 88.28%] [G loss: 1.224261]\n",
      "[Epoch 38/50] [Batch 154/235] [D loss: 1.088280, acc: 86.13%] [G loss: 1.059407]\n",
      "[Epoch 38/50] [Batch 155/235] [D loss: 1.068313, acc: 87.50%] [G loss: 1.196760]\n",
      "[Epoch 38/50] [Batch 156/235] [D loss: 1.087373, acc: 88.67%] [G loss: 1.022973]\n",
      "[Epoch 38/50] [Batch 157/235] [D loss: 1.103212, acc: 87.30%] [G loss: 1.032812]\n",
      "[Epoch 38/50] [Batch 158/235] [D loss: 1.089895, acc: 87.11%] [G loss: 1.248248]\n",
      "[Epoch 38/50] [Batch 159/235] [D loss: 1.126140, acc: 87.89%] [G loss: 1.200909]\n",
      "[Epoch 38/50] [Batch 160/235] [D loss: 1.144694, acc: 85.55%] [G loss: 0.978263]\n",
      "[Epoch 38/50] [Batch 161/235] [D loss: 1.105732, acc: 88.09%] [G loss: 1.018771]\n",
      "[Epoch 38/50] [Batch 162/235] [D loss: 1.100667, acc: 85.94%] [G loss: 1.132076]\n",
      "[Epoch 38/50] [Batch 163/235] [D loss: 1.154667, acc: 83.59%] [G loss: 1.245121]\n",
      "[Epoch 38/50] [Batch 164/235] [D loss: 1.096871, acc: 87.11%] [G loss: 1.312975]\n",
      "[Epoch 38/50] [Batch 165/235] [D loss: 1.117215, acc: 86.91%] [G loss: 1.210796]\n",
      "[Epoch 38/50] [Batch 166/235] [D loss: 1.114223, acc: 87.30%] [G loss: 1.057314]\n",
      "[Epoch 38/50] [Batch 167/235] [D loss: 1.160420, acc: 88.28%] [G loss: 1.092316]\n",
      "[Epoch 38/50] [Batch 168/235] [D loss: 1.109627, acc: 85.74%] [G loss: 1.290490]\n",
      "[Epoch 38/50] [Batch 169/235] [D loss: 1.095126, acc: 88.09%] [G loss: 1.156035]\n",
      "[Epoch 38/50] [Batch 170/235] [D loss: 1.173521, acc: 86.13%] [G loss: 1.122075]\n",
      "[Epoch 38/50] [Batch 171/235] [D loss: 1.167962, acc: 88.09%] [G loss: 1.226408]\n",
      "[Epoch 38/50] [Batch 172/235] [D loss: 1.098882, acc: 86.13%] [G loss: 1.113927]\n",
      "[Epoch 38/50] [Batch 173/235] [D loss: 1.140229, acc: 86.52%] [G loss: 1.072810]\n",
      "[Epoch 38/50] [Batch 174/235] [D loss: 1.125304, acc: 89.84%] [G loss: 1.159992]\n",
      "[Epoch 38/50] [Batch 175/235] [D loss: 1.098594, acc: 88.28%] [G loss: 1.078905]\n",
      "[Epoch 38/50] [Batch 176/235] [D loss: 1.112914, acc: 86.72%] [G loss: 1.235288]\n",
      "[Epoch 38/50] [Batch 177/235] [D loss: 1.142676, acc: 87.70%] [G loss: 1.107242]\n",
      "[Epoch 38/50] [Batch 178/235] [D loss: 1.121895, acc: 88.28%] [G loss: 1.288850]\n",
      "[Epoch 38/50] [Batch 179/235] [D loss: 1.129695, acc: 86.52%] [G loss: 1.052666]\n",
      "[Epoch 38/50] [Batch 180/235] [D loss: 1.117098, acc: 88.09%] [G loss: 1.112277]\n",
      "[Epoch 38/50] [Batch 181/235] [D loss: 1.055619, acc: 86.33%] [G loss: 1.261587]\n",
      "[Epoch 38/50] [Batch 182/235] [D loss: 1.109106, acc: 86.13%] [G loss: 1.380992]\n",
      "[Epoch 38/50] [Batch 183/235] [D loss: 1.091436, acc: 84.96%] [G loss: 1.094637]\n",
      "[Epoch 38/50] [Batch 184/235] [D loss: 1.088055, acc: 87.70%] [G loss: 0.973172]\n",
      "[Epoch 38/50] [Batch 185/235] [D loss: 1.211437, acc: 86.91%] [G loss: 1.139547]\n",
      "[Epoch 38/50] [Batch 186/235] [D loss: 1.114784, acc: 86.91%] [G loss: 1.306048]\n",
      "[Epoch 38/50] [Batch 187/235] [D loss: 1.159195, acc: 87.70%] [G loss: 1.291141]\n",
      "[Epoch 38/50] [Batch 188/235] [D loss: 1.106365, acc: 87.70%] [G loss: 1.234391]\n",
      "[Epoch 38/50] [Batch 189/235] [D loss: 1.188884, acc: 88.09%] [G loss: 1.007058]\n",
      "[Epoch 38/50] [Batch 190/235] [D loss: 1.084063, acc: 87.11%] [G loss: 1.274034]\n",
      "[Epoch 38/50] [Batch 191/235] [D loss: 1.148686, acc: 86.52%] [G loss: 1.143719]\n",
      "[Epoch 38/50] [Batch 192/235] [D loss: 1.026021, acc: 90.04%] [G loss: 1.091584]\n",
      "[Epoch 38/50] [Batch 193/235] [D loss: 1.079793, acc: 86.91%] [G loss: 1.155809]\n",
      "[Epoch 38/50] [Batch 194/235] [D loss: 1.063354, acc: 87.50%] [G loss: 1.217925]\n",
      "[Epoch 38/50] [Batch 195/235] [D loss: 1.155881, acc: 89.26%] [G loss: 1.242158]\n",
      "[Epoch 38/50] [Batch 196/235] [D loss: 1.127817, acc: 85.74%] [G loss: 1.134408]\n",
      "[Epoch 38/50] [Batch 197/235] [D loss: 1.101700, acc: 88.09%] [G loss: 1.289196]\n",
      "[Epoch 38/50] [Batch 198/235] [D loss: 1.220419, acc: 87.50%] [G loss: 1.274931]\n",
      "[Epoch 38/50] [Batch 199/235] [D loss: 1.107885, acc: 88.09%] [G loss: 1.149388]\n",
      "[Epoch 38/50] [Batch 200/235] [D loss: 1.195172, acc: 86.72%] [G loss: 1.088900]\n",
      "[Epoch 38/50] [Batch 201/235] [D loss: 1.100488, acc: 87.89%] [G loss: 1.197111]\n",
      "[Epoch 38/50] [Batch 202/235] [D loss: 1.118559, acc: 87.11%] [G loss: 1.132030]\n",
      "[Epoch 38/50] [Batch 203/235] [D loss: 1.105474, acc: 87.50%] [G loss: 1.019815]\n",
      "[Epoch 38/50] [Batch 204/235] [D loss: 1.172449, acc: 86.52%] [G loss: 1.128643]\n",
      "[Epoch 38/50] [Batch 205/235] [D loss: 1.124080, acc: 85.74%] [G loss: 1.133220]\n",
      "[Epoch 38/50] [Batch 206/235] [D loss: 1.093102, acc: 86.91%] [G loss: 1.193728]\n",
      "[Epoch 38/50] [Batch 207/235] [D loss: 1.146536, acc: 87.89%] [G loss: 1.157436]\n",
      "[Epoch 38/50] [Batch 208/235] [D loss: 1.104742, acc: 88.09%] [G loss: 1.319985]\n",
      "[Epoch 38/50] [Batch 209/235] [D loss: 1.109667, acc: 85.94%] [G loss: 1.234865]\n",
      "[Epoch 38/50] [Batch 210/235] [D loss: 1.123782, acc: 87.11%] [G loss: 1.140683]\n",
      "[Epoch 38/50] [Batch 211/235] [D loss: 1.129190, acc: 87.70%] [G loss: 1.320434]\n",
      "[Epoch 38/50] [Batch 212/235] [D loss: 1.139002, acc: 84.96%] [G loss: 1.184784]\n",
      "[Epoch 38/50] [Batch 213/235] [D loss: 1.141133, acc: 85.94%] [G loss: 1.313992]\n",
      "[Epoch 38/50] [Batch 214/235] [D loss: 1.092593, acc: 87.50%] [G loss: 1.053075]\n",
      "[Epoch 38/50] [Batch 215/235] [D loss: 1.129377, acc: 88.48%] [G loss: 1.128303]\n",
      "[Epoch 38/50] [Batch 216/235] [D loss: 1.143017, acc: 88.48%] [G loss: 1.200910]\n",
      "[Epoch 38/50] [Batch 217/235] [D loss: 1.137182, acc: 85.35%] [G loss: 1.082211]\n",
      "[Epoch 38/50] [Batch 218/235] [D loss: 1.052581, acc: 88.09%] [G loss: 1.080952]\n",
      "[Epoch 38/50] [Batch 219/235] [D loss: 1.157584, acc: 85.74%] [G loss: 1.013588]\n",
      "[Epoch 38/50] [Batch 220/235] [D loss: 1.158428, acc: 85.16%] [G loss: 1.133069]\n",
      "[Epoch 38/50] [Batch 221/235] [D loss: 1.075572, acc: 88.67%] [G loss: 1.152715]\n",
      "[Epoch 38/50] [Batch 222/235] [D loss: 1.081769, acc: 86.72%] [G loss: 1.271351]\n",
      "[Epoch 38/50] [Batch 223/235] [D loss: 1.108826, acc: 87.11%] [G loss: 1.078062]\n",
      "[Epoch 38/50] [Batch 224/235] [D loss: 1.103001, acc: 86.52%] [G loss: 1.149839]\n",
      "[Epoch 38/50] [Batch 225/235] [D loss: 1.075227, acc: 88.67%] [G loss: 1.129837]\n",
      "[Epoch 38/50] [Batch 226/235] [D loss: 1.153262, acc: 87.89%] [G loss: 1.168450]\n",
      "[Epoch 38/50] [Batch 227/235] [D loss: 1.140468, acc: 88.67%] [G loss: 1.176671]\n",
      "[Epoch 38/50] [Batch 228/235] [D loss: 1.100410, acc: 87.89%] [G loss: 1.098611]\n",
      "[Epoch 38/50] [Batch 229/235] [D loss: 1.094973, acc: 86.72%] [G loss: 1.093411]\n",
      "[Epoch 38/50] [Batch 230/235] [D loss: 1.105071, acc: 86.52%] [G loss: 1.131797]\n",
      "[Epoch 38/50] [Batch 231/235] [D loss: 1.123749, acc: 86.52%] [G loss: 1.126751]\n",
      "[Epoch 38/50] [Batch 232/235] [D loss: 1.133652, acc: 86.13%] [G loss: 1.302956]\n",
      "[Epoch 38/50] [Batch 233/235] [D loss: 1.158954, acc: 85.94%] [G loss: 1.305544]\n",
      "[Epoch 38/50] [Batch 234/235] [D loss: 1.088858, acc: 85.94%] [G loss: 1.229619]\n",
      "[Epoch 39/50] [Batch 0/235] [D loss: 1.078595, acc: 88.48%] [G loss: 1.087470]\n",
      "[Epoch 39/50] [Batch 1/235] [D loss: 1.088104, acc: 90.23%] [G loss: 1.204100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/50] [Batch 2/235] [D loss: 1.155030, acc: 87.89%] [G loss: 1.173626]\n",
      "[Epoch 39/50] [Batch 3/235] [D loss: 0.984892, acc: 88.48%] [G loss: 1.333697]\n",
      "[Epoch 39/50] [Batch 4/235] [D loss: 1.123586, acc: 87.89%] [G loss: 1.348939]\n",
      "[Epoch 39/50] [Batch 5/235] [D loss: 1.127695, acc: 86.33%] [G loss: 1.162232]\n",
      "[Epoch 39/50] [Batch 6/235] [D loss: 1.155698, acc: 87.30%] [G loss: 1.215041]\n",
      "[Epoch 39/50] [Batch 7/235] [D loss: 1.084388, acc: 86.33%] [G loss: 1.169342]\n",
      "[Epoch 39/50] [Batch 8/235] [D loss: 1.141895, acc: 87.70%] [G loss: 1.147761]\n",
      "[Epoch 39/50] [Batch 9/235] [D loss: 1.084712, acc: 87.89%] [G loss: 1.024051]\n",
      "[Epoch 39/50] [Batch 10/235] [D loss: 1.079082, acc: 87.50%] [G loss: 1.143640]\n",
      "[Epoch 39/50] [Batch 11/235] [D loss: 1.102958, acc: 88.87%] [G loss: 1.146936]\n",
      "[Epoch 39/50] [Batch 12/235] [D loss: 1.190658, acc: 84.57%] [G loss: 1.100440]\n",
      "[Epoch 39/50] [Batch 13/235] [D loss: 1.170309, acc: 88.67%] [G loss: 1.191721]\n",
      "[Epoch 39/50] [Batch 14/235] [D loss: 1.082535, acc: 89.26%] [G loss: 1.142598]\n",
      "[Epoch 39/50] [Batch 15/235] [D loss: 1.079621, acc: 87.30%] [G loss: 1.153818]\n",
      "[Epoch 39/50] [Batch 16/235] [D loss: 1.112825, acc: 87.70%] [G loss: 1.158986]\n",
      "[Epoch 39/50] [Batch 17/235] [D loss: 1.092066, acc: 89.06%] [G loss: 1.183041]\n",
      "[Epoch 39/50] [Batch 18/235] [D loss: 1.111725, acc: 85.74%] [G loss: 1.146888]\n",
      "[Epoch 39/50] [Batch 19/235] [D loss: 1.076283, acc: 88.67%] [G loss: 1.203318]\n",
      "[Epoch 39/50] [Batch 20/235] [D loss: 1.120261, acc: 85.55%] [G loss: 1.185964]\n",
      "[Epoch 39/50] [Batch 21/235] [D loss: 1.116168, acc: 88.48%] [G loss: 1.280186]\n",
      "[Epoch 39/50] [Batch 22/235] [D loss: 1.085873, acc: 89.65%] [G loss: 1.264989]\n",
      "[Epoch 39/50] [Batch 23/235] [D loss: 1.145549, acc: 88.67%] [G loss: 1.192243]\n",
      "[Epoch 39/50] [Batch 24/235] [D loss: 1.127254, acc: 89.45%] [G loss: 1.165859]\n",
      "[Epoch 39/50] [Batch 25/235] [D loss: 1.133649, acc: 86.52%] [G loss: 1.194270]\n",
      "[Epoch 39/50] [Batch 26/235] [D loss: 1.070677, acc: 88.09%] [G loss: 1.234696]\n",
      "[Epoch 39/50] [Batch 27/235] [D loss: 1.137377, acc: 86.52%] [G loss: 1.020099]\n",
      "[Epoch 39/50] [Batch 28/235] [D loss: 1.113435, acc: 83.40%] [G loss: 1.063937]\n",
      "[Epoch 39/50] [Batch 29/235] [D loss: 1.140185, acc: 89.06%] [G loss: 1.138523]\n",
      "[Epoch 39/50] [Batch 30/235] [D loss: 1.121680, acc: 87.89%] [G loss: 1.368593]\n",
      "[Epoch 39/50] [Batch 31/235] [D loss: 1.146125, acc: 87.70%] [G loss: 1.275856]\n",
      "[Epoch 39/50] [Batch 32/235] [D loss: 1.104932, acc: 84.77%] [G loss: 1.116180]\n",
      "[Epoch 39/50] [Batch 33/235] [D loss: 1.101665, acc: 85.74%] [G loss: 1.206940]\n",
      "[Epoch 39/50] [Batch 34/235] [D loss: 1.109154, acc: 86.72%] [G loss: 1.290908]\n",
      "[Epoch 39/50] [Batch 35/235] [D loss: 1.161598, acc: 86.91%] [G loss: 0.976020]\n",
      "[Epoch 39/50] [Batch 36/235] [D loss: 1.113553, acc: 87.89%] [G loss: 1.219948]\n",
      "[Epoch 39/50] [Batch 37/235] [D loss: 1.120702, acc: 89.45%] [G loss: 1.229434]\n",
      "[Epoch 39/50] [Batch 38/235] [D loss: 1.093004, acc: 86.72%] [G loss: 1.097885]\n",
      "[Epoch 39/50] [Batch 39/235] [D loss: 1.139304, acc: 86.72%] [G loss: 1.061306]\n",
      "[Epoch 39/50] [Batch 40/235] [D loss: 1.057831, acc: 86.52%] [G loss: 1.210250]\n",
      "[Epoch 39/50] [Batch 41/235] [D loss: 1.156467, acc: 88.28%] [G loss: 1.339757]\n",
      "[Epoch 39/50] [Batch 42/235] [D loss: 1.108747, acc: 86.13%] [G loss: 1.194142]\n",
      "[Epoch 39/50] [Batch 43/235] [D loss: 1.131669, acc: 89.26%] [G loss: 1.140596]\n",
      "[Epoch 39/50] [Batch 44/235] [D loss: 1.089815, acc: 86.13%] [G loss: 1.142215]\n",
      "[Epoch 39/50] [Batch 45/235] [D loss: 1.064714, acc: 87.50%] [G loss: 1.199269]\n",
      "[Epoch 39/50] [Batch 46/235] [D loss: 1.125816, acc: 88.09%] [G loss: 1.104019]\n",
      "[Epoch 39/50] [Batch 47/235] [D loss: 1.073581, acc: 86.72%] [G loss: 1.080114]\n",
      "[Epoch 39/50] [Batch 48/235] [D loss: 1.065424, acc: 86.91%] [G loss: 1.048170]\n",
      "[Epoch 39/50] [Batch 49/235] [D loss: 1.142367, acc: 89.06%] [G loss: 1.184933]\n",
      "[Epoch 39/50] [Batch 50/235] [D loss: 1.102504, acc: 89.65%] [G loss: 1.321314]\n",
      "[Epoch 39/50] [Batch 51/235] [D loss: 1.127257, acc: 83.98%] [G loss: 1.019379]\n",
      "[Epoch 39/50] [Batch 52/235] [D loss: 1.114703, acc: 86.91%] [G loss: 1.175783]\n",
      "[Epoch 39/50] [Batch 53/235] [D loss: 1.121840, acc: 86.91%] [G loss: 1.046999]\n",
      "[Epoch 39/50] [Batch 54/235] [D loss: 1.138040, acc: 87.89%] [G loss: 1.185034]\n",
      "[Epoch 39/50] [Batch 55/235] [D loss: 1.083964, acc: 86.72%] [G loss: 1.198922]\n",
      "[Epoch 39/50] [Batch 56/235] [D loss: 1.169886, acc: 87.11%] [G loss: 1.196601]\n",
      "[Epoch 39/50] [Batch 57/235] [D loss: 1.072815, acc: 85.35%] [G loss: 1.037251]\n",
      "[Epoch 39/50] [Batch 58/235] [D loss: 1.139192, acc: 89.45%] [G loss: 1.093418]\n",
      "[Epoch 39/50] [Batch 59/235] [D loss: 1.128477, acc: 87.70%] [G loss: 1.064685]\n",
      "[Epoch 39/50] [Batch 60/235] [D loss: 1.099842, acc: 88.09%] [G loss: 1.144493]\n",
      "[Epoch 39/50] [Batch 61/235] [D loss: 1.101104, acc: 87.30%] [G loss: 1.266121]\n",
      "[Epoch 39/50] [Batch 62/235] [D loss: 1.140345, acc: 88.28%] [G loss: 1.100529]\n",
      "[Epoch 39/50] [Batch 63/235] [D loss: 1.173665, acc: 85.94%] [G loss: 1.115399]\n",
      "[Epoch 39/50] [Batch 64/235] [D loss: 1.150419, acc: 87.89%] [G loss: 1.089657]\n",
      "[Epoch 39/50] [Batch 65/235] [D loss: 1.125117, acc: 85.35%] [G loss: 1.167722]\n",
      "[Epoch 39/50] [Batch 66/235] [D loss: 1.038566, acc: 86.52%] [G loss: 1.044599]\n",
      "[Epoch 39/50] [Batch 67/235] [D loss: 1.087369, acc: 86.33%] [G loss: 1.048302]\n",
      "[Epoch 39/50] [Batch 68/235] [D loss: 1.073633, acc: 89.06%] [G loss: 1.117617]\n",
      "[Epoch 39/50] [Batch 69/235] [D loss: 1.168415, acc: 87.89%] [G loss: 1.335541]\n",
      "[Epoch 39/50] [Batch 70/235] [D loss: 1.132141, acc: 89.06%] [G loss: 1.126145]\n",
      "[Epoch 39/50] [Batch 71/235] [D loss: 1.160669, acc: 86.13%] [G loss: 1.068090]\n",
      "[Epoch 39/50] [Batch 72/235] [D loss: 1.101783, acc: 85.55%] [G loss: 1.220532]\n",
      "[Epoch 39/50] [Batch 73/235] [D loss: 1.099121, acc: 88.48%] [G loss: 1.116022]\n",
      "[Epoch 39/50] [Batch 74/235] [D loss: 1.132376, acc: 85.35%] [G loss: 1.162233]\n",
      "[Epoch 39/50] [Batch 75/235] [D loss: 1.094609, acc: 88.87%] [G loss: 1.161319]\n",
      "[Epoch 39/50] [Batch 76/235] [D loss: 1.150996, acc: 86.91%] [G loss: 1.215026]\n",
      "[Epoch 39/50] [Batch 77/235] [D loss: 1.085920, acc: 88.28%] [G loss: 1.116530]\n",
      "[Epoch 39/50] [Batch 78/235] [D loss: 1.102492, acc: 87.50%] [G loss: 1.145119]\n",
      "[Epoch 39/50] [Batch 79/235] [D loss: 1.146534, acc: 86.13%] [G loss: 1.170142]\n",
      "[Epoch 39/50] [Batch 80/235] [D loss: 1.121992, acc: 89.26%] [G loss: 1.278883]\n",
      "[Epoch 39/50] [Batch 81/235] [D loss: 1.130490, acc: 85.94%] [G loss: 1.143065]\n",
      "[Epoch 39/50] [Batch 82/235] [D loss: 1.161593, acc: 87.50%] [G loss: 1.185639]\n",
      "[Epoch 39/50] [Batch 83/235] [D loss: 1.134001, acc: 86.33%] [G loss: 1.207452]\n",
      "[Epoch 39/50] [Batch 84/235] [D loss: 1.189819, acc: 87.50%] [G loss: 1.256855]\n",
      "[Epoch 39/50] [Batch 85/235] [D loss: 1.089764, acc: 86.91%] [G loss: 1.345402]\n",
      "[Epoch 39/50] [Batch 86/235] [D loss: 1.169460, acc: 86.72%] [G loss: 1.172623]\n",
      "[Epoch 39/50] [Batch 87/235] [D loss: 1.057950, acc: 89.45%] [G loss: 1.083011]\n",
      "[Epoch 39/50] [Batch 88/235] [D loss: 1.101341, acc: 87.30%] [G loss: 1.073401]\n",
      "[Epoch 39/50] [Batch 89/235] [D loss: 1.133040, acc: 89.06%] [G loss: 1.084640]\n",
      "[Epoch 39/50] [Batch 90/235] [D loss: 1.136714, acc: 82.42%] [G loss: 1.238604]\n",
      "[Epoch 39/50] [Batch 91/235] [D loss: 1.094590, acc: 85.55%] [G loss: 1.088636]\n",
      "[Epoch 39/50] [Batch 92/235] [D loss: 1.183239, acc: 87.70%] [G loss: 1.162209]\n",
      "[Epoch 39/50] [Batch 93/235] [D loss: 1.134224, acc: 84.96%] [G loss: 1.210001]\n",
      "[Epoch 39/50] [Batch 94/235] [D loss: 1.156786, acc: 88.48%] [G loss: 1.086830]\n",
      "[Epoch 39/50] [Batch 95/235] [D loss: 1.084432, acc: 89.45%] [G loss: 0.968474]\n",
      "[Epoch 39/50] [Batch 96/235] [D loss: 1.175295, acc: 87.50%] [G loss: 1.237697]\n",
      "[Epoch 39/50] [Batch 97/235] [D loss: 1.119505, acc: 88.09%] [G loss: 1.223076]\n",
      "[Epoch 39/50] [Batch 98/235] [D loss: 1.148386, acc: 87.70%] [G loss: 1.117559]\n",
      "[Epoch 39/50] [Batch 99/235] [D loss: 1.094457, acc: 89.06%] [G loss: 1.163306]\n",
      "[Epoch 39/50] [Batch 100/235] [D loss: 1.108733, acc: 88.28%] [G loss: 1.135641]\n",
      "[Epoch 39/50] [Batch 101/235] [D loss: 1.077502, acc: 87.30%] [G loss: 1.061264]\n",
      "[Epoch 39/50] [Batch 102/235] [D loss: 1.147135, acc: 86.91%] [G loss: 1.249355]\n",
      "[Epoch 39/50] [Batch 103/235] [D loss: 1.154499, acc: 89.06%] [G loss: 1.097207]\n",
      "[Epoch 39/50] [Batch 104/235] [D loss: 1.090923, acc: 89.84%] [G loss: 1.180811]\n",
      "[Epoch 39/50] [Batch 105/235] [D loss: 1.111466, acc: 85.16%] [G loss: 1.149842]\n",
      "[Epoch 39/50] [Batch 106/235] [D loss: 1.151731, acc: 85.55%] [G loss: 1.159855]\n",
      "[Epoch 39/50] [Batch 107/235] [D loss: 1.096391, acc: 86.91%] [G loss: 1.069556]\n",
      "[Epoch 39/50] [Batch 108/235] [D loss: 1.164543, acc: 87.11%] [G loss: 1.108646]\n",
      "[Epoch 39/50] [Batch 109/235] [D loss: 1.104944, acc: 87.70%] [G loss: 1.066019]\n",
      "[Epoch 39/50] [Batch 110/235] [D loss: 1.141844, acc: 87.89%] [G loss: 1.122861]\n",
      "[Epoch 39/50] [Batch 111/235] [D loss: 1.093137, acc: 87.50%] [G loss: 1.150556]\n",
      "[Epoch 39/50] [Batch 112/235] [D loss: 1.131896, acc: 89.06%] [G loss: 1.156714]\n",
      "[Epoch 39/50] [Batch 113/235] [D loss: 1.096293, acc: 88.28%] [G loss: 1.151743]\n",
      "[Epoch 39/50] [Batch 114/235] [D loss: 1.119288, acc: 86.33%] [G loss: 1.161839]\n",
      "[Epoch 39/50] [Batch 115/235] [D loss: 1.126264, acc: 89.65%] [G loss: 1.082216]\n",
      "[Epoch 39/50] [Batch 116/235] [D loss: 1.154883, acc: 87.89%] [G loss: 1.058204]\n",
      "[Epoch 39/50] [Batch 117/235] [D loss: 1.099442, acc: 86.91%] [G loss: 1.185005]\n",
      "[Epoch 39/50] [Batch 118/235] [D loss: 1.123016, acc: 85.94%] [G loss: 1.338697]\n",
      "[Epoch 39/50] [Batch 119/235] [D loss: 1.096455, acc: 89.06%] [G loss: 1.159368]\n",
      "[Epoch 39/50] [Batch 120/235] [D loss: 1.162067, acc: 86.33%] [G loss: 1.184255]\n",
      "[Epoch 39/50] [Batch 121/235] [D loss: 1.096492, acc: 89.26%] [G loss: 1.274737]\n",
      "[Epoch 39/50] [Batch 122/235] [D loss: 1.134025, acc: 87.30%] [G loss: 1.049772]\n",
      "[Epoch 39/50] [Batch 123/235] [D loss: 1.054246, acc: 89.06%] [G loss: 1.216415]\n",
      "[Epoch 39/50] [Batch 124/235] [D loss: 1.036571, acc: 87.70%] [G loss: 1.065874]\n",
      "[Epoch 39/50] [Batch 125/235] [D loss: 1.054973, acc: 87.89%] [G loss: 1.088279]\n",
      "[Epoch 39/50] [Batch 126/235] [D loss: 1.095652, acc: 88.87%] [G loss: 1.191194]\n",
      "[Epoch 39/50] [Batch 127/235] [D loss: 1.128782, acc: 85.55%] [G loss: 1.155428]\n",
      "[Epoch 39/50] [Batch 128/235] [D loss: 1.213398, acc: 88.87%] [G loss: 1.098295]\n",
      "[Epoch 39/50] [Batch 129/235] [D loss: 1.098874, acc: 87.30%] [G loss: 1.025046]\n",
      "[Epoch 39/50] [Batch 130/235] [D loss: 1.046435, acc: 86.52%] [G loss: 1.130139]\n",
      "[Epoch 39/50] [Batch 131/235] [D loss: 1.116585, acc: 88.87%] [G loss: 1.306016]\n",
      "[Epoch 39/50] [Batch 132/235] [D loss: 1.142666, acc: 89.26%] [G loss: 1.224654]\n",
      "[Epoch 39/50] [Batch 133/235] [D loss: 1.115617, acc: 86.33%] [G loss: 1.255600]\n",
      "[Epoch 39/50] [Batch 134/235] [D loss: 1.130542, acc: 87.89%] [G loss: 1.055085]\n",
      "[Epoch 39/50] [Batch 135/235] [D loss: 1.125064, acc: 89.45%] [G loss: 1.121604]\n",
      "[Epoch 39/50] [Batch 136/235] [D loss: 1.116579, acc: 86.13%] [G loss: 1.316328]\n",
      "[Epoch 39/50] [Batch 137/235] [D loss: 1.136287, acc: 86.13%] [G loss: 1.115613]\n",
      "[Epoch 39/50] [Batch 138/235] [D loss: 1.139394, acc: 88.28%] [G loss: 1.107988]\n",
      "[Epoch 39/50] [Batch 139/235] [D loss: 1.078235, acc: 88.67%] [G loss: 1.338911]\n",
      "[Epoch 39/50] [Batch 140/235] [D loss: 1.202186, acc: 85.35%] [G loss: 1.210715]\n",
      "[Epoch 39/50] [Batch 141/235] [D loss: 1.085466, acc: 88.67%] [G loss: 1.123614]\n",
      "[Epoch 39/50] [Batch 142/235] [D loss: 1.106524, acc: 88.28%] [G loss: 1.092481]\n",
      "[Epoch 39/50] [Batch 143/235] [D loss: 1.152570, acc: 88.67%] [G loss: 1.023419]\n",
      "[Epoch 39/50] [Batch 144/235] [D loss: 1.101558, acc: 86.33%] [G loss: 1.071735]\n",
      "[Epoch 39/50] [Batch 145/235] [D loss: 1.180438, acc: 85.55%] [G loss: 1.198693]\n",
      "[Epoch 39/50] [Batch 146/235] [D loss: 1.101003, acc: 86.13%] [G loss: 1.227841]\n",
      "[Epoch 39/50] [Batch 147/235] [D loss: 1.206273, acc: 85.35%] [G loss: 1.192551]\n",
      "[Epoch 39/50] [Batch 148/235] [D loss: 1.154262, acc: 86.33%] [G loss: 1.257529]\n",
      "[Epoch 39/50] [Batch 149/235] [D loss: 1.108813, acc: 89.45%] [G loss: 1.160957]\n",
      "[Epoch 39/50] [Batch 150/235] [D loss: 1.147642, acc: 86.33%] [G loss: 1.114209]\n",
      "[Epoch 39/50] [Batch 151/235] [D loss: 1.102734, acc: 87.30%] [G loss: 1.215885]\n",
      "[Epoch 39/50] [Batch 152/235] [D loss: 1.052977, acc: 87.30%] [G loss: 1.152810]\n",
      "[Epoch 39/50] [Batch 153/235] [D loss: 1.074700, acc: 84.96%] [G loss: 1.114523]\n",
      "[Epoch 39/50] [Batch 154/235] [D loss: 1.128464, acc: 86.72%] [G loss: 1.140870]\n",
      "[Epoch 39/50] [Batch 155/235] [D loss: 1.109227, acc: 87.50%] [G loss: 1.148389]\n",
      "[Epoch 39/50] [Batch 156/235] [D loss: 1.097293, acc: 88.87%] [G loss: 1.224702]\n",
      "[Epoch 39/50] [Batch 157/235] [D loss: 1.093669, acc: 86.72%] [G loss: 1.137644]\n",
      "[Epoch 39/50] [Batch 158/235] [D loss: 1.076077, acc: 84.57%] [G loss: 1.117057]\n",
      "[Epoch 39/50] [Batch 159/235] [D loss: 1.228431, acc: 86.52%] [G loss: 1.222573]\n",
      "[Epoch 39/50] [Batch 160/235] [D loss: 1.069619, acc: 88.28%] [G loss: 1.170108]\n",
      "[Epoch 39/50] [Batch 161/235] [D loss: 1.172140, acc: 90.62%] [G loss: 1.159455]\n",
      "[Epoch 39/50] [Batch 162/235] [D loss: 1.121353, acc: 87.50%] [G loss: 1.116692]\n",
      "[Epoch 39/50] [Batch 163/235] [D loss: 1.131800, acc: 88.09%] [G loss: 1.090446]\n",
      "[Epoch 39/50] [Batch 164/235] [D loss: 1.142842, acc: 88.09%] [G loss: 0.997263]\n",
      "[Epoch 39/50] [Batch 165/235] [D loss: 1.057838, acc: 87.11%] [G loss: 1.083675]\n",
      "[Epoch 39/50] [Batch 166/235] [D loss: 1.103890, acc: 87.30%] [G loss: 1.090447]\n",
      "[Epoch 39/50] [Batch 167/235] [D loss: 1.094811, acc: 86.52%] [G loss: 1.183020]\n",
      "[Epoch 39/50] [Batch 168/235] [D loss: 1.077339, acc: 88.28%] [G loss: 1.170644]\n",
      "[Epoch 39/50] [Batch 169/235] [D loss: 1.156867, acc: 85.16%] [G loss: 1.049234]\n",
      "[Epoch 39/50] [Batch 170/235] [D loss: 1.133356, acc: 86.33%] [G loss: 1.093505]\n",
      "[Epoch 39/50] [Batch 171/235] [D loss: 1.163418, acc: 88.09%] [G loss: 1.183918]\n",
      "[Epoch 39/50] [Batch 172/235] [D loss: 1.129717, acc: 89.26%] [G loss: 1.103988]\n",
      "[Epoch 39/50] [Batch 173/235] [D loss: 1.087216, acc: 86.52%] [G loss: 1.092822]\n",
      "[Epoch 39/50] [Batch 174/235] [D loss: 1.118226, acc: 84.96%] [G loss: 1.064207]\n",
      "[Epoch 39/50] [Batch 175/235] [D loss: 1.125956, acc: 86.33%] [G loss: 1.197411]\n",
      "[Epoch 39/50] [Batch 176/235] [D loss: 1.099277, acc: 86.33%] [G loss: 1.239096]\n",
      "[Epoch 39/50] [Batch 177/235] [D loss: 1.172573, acc: 87.70%] [G loss: 1.190462]\n",
      "[Epoch 39/50] [Batch 178/235] [D loss: 1.106672, acc: 87.50%] [G loss: 1.136260]\n",
      "[Epoch 39/50] [Batch 179/235] [D loss: 1.173630, acc: 88.67%] [G loss: 1.135616]\n",
      "[Epoch 39/50] [Batch 180/235] [D loss: 1.132040, acc: 87.11%] [G loss: 1.008659]\n",
      "[Epoch 39/50] [Batch 181/235] [D loss: 1.139385, acc: 85.94%] [G loss: 1.110735]\n",
      "[Epoch 39/50] [Batch 182/235] [D loss: 1.091466, acc: 88.09%] [G loss: 1.281181]\n",
      "[Epoch 39/50] [Batch 183/235] [D loss: 1.072783, acc: 88.48%] [G loss: 1.277675]\n",
      "[Epoch 39/50] [Batch 184/235] [D loss: 1.146900, acc: 87.70%] [G loss: 1.169878]\n",
      "[Epoch 39/50] [Batch 185/235] [D loss: 1.102723, acc: 86.72%] [G loss: 1.218646]\n",
      "[Epoch 39/50] [Batch 186/235] [D loss: 1.134420, acc: 87.89%] [G loss: 1.185509]\n",
      "[Epoch 39/50] [Batch 187/235] [D loss: 1.123571, acc: 85.94%] [G loss: 1.186467]\n",
      "[Epoch 39/50] [Batch 188/235] [D loss: 1.019571, acc: 89.06%] [G loss: 0.999911]\n",
      "[Epoch 39/50] [Batch 189/235] [D loss: 1.122613, acc: 90.23%] [G loss: 1.056174]\n",
      "[Epoch 39/50] [Batch 190/235] [D loss: 1.095742, acc: 86.91%] [G loss: 1.309388]\n",
      "[Epoch 39/50] [Batch 191/235] [D loss: 1.102704, acc: 88.28%] [G loss: 1.276728]\n",
      "[Epoch 39/50] [Batch 192/235] [D loss: 1.129040, acc: 86.91%] [G loss: 1.029129]\n",
      "[Epoch 39/50] [Batch 193/235] [D loss: 1.162978, acc: 89.26%] [G loss: 0.975756]\n",
      "[Epoch 39/50] [Batch 194/235] [D loss: 1.096137, acc: 84.96%] [G loss: 1.104766]\n",
      "[Epoch 39/50] [Batch 195/235] [D loss: 1.088751, acc: 87.50%] [G loss: 1.323016]\n",
      "[Epoch 39/50] [Batch 196/235] [D loss: 1.114978, acc: 88.48%] [G loss: 1.260697]\n",
      "[Epoch 39/50] [Batch 197/235] [D loss: 1.061476, acc: 87.50%] [G loss: 1.017573]\n",
      "[Epoch 39/50] [Batch 198/235] [D loss: 1.179469, acc: 86.33%] [G loss: 1.087399]\n",
      "[Epoch 39/50] [Batch 199/235] [D loss: 1.114164, acc: 88.48%] [G loss: 1.050528]\n",
      "[Epoch 39/50] [Batch 200/235] [D loss: 1.096434, acc: 87.30%] [G loss: 1.344547]\n",
      "[Epoch 39/50] [Batch 201/235] [D loss: 1.098716, acc: 86.52%] [G loss: 1.232941]\n",
      "[Epoch 39/50] [Batch 202/235] [D loss: 1.115346, acc: 87.11%] [G loss: 1.115164]\n",
      "[Epoch 39/50] [Batch 203/235] [D loss: 1.166841, acc: 87.30%] [G loss: 1.075523]\n",
      "[Epoch 39/50] [Batch 204/235] [D loss: 1.120042, acc: 87.70%] [G loss: 1.060338]\n",
      "[Epoch 39/50] [Batch 205/235] [D loss: 1.140531, acc: 91.02%] [G loss: 1.066333]\n",
      "[Epoch 39/50] [Batch 206/235] [D loss: 1.118477, acc: 86.13%] [G loss: 1.124541]\n",
      "[Epoch 39/50] [Batch 207/235] [D loss: 1.094114, acc: 87.11%] [G loss: 1.212247]\n",
      "[Epoch 39/50] [Batch 208/235] [D loss: 1.102652, acc: 85.55%] [G loss: 1.161973]\n",
      "[Epoch 39/50] [Batch 209/235] [D loss: 1.089329, acc: 87.30%] [G loss: 1.054844]\n",
      "[Epoch 39/50] [Batch 210/235] [D loss: 1.108641, acc: 84.57%] [G loss: 1.191732]\n",
      "[Epoch 39/50] [Batch 211/235] [D loss: 1.137005, acc: 88.48%] [G loss: 1.188387]\n",
      "[Epoch 39/50] [Batch 212/235] [D loss: 1.188282, acc: 88.48%] [G loss: 1.206778]\n",
      "[Epoch 39/50] [Batch 213/235] [D loss: 1.093576, acc: 88.09%] [G loss: 1.119054]\n",
      "[Epoch 39/50] [Batch 214/235] [D loss: 1.125013, acc: 88.28%] [G loss: 1.046649]\n",
      "[Epoch 39/50] [Batch 215/235] [D loss: 1.071812, acc: 87.70%] [G loss: 1.149740]\n",
      "[Epoch 39/50] [Batch 216/235] [D loss: 1.084977, acc: 89.45%] [G loss: 1.135846]\n",
      "[Epoch 39/50] [Batch 217/235] [D loss: 1.096295, acc: 86.91%] [G loss: 1.175022]\n",
      "[Epoch 39/50] [Batch 218/235] [D loss: 1.053268, acc: 89.06%] [G loss: 1.245841]\n",
      "[Epoch 39/50] [Batch 219/235] [D loss: 1.105611, acc: 89.45%] [G loss: 1.144149]\n",
      "[Epoch 39/50] [Batch 220/235] [D loss: 1.098582, acc: 89.26%] [G loss: 1.140794]\n",
      "[Epoch 39/50] [Batch 221/235] [D loss: 1.096708, acc: 87.70%] [G loss: 1.083662]\n",
      "[Epoch 39/50] [Batch 222/235] [D loss: 1.059829, acc: 85.74%] [G loss: 1.359812]\n",
      "[Epoch 39/50] [Batch 223/235] [D loss: 1.195296, acc: 89.65%] [G loss: 1.141575]\n",
      "[Epoch 39/50] [Batch 224/235] [D loss: 1.097164, acc: 88.09%] [G loss: 1.089573]\n",
      "[Epoch 39/50] [Batch 225/235] [D loss: 1.112714, acc: 86.72%] [G loss: 1.075830]\n",
      "[Epoch 39/50] [Batch 226/235] [D loss: 1.088314, acc: 87.30%] [G loss: 1.104953]\n",
      "[Epoch 39/50] [Batch 227/235] [D loss: 1.133569, acc: 87.11%] [G loss: 1.239631]\n",
      "[Epoch 39/50] [Batch 228/235] [D loss: 1.182879, acc: 87.70%] [G loss: 1.348496]\n",
      "[Epoch 39/50] [Batch 229/235] [D loss: 1.149571, acc: 87.89%] [G loss: 1.171703]\n",
      "[Epoch 39/50] [Batch 230/235] [D loss: 1.132061, acc: 87.11%] [G loss: 1.057266]\n",
      "[Epoch 39/50] [Batch 231/235] [D loss: 1.117955, acc: 86.72%] [G loss: 1.086993]\n",
      "[Epoch 39/50] [Batch 232/235] [D loss: 1.090296, acc: 91.41%] [G loss: 1.235131]\n",
      "[Epoch 39/50] [Batch 233/235] [D loss: 1.112098, acc: 88.09%] [G loss: 1.134917]\n",
      "[Epoch 39/50] [Batch 234/235] [D loss: 1.136352, acc: 88.54%] [G loss: 1.186213]\n",
      "[Epoch 40/50] [Batch 0/235] [D loss: 1.091669, acc: 84.38%] [G loss: 1.227924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/50] [Batch 1/235] [D loss: 1.156258, acc: 87.30%] [G loss: 1.139845]\n",
      "[Epoch 40/50] [Batch 2/235] [D loss: 1.089879, acc: 88.67%] [G loss: 1.132462]\n",
      "[Epoch 40/50] [Batch 3/235] [D loss: 1.063229, acc: 87.30%] [G loss: 1.180878]\n",
      "[Epoch 40/50] [Batch 4/235] [D loss: 1.153593, acc: 86.33%] [G loss: 1.127717]\n",
      "[Epoch 40/50] [Batch 5/235] [D loss: 1.115404, acc: 86.91%] [G loss: 1.076189]\n",
      "[Epoch 40/50] [Batch 6/235] [D loss: 1.105525, acc: 86.72%] [G loss: 1.247704]\n",
      "[Epoch 40/50] [Batch 7/235] [D loss: 1.132684, acc: 85.35%] [G loss: 1.194635]\n",
      "[Epoch 40/50] [Batch 8/235] [D loss: 1.117672, acc: 90.04%] [G loss: 1.080442]\n",
      "[Epoch 40/50] [Batch 9/235] [D loss: 1.164139, acc: 88.48%] [G loss: 1.102214]\n",
      "[Epoch 40/50] [Batch 10/235] [D loss: 1.090827, acc: 87.11%] [G loss: 1.198231]\n",
      "[Epoch 40/50] [Batch 11/235] [D loss: 1.070414, acc: 86.33%] [G loss: 1.100904]\n",
      "[Epoch 40/50] [Batch 12/235] [D loss: 1.095881, acc: 87.11%] [G loss: 1.053453]\n",
      "[Epoch 40/50] [Batch 13/235] [D loss: 1.088483, acc: 87.11%] [G loss: 1.103696]\n",
      "[Epoch 40/50] [Batch 14/235] [D loss: 1.115021, acc: 84.57%] [G loss: 1.048778]\n",
      "[Epoch 40/50] [Batch 15/235] [D loss: 1.055474, acc: 86.72%] [G loss: 1.165879]\n",
      "[Epoch 40/50] [Batch 16/235] [D loss: 1.171109, acc: 87.11%] [G loss: 1.032435]\n",
      "[Epoch 40/50] [Batch 17/235] [D loss: 1.099756, acc: 88.09%] [G loss: 1.028954]\n",
      "[Epoch 40/50] [Batch 18/235] [D loss: 1.103805, acc: 88.48%] [G loss: 1.231080]\n",
      "[Epoch 40/50] [Batch 19/235] [D loss: 1.078521, acc: 86.13%] [G loss: 1.199674]\n",
      "[Epoch 40/50] [Batch 20/235] [D loss: 1.091438, acc: 85.35%] [G loss: 1.182975]\n",
      "[Epoch 40/50] [Batch 21/235] [D loss: 1.102076, acc: 86.52%] [G loss: 1.105853]\n",
      "[Epoch 40/50] [Batch 22/235] [D loss: 1.129733, acc: 86.72%] [G loss: 1.040071]\n",
      "[Epoch 40/50] [Batch 23/235] [D loss: 1.176874, acc: 86.91%] [G loss: 1.143312]\n",
      "[Epoch 40/50] [Batch 24/235] [D loss: 1.066012, acc: 88.87%] [G loss: 1.149588]\n",
      "[Epoch 40/50] [Batch 25/235] [D loss: 1.110760, acc: 86.52%] [G loss: 1.274533]\n",
      "[Epoch 40/50] [Batch 26/235] [D loss: 1.097155, acc: 86.72%] [G loss: 1.276155]\n",
      "[Epoch 40/50] [Batch 27/235] [D loss: 1.118071, acc: 87.70%] [G loss: 1.259121]\n",
      "[Epoch 40/50] [Batch 28/235] [D loss: 1.136448, acc: 86.33%] [G loss: 1.155986]\n",
      "[Epoch 40/50] [Batch 29/235] [D loss: 1.195543, acc: 83.40%] [G loss: 1.100468]\n",
      "[Epoch 40/50] [Batch 30/235] [D loss: 1.050063, acc: 84.96%] [G loss: 1.198911]\n",
      "[Epoch 40/50] [Batch 31/235] [D loss: 1.141950, acc: 87.70%] [G loss: 1.067544]\n",
      "[Epoch 40/50] [Batch 32/235] [D loss: 1.174392, acc: 86.91%] [G loss: 1.143531]\n",
      "[Epoch 40/50] [Batch 33/235] [D loss: 1.154633, acc: 88.28%] [G loss: 1.149381]\n",
      "[Epoch 40/50] [Batch 34/235] [D loss: 1.088907, acc: 87.30%] [G loss: 1.169776]\n",
      "[Epoch 40/50] [Batch 35/235] [D loss: 1.090204, acc: 88.67%] [G loss: 1.222654]\n",
      "[Epoch 40/50] [Batch 36/235] [D loss: 1.115451, acc: 88.48%] [G loss: 1.324938]\n",
      "[Epoch 40/50] [Batch 37/235] [D loss: 1.107990, acc: 88.87%] [G loss: 1.140613]\n",
      "[Epoch 40/50] [Batch 38/235] [D loss: 1.047664, acc: 86.91%] [G loss: 1.191710]\n",
      "[Epoch 40/50] [Batch 39/235] [D loss: 1.077415, acc: 88.28%] [G loss: 1.141752]\n",
      "[Epoch 40/50] [Batch 40/235] [D loss: 1.146840, acc: 86.13%] [G loss: 1.017191]\n",
      "[Epoch 40/50] [Batch 41/235] [D loss: 1.112732, acc: 88.28%] [G loss: 1.168250]\n",
      "[Epoch 40/50] [Batch 42/235] [D loss: 1.027185, acc: 88.67%] [G loss: 1.396870]\n",
      "[Epoch 40/50] [Batch 43/235] [D loss: 1.106980, acc: 88.48%] [G loss: 1.241004]\n",
      "[Epoch 40/50] [Batch 44/235] [D loss: 1.140323, acc: 87.30%] [G loss: 1.080719]\n",
      "[Epoch 40/50] [Batch 45/235] [D loss: 1.073865, acc: 89.45%] [G loss: 1.204087]\n",
      "[Epoch 40/50] [Batch 46/235] [D loss: 1.107411, acc: 88.48%] [G loss: 1.144267]\n",
      "[Epoch 40/50] [Batch 47/235] [D loss: 1.130155, acc: 87.89%] [G loss: 1.044863]\n",
      "[Epoch 40/50] [Batch 48/235] [D loss: 1.162197, acc: 88.09%] [G loss: 1.328540]\n",
      "[Epoch 40/50] [Batch 49/235] [D loss: 1.110039, acc: 88.28%] [G loss: 1.270091]\n",
      "[Epoch 40/50] [Batch 50/235] [D loss: 1.158123, acc: 87.89%] [G loss: 0.991031]\n",
      "[Epoch 40/50] [Batch 51/235] [D loss: 1.071848, acc: 86.91%] [G loss: 1.298010]\n",
      "[Epoch 40/50] [Batch 52/235] [D loss: 1.113171, acc: 88.28%] [G loss: 1.238923]\n",
      "[Epoch 40/50] [Batch 53/235] [D loss: 1.106670, acc: 86.52%] [G loss: 1.086337]\n",
      "[Epoch 40/50] [Batch 54/235] [D loss: 1.131017, acc: 85.94%] [G loss: 1.080432]\n",
      "[Epoch 40/50] [Batch 55/235] [D loss: 1.104116, acc: 87.50%] [G loss: 1.142907]\n",
      "[Epoch 40/50] [Batch 56/235] [D loss: 1.046896, acc: 84.96%] [G loss: 1.203111]\n",
      "[Epoch 40/50] [Batch 57/235] [D loss: 1.172250, acc: 86.13%] [G loss: 1.172633]\n",
      "[Epoch 40/50] [Batch 58/235] [D loss: 1.099174, acc: 89.84%] [G loss: 1.031589]\n",
      "[Epoch 40/50] [Batch 59/235] [D loss: 1.093456, acc: 87.30%] [G loss: 0.964196]\n",
      "[Epoch 40/50] [Batch 60/235] [D loss: 1.119057, acc: 84.57%] [G loss: 1.157943]\n",
      "[Epoch 40/50] [Batch 61/235] [D loss: 1.096560, acc: 88.87%] [G loss: 1.117210]\n",
      "[Epoch 40/50] [Batch 62/235] [D loss: 1.154258, acc: 85.55%] [G loss: 1.091529]\n",
      "[Epoch 40/50] [Batch 63/235] [D loss: 1.100922, acc: 89.06%] [G loss: 1.141105]\n",
      "[Epoch 40/50] [Batch 64/235] [D loss: 1.043938, acc: 90.23%] [G loss: 1.118948]\n",
      "[Epoch 40/50] [Batch 65/235] [D loss: 1.096417, acc: 87.30%] [G loss: 1.114572]\n",
      "[Epoch 40/50] [Batch 66/235] [D loss: 1.080659, acc: 84.77%] [G loss: 1.145146]\n",
      "[Epoch 40/50] [Batch 67/235] [D loss: 1.141933, acc: 88.67%] [G loss: 1.184746]\n",
      "[Epoch 40/50] [Batch 68/235] [D loss: 1.102494, acc: 88.67%] [G loss: 1.260859]\n",
      "[Epoch 40/50] [Batch 69/235] [D loss: 1.168949, acc: 88.09%] [G loss: 1.336852]\n",
      "[Epoch 40/50] [Batch 70/235] [D loss: 1.126965, acc: 87.70%] [G loss: 1.189974]\n",
      "[Epoch 40/50] [Batch 71/235] [D loss: 1.108978, acc: 87.11%] [G loss: 1.099487]\n",
      "[Epoch 40/50] [Batch 72/235] [D loss: 1.121338, acc: 87.50%] [G loss: 1.137948]\n",
      "[Epoch 40/50] [Batch 73/235] [D loss: 1.072600, acc: 87.11%] [G loss: 1.055212]\n",
      "[Epoch 40/50] [Batch 74/235] [D loss: 1.069450, acc: 86.91%] [G loss: 1.112236]\n",
      "[Epoch 40/50] [Batch 75/235] [D loss: 1.092846, acc: 87.30%] [G loss: 1.089166]\n",
      "[Epoch 40/50] [Batch 76/235] [D loss: 1.155189, acc: 87.50%] [G loss: 1.222208]\n",
      "[Epoch 40/50] [Batch 77/235] [D loss: 1.106501, acc: 87.50%] [G loss: 1.140973]\n",
      "[Epoch 40/50] [Batch 78/235] [D loss: 1.113690, acc: 88.48%] [G loss: 1.144516]\n",
      "[Epoch 40/50] [Batch 79/235] [D loss: 1.089245, acc: 85.74%] [G loss: 1.095921]\n",
      "[Epoch 40/50] [Batch 80/235] [D loss: 1.185602, acc: 85.16%] [G loss: 1.097757]\n",
      "[Epoch 40/50] [Batch 81/235] [D loss: 1.055705, acc: 88.09%] [G loss: 1.109974]\n",
      "[Epoch 40/50] [Batch 82/235] [D loss: 1.144324, acc: 86.91%] [G loss: 1.237872]\n",
      "[Epoch 40/50] [Batch 83/235] [D loss: 1.198901, acc: 87.70%] [G loss: 1.053789]\n",
      "[Epoch 40/50] [Batch 84/235] [D loss: 1.147191, acc: 86.13%] [G loss: 1.096859]\n",
      "[Epoch 40/50] [Batch 85/235] [D loss: 1.111229, acc: 88.09%] [G loss: 1.154540]\n",
      "[Epoch 40/50] [Batch 86/235] [D loss: 1.115335, acc: 84.38%] [G loss: 1.023674]\n",
      "[Epoch 40/50] [Batch 87/235] [D loss: 1.083860, acc: 86.13%] [G loss: 1.095516]\n",
      "[Epoch 40/50] [Batch 88/235] [D loss: 1.142418, acc: 84.57%] [G loss: 1.153193]\n",
      "[Epoch 40/50] [Batch 89/235] [D loss: 1.088415, acc: 86.91%] [G loss: 1.208856]\n",
      "[Epoch 40/50] [Batch 90/235] [D loss: 1.127159, acc: 88.28%] [G loss: 1.152653]\n",
      "[Epoch 40/50] [Batch 91/235] [D loss: 1.098073, acc: 85.94%] [G loss: 0.996073]\n",
      "[Epoch 40/50] [Batch 92/235] [D loss: 1.057672, acc: 88.28%] [G loss: 1.189331]\n",
      "[Epoch 40/50] [Batch 93/235] [D loss: 1.076387, acc: 87.70%] [G loss: 1.255291]\n",
      "[Epoch 40/50] [Batch 94/235] [D loss: 1.081459, acc: 88.09%] [G loss: 1.146562]\n",
      "[Epoch 40/50] [Batch 95/235] [D loss: 1.123616, acc: 85.74%] [G loss: 1.113929]\n",
      "[Epoch 40/50] [Batch 96/235] [D loss: 1.087062, acc: 89.84%] [G loss: 1.184321]\n",
      "[Epoch 40/50] [Batch 97/235] [D loss: 1.093311, acc: 86.91%] [G loss: 1.301579]\n",
      "[Epoch 40/50] [Batch 98/235] [D loss: 1.088676, acc: 90.82%] [G loss: 1.279185]\n",
      "[Epoch 40/50] [Batch 99/235] [D loss: 1.104591, acc: 85.16%] [G loss: 1.131014]\n",
      "[Epoch 40/50] [Batch 100/235] [D loss: 1.093671, acc: 87.89%] [G loss: 1.033605]\n",
      "[Epoch 40/50] [Batch 101/235] [D loss: 1.113295, acc: 88.09%] [G loss: 1.065181]\n",
      "[Epoch 40/50] [Batch 102/235] [D loss: 1.119769, acc: 86.13%] [G loss: 1.312877]\n",
      "[Epoch 40/50] [Batch 103/235] [D loss: 1.117733, acc: 87.89%] [G loss: 1.089024]\n",
      "[Epoch 40/50] [Batch 104/235] [D loss: 1.024762, acc: 88.87%] [G loss: 1.229452]\n",
      "[Epoch 40/50] [Batch 105/235] [D loss: 1.104497, acc: 88.67%] [G loss: 1.092775]\n",
      "[Epoch 40/50] [Batch 106/235] [D loss: 1.148779, acc: 88.09%] [G loss: 1.146894]\n",
      "[Epoch 40/50] [Batch 107/235] [D loss: 1.179055, acc: 89.26%] [G loss: 1.152879]\n",
      "[Epoch 40/50] [Batch 108/235] [D loss: 1.175310, acc: 87.11%] [G loss: 1.071914]\n",
      "[Epoch 40/50] [Batch 109/235] [D loss: 1.097881, acc: 87.30%] [G loss: 1.074216]\n",
      "[Epoch 40/50] [Batch 110/235] [D loss: 1.093333, acc: 90.82%] [G loss: 1.207951]\n",
      "[Epoch 40/50] [Batch 111/235] [D loss: 1.162129, acc: 87.50%] [G loss: 1.180099]\n",
      "[Epoch 40/50] [Batch 112/235] [D loss: 1.085140, acc: 87.11%] [G loss: 1.145001]\n",
      "[Epoch 40/50] [Batch 113/235] [D loss: 1.041752, acc: 88.09%] [G loss: 1.057508]\n",
      "[Epoch 40/50] [Batch 114/235] [D loss: 1.080989, acc: 87.30%] [G loss: 1.070516]\n",
      "[Epoch 40/50] [Batch 115/235] [D loss: 1.102332, acc: 87.30%] [G loss: 0.982003]\n",
      "[Epoch 40/50] [Batch 116/235] [D loss: 1.081852, acc: 85.55%] [G loss: 1.113573]\n",
      "[Epoch 40/50] [Batch 117/235] [D loss: 1.120188, acc: 89.06%] [G loss: 1.184930]\n",
      "[Epoch 40/50] [Batch 118/235] [D loss: 1.061579, acc: 86.72%] [G loss: 1.281821]\n",
      "[Epoch 40/50] [Batch 119/235] [D loss: 1.091114, acc: 84.96%] [G loss: 1.289410]\n",
      "[Epoch 40/50] [Batch 120/235] [D loss: 1.143021, acc: 87.30%] [G loss: 1.048409]\n",
      "[Epoch 40/50] [Batch 121/235] [D loss: 1.057815, acc: 89.45%] [G loss: 1.094689]\n",
      "[Epoch 40/50] [Batch 122/235] [D loss: 1.100043, acc: 87.89%] [G loss: 1.121782]\n",
      "[Epoch 40/50] [Batch 123/235] [D loss: 1.110457, acc: 89.84%] [G loss: 1.311303]\n",
      "[Epoch 40/50] [Batch 124/235] [D loss: 1.153862, acc: 85.35%] [G loss: 1.126172]\n",
      "[Epoch 40/50] [Batch 125/235] [D loss: 1.101778, acc: 84.96%] [G loss: 1.057742]\n",
      "[Epoch 40/50] [Batch 126/235] [D loss: 1.072949, acc: 88.48%] [G loss: 1.045137]\n",
      "[Epoch 40/50] [Batch 127/235] [D loss: 1.121498, acc: 89.06%] [G loss: 1.036616]\n",
      "[Epoch 40/50] [Batch 128/235] [D loss: 1.120476, acc: 87.50%] [G loss: 1.250697]\n",
      "[Epoch 40/50] [Batch 129/235] [D loss: 1.154917, acc: 87.30%] [G loss: 1.063469]\n",
      "[Epoch 40/50] [Batch 130/235] [D loss: 1.110638, acc: 89.26%] [G loss: 1.073564]\n",
      "[Epoch 40/50] [Batch 131/235] [D loss: 1.118130, acc: 87.30%] [G loss: 1.116642]\n",
      "[Epoch 40/50] [Batch 132/235] [D loss: 1.072024, acc: 88.28%] [G loss: 1.213848]\n",
      "[Epoch 40/50] [Batch 133/235] [D loss: 1.075296, acc: 87.89%] [G loss: 1.166758]\n",
      "[Epoch 40/50] [Batch 134/235] [D loss: 1.115969, acc: 87.30%] [G loss: 1.193269]\n",
      "[Epoch 40/50] [Batch 135/235] [D loss: 1.160447, acc: 87.70%] [G loss: 1.190461]\n",
      "[Epoch 40/50] [Batch 136/235] [D loss: 1.169025, acc: 86.13%] [G loss: 1.175915]\n",
      "[Epoch 40/50] [Batch 137/235] [D loss: 1.114036, acc: 88.87%] [G loss: 1.317761]\n",
      "[Epoch 40/50] [Batch 138/235] [D loss: 1.073620, acc: 88.48%] [G loss: 1.153690]\n",
      "[Epoch 40/50] [Batch 139/235] [D loss: 1.138997, acc: 88.87%] [G loss: 1.150821]\n",
      "[Epoch 40/50] [Batch 140/235] [D loss: 1.070867, acc: 89.06%] [G loss: 1.167117]\n",
      "[Epoch 40/50] [Batch 141/235] [D loss: 1.129551, acc: 87.50%] [G loss: 1.284450]\n",
      "[Epoch 40/50] [Batch 142/235] [D loss: 1.068872, acc: 87.50%] [G loss: 1.232902]\n",
      "[Epoch 40/50] [Batch 143/235] [D loss: 1.065680, acc: 90.43%] [G loss: 1.150713]\n",
      "[Epoch 40/50] [Batch 144/235] [D loss: 1.122133, acc: 87.70%] [G loss: 1.074398]\n",
      "[Epoch 40/50] [Batch 145/235] [D loss: 1.155373, acc: 90.23%] [G loss: 1.017690]\n",
      "[Epoch 40/50] [Batch 146/235] [D loss: 1.118051, acc: 83.59%] [G loss: 1.188550]\n",
      "[Epoch 40/50] [Batch 147/235] [D loss: 1.076901, acc: 88.28%] [G loss: 1.206274]\n",
      "[Epoch 40/50] [Batch 148/235] [D loss: 1.080553, acc: 87.30%] [G loss: 1.073374]\n",
      "[Epoch 40/50] [Batch 149/235] [D loss: 1.109360, acc: 86.52%] [G loss: 1.077432]\n",
      "[Epoch 40/50] [Batch 150/235] [D loss: 1.073567, acc: 88.09%] [G loss: 1.197568]\n",
      "[Epoch 40/50] [Batch 151/235] [D loss: 1.074854, acc: 88.48%] [G loss: 1.203040]\n",
      "[Epoch 40/50] [Batch 152/235] [D loss: 1.106755, acc: 87.50%] [G loss: 1.032197]\n",
      "[Epoch 40/50] [Batch 153/235] [D loss: 1.125041, acc: 85.74%] [G loss: 1.064107]\n",
      "[Epoch 40/50] [Batch 154/235] [D loss: 1.123771, acc: 85.55%] [G loss: 1.352538]\n",
      "[Epoch 40/50] [Batch 155/235] [D loss: 1.105312, acc: 87.11%] [G loss: 1.224637]\n",
      "[Epoch 40/50] [Batch 156/235] [D loss: 1.100021, acc: 89.26%] [G loss: 1.200251]\n",
      "[Epoch 40/50] [Batch 157/235] [D loss: 1.051589, acc: 87.70%] [G loss: 1.150946]\n",
      "[Epoch 40/50] [Batch 158/235] [D loss: 1.163316, acc: 89.65%] [G loss: 0.976240]\n",
      "[Epoch 40/50] [Batch 159/235] [D loss: 1.159439, acc: 86.91%] [G loss: 1.180633]\n",
      "[Epoch 40/50] [Batch 160/235] [D loss: 1.161152, acc: 85.74%] [G loss: 1.312824]\n",
      "[Epoch 40/50] [Batch 161/235] [D loss: 1.059302, acc: 87.11%] [G loss: 1.300093]\n",
      "[Epoch 40/50] [Batch 162/235] [D loss: 1.092212, acc: 85.55%] [G loss: 1.076914]\n",
      "[Epoch 40/50] [Batch 163/235] [D loss: 1.073102, acc: 85.55%] [G loss: 1.045559]\n",
      "[Epoch 40/50] [Batch 164/235] [D loss: 1.131108, acc: 89.06%] [G loss: 1.063680]\n",
      "[Epoch 40/50] [Batch 165/235] [D loss: 1.148457, acc: 87.70%] [G loss: 1.116439]\n",
      "[Epoch 40/50] [Batch 166/235] [D loss: 1.051173, acc: 88.48%] [G loss: 1.130339]\n",
      "[Epoch 40/50] [Batch 167/235] [D loss: 1.159027, acc: 86.13%] [G loss: 1.208991]\n",
      "[Epoch 40/50] [Batch 168/235] [D loss: 1.090361, acc: 88.67%] [G loss: 1.146115]\n",
      "[Epoch 40/50] [Batch 169/235] [D loss: 1.131133, acc: 87.50%] [G loss: 1.047819]\n",
      "[Epoch 40/50] [Batch 170/235] [D loss: 1.119057, acc: 85.16%] [G loss: 0.994890]\n",
      "[Epoch 40/50] [Batch 171/235] [D loss: 1.054810, acc: 86.52%] [G loss: 1.222399]\n",
      "[Epoch 40/50] [Batch 172/235] [D loss: 1.171659, acc: 85.74%] [G loss: 1.203562]\n",
      "[Epoch 40/50] [Batch 173/235] [D loss: 1.152686, acc: 89.26%] [G loss: 1.188126]\n",
      "[Epoch 40/50] [Batch 174/235] [D loss: 1.138059, acc: 87.89%] [G loss: 1.019926]\n",
      "[Epoch 40/50] [Batch 175/235] [D loss: 1.059663, acc: 87.70%] [G loss: 1.100930]\n",
      "[Epoch 40/50] [Batch 176/235] [D loss: 1.165096, acc: 88.09%] [G loss: 1.316261]\n",
      "[Epoch 40/50] [Batch 177/235] [D loss: 1.115725, acc: 86.52%] [G loss: 1.122087]\n",
      "[Epoch 40/50] [Batch 178/235] [D loss: 1.069312, acc: 85.35%] [G loss: 1.023907]\n",
      "[Epoch 40/50] [Batch 179/235] [D loss: 1.138891, acc: 85.74%] [G loss: 1.146108]\n",
      "[Epoch 40/50] [Batch 180/235] [D loss: 1.172734, acc: 87.50%] [G loss: 1.203749]\n",
      "[Epoch 40/50] [Batch 181/235] [D loss: 1.095095, acc: 87.70%] [G loss: 1.088009]\n",
      "[Epoch 40/50] [Batch 182/235] [D loss: 1.168481, acc: 86.52%] [G loss: 1.149704]\n",
      "[Epoch 40/50] [Batch 183/235] [D loss: 1.077403, acc: 88.67%] [G loss: 1.209349]\n",
      "[Epoch 40/50] [Batch 184/235] [D loss: 1.095509, acc: 87.89%] [G loss: 1.055488]\n",
      "[Epoch 40/50] [Batch 185/235] [D loss: 1.161243, acc: 88.28%] [G loss: 1.120125]\n",
      "[Epoch 40/50] [Batch 186/235] [D loss: 1.064969, acc: 87.70%] [G loss: 1.135002]\n",
      "[Epoch 40/50] [Batch 187/235] [D loss: 1.147936, acc: 83.59%] [G loss: 1.367000]\n",
      "[Epoch 40/50] [Batch 188/235] [D loss: 1.114648, acc: 87.50%] [G loss: 1.209939]\n",
      "[Epoch 40/50] [Batch 189/235] [D loss: 1.062617, acc: 88.48%] [G loss: 1.177817]\n",
      "[Epoch 40/50] [Batch 190/235] [D loss: 1.076470, acc: 88.28%] [G loss: 1.059486]\n",
      "[Epoch 40/50] [Batch 191/235] [D loss: 1.024837, acc: 86.91%] [G loss: 1.101445]\n",
      "[Epoch 40/50] [Batch 192/235] [D loss: 1.108733, acc: 90.23%] [G loss: 1.215412]\n",
      "[Epoch 40/50] [Batch 193/235] [D loss: 1.130379, acc: 88.67%] [G loss: 1.229956]\n",
      "[Epoch 40/50] [Batch 194/235] [D loss: 1.204914, acc: 86.33%] [G loss: 1.180996]\n",
      "[Epoch 40/50] [Batch 195/235] [D loss: 1.150445, acc: 86.91%] [G loss: 1.172950]\n",
      "[Epoch 40/50] [Batch 196/235] [D loss: 1.047501, acc: 86.91%] [G loss: 1.132871]\n",
      "[Epoch 40/50] [Batch 197/235] [D loss: 1.114610, acc: 89.65%] [G loss: 1.134500]\n",
      "[Epoch 40/50] [Batch 198/235] [D loss: 1.070454, acc: 86.72%] [G loss: 1.196729]\n",
      "[Epoch 40/50] [Batch 199/235] [D loss: 1.140053, acc: 89.06%] [G loss: 1.147858]\n",
      "[Epoch 40/50] [Batch 200/235] [D loss: 1.072379, acc: 88.67%] [G loss: 1.362214]\n",
      "[Epoch 40/50] [Batch 201/235] [D loss: 1.145133, acc: 88.48%] [G loss: 1.182934]\n",
      "[Epoch 40/50] [Batch 202/235] [D loss: 1.081957, acc: 87.11%] [G loss: 1.127330]\n",
      "[Epoch 40/50] [Batch 203/235] [D loss: 1.076298, acc: 89.65%] [G loss: 1.137752]\n",
      "[Epoch 40/50] [Batch 204/235] [D loss: 1.050524, acc: 85.74%] [G loss: 1.173265]\n",
      "[Epoch 40/50] [Batch 205/235] [D loss: 1.143318, acc: 87.11%] [G loss: 1.094806]\n",
      "[Epoch 40/50] [Batch 206/235] [D loss: 1.051533, acc: 87.30%] [G loss: 1.101677]\n",
      "[Epoch 40/50] [Batch 207/235] [D loss: 1.114933, acc: 87.89%] [G loss: 1.141624]\n",
      "[Epoch 40/50] [Batch 208/235] [D loss: 1.159526, acc: 86.72%] [G loss: 1.182636]\n",
      "[Epoch 40/50] [Batch 209/235] [D loss: 1.088888, acc: 87.30%] [G loss: 1.298987]\n",
      "[Epoch 40/50] [Batch 210/235] [D loss: 1.087424, acc: 88.28%] [G loss: 1.185969]\n",
      "[Epoch 40/50] [Batch 211/235] [D loss: 1.064157, acc: 88.67%] [G loss: 1.020733]\n",
      "[Epoch 40/50] [Batch 212/235] [D loss: 1.107341, acc: 84.77%] [G loss: 1.102821]\n",
      "[Epoch 40/50] [Batch 213/235] [D loss: 1.053296, acc: 87.30%] [G loss: 1.174201]\n",
      "[Epoch 40/50] [Batch 214/235] [D loss: 1.023679, acc: 89.65%] [G loss: 1.316539]\n",
      "[Epoch 40/50] [Batch 215/235] [D loss: 1.067212, acc: 86.52%] [G loss: 1.116101]\n",
      "[Epoch 40/50] [Batch 216/235] [D loss: 1.171229, acc: 88.48%] [G loss: 1.123518]\n",
      "[Epoch 40/50] [Batch 217/235] [D loss: 1.115929, acc: 89.06%] [G loss: 1.125143]\n",
      "[Epoch 40/50] [Batch 218/235] [D loss: 1.102437, acc: 86.33%] [G loss: 1.231627]\n",
      "[Epoch 40/50] [Batch 219/235] [D loss: 1.149351, acc: 86.91%] [G loss: 1.190583]\n",
      "[Epoch 40/50] [Batch 220/235] [D loss: 1.089915, acc: 88.28%] [G loss: 1.339498]\n",
      "[Epoch 40/50] [Batch 221/235] [D loss: 1.083252, acc: 88.09%] [G loss: 1.233283]\n",
      "[Epoch 40/50] [Batch 222/235] [D loss: 1.131495, acc: 88.09%] [G loss: 1.195223]\n",
      "[Epoch 40/50] [Batch 223/235] [D loss: 1.069994, acc: 88.09%] [G loss: 1.074416]\n",
      "[Epoch 40/50] [Batch 224/235] [D loss: 1.102310, acc: 88.67%] [G loss: 0.977385]\n",
      "[Epoch 40/50] [Batch 225/235] [D loss: 1.100928, acc: 88.48%] [G loss: 1.125327]\n",
      "[Epoch 40/50] [Batch 226/235] [D loss: 1.108584, acc: 86.33%] [G loss: 1.249314]\n",
      "[Epoch 40/50] [Batch 227/235] [D loss: 1.145364, acc: 87.50%] [G loss: 1.158441]\n",
      "[Epoch 40/50] [Batch 228/235] [D loss: 1.113570, acc: 86.72%] [G loss: 1.202512]\n",
      "[Epoch 40/50] [Batch 229/235] [D loss: 1.155502, acc: 87.30%] [G loss: 1.041642]\n",
      "[Epoch 40/50] [Batch 230/235] [D loss: 1.098040, acc: 87.89%] [G loss: 1.192157]\n",
      "[Epoch 40/50] [Batch 231/235] [D loss: 1.229177, acc: 87.50%] [G loss: 1.113074]\n",
      "[Epoch 40/50] [Batch 232/235] [D loss: 1.147731, acc: 88.09%] [G loss: 1.320107]\n",
      "[Epoch 40/50] [Batch 233/235] [D loss: 1.036451, acc: 86.13%] [G loss: 1.163679]\n",
      "[Epoch 40/50] [Batch 234/235] [D loss: 1.205808, acc: 87.50%] [G loss: 1.050267]\n",
      "[Epoch 41/50] [Batch 0/235] [D loss: 1.128119, acc: 86.52%] [G loss: 1.103387]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/50] [Batch 1/235] [D loss: 1.118317, acc: 85.74%] [G loss: 1.172301]\n",
      "[Epoch 41/50] [Batch 2/235] [D loss: 1.077616, acc: 88.48%] [G loss: 1.154770]\n",
      "[Epoch 41/50] [Batch 3/235] [D loss: 1.131016, acc: 86.52%] [G loss: 1.198000]\n",
      "[Epoch 41/50] [Batch 4/235] [D loss: 1.125003, acc: 86.91%] [G loss: 1.155189]\n",
      "[Epoch 41/50] [Batch 5/235] [D loss: 1.050053, acc: 87.50%] [G loss: 1.195128]\n",
      "[Epoch 41/50] [Batch 6/235] [D loss: 1.142823, acc: 89.26%] [G loss: 1.085916]\n",
      "[Epoch 41/50] [Batch 7/235] [D loss: 1.085068, acc: 86.13%] [G loss: 1.195263]\n",
      "[Epoch 41/50] [Batch 8/235] [D loss: 1.080177, acc: 86.91%] [G loss: 1.387805]\n",
      "[Epoch 41/50] [Batch 9/235] [D loss: 1.169178, acc: 87.89%] [G loss: 1.242306]\n",
      "[Epoch 41/50] [Batch 10/235] [D loss: 1.114200, acc: 89.65%] [G loss: 1.217916]\n",
      "[Epoch 41/50] [Batch 11/235] [D loss: 1.094888, acc: 90.04%] [G loss: 1.068286]\n",
      "[Epoch 41/50] [Batch 12/235] [D loss: 1.111770, acc: 86.33%] [G loss: 1.280371]\n",
      "[Epoch 41/50] [Batch 13/235] [D loss: 1.174585, acc: 88.67%] [G loss: 1.105060]\n",
      "[Epoch 41/50] [Batch 14/235] [D loss: 1.080930, acc: 87.70%] [G loss: 1.163065]\n",
      "[Epoch 41/50] [Batch 15/235] [D loss: 1.088338, acc: 88.28%] [G loss: 1.103961]\n",
      "[Epoch 41/50] [Batch 16/235] [D loss: 1.071421, acc: 87.11%] [G loss: 1.242857]\n",
      "[Epoch 41/50] [Batch 17/235] [D loss: 1.061512, acc: 89.84%] [G loss: 1.257746]\n",
      "[Epoch 41/50] [Batch 18/235] [D loss: 1.103109, acc: 87.70%] [G loss: 1.070849]\n",
      "[Epoch 41/50] [Batch 19/235] [D loss: 1.060507, acc: 88.48%] [G loss: 1.226501]\n",
      "[Epoch 41/50] [Batch 20/235] [D loss: 1.154670, acc: 86.91%] [G loss: 1.149819]\n",
      "[Epoch 41/50] [Batch 21/235] [D loss: 1.043392, acc: 89.65%] [G loss: 1.328331]\n",
      "[Epoch 41/50] [Batch 22/235] [D loss: 1.151258, acc: 88.09%] [G loss: 1.195359]\n",
      "[Epoch 41/50] [Batch 23/235] [D loss: 1.166880, acc: 89.84%] [G loss: 1.126254]\n",
      "[Epoch 41/50] [Batch 24/235] [D loss: 1.157542, acc: 87.70%] [G loss: 1.192092]\n",
      "[Epoch 41/50] [Batch 25/235] [D loss: 1.063180, acc: 88.28%] [G loss: 1.289579]\n",
      "[Epoch 41/50] [Batch 26/235] [D loss: 1.066152, acc: 85.16%] [G loss: 1.163091]\n",
      "[Epoch 41/50] [Batch 27/235] [D loss: 1.127305, acc: 86.52%] [G loss: 1.129652]\n",
      "[Epoch 41/50] [Batch 28/235] [D loss: 1.134225, acc: 87.11%] [G loss: 1.125650]\n",
      "[Epoch 41/50] [Batch 29/235] [D loss: 1.144031, acc: 87.50%] [G loss: 1.269688]\n",
      "[Epoch 41/50] [Batch 30/235] [D loss: 1.123095, acc: 83.79%] [G loss: 1.131943]\n",
      "[Epoch 41/50] [Batch 31/235] [D loss: 1.068859, acc: 90.04%] [G loss: 1.055032]\n",
      "[Epoch 41/50] [Batch 32/235] [D loss: 1.116522, acc: 85.35%] [G loss: 1.223931]\n",
      "[Epoch 41/50] [Batch 33/235] [D loss: 1.131755, acc: 86.33%] [G loss: 1.368401]\n",
      "[Epoch 41/50] [Batch 34/235] [D loss: 1.178543, acc: 86.13%] [G loss: 1.046004]\n",
      "[Epoch 41/50] [Batch 35/235] [D loss: 1.129612, acc: 89.45%] [G loss: 1.046709]\n",
      "[Epoch 41/50] [Batch 36/235] [D loss: 1.077612, acc: 87.50%] [G loss: 1.208491]\n",
      "[Epoch 41/50] [Batch 37/235] [D loss: 1.070355, acc: 88.09%] [G loss: 1.281264]\n",
      "[Epoch 41/50] [Batch 38/235] [D loss: 1.105340, acc: 89.45%] [G loss: 1.239124]\n",
      "[Epoch 41/50] [Batch 39/235] [D loss: 1.068738, acc: 88.28%] [G loss: 1.131116]\n",
      "[Epoch 41/50] [Batch 40/235] [D loss: 1.132929, acc: 89.65%] [G loss: 1.268001]\n",
      "[Epoch 41/50] [Batch 41/235] [D loss: 1.110206, acc: 90.62%] [G loss: 1.057304]\n",
      "[Epoch 41/50] [Batch 42/235] [D loss: 1.036798, acc: 89.84%] [G loss: 1.024806]\n",
      "[Epoch 41/50] [Batch 43/235] [D loss: 1.094144, acc: 89.84%] [G loss: 1.144757]\n",
      "[Epoch 41/50] [Batch 44/235] [D loss: 1.116472, acc: 86.72%] [G loss: 1.192702]\n",
      "[Epoch 41/50] [Batch 45/235] [D loss: 1.124532, acc: 87.50%] [G loss: 1.151744]\n",
      "[Epoch 41/50] [Batch 46/235] [D loss: 1.060183, acc: 88.48%] [G loss: 1.235541]\n",
      "[Epoch 41/50] [Batch 47/235] [D loss: 1.111325, acc: 87.70%] [G loss: 1.237705]\n",
      "[Epoch 41/50] [Batch 48/235] [D loss: 1.067556, acc: 88.28%] [G loss: 1.096663]\n",
      "[Epoch 41/50] [Batch 49/235] [D loss: 1.109513, acc: 88.09%] [G loss: 1.173171]\n",
      "[Epoch 41/50] [Batch 50/235] [D loss: 1.107849, acc: 87.11%] [G loss: 1.342204]\n",
      "[Epoch 41/50] [Batch 51/235] [D loss: 1.139253, acc: 86.72%] [G loss: 1.118335]\n",
      "[Epoch 41/50] [Batch 52/235] [D loss: 1.109668, acc: 87.11%] [G loss: 1.075083]\n",
      "[Epoch 41/50] [Batch 53/235] [D loss: 1.095399, acc: 88.28%] [G loss: 1.190777]\n",
      "[Epoch 41/50] [Batch 54/235] [D loss: 1.096372, acc: 87.30%] [G loss: 1.140241]\n",
      "[Epoch 41/50] [Batch 55/235] [D loss: 1.075718, acc: 88.09%] [G loss: 1.049840]\n",
      "[Epoch 41/50] [Batch 56/235] [D loss: 1.096325, acc: 89.45%] [G loss: 1.056238]\n",
      "[Epoch 41/50] [Batch 57/235] [D loss: 1.131879, acc: 86.52%] [G loss: 1.075507]\n",
      "[Epoch 41/50] [Batch 58/235] [D loss: 1.119561, acc: 86.91%] [G loss: 1.105668]\n",
      "[Epoch 41/50] [Batch 59/235] [D loss: 1.094508, acc: 88.87%] [G loss: 1.292325]\n",
      "[Epoch 41/50] [Batch 60/235] [D loss: 1.075397, acc: 85.94%] [G loss: 1.198251]\n",
      "[Epoch 41/50] [Batch 61/235] [D loss: 1.086318, acc: 86.33%] [G loss: 1.272402]\n",
      "[Epoch 41/50] [Batch 62/235] [D loss: 1.181846, acc: 86.52%] [G loss: 1.126172]\n",
      "[Epoch 41/50] [Batch 63/235] [D loss: 1.164203, acc: 89.26%] [G loss: 1.106302]\n",
      "[Epoch 41/50] [Batch 64/235] [D loss: 1.047480, acc: 91.02%] [G loss: 1.087311]\n",
      "[Epoch 41/50] [Batch 65/235] [D loss: 1.133294, acc: 89.84%] [G loss: 1.100580]\n",
      "[Epoch 41/50] [Batch 66/235] [D loss: 1.108989, acc: 86.13%] [G loss: 1.126863]\n",
      "[Epoch 41/50] [Batch 67/235] [D loss: 1.180134, acc: 89.06%] [G loss: 1.096448]\n",
      "[Epoch 41/50] [Batch 68/235] [D loss: 1.136673, acc: 89.06%] [G loss: 1.161303]\n",
      "[Epoch 41/50] [Batch 69/235] [D loss: 1.084011, acc: 86.72%] [G loss: 1.254376]\n",
      "[Epoch 41/50] [Batch 70/235] [D loss: 1.206134, acc: 87.50%] [G loss: 1.190585]\n",
      "[Epoch 41/50] [Batch 71/235] [D loss: 1.077160, acc: 86.52%] [G loss: 1.278906]\n",
      "[Epoch 41/50] [Batch 72/235] [D loss: 1.126321, acc: 85.55%] [G loss: 1.351867]\n",
      "[Epoch 41/50] [Batch 73/235] [D loss: 1.101886, acc: 87.11%] [G loss: 1.110355]\n",
      "[Epoch 41/50] [Batch 74/235] [D loss: 1.091225, acc: 85.55%] [G loss: 1.088000]\n",
      "[Epoch 41/50] [Batch 75/235] [D loss: 1.147785, acc: 88.67%] [G loss: 1.139376]\n",
      "[Epoch 41/50] [Batch 76/235] [D loss: 1.074370, acc: 89.26%] [G loss: 1.211337]\n",
      "[Epoch 41/50] [Batch 77/235] [D loss: 1.156483, acc: 86.52%] [G loss: 1.244897]\n",
      "[Epoch 41/50] [Batch 78/235] [D loss: 1.076101, acc: 86.33%] [G loss: 1.213550]\n",
      "[Epoch 41/50] [Batch 79/235] [D loss: 1.089151, acc: 86.91%] [G loss: 1.062682]\n",
      "[Epoch 41/50] [Batch 80/235] [D loss: 1.114063, acc: 83.59%] [G loss: 1.246891]\n",
      "[Epoch 41/50] [Batch 81/235] [D loss: 1.071450, acc: 86.72%] [G loss: 1.282251]\n",
      "[Epoch 41/50] [Batch 82/235] [D loss: 1.121947, acc: 89.06%] [G loss: 1.262475]\n",
      "[Epoch 41/50] [Batch 83/235] [D loss: 1.065206, acc: 87.11%] [G loss: 1.169228]\n",
      "[Epoch 41/50] [Batch 84/235] [D loss: 1.151124, acc: 86.33%] [G loss: 1.204185]\n",
      "[Epoch 41/50] [Batch 85/235] [D loss: 1.154796, acc: 84.96%] [G loss: 1.179354]\n",
      "[Epoch 41/50] [Batch 86/235] [D loss: 1.116771, acc: 88.28%] [G loss: 1.180156]\n",
      "[Epoch 41/50] [Batch 87/235] [D loss: 1.146127, acc: 87.50%] [G loss: 1.162140]\n",
      "[Epoch 41/50] [Batch 88/235] [D loss: 1.112616, acc: 86.33%] [G loss: 1.126859]\n",
      "[Epoch 41/50] [Batch 89/235] [D loss: 1.087542, acc: 88.09%] [G loss: 1.075027]\n",
      "[Epoch 41/50] [Batch 90/235] [D loss: 1.138081, acc: 88.48%] [G loss: 1.110224]\n",
      "[Epoch 41/50] [Batch 91/235] [D loss: 1.130958, acc: 84.96%] [G loss: 1.238915]\n",
      "[Epoch 41/50] [Batch 92/235] [D loss: 1.066190, acc: 87.70%] [G loss: 1.061017]\n",
      "[Epoch 41/50] [Batch 93/235] [D loss: 1.131726, acc: 86.52%] [G loss: 1.080456]\n",
      "[Epoch 41/50] [Batch 94/235] [D loss: 1.145034, acc: 87.50%] [G loss: 1.172332]\n",
      "[Epoch 41/50] [Batch 95/235] [D loss: 1.063535, acc: 87.70%] [G loss: 1.438068]\n",
      "[Epoch 41/50] [Batch 96/235] [D loss: 1.122197, acc: 87.11%] [G loss: 1.230269]\n",
      "[Epoch 41/50] [Batch 97/235] [D loss: 1.057196, acc: 88.48%] [G loss: 1.141887]\n",
      "[Epoch 41/50] [Batch 98/235] [D loss: 1.083704, acc: 86.13%] [G loss: 1.156199]\n",
      "[Epoch 41/50] [Batch 99/235] [D loss: 1.097209, acc: 86.13%] [G loss: 1.057727]\n",
      "[Epoch 41/50] [Batch 100/235] [D loss: 1.053833, acc: 87.11%] [G loss: 1.228013]\n",
      "[Epoch 41/50] [Batch 101/235] [D loss: 1.172051, acc: 83.40%] [G loss: 1.205738]\n",
      "[Epoch 41/50] [Batch 102/235] [D loss: 1.076492, acc: 86.91%] [G loss: 1.116434]\n",
      "[Epoch 41/50] [Batch 103/235] [D loss: 1.112216, acc: 88.87%] [G loss: 1.035762]\n",
      "[Epoch 41/50] [Batch 104/235] [D loss: 1.129452, acc: 88.28%] [G loss: 1.174587]\n",
      "[Epoch 41/50] [Batch 105/235] [D loss: 1.108823, acc: 86.33%] [G loss: 1.127867]\n",
      "[Epoch 41/50] [Batch 106/235] [D loss: 1.082765, acc: 87.89%] [G loss: 1.175144]\n",
      "[Epoch 41/50] [Batch 107/235] [D loss: 1.139529, acc: 86.91%] [G loss: 1.170707]\n",
      "[Epoch 41/50] [Batch 108/235] [D loss: 1.122720, acc: 88.28%] [G loss: 1.151139]\n",
      "[Epoch 41/50] [Batch 109/235] [D loss: 1.034089, acc: 89.06%] [G loss: 1.289740]\n",
      "[Epoch 41/50] [Batch 110/235] [D loss: 1.014555, acc: 87.70%] [G loss: 1.278146]\n",
      "[Epoch 41/50] [Batch 111/235] [D loss: 1.175243, acc: 87.50%] [G loss: 1.152220]\n",
      "[Epoch 41/50] [Batch 112/235] [D loss: 1.175971, acc: 85.55%] [G loss: 1.234778]\n",
      "[Epoch 41/50] [Batch 113/235] [D loss: 1.114305, acc: 88.87%] [G loss: 1.068865]\n",
      "[Epoch 41/50] [Batch 114/235] [D loss: 1.059633, acc: 89.45%] [G loss: 1.137016]\n",
      "[Epoch 41/50] [Batch 115/235] [D loss: 1.088817, acc: 86.72%] [G loss: 1.046770]\n",
      "[Epoch 41/50] [Batch 116/235] [D loss: 1.082601, acc: 88.28%] [G loss: 1.194579]\n",
      "[Epoch 41/50] [Batch 117/235] [D loss: 1.089257, acc: 87.30%] [G loss: 1.238213]\n",
      "[Epoch 41/50] [Batch 118/235] [D loss: 1.078382, acc: 87.30%] [G loss: 1.113766]\n",
      "[Epoch 41/50] [Batch 119/235] [D loss: 1.100416, acc: 86.91%] [G loss: 1.026367]\n",
      "[Epoch 41/50] [Batch 120/235] [D loss: 1.167763, acc: 87.89%] [G loss: 1.211282]\n",
      "[Epoch 41/50] [Batch 121/235] [D loss: 1.078403, acc: 87.11%] [G loss: 1.376389]\n",
      "[Epoch 41/50] [Batch 122/235] [D loss: 1.194725, acc: 85.35%] [G loss: 1.057189]\n",
      "[Epoch 41/50] [Batch 123/235] [D loss: 1.128272, acc: 85.94%] [G loss: 1.156998]\n",
      "[Epoch 41/50] [Batch 124/235] [D loss: 1.084531, acc: 85.55%] [G loss: 1.136506]\n",
      "[Epoch 41/50] [Batch 125/235] [D loss: 1.173815, acc: 86.72%] [G loss: 1.105594]\n",
      "[Epoch 41/50] [Batch 126/235] [D loss: 1.077548, acc: 88.28%] [G loss: 1.187691]\n",
      "[Epoch 41/50] [Batch 127/235] [D loss: 1.065950, acc: 86.33%] [G loss: 1.220422]\n",
      "[Epoch 41/50] [Batch 128/235] [D loss: 1.156900, acc: 84.18%] [G loss: 1.137081]\n",
      "[Epoch 41/50] [Batch 129/235] [D loss: 1.066455, acc: 88.48%] [G loss: 1.224417]\n",
      "[Epoch 41/50] [Batch 130/235] [D loss: 1.143465, acc: 88.48%] [G loss: 1.051738]\n",
      "[Epoch 41/50] [Batch 131/235] [D loss: 1.142162, acc: 87.11%] [G loss: 1.165177]\n",
      "[Epoch 41/50] [Batch 132/235] [D loss: 1.053487, acc: 87.89%] [G loss: 1.152779]\n",
      "[Epoch 41/50] [Batch 133/235] [D loss: 1.115273, acc: 88.67%] [G loss: 1.209796]\n",
      "[Epoch 41/50] [Batch 134/235] [D loss: 1.073365, acc: 85.74%] [G loss: 1.092983]\n",
      "[Epoch 41/50] [Batch 135/235] [D loss: 1.096177, acc: 87.70%] [G loss: 1.216014]\n",
      "[Epoch 41/50] [Batch 136/235] [D loss: 1.073809, acc: 89.26%] [G loss: 1.262886]\n",
      "[Epoch 41/50] [Batch 137/235] [D loss: 1.055270, acc: 87.30%] [G loss: 1.174510]\n",
      "[Epoch 41/50] [Batch 138/235] [D loss: 1.185037, acc: 89.26%] [G loss: 1.177047]\n",
      "[Epoch 41/50] [Batch 139/235] [D loss: 1.166691, acc: 87.30%] [G loss: 1.139942]\n",
      "[Epoch 41/50] [Batch 140/235] [D loss: 1.091157, acc: 87.70%] [G loss: 1.195257]\n",
      "[Epoch 41/50] [Batch 141/235] [D loss: 1.127942, acc: 85.16%] [G loss: 1.277505]\n",
      "[Epoch 41/50] [Batch 142/235] [D loss: 1.204981, acc: 87.30%] [G loss: 1.056395]\n",
      "[Epoch 41/50] [Batch 143/235] [D loss: 1.035459, acc: 86.33%] [G loss: 1.162636]\n",
      "[Epoch 41/50] [Batch 144/235] [D loss: 1.130388, acc: 88.67%] [G loss: 1.193055]\n",
      "[Epoch 41/50] [Batch 145/235] [D loss: 1.087599, acc: 84.96%] [G loss: 1.092683]\n",
      "[Epoch 41/50] [Batch 146/235] [D loss: 1.160079, acc: 89.06%] [G loss: 1.225399]\n",
      "[Epoch 41/50] [Batch 147/235] [D loss: 1.114287, acc: 87.89%] [G loss: 1.121881]\n",
      "[Epoch 41/50] [Batch 148/235] [D loss: 1.109265, acc: 90.04%] [G loss: 1.098846]\n",
      "[Epoch 41/50] [Batch 149/235] [D loss: 1.164207, acc: 87.11%] [G loss: 1.308914]\n",
      "[Epoch 41/50] [Batch 150/235] [D loss: 1.120872, acc: 85.35%] [G loss: 1.077168]\n",
      "[Epoch 41/50] [Batch 151/235] [D loss: 1.125449, acc: 86.72%] [G loss: 1.171432]\n",
      "[Epoch 41/50] [Batch 152/235] [D loss: 1.144365, acc: 84.38%] [G loss: 1.123265]\n",
      "[Epoch 41/50] [Batch 153/235] [D loss: 1.103835, acc: 85.94%] [G loss: 1.237784]\n",
      "[Epoch 41/50] [Batch 154/235] [D loss: 1.118353, acc: 86.91%] [G loss: 1.110683]\n",
      "[Epoch 41/50] [Batch 155/235] [D loss: 1.090364, acc: 89.26%] [G loss: 1.071072]\n",
      "[Epoch 41/50] [Batch 156/235] [D loss: 1.090951, acc: 89.26%] [G loss: 1.109942]\n",
      "[Epoch 41/50] [Batch 157/235] [D loss: 1.128368, acc: 85.35%] [G loss: 1.166731]\n",
      "[Epoch 41/50] [Batch 158/235] [D loss: 1.098626, acc: 87.70%] [G loss: 1.115259]\n",
      "[Epoch 41/50] [Batch 159/235] [D loss: 1.162951, acc: 87.30%] [G loss: 1.117547]\n",
      "[Epoch 41/50] [Batch 160/235] [D loss: 1.098382, acc: 89.06%] [G loss: 1.012567]\n",
      "[Epoch 41/50] [Batch 161/235] [D loss: 1.091703, acc: 84.57%] [G loss: 1.154303]\n",
      "[Epoch 41/50] [Batch 162/235] [D loss: 1.067014, acc: 86.13%] [G loss: 1.290622]\n",
      "[Epoch 41/50] [Batch 163/235] [D loss: 1.116381, acc: 87.50%] [G loss: 1.238980]\n",
      "[Epoch 41/50] [Batch 164/235] [D loss: 1.118503, acc: 89.84%] [G loss: 1.229979]\n",
      "[Epoch 41/50] [Batch 165/235] [D loss: 1.085706, acc: 87.50%] [G loss: 1.071453]\n",
      "[Epoch 41/50] [Batch 166/235] [D loss: 1.075762, acc: 87.70%] [G loss: 1.366149]\n",
      "[Epoch 41/50] [Batch 167/235] [D loss: 1.079137, acc: 87.70%] [G loss: 1.095766]\n",
      "[Epoch 41/50] [Batch 168/235] [D loss: 1.127223, acc: 87.50%] [G loss: 1.255296]\n",
      "[Epoch 41/50] [Batch 169/235] [D loss: 1.130418, acc: 88.67%] [G loss: 1.032983]\n",
      "[Epoch 41/50] [Batch 170/235] [D loss: 1.128829, acc: 85.94%] [G loss: 1.174256]\n",
      "[Epoch 41/50] [Batch 171/235] [D loss: 1.103634, acc: 89.26%] [G loss: 1.240050]\n",
      "[Epoch 41/50] [Batch 172/235] [D loss: 1.163671, acc: 86.52%] [G loss: 1.087820]\n",
      "[Epoch 41/50] [Batch 173/235] [D loss: 1.137304, acc: 88.87%] [G loss: 1.115195]\n",
      "[Epoch 41/50] [Batch 174/235] [D loss: 1.147866, acc: 86.52%] [G loss: 1.199236]\n",
      "[Epoch 41/50] [Batch 175/235] [D loss: 1.141930, acc: 86.52%] [G loss: 1.062016]\n",
      "[Epoch 41/50] [Batch 176/235] [D loss: 1.091462, acc: 85.55%] [G loss: 1.196518]\n",
      "[Epoch 41/50] [Batch 177/235] [D loss: 1.103560, acc: 90.43%] [G loss: 1.351310]\n",
      "[Epoch 41/50] [Batch 178/235] [D loss: 1.099696, acc: 87.89%] [G loss: 1.116499]\n",
      "[Epoch 41/50] [Batch 179/235] [D loss: 1.118730, acc: 89.26%] [G loss: 1.093750]\n",
      "[Epoch 41/50] [Batch 180/235] [D loss: 1.126091, acc: 89.84%] [G loss: 1.259329]\n",
      "[Epoch 41/50] [Batch 181/235] [D loss: 1.143442, acc: 88.09%] [G loss: 1.263439]\n",
      "[Epoch 41/50] [Batch 182/235] [D loss: 1.183005, acc: 85.16%] [G loss: 1.117827]\n",
      "[Epoch 41/50] [Batch 183/235] [D loss: 1.093667, acc: 87.11%] [G loss: 1.159853]\n",
      "[Epoch 41/50] [Batch 184/235] [D loss: 1.137739, acc: 86.13%] [G loss: 1.147254]\n",
      "[Epoch 41/50] [Batch 185/235] [D loss: 1.122511, acc: 87.30%] [G loss: 1.289416]\n",
      "[Epoch 41/50] [Batch 186/235] [D loss: 1.083161, acc: 88.67%] [G loss: 1.228378]\n",
      "[Epoch 41/50] [Batch 187/235] [D loss: 1.118038, acc: 86.13%] [G loss: 1.198615]\n",
      "[Epoch 41/50] [Batch 188/235] [D loss: 1.097262, acc: 88.48%] [G loss: 1.264186]\n",
      "[Epoch 41/50] [Batch 189/235] [D loss: 1.083928, acc: 86.72%] [G loss: 1.240357]\n",
      "[Epoch 41/50] [Batch 190/235] [D loss: 1.091476, acc: 87.50%] [G loss: 1.196432]\n",
      "[Epoch 41/50] [Batch 191/235] [D loss: 1.084290, acc: 88.09%] [G loss: 1.061060]\n",
      "[Epoch 41/50] [Batch 192/235] [D loss: 1.081287, acc: 87.11%] [G loss: 1.119845]\n",
      "[Epoch 41/50] [Batch 193/235] [D loss: 1.163411, acc: 86.33%] [G loss: 1.027339]\n",
      "[Epoch 41/50] [Batch 194/235] [D loss: 1.106592, acc: 87.89%] [G loss: 1.248662]\n",
      "[Epoch 41/50] [Batch 195/235] [D loss: 1.154260, acc: 85.74%] [G loss: 1.084623]\n",
      "[Epoch 41/50] [Batch 196/235] [D loss: 1.120538, acc: 89.65%] [G loss: 1.005522]\n",
      "[Epoch 41/50] [Batch 197/235] [D loss: 1.049586, acc: 88.48%] [G loss: 1.065634]\n",
      "[Epoch 41/50] [Batch 198/235] [D loss: 1.084931, acc: 87.30%] [G loss: 1.090980]\n",
      "[Epoch 41/50] [Batch 199/235] [D loss: 1.063591, acc: 86.72%] [G loss: 1.276323]\n",
      "[Epoch 41/50] [Batch 200/235] [D loss: 1.117847, acc: 86.33%] [G loss: 1.376202]\n",
      "[Epoch 41/50] [Batch 201/235] [D loss: 1.132467, acc: 84.96%] [G loss: 1.198042]\n",
      "[Epoch 41/50] [Batch 202/235] [D loss: 1.137428, acc: 84.96%] [G loss: 1.180756]\n",
      "[Epoch 41/50] [Batch 203/235] [D loss: 1.103551, acc: 84.57%] [G loss: 1.340139]\n",
      "[Epoch 41/50] [Batch 204/235] [D loss: 1.063201, acc: 87.50%] [G loss: 1.235953]\n",
      "[Epoch 41/50] [Batch 205/235] [D loss: 1.073307, acc: 86.91%] [G loss: 1.124213]\n",
      "[Epoch 41/50] [Batch 206/235] [D loss: 1.148422, acc: 86.52%] [G loss: 1.087321]\n",
      "[Epoch 41/50] [Batch 207/235] [D loss: 1.122687, acc: 86.52%] [G loss: 1.151945]\n",
      "[Epoch 41/50] [Batch 208/235] [D loss: 1.103933, acc: 86.52%] [G loss: 1.143147]\n",
      "[Epoch 41/50] [Batch 209/235] [D loss: 1.069996, acc: 86.72%] [G loss: 1.349401]\n",
      "[Epoch 41/50] [Batch 210/235] [D loss: 1.144600, acc: 88.09%] [G loss: 1.188276]\n",
      "[Epoch 41/50] [Batch 211/235] [D loss: 1.103981, acc: 90.04%] [G loss: 1.068439]\n",
      "[Epoch 41/50] [Batch 212/235] [D loss: 1.188770, acc: 87.70%] [G loss: 1.003951]\n",
      "[Epoch 41/50] [Batch 213/235] [D loss: 1.105616, acc: 88.09%] [G loss: 1.078840]\n",
      "[Epoch 41/50] [Batch 214/235] [D loss: 1.154333, acc: 86.33%] [G loss: 1.142924]\n",
      "[Epoch 41/50] [Batch 215/235] [D loss: 1.126459, acc: 87.70%] [G loss: 1.156042]\n",
      "[Epoch 41/50] [Batch 216/235] [D loss: 1.114081, acc: 87.11%] [G loss: 1.245720]\n",
      "[Epoch 41/50] [Batch 217/235] [D loss: 1.116745, acc: 88.87%] [G loss: 1.105759]\n",
      "[Epoch 41/50] [Batch 218/235] [D loss: 1.074191, acc: 85.16%] [G loss: 1.082150]\n",
      "[Epoch 41/50] [Batch 219/235] [D loss: 1.080947, acc: 86.91%] [G loss: 1.321331]\n",
      "[Epoch 41/50] [Batch 220/235] [D loss: 1.132351, acc: 86.91%] [G loss: 1.290777]\n",
      "[Epoch 41/50] [Batch 221/235] [D loss: 1.072630, acc: 90.04%] [G loss: 1.146215]\n",
      "[Epoch 41/50] [Batch 222/235] [D loss: 1.165951, acc: 87.11%] [G loss: 1.102089]\n",
      "[Epoch 41/50] [Batch 223/235] [D loss: 1.110399, acc: 86.91%] [G loss: 1.104167]\n",
      "[Epoch 41/50] [Batch 224/235] [D loss: 1.109413, acc: 88.87%] [G loss: 1.199753]\n",
      "[Epoch 41/50] [Batch 225/235] [D loss: 1.089278, acc: 89.26%] [G loss: 1.169889]\n",
      "[Epoch 41/50] [Batch 226/235] [D loss: 1.088925, acc: 88.09%] [G loss: 1.134163]\n",
      "[Epoch 41/50] [Batch 227/235] [D loss: 1.105351, acc: 88.87%] [G loss: 1.166011]\n",
      "[Epoch 41/50] [Batch 228/235] [D loss: 1.136265, acc: 88.09%] [G loss: 1.102269]\n",
      "[Epoch 41/50] [Batch 229/235] [D loss: 1.103966, acc: 88.09%] [G loss: 1.095814]\n",
      "[Epoch 41/50] [Batch 230/235] [D loss: 1.075117, acc: 88.09%] [G loss: 1.220877]\n",
      "[Epoch 41/50] [Batch 231/235] [D loss: 1.111483, acc: 85.16%] [G loss: 1.184660]\n",
      "[Epoch 41/50] [Batch 232/235] [D loss: 1.046138, acc: 87.89%] [G loss: 1.291753]\n",
      "[Epoch 41/50] [Batch 233/235] [D loss: 1.090523, acc: 85.35%] [G loss: 0.971164]\n",
      "[Epoch 41/50] [Batch 234/235] [D loss: 1.132059, acc: 83.85%] [G loss: 1.126070]\n",
      "[Epoch 42/50] [Batch 0/235] [D loss: 1.144101, acc: 88.28%] [G loss: 0.993728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/50] [Batch 1/235] [D loss: 1.117691, acc: 88.87%] [G loss: 1.184318]\n",
      "[Epoch 42/50] [Batch 2/235] [D loss: 1.072301, acc: 87.11%] [G loss: 1.249177]\n",
      "[Epoch 42/50] [Batch 3/235] [D loss: 1.127725, acc: 89.06%] [G loss: 1.055037]\n",
      "[Epoch 42/50] [Batch 4/235] [D loss: 1.125538, acc: 87.30%] [G loss: 1.229187]\n",
      "[Epoch 42/50] [Batch 5/235] [D loss: 1.148833, acc: 88.28%] [G loss: 1.123541]\n",
      "[Epoch 42/50] [Batch 6/235] [D loss: 1.118396, acc: 87.89%] [G loss: 1.170609]\n",
      "[Epoch 42/50] [Batch 7/235] [D loss: 1.089917, acc: 87.70%] [G loss: 1.270432]\n",
      "[Epoch 42/50] [Batch 8/235] [D loss: 1.126446, acc: 87.50%] [G loss: 1.364186]\n",
      "[Epoch 42/50] [Batch 9/235] [D loss: 1.062672, acc: 85.94%] [G loss: 1.118296]\n",
      "[Epoch 42/50] [Batch 10/235] [D loss: 1.158330, acc: 85.94%] [G loss: 1.134136]\n",
      "[Epoch 42/50] [Batch 11/235] [D loss: 1.103425, acc: 88.09%] [G loss: 1.064011]\n",
      "[Epoch 42/50] [Batch 12/235] [D loss: 1.135353, acc: 87.30%] [G loss: 1.035016]\n",
      "[Epoch 42/50] [Batch 13/235] [D loss: 1.112389, acc: 85.94%] [G loss: 1.086203]\n",
      "[Epoch 42/50] [Batch 14/235] [D loss: 1.137617, acc: 85.55%] [G loss: 1.230982]\n",
      "[Epoch 42/50] [Batch 15/235] [D loss: 1.099530, acc: 87.89%] [G loss: 1.111925]\n",
      "[Epoch 42/50] [Batch 16/235] [D loss: 1.085865, acc: 87.70%] [G loss: 1.197993]\n",
      "[Epoch 42/50] [Batch 17/235] [D loss: 1.056600, acc: 85.94%] [G loss: 1.189608]\n",
      "[Epoch 42/50] [Batch 18/235] [D loss: 1.100642, acc: 86.91%] [G loss: 1.110319]\n",
      "[Epoch 42/50] [Batch 19/235] [D loss: 1.032019, acc: 85.94%] [G loss: 1.106000]\n",
      "[Epoch 42/50] [Batch 20/235] [D loss: 1.046426, acc: 88.67%] [G loss: 1.199336]\n",
      "[Epoch 42/50] [Batch 21/235] [D loss: 1.145259, acc: 87.11%] [G loss: 1.240070]\n",
      "[Epoch 42/50] [Batch 22/235] [D loss: 1.115332, acc: 87.30%] [G loss: 1.036073]\n",
      "[Epoch 42/50] [Batch 23/235] [D loss: 1.053397, acc: 86.91%] [G loss: 1.101981]\n",
      "[Epoch 42/50] [Batch 24/235] [D loss: 1.127944, acc: 86.91%] [G loss: 1.184980]\n",
      "[Epoch 42/50] [Batch 25/235] [D loss: 1.046948, acc: 90.82%] [G loss: 1.207177]\n",
      "[Epoch 42/50] [Batch 26/235] [D loss: 1.157003, acc: 88.28%] [G loss: 1.018735]\n",
      "[Epoch 42/50] [Batch 27/235] [D loss: 1.191948, acc: 87.30%] [G loss: 1.412686]\n",
      "[Epoch 42/50] [Batch 28/235] [D loss: 1.146999, acc: 85.35%] [G loss: 1.332997]\n",
      "[Epoch 42/50] [Batch 29/235] [D loss: 1.075424, acc: 88.28%] [G loss: 1.243450]\n",
      "[Epoch 42/50] [Batch 30/235] [D loss: 1.112073, acc: 91.41%] [G loss: 1.141192]\n",
      "[Epoch 42/50] [Batch 31/235] [D loss: 1.106438, acc: 91.41%] [G loss: 1.203943]\n",
      "[Epoch 42/50] [Batch 32/235] [D loss: 1.095464, acc: 88.28%] [G loss: 1.065678]\n",
      "[Epoch 42/50] [Batch 33/235] [D loss: 1.141126, acc: 84.18%] [G loss: 1.228840]\n",
      "[Epoch 42/50] [Batch 34/235] [D loss: 1.140786, acc: 85.94%] [G loss: 1.185035]\n",
      "[Epoch 42/50] [Batch 35/235] [D loss: 1.042550, acc: 90.04%] [G loss: 1.086017]\n",
      "[Epoch 42/50] [Batch 36/235] [D loss: 1.079608, acc: 87.50%] [G loss: 1.192184]\n",
      "[Epoch 42/50] [Batch 37/235] [D loss: 1.106322, acc: 85.94%] [G loss: 1.153072]\n",
      "[Epoch 42/50] [Batch 38/235] [D loss: 1.209495, acc: 87.30%] [G loss: 1.254049]\n",
      "[Epoch 42/50] [Batch 39/235] [D loss: 1.103220, acc: 88.87%] [G loss: 1.135446]\n",
      "[Epoch 42/50] [Batch 40/235] [D loss: 1.103800, acc: 85.94%] [G loss: 0.992471]\n",
      "[Epoch 42/50] [Batch 41/235] [D loss: 1.127933, acc: 86.13%] [G loss: 1.215748]\n",
      "[Epoch 42/50] [Batch 42/235] [D loss: 1.103246, acc: 86.33%] [G loss: 1.167906]\n",
      "[Epoch 42/50] [Batch 43/235] [D loss: 1.100983, acc: 89.26%] [G loss: 1.115349]\n",
      "[Epoch 42/50] [Batch 44/235] [D loss: 1.186162, acc: 84.96%] [G loss: 1.031081]\n",
      "[Epoch 42/50] [Batch 45/235] [D loss: 1.184722, acc: 87.11%] [G loss: 1.196853]\n",
      "[Epoch 42/50] [Batch 46/235] [D loss: 1.144734, acc: 90.23%] [G loss: 1.205710]\n",
      "[Epoch 42/50] [Batch 47/235] [D loss: 1.079866, acc: 87.70%] [G loss: 1.163118]\n",
      "[Epoch 42/50] [Batch 48/235] [D loss: 1.181228, acc: 86.72%] [G loss: 1.284883]\n",
      "[Epoch 42/50] [Batch 49/235] [D loss: 1.108057, acc: 86.13%] [G loss: 0.975152]\n",
      "[Epoch 42/50] [Batch 50/235] [D loss: 1.151558, acc: 89.06%] [G loss: 1.160634]\n",
      "[Epoch 42/50] [Batch 51/235] [D loss: 1.051786, acc: 86.33%] [G loss: 1.083566]\n",
      "[Epoch 42/50] [Batch 52/235] [D loss: 1.044276, acc: 86.13%] [G loss: 1.164013]\n",
      "[Epoch 42/50] [Batch 53/235] [D loss: 1.114242, acc: 86.13%] [G loss: 1.127510]\n",
      "[Epoch 42/50] [Batch 54/235] [D loss: 1.079818, acc: 87.30%] [G loss: 1.193558]\n",
      "[Epoch 42/50] [Batch 55/235] [D loss: 1.168311, acc: 87.30%] [G loss: 1.295677]\n",
      "[Epoch 42/50] [Batch 56/235] [D loss: 1.088226, acc: 87.50%] [G loss: 1.357166]\n",
      "[Epoch 42/50] [Batch 57/235] [D loss: 1.053483, acc: 87.50%] [G loss: 1.243517]\n",
      "[Epoch 42/50] [Batch 58/235] [D loss: 1.152631, acc: 87.50%] [G loss: 1.160047]\n",
      "[Epoch 42/50] [Batch 59/235] [D loss: 1.165375, acc: 87.70%] [G loss: 1.195987]\n",
      "[Epoch 42/50] [Batch 60/235] [D loss: 1.104229, acc: 87.30%] [G loss: 1.279507]\n",
      "[Epoch 42/50] [Batch 61/235] [D loss: 1.191760, acc: 88.67%] [G loss: 1.203863]\n",
      "[Epoch 42/50] [Batch 62/235] [D loss: 1.140524, acc: 86.13%] [G loss: 1.037215]\n",
      "[Epoch 42/50] [Batch 63/235] [D loss: 1.148015, acc: 87.89%] [G loss: 1.201854]\n",
      "[Epoch 42/50] [Batch 64/235] [D loss: 1.121679, acc: 89.26%] [G loss: 1.029694]\n",
      "[Epoch 42/50] [Batch 65/235] [D loss: 1.137172, acc: 87.30%] [G loss: 1.239125]\n",
      "[Epoch 42/50] [Batch 66/235] [D loss: 1.115957, acc: 86.91%] [G loss: 1.212726]\n",
      "[Epoch 42/50] [Batch 67/235] [D loss: 1.135031, acc: 84.96%] [G loss: 1.284171]\n",
      "[Epoch 42/50] [Batch 68/235] [D loss: 1.120957, acc: 83.59%] [G loss: 1.172405]\n",
      "[Epoch 42/50] [Batch 69/235] [D loss: 1.094161, acc: 86.52%] [G loss: 1.105283]\n",
      "[Epoch 42/50] [Batch 70/235] [D loss: 1.118646, acc: 88.09%] [G loss: 1.047906]\n",
      "[Epoch 42/50] [Batch 71/235] [D loss: 1.084376, acc: 87.50%] [G loss: 1.169695]\n",
      "[Epoch 42/50] [Batch 72/235] [D loss: 1.082771, acc: 85.74%] [G loss: 1.227788]\n",
      "[Epoch 42/50] [Batch 73/235] [D loss: 1.142980, acc: 88.87%] [G loss: 1.270661]\n",
      "[Epoch 42/50] [Batch 74/235] [D loss: 1.089491, acc: 89.45%] [G loss: 1.072391]\n",
      "[Epoch 42/50] [Batch 75/235] [D loss: 1.083743, acc: 88.67%] [G loss: 1.140361]\n",
      "[Epoch 42/50] [Batch 76/235] [D loss: 1.087612, acc: 88.09%] [G loss: 1.223436]\n",
      "[Epoch 42/50] [Batch 77/235] [D loss: 1.105240, acc: 88.48%] [G loss: 1.151973]\n",
      "[Epoch 42/50] [Batch 78/235] [D loss: 1.180553, acc: 85.94%] [G loss: 1.115634]\n",
      "[Epoch 42/50] [Batch 79/235] [D loss: 1.117301, acc: 89.45%] [G loss: 1.118965]\n",
      "[Epoch 42/50] [Batch 80/235] [D loss: 1.133546, acc: 86.72%] [G loss: 1.131025]\n",
      "[Epoch 42/50] [Batch 81/235] [D loss: 1.075395, acc: 87.50%] [G loss: 1.267485]\n",
      "[Epoch 42/50] [Batch 82/235] [D loss: 1.136540, acc: 88.67%] [G loss: 1.010480]\n",
      "[Epoch 42/50] [Batch 83/235] [D loss: 1.067979, acc: 85.94%] [G loss: 1.049356]\n",
      "[Epoch 42/50] [Batch 84/235] [D loss: 1.152993, acc: 87.89%] [G loss: 1.060212]\n",
      "[Epoch 42/50] [Batch 85/235] [D loss: 1.102790, acc: 90.04%] [G loss: 1.196136]\n",
      "[Epoch 42/50] [Batch 86/235] [D loss: 1.105888, acc: 87.89%] [G loss: 1.185326]\n",
      "[Epoch 42/50] [Batch 87/235] [D loss: 1.120413, acc: 88.48%] [G loss: 1.049966]\n",
      "[Epoch 42/50] [Batch 88/235] [D loss: 1.097269, acc: 86.91%] [G loss: 1.044566]\n",
      "[Epoch 42/50] [Batch 89/235] [D loss: 1.095854, acc: 89.06%] [G loss: 1.255356]\n",
      "[Epoch 42/50] [Batch 90/235] [D loss: 1.159303, acc: 87.89%] [G loss: 1.275172]\n",
      "[Epoch 42/50] [Batch 91/235] [D loss: 1.099191, acc: 87.11%] [G loss: 1.092698]\n",
      "[Epoch 42/50] [Batch 92/235] [D loss: 1.123977, acc: 88.09%] [G loss: 1.044988]\n",
      "[Epoch 42/50] [Batch 93/235] [D loss: 1.181644, acc: 86.91%] [G loss: 1.236075]\n",
      "[Epoch 42/50] [Batch 94/235] [D loss: 1.132565, acc: 84.57%] [G loss: 1.110598]\n",
      "[Epoch 42/50] [Batch 95/235] [D loss: 1.121879, acc: 89.65%] [G loss: 1.056895]\n",
      "[Epoch 42/50] [Batch 96/235] [D loss: 1.047471, acc: 86.52%] [G loss: 1.155277]\n",
      "[Epoch 42/50] [Batch 97/235] [D loss: 1.118220, acc: 85.74%] [G loss: 1.241290]\n",
      "[Epoch 42/50] [Batch 98/235] [D loss: 1.086731, acc: 87.30%] [G loss: 1.080140]\n",
      "[Epoch 42/50] [Batch 99/235] [D loss: 1.088789, acc: 88.09%] [G loss: 1.146224]\n",
      "[Epoch 42/50] [Batch 100/235] [D loss: 1.142473, acc: 89.45%] [G loss: 1.149436]\n",
      "[Epoch 42/50] [Batch 101/235] [D loss: 1.096089, acc: 88.09%] [G loss: 1.169368]\n",
      "[Epoch 42/50] [Batch 102/235] [D loss: 1.177298, acc: 85.74%] [G loss: 1.092647]\n",
      "[Epoch 42/50] [Batch 103/235] [D loss: 1.151564, acc: 85.74%] [G loss: 1.200938]\n",
      "[Epoch 42/50] [Batch 104/235] [D loss: 1.077638, acc: 86.91%] [G loss: 1.143808]\n",
      "[Epoch 42/50] [Batch 105/235] [D loss: 1.093130, acc: 89.26%] [G loss: 1.147454]\n",
      "[Epoch 42/50] [Batch 106/235] [D loss: 1.049580, acc: 89.06%] [G loss: 1.125895]\n",
      "[Epoch 42/50] [Batch 107/235] [D loss: 1.129592, acc: 85.74%] [G loss: 1.057929]\n",
      "[Epoch 42/50] [Batch 108/235] [D loss: 1.062346, acc: 87.70%] [G loss: 1.152972]\n",
      "[Epoch 42/50] [Batch 109/235] [D loss: 1.061204, acc: 85.16%] [G loss: 1.135899]\n",
      "[Epoch 42/50] [Batch 110/235] [D loss: 1.143254, acc: 84.96%] [G loss: 1.155465]\n",
      "[Epoch 42/50] [Batch 111/235] [D loss: 1.136510, acc: 87.70%] [G loss: 1.141092]\n",
      "[Epoch 42/50] [Batch 112/235] [D loss: 1.175665, acc: 86.91%] [G loss: 1.223300]\n",
      "[Epoch 42/50] [Batch 113/235] [D loss: 1.099947, acc: 87.50%] [G loss: 1.006973]\n",
      "[Epoch 42/50] [Batch 114/235] [D loss: 1.124040, acc: 86.13%] [G loss: 0.979989]\n",
      "[Epoch 42/50] [Batch 115/235] [D loss: 1.079052, acc: 90.23%] [G loss: 1.090648]\n",
      "[Epoch 42/50] [Batch 116/235] [D loss: 1.086261, acc: 89.26%] [G loss: 1.205197]\n",
      "[Epoch 42/50] [Batch 117/235] [D loss: 1.052027, acc: 87.89%] [G loss: 1.181039]\n",
      "[Epoch 42/50] [Batch 118/235] [D loss: 1.106096, acc: 86.91%] [G loss: 1.119485]\n",
      "[Epoch 42/50] [Batch 119/235] [D loss: 1.074489, acc: 85.94%] [G loss: 1.252965]\n",
      "[Epoch 42/50] [Batch 120/235] [D loss: 1.105765, acc: 86.33%] [G loss: 1.055979]\n",
      "[Epoch 42/50] [Batch 121/235] [D loss: 1.126195, acc: 84.96%] [G loss: 1.184577]\n",
      "[Epoch 42/50] [Batch 122/235] [D loss: 1.140978, acc: 87.30%] [G loss: 1.242821]\n",
      "[Epoch 42/50] [Batch 123/235] [D loss: 1.133153, acc: 88.87%] [G loss: 1.057680]\n",
      "[Epoch 42/50] [Batch 124/235] [D loss: 1.056808, acc: 88.28%] [G loss: 1.224099]\n",
      "[Epoch 42/50] [Batch 125/235] [D loss: 1.076212, acc: 87.70%] [G loss: 1.351363]\n",
      "[Epoch 42/50] [Batch 126/235] [D loss: 1.122885, acc: 88.67%] [G loss: 1.262732]\n",
      "[Epoch 42/50] [Batch 127/235] [D loss: 1.136158, acc: 87.11%] [G loss: 1.042456]\n",
      "[Epoch 42/50] [Batch 128/235] [D loss: 1.008738, acc: 89.26%] [G loss: 1.238618]\n",
      "[Epoch 42/50] [Batch 129/235] [D loss: 1.155716, acc: 87.30%] [G loss: 1.361324]\n",
      "[Epoch 42/50] [Batch 130/235] [D loss: 1.151742, acc: 87.30%] [G loss: 1.242412]\n",
      "[Epoch 42/50] [Batch 131/235] [D loss: 1.152997, acc: 87.30%] [G loss: 1.076318]\n",
      "[Epoch 42/50] [Batch 132/235] [D loss: 1.099943, acc: 87.30%] [G loss: 1.168790]\n",
      "[Epoch 42/50] [Batch 133/235] [D loss: 1.187582, acc: 86.91%] [G loss: 1.178630]\n",
      "[Epoch 42/50] [Batch 134/235] [D loss: 1.091261, acc: 86.72%] [G loss: 1.168325]\n",
      "[Epoch 42/50] [Batch 135/235] [D loss: 1.143902, acc: 87.70%] [G loss: 1.124519]\n",
      "[Epoch 42/50] [Batch 136/235] [D loss: 1.169251, acc: 87.50%] [G loss: 1.213414]\n",
      "[Epoch 42/50] [Batch 137/235] [D loss: 1.169125, acc: 87.30%] [G loss: 1.154577]\n",
      "[Epoch 42/50] [Batch 138/235] [D loss: 1.072160, acc: 86.13%] [G loss: 1.111696]\n",
      "[Epoch 42/50] [Batch 139/235] [D loss: 1.057905, acc: 85.74%] [G loss: 1.086780]\n",
      "[Epoch 42/50] [Batch 140/235] [D loss: 1.113980, acc: 87.11%] [G loss: 1.152661]\n",
      "[Epoch 42/50] [Batch 141/235] [D loss: 1.127115, acc: 89.65%] [G loss: 1.143473]\n",
      "[Epoch 42/50] [Batch 142/235] [D loss: 1.167397, acc: 89.26%] [G loss: 1.106616]\n",
      "[Epoch 42/50] [Batch 143/235] [D loss: 1.082268, acc: 86.72%] [G loss: 1.048724]\n",
      "[Epoch 42/50] [Batch 144/235] [D loss: 1.047292, acc: 88.09%] [G loss: 1.090303]\n",
      "[Epoch 42/50] [Batch 145/235] [D loss: 1.107510, acc: 88.28%] [G loss: 1.163368]\n",
      "[Epoch 42/50] [Batch 146/235] [D loss: 1.118985, acc: 85.94%] [G loss: 1.188745]\n",
      "[Epoch 42/50] [Batch 147/235] [D loss: 1.108050, acc: 87.89%] [G loss: 1.202723]\n",
      "[Epoch 42/50] [Batch 148/235] [D loss: 1.127395, acc: 86.52%] [G loss: 1.029549]\n",
      "[Epoch 42/50] [Batch 149/235] [D loss: 1.103264, acc: 88.87%] [G loss: 1.110493]\n",
      "[Epoch 42/50] [Batch 150/235] [D loss: 1.145880, acc: 85.35%] [G loss: 1.122030]\n",
      "[Epoch 42/50] [Batch 151/235] [D loss: 1.122292, acc: 85.74%] [G loss: 1.108051]\n",
      "[Epoch 42/50] [Batch 152/235] [D loss: 1.138616, acc: 89.26%] [G loss: 1.195558]\n",
      "[Epoch 42/50] [Batch 153/235] [D loss: 1.051670, acc: 86.91%] [G loss: 1.121188]\n",
      "[Epoch 42/50] [Batch 154/235] [D loss: 1.162438, acc: 85.35%] [G loss: 1.155306]\n",
      "[Epoch 42/50] [Batch 155/235] [D loss: 1.125244, acc: 88.28%] [G loss: 1.190084]\n",
      "[Epoch 42/50] [Batch 156/235] [D loss: 1.122290, acc: 88.28%] [G loss: 1.071791]\n",
      "[Epoch 42/50] [Batch 157/235] [D loss: 1.123921, acc: 87.11%] [G loss: 1.044385]\n",
      "[Epoch 42/50] [Batch 158/235] [D loss: 1.120756, acc: 89.45%] [G loss: 1.050025]\n",
      "[Epoch 42/50] [Batch 159/235] [D loss: 1.079144, acc: 86.91%] [G loss: 1.079516]\n",
      "[Epoch 42/50] [Batch 160/235] [D loss: 1.115992, acc: 86.52%] [G loss: 1.149680]\n",
      "[Epoch 42/50] [Batch 161/235] [D loss: 1.159022, acc: 84.57%] [G loss: 1.212974]\n",
      "[Epoch 42/50] [Batch 162/235] [D loss: 1.037149, acc: 89.65%] [G loss: 1.075884]\n",
      "[Epoch 42/50] [Batch 163/235] [D loss: 1.119435, acc: 87.89%] [G loss: 1.104312]\n",
      "[Epoch 42/50] [Batch 164/235] [D loss: 1.122068, acc: 88.48%] [G loss: 1.185712]\n",
      "[Epoch 42/50] [Batch 165/235] [D loss: 1.165809, acc: 88.67%] [G loss: 1.126589]\n",
      "[Epoch 42/50] [Batch 166/235] [D loss: 1.151844, acc: 90.04%] [G loss: 1.151619]\n",
      "[Epoch 42/50] [Batch 167/235] [D loss: 1.084055, acc: 84.96%] [G loss: 1.087049]\n",
      "[Epoch 42/50] [Batch 168/235] [D loss: 1.110801, acc: 86.91%] [G loss: 1.016928]\n",
      "[Epoch 42/50] [Batch 169/235] [D loss: 1.103855, acc: 88.48%] [G loss: 1.267809]\n",
      "[Epoch 42/50] [Batch 170/235] [D loss: 1.105225, acc: 89.45%] [G loss: 1.047139]\n",
      "[Epoch 42/50] [Batch 171/235] [D loss: 1.103773, acc: 86.33%] [G loss: 1.133756]\n",
      "[Epoch 42/50] [Batch 172/235] [D loss: 1.072173, acc: 87.11%] [G loss: 1.222404]\n",
      "[Epoch 42/50] [Batch 173/235] [D loss: 1.187264, acc: 83.40%] [G loss: 1.226528]\n",
      "[Epoch 42/50] [Batch 174/235] [D loss: 1.131063, acc: 89.26%] [G loss: 1.178714]\n",
      "[Epoch 42/50] [Batch 175/235] [D loss: 1.127980, acc: 85.35%] [G loss: 1.142627]\n",
      "[Epoch 42/50] [Batch 176/235] [D loss: 1.051163, acc: 89.65%] [G loss: 1.144032]\n",
      "[Epoch 42/50] [Batch 177/235] [D loss: 1.092775, acc: 87.70%] [G loss: 1.016981]\n",
      "[Epoch 42/50] [Batch 178/235] [D loss: 1.222566, acc: 86.72%] [G loss: 1.182110]\n",
      "[Epoch 42/50] [Batch 179/235] [D loss: 1.103404, acc: 88.87%] [G loss: 1.374266]\n",
      "[Epoch 42/50] [Batch 180/235] [D loss: 1.124614, acc: 86.72%] [G loss: 1.009565]\n",
      "[Epoch 42/50] [Batch 181/235] [D loss: 1.105102, acc: 87.50%] [G loss: 1.102548]\n",
      "[Epoch 42/50] [Batch 182/235] [D loss: 1.117246, acc: 86.33%] [G loss: 1.112950]\n",
      "[Epoch 42/50] [Batch 183/235] [D loss: 1.115226, acc: 88.28%] [G loss: 1.085757]\n",
      "[Epoch 42/50] [Batch 184/235] [D loss: 1.165409, acc: 88.09%] [G loss: 1.065013]\n",
      "[Epoch 42/50] [Batch 185/235] [D loss: 1.176330, acc: 86.52%] [G loss: 1.096205]\n",
      "[Epoch 42/50] [Batch 186/235] [D loss: 1.134352, acc: 88.48%] [G loss: 1.277753]\n",
      "[Epoch 42/50] [Batch 187/235] [D loss: 1.075563, acc: 88.67%] [G loss: 1.196255]\n",
      "[Epoch 42/50] [Batch 188/235] [D loss: 1.093788, acc: 86.91%] [G loss: 1.142835]\n",
      "[Epoch 42/50] [Batch 189/235] [D loss: 1.125446, acc: 86.13%] [G loss: 1.184246]\n",
      "[Epoch 42/50] [Batch 190/235] [D loss: 1.135609, acc: 88.87%] [G loss: 1.105914]\n",
      "[Epoch 42/50] [Batch 191/235] [D loss: 1.071011, acc: 87.50%] [G loss: 1.077407]\n",
      "[Epoch 42/50] [Batch 192/235] [D loss: 1.155329, acc: 87.89%] [G loss: 1.129139]\n",
      "[Epoch 42/50] [Batch 193/235] [D loss: 1.143962, acc: 87.70%] [G loss: 1.249161]\n",
      "[Epoch 42/50] [Batch 194/235] [D loss: 1.097858, acc: 90.23%] [G loss: 1.195808]\n",
      "[Epoch 42/50] [Batch 195/235] [D loss: 1.074407, acc: 89.06%] [G loss: 1.431363]\n",
      "[Epoch 42/50] [Batch 196/235] [D loss: 1.139201, acc: 87.11%] [G loss: 1.170971]\n",
      "[Epoch 42/50] [Batch 197/235] [D loss: 1.119493, acc: 86.13%] [G loss: 1.148922]\n",
      "[Epoch 42/50] [Batch 198/235] [D loss: 1.098550, acc: 87.30%] [G loss: 1.104204]\n",
      "[Epoch 42/50] [Batch 199/235] [D loss: 1.045108, acc: 89.65%] [G loss: 1.040976]\n",
      "[Epoch 42/50] [Batch 200/235] [D loss: 1.077133, acc: 89.26%] [G loss: 1.139554]\n",
      "[Epoch 42/50] [Batch 201/235] [D loss: 1.111500, acc: 87.70%] [G loss: 1.186788]\n",
      "[Epoch 42/50] [Batch 202/235] [D loss: 1.165773, acc: 86.91%] [G loss: 1.205609]\n",
      "[Epoch 42/50] [Batch 203/235] [D loss: 1.101215, acc: 87.70%] [G loss: 1.062678]\n",
      "[Epoch 42/50] [Batch 204/235] [D loss: 1.073573, acc: 85.94%] [G loss: 0.993829]\n",
      "[Epoch 42/50] [Batch 205/235] [D loss: 1.107488, acc: 89.26%] [G loss: 1.147882]\n",
      "[Epoch 42/50] [Batch 206/235] [D loss: 1.130220, acc: 88.09%] [G loss: 1.214303]\n",
      "[Epoch 42/50] [Batch 207/235] [D loss: 1.116397, acc: 88.67%] [G loss: 1.211958]\n",
      "[Epoch 42/50] [Batch 208/235] [D loss: 1.071976, acc: 87.70%] [G loss: 1.334403]\n",
      "[Epoch 42/50] [Batch 209/235] [D loss: 1.144909, acc: 86.91%] [G loss: 1.069166]\n",
      "[Epoch 42/50] [Batch 210/235] [D loss: 1.128067, acc: 85.16%] [G loss: 1.201413]\n",
      "[Epoch 42/50] [Batch 211/235] [D loss: 1.121360, acc: 87.11%] [G loss: 1.130166]\n",
      "[Epoch 42/50] [Batch 212/235] [D loss: 1.069642, acc: 87.11%] [G loss: 1.057601]\n",
      "[Epoch 42/50] [Batch 213/235] [D loss: 1.073691, acc: 89.65%] [G loss: 1.162529]\n",
      "[Epoch 42/50] [Batch 214/235] [D loss: 1.132620, acc: 89.26%] [G loss: 1.068631]\n",
      "[Epoch 42/50] [Batch 215/235] [D loss: 1.097364, acc: 83.01%] [G loss: 1.184514]\n",
      "[Epoch 42/50] [Batch 216/235] [D loss: 1.158308, acc: 88.87%] [G loss: 1.310475]\n",
      "[Epoch 42/50] [Batch 217/235] [D loss: 1.097921, acc: 85.74%] [G loss: 1.132101]\n",
      "[Epoch 42/50] [Batch 218/235] [D loss: 1.178062, acc: 86.91%] [G loss: 1.099140]\n",
      "[Epoch 42/50] [Batch 219/235] [D loss: 1.134267, acc: 86.33%] [G loss: 1.096316]\n",
      "[Epoch 42/50] [Batch 220/235] [D loss: 1.112647, acc: 89.06%] [G loss: 1.177058]\n",
      "[Epoch 42/50] [Batch 221/235] [D loss: 1.132182, acc: 87.11%] [G loss: 1.095693]\n",
      "[Epoch 42/50] [Batch 222/235] [D loss: 1.112205, acc: 88.67%] [G loss: 0.980705]\n",
      "[Epoch 42/50] [Batch 223/235] [D loss: 1.114899, acc: 87.11%] [G loss: 1.198529]\n",
      "[Epoch 42/50] [Batch 224/235] [D loss: 1.122928, acc: 87.30%] [G loss: 1.037184]\n",
      "[Epoch 42/50] [Batch 225/235] [D loss: 1.219976, acc: 89.45%] [G loss: 1.162859]\n",
      "[Epoch 42/50] [Batch 226/235] [D loss: 1.083990, acc: 87.50%] [G loss: 1.180519]\n",
      "[Epoch 42/50] [Batch 227/235] [D loss: 1.051297, acc: 85.55%] [G loss: 1.228653]\n",
      "[Epoch 42/50] [Batch 228/235] [D loss: 1.157041, acc: 88.09%] [G loss: 1.161103]\n",
      "[Epoch 42/50] [Batch 229/235] [D loss: 1.089009, acc: 86.72%] [G loss: 1.042106]\n",
      "[Epoch 42/50] [Batch 230/235] [D loss: 1.098471, acc: 90.23%] [G loss: 1.275488]\n",
      "[Epoch 42/50] [Batch 231/235] [D loss: 1.094307, acc: 88.67%] [G loss: 1.113705]\n",
      "[Epoch 42/50] [Batch 232/235] [D loss: 1.147480, acc: 89.65%] [G loss: 1.165652]\n",
      "[Epoch 42/50] [Batch 233/235] [D loss: 1.101285, acc: 87.50%] [G loss: 1.095848]\n",
      "[Epoch 42/50] [Batch 234/235] [D loss: 1.037617, acc: 90.62%] [G loss: 1.230750]\n",
      "[Epoch 43/50] [Batch 0/235] [D loss: 1.139014, acc: 86.91%] [G loss: 1.194501]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/50] [Batch 1/235] [D loss: 1.057695, acc: 86.52%] [G loss: 1.117693]\n",
      "[Epoch 43/50] [Batch 2/235] [D loss: 1.104972, acc: 87.30%] [G loss: 1.169077]\n",
      "[Epoch 43/50] [Batch 3/235] [D loss: 1.097790, acc: 88.09%] [G loss: 1.202935]\n",
      "[Epoch 43/50] [Batch 4/235] [D loss: 1.131005, acc: 85.94%] [G loss: 1.082727]\n",
      "[Epoch 43/50] [Batch 5/235] [D loss: 1.071002, acc: 85.74%] [G loss: 1.188564]\n",
      "[Epoch 43/50] [Batch 6/235] [D loss: 1.074136, acc: 87.50%] [G loss: 1.221238]\n",
      "[Epoch 43/50] [Batch 7/235] [D loss: 1.036870, acc: 88.28%] [G loss: 1.155925]\n",
      "[Epoch 43/50] [Batch 8/235] [D loss: 1.106954, acc: 86.91%] [G loss: 1.133547]\n",
      "[Epoch 43/50] [Batch 9/235] [D loss: 1.188062, acc: 87.70%] [G loss: 1.123751]\n",
      "[Epoch 43/50] [Batch 10/235] [D loss: 1.096172, acc: 86.13%] [G loss: 1.169702]\n",
      "[Epoch 43/50] [Batch 11/235] [D loss: 1.126313, acc: 87.70%] [G loss: 1.163765]\n",
      "[Epoch 43/50] [Batch 12/235] [D loss: 1.069000, acc: 88.09%] [G loss: 1.147639]\n",
      "[Epoch 43/50] [Batch 13/235] [D loss: 1.148497, acc: 85.94%] [G loss: 1.058467]\n",
      "[Epoch 43/50] [Batch 14/235] [D loss: 1.160793, acc: 83.59%] [G loss: 1.234438]\n",
      "[Epoch 43/50] [Batch 15/235] [D loss: 1.092733, acc: 87.50%] [G loss: 1.222436]\n",
      "[Epoch 43/50] [Batch 16/235] [D loss: 1.054070, acc: 87.11%] [G loss: 1.136241]\n",
      "[Epoch 43/50] [Batch 17/235] [D loss: 1.148634, acc: 86.13%] [G loss: 1.082413]\n",
      "[Epoch 43/50] [Batch 18/235] [D loss: 1.106171, acc: 87.70%] [G loss: 1.248227]\n",
      "[Epoch 43/50] [Batch 19/235] [D loss: 1.110792, acc: 88.87%] [G loss: 1.147554]\n",
      "[Epoch 43/50] [Batch 20/235] [D loss: 1.149640, acc: 88.87%] [G loss: 1.038987]\n",
      "[Epoch 43/50] [Batch 21/235] [D loss: 1.203111, acc: 86.91%] [G loss: 1.082196]\n",
      "[Epoch 43/50] [Batch 22/235] [D loss: 1.168416, acc: 87.70%] [G loss: 1.154150]\n",
      "[Epoch 43/50] [Batch 23/235] [D loss: 1.077379, acc: 87.89%] [G loss: 1.291809]\n",
      "[Epoch 43/50] [Batch 24/235] [D loss: 1.115629, acc: 88.87%] [G loss: 1.108807]\n",
      "[Epoch 43/50] [Batch 25/235] [D loss: 1.138489, acc: 87.30%] [G loss: 1.130962]\n",
      "[Epoch 43/50] [Batch 26/235] [D loss: 1.177557, acc: 85.16%] [G loss: 1.209713]\n",
      "[Epoch 43/50] [Batch 27/235] [D loss: 1.155699, acc: 87.70%] [G loss: 1.070838]\n",
      "[Epoch 43/50] [Batch 28/235] [D loss: 1.161452, acc: 85.94%] [G loss: 1.276823]\n",
      "[Epoch 43/50] [Batch 29/235] [D loss: 1.117825, acc: 87.70%] [G loss: 1.092043]\n",
      "[Epoch 43/50] [Batch 30/235] [D loss: 1.125195, acc: 87.30%] [G loss: 1.109794]\n",
      "[Epoch 43/50] [Batch 31/235] [D loss: 1.172968, acc: 87.70%] [G loss: 1.131919]\n",
      "[Epoch 43/50] [Batch 32/235] [D loss: 1.075182, acc: 86.13%] [G loss: 1.242993]\n",
      "[Epoch 43/50] [Batch 33/235] [D loss: 1.084226, acc: 88.67%] [G loss: 1.299322]\n",
      "[Epoch 43/50] [Batch 34/235] [D loss: 1.116399, acc: 87.30%] [G loss: 1.121783]\n",
      "[Epoch 43/50] [Batch 35/235] [D loss: 1.139211, acc: 87.70%] [G loss: 1.116102]\n",
      "[Epoch 43/50] [Batch 36/235] [D loss: 1.127065, acc: 88.67%] [G loss: 1.076813]\n",
      "[Epoch 43/50] [Batch 37/235] [D loss: 1.184013, acc: 87.70%] [G loss: 1.111432]\n",
      "[Epoch 43/50] [Batch 38/235] [D loss: 1.120434, acc: 86.91%] [G loss: 1.288548]\n",
      "[Epoch 43/50] [Batch 39/235] [D loss: 1.118790, acc: 87.50%] [G loss: 1.195155]\n",
      "[Epoch 43/50] [Batch 40/235] [D loss: 1.103233, acc: 88.87%] [G loss: 1.127011]\n",
      "[Epoch 43/50] [Batch 41/235] [D loss: 1.162266, acc: 87.30%] [G loss: 1.077029]\n",
      "[Epoch 43/50] [Batch 42/235] [D loss: 1.225093, acc: 86.33%] [G loss: 1.313254]\n",
      "[Epoch 43/50] [Batch 43/235] [D loss: 1.097637, acc: 87.89%] [G loss: 1.157067]\n",
      "[Epoch 43/50] [Batch 44/235] [D loss: 1.118672, acc: 88.09%] [G loss: 1.198446]\n",
      "[Epoch 43/50] [Batch 45/235] [D loss: 1.132922, acc: 88.09%] [G loss: 1.230865]\n",
      "[Epoch 43/50] [Batch 46/235] [D loss: 1.109965, acc: 83.59%] [G loss: 1.101069]\n",
      "[Epoch 43/50] [Batch 47/235] [D loss: 1.060221, acc: 89.06%] [G loss: 1.129331]\n",
      "[Epoch 43/50] [Batch 48/235] [D loss: 1.099773, acc: 87.11%] [G loss: 1.115682]\n",
      "[Epoch 43/50] [Batch 49/235] [D loss: 1.105707, acc: 85.74%] [G loss: 1.101369]\n",
      "[Epoch 43/50] [Batch 50/235] [D loss: 1.111771, acc: 88.67%] [G loss: 1.253812]\n",
      "[Epoch 43/50] [Batch 51/235] [D loss: 1.087957, acc: 86.52%] [G loss: 1.269425]\n",
      "[Epoch 43/50] [Batch 52/235] [D loss: 1.015977, acc: 89.45%] [G loss: 1.199345]\n",
      "[Epoch 43/50] [Batch 53/235] [D loss: 1.114086, acc: 88.48%] [G loss: 1.240644]\n",
      "[Epoch 43/50] [Batch 54/235] [D loss: 1.104523, acc: 87.89%] [G loss: 1.101404]\n",
      "[Epoch 43/50] [Batch 55/235] [D loss: 1.184623, acc: 84.96%] [G loss: 1.196796]\n",
      "[Epoch 43/50] [Batch 56/235] [D loss: 1.041845, acc: 89.26%] [G loss: 1.363247]\n",
      "[Epoch 43/50] [Batch 57/235] [D loss: 1.098737, acc: 85.16%] [G loss: 1.158570]\n",
      "[Epoch 43/50] [Batch 58/235] [D loss: 1.105631, acc: 87.70%] [G loss: 1.086778]\n",
      "[Epoch 43/50] [Batch 59/235] [D loss: 1.169688, acc: 89.06%] [G loss: 1.076648]\n",
      "[Epoch 43/50] [Batch 60/235] [D loss: 1.133481, acc: 86.91%] [G loss: 1.146617]\n",
      "[Epoch 43/50] [Batch 61/235] [D loss: 1.142937, acc: 90.23%] [G loss: 1.144173]\n",
      "[Epoch 43/50] [Batch 62/235] [D loss: 1.145814, acc: 88.09%] [G loss: 1.174587]\n",
      "[Epoch 43/50] [Batch 63/235] [D loss: 1.124550, acc: 88.09%] [G loss: 1.182703]\n",
      "[Epoch 43/50] [Batch 64/235] [D loss: 1.133294, acc: 86.52%] [G loss: 1.159515]\n",
      "[Epoch 43/50] [Batch 65/235] [D loss: 1.108065, acc: 91.80%] [G loss: 1.108717]\n",
      "[Epoch 43/50] [Batch 66/235] [D loss: 1.136022, acc: 86.13%] [G loss: 1.275153]\n",
      "[Epoch 43/50] [Batch 67/235] [D loss: 1.134237, acc: 88.09%] [G loss: 1.044272]\n",
      "[Epoch 43/50] [Batch 68/235] [D loss: 1.057644, acc: 88.87%] [G loss: 1.101663]\n",
      "[Epoch 43/50] [Batch 69/235] [D loss: 1.169535, acc: 84.38%] [G loss: 1.239208]\n",
      "[Epoch 43/50] [Batch 70/235] [D loss: 1.092912, acc: 87.70%] [G loss: 1.149537]\n",
      "[Epoch 43/50] [Batch 71/235] [D loss: 1.112168, acc: 88.09%] [G loss: 1.105593]\n",
      "[Epoch 43/50] [Batch 72/235] [D loss: 1.123499, acc: 84.96%] [G loss: 1.291579]\n",
      "[Epoch 43/50] [Batch 73/235] [D loss: 1.185178, acc: 85.35%] [G loss: 1.145208]\n",
      "[Epoch 43/50] [Batch 74/235] [D loss: 1.118930, acc: 88.87%] [G loss: 1.249280]\n",
      "[Epoch 43/50] [Batch 75/235] [D loss: 1.134876, acc: 86.91%] [G loss: 1.301422]\n",
      "[Epoch 43/50] [Batch 76/235] [D loss: 1.162968, acc: 88.67%] [G loss: 1.274253]\n",
      "[Epoch 43/50] [Batch 77/235] [D loss: 1.125745, acc: 85.74%] [G loss: 1.042469]\n",
      "[Epoch 43/50] [Batch 78/235] [D loss: 1.059964, acc: 88.48%] [G loss: 1.065797]\n",
      "[Epoch 43/50] [Batch 79/235] [D loss: 1.118596, acc: 88.87%] [G loss: 1.115837]\n",
      "[Epoch 43/50] [Batch 80/235] [D loss: 1.113388, acc: 87.50%] [G loss: 1.251116]\n",
      "[Epoch 43/50] [Batch 81/235] [D loss: 1.138227, acc: 89.84%] [G loss: 1.127698]\n",
      "[Epoch 43/50] [Batch 82/235] [D loss: 1.087720, acc: 87.50%] [G loss: 1.156979]\n",
      "[Epoch 43/50] [Batch 83/235] [D loss: 1.145347, acc: 86.52%] [G loss: 1.135887]\n",
      "[Epoch 43/50] [Batch 84/235] [D loss: 1.124194, acc: 87.50%] [G loss: 1.087113]\n",
      "[Epoch 43/50] [Batch 85/235] [D loss: 1.088231, acc: 85.94%] [G loss: 1.110374]\n",
      "[Epoch 43/50] [Batch 86/235] [D loss: 1.046294, acc: 87.30%] [G loss: 1.084841]\n",
      "[Epoch 43/50] [Batch 87/235] [D loss: 1.184320, acc: 87.50%] [G loss: 1.235067]\n",
      "[Epoch 43/50] [Batch 88/235] [D loss: 1.163769, acc: 86.72%] [G loss: 1.171247]\n",
      "[Epoch 43/50] [Batch 89/235] [D loss: 1.040719, acc: 89.65%] [G loss: 1.164739]\n",
      "[Epoch 43/50] [Batch 90/235] [D loss: 1.141582, acc: 88.28%] [G loss: 1.114419]\n",
      "[Epoch 43/50] [Batch 91/235] [D loss: 1.143553, acc: 87.89%] [G loss: 1.238147]\n",
      "[Epoch 43/50] [Batch 92/235] [D loss: 1.110178, acc: 87.11%] [G loss: 1.181640]\n",
      "[Epoch 43/50] [Batch 93/235] [D loss: 1.090494, acc: 89.45%] [G loss: 1.067796]\n",
      "[Epoch 43/50] [Batch 94/235] [D loss: 1.126126, acc: 86.13%] [G loss: 1.147331]\n",
      "[Epoch 43/50] [Batch 95/235] [D loss: 1.134973, acc: 87.70%] [G loss: 1.251931]\n",
      "[Epoch 43/50] [Batch 96/235] [D loss: 1.133568, acc: 89.65%] [G loss: 1.147559]\n",
      "[Epoch 43/50] [Batch 97/235] [D loss: 1.125298, acc: 87.50%] [G loss: 1.084434]\n",
      "[Epoch 43/50] [Batch 98/235] [D loss: 1.100688, acc: 88.48%] [G loss: 1.130898]\n",
      "[Epoch 43/50] [Batch 99/235] [D loss: 1.077294, acc: 87.30%] [G loss: 1.192292]\n",
      "[Epoch 43/50] [Batch 100/235] [D loss: 1.147511, acc: 87.50%] [G loss: 1.220403]\n",
      "[Epoch 43/50] [Batch 101/235] [D loss: 1.181644, acc: 88.09%] [G loss: 1.158911]\n",
      "[Epoch 43/50] [Batch 102/235] [D loss: 1.085702, acc: 87.50%] [G loss: 1.292747]\n",
      "[Epoch 43/50] [Batch 103/235] [D loss: 1.100641, acc: 87.50%] [G loss: 1.147952]\n",
      "[Epoch 43/50] [Batch 104/235] [D loss: 1.124959, acc: 86.13%] [G loss: 1.229665]\n",
      "[Epoch 43/50] [Batch 105/235] [D loss: 1.069218, acc: 87.70%] [G loss: 1.186646]\n",
      "[Epoch 43/50] [Batch 106/235] [D loss: 1.130335, acc: 87.11%] [G loss: 1.245236]\n",
      "[Epoch 43/50] [Batch 107/235] [D loss: 1.076006, acc: 87.50%] [G loss: 1.189745]\n",
      "[Epoch 43/50] [Batch 108/235] [D loss: 1.073384, acc: 89.26%] [G loss: 1.270067]\n",
      "[Epoch 43/50] [Batch 109/235] [D loss: 1.112201, acc: 85.94%] [G loss: 1.121720]\n",
      "[Epoch 43/50] [Batch 110/235] [D loss: 1.116845, acc: 88.48%] [G loss: 1.039546]\n",
      "[Epoch 43/50] [Batch 111/235] [D loss: 1.143498, acc: 88.28%] [G loss: 1.072617]\n",
      "[Epoch 43/50] [Batch 112/235] [D loss: 1.152191, acc: 87.50%] [G loss: 1.279613]\n",
      "[Epoch 43/50] [Batch 113/235] [D loss: 1.194494, acc: 86.33%] [G loss: 1.258414]\n",
      "[Epoch 43/50] [Batch 114/235] [D loss: 1.200456, acc: 88.28%] [G loss: 1.084401]\n",
      "[Epoch 43/50] [Batch 115/235] [D loss: 1.116908, acc: 88.67%] [G loss: 1.014295]\n",
      "[Epoch 43/50] [Batch 116/235] [D loss: 1.074098, acc: 85.35%] [G loss: 1.205372]\n",
      "[Epoch 43/50] [Batch 117/235] [D loss: 1.120797, acc: 87.11%] [G loss: 1.213817]\n",
      "[Epoch 43/50] [Batch 118/235] [D loss: 1.159955, acc: 86.52%] [G loss: 1.213953]\n",
      "[Epoch 43/50] [Batch 119/235] [D loss: 1.139003, acc: 86.91%] [G loss: 1.022368]\n",
      "[Epoch 43/50] [Batch 120/235] [D loss: 1.126097, acc: 89.45%] [G loss: 1.141253]\n",
      "[Epoch 43/50] [Batch 121/235] [D loss: 1.172326, acc: 87.30%] [G loss: 1.161388]\n",
      "[Epoch 43/50] [Batch 122/235] [D loss: 1.136982, acc: 87.70%] [G loss: 1.228992]\n",
      "[Epoch 43/50] [Batch 123/235] [D loss: 1.149615, acc: 88.67%] [G loss: 1.136861]\n",
      "[Epoch 43/50] [Batch 124/235] [D loss: 1.113440, acc: 84.96%] [G loss: 1.167548]\n",
      "[Epoch 43/50] [Batch 125/235] [D loss: 1.130349, acc: 88.87%] [G loss: 1.189565]\n",
      "[Epoch 43/50] [Batch 126/235] [D loss: 1.155121, acc: 88.48%] [G loss: 1.083796]\n",
      "[Epoch 43/50] [Batch 127/235] [D loss: 1.147085, acc: 90.04%] [G loss: 1.139594]\n",
      "[Epoch 43/50] [Batch 128/235] [D loss: 1.071073, acc: 87.89%] [G loss: 1.140076]\n",
      "[Epoch 43/50] [Batch 129/235] [D loss: 1.112180, acc: 86.91%] [G loss: 0.954642]\n",
      "[Epoch 43/50] [Batch 130/235] [D loss: 1.065675, acc: 88.09%] [G loss: 1.105550]\n",
      "[Epoch 43/50] [Batch 131/235] [D loss: 1.149834, acc: 87.30%] [G loss: 1.204860]\n",
      "[Epoch 43/50] [Batch 132/235] [D loss: 1.127663, acc: 86.72%] [G loss: 1.194224]\n",
      "[Epoch 43/50] [Batch 133/235] [D loss: 1.090329, acc: 87.89%] [G loss: 1.245167]\n",
      "[Epoch 43/50] [Batch 134/235] [D loss: 1.122428, acc: 87.50%] [G loss: 1.139595]\n",
      "[Epoch 43/50] [Batch 135/235] [D loss: 1.158185, acc: 86.13%] [G loss: 1.182710]\n",
      "[Epoch 43/50] [Batch 136/235] [D loss: 1.102832, acc: 91.21%] [G loss: 1.198694]\n",
      "[Epoch 43/50] [Batch 137/235] [D loss: 1.126335, acc: 85.74%] [G loss: 1.125586]\n",
      "[Epoch 43/50] [Batch 138/235] [D loss: 1.096833, acc: 89.65%] [G loss: 1.008823]\n",
      "[Epoch 43/50] [Batch 139/235] [D loss: 1.061824, acc: 87.70%] [G loss: 1.025701]\n",
      "[Epoch 43/50] [Batch 140/235] [D loss: 1.087296, acc: 87.70%] [G loss: 1.229934]\n",
      "[Epoch 43/50] [Batch 141/235] [D loss: 1.072763, acc: 86.72%] [G loss: 1.144861]\n",
      "[Epoch 43/50] [Batch 142/235] [D loss: 1.062859, acc: 87.50%] [G loss: 1.246612]\n",
      "[Epoch 43/50] [Batch 143/235] [D loss: 1.108780, acc: 89.26%] [G loss: 1.159675]\n",
      "[Epoch 43/50] [Batch 144/235] [D loss: 1.164428, acc: 89.06%] [G loss: 1.199648]\n",
      "[Epoch 43/50] [Batch 145/235] [D loss: 1.114331, acc: 86.91%] [G loss: 1.287676]\n",
      "[Epoch 43/50] [Batch 146/235] [D loss: 1.099118, acc: 86.52%] [G loss: 1.259004]\n",
      "[Epoch 43/50] [Batch 147/235] [D loss: 1.126104, acc: 87.50%] [G loss: 1.018068]\n",
      "[Epoch 43/50] [Batch 148/235] [D loss: 1.086925, acc: 89.65%] [G loss: 1.234365]\n",
      "[Epoch 43/50] [Batch 149/235] [D loss: 1.083723, acc: 87.70%] [G loss: 1.272234]\n",
      "[Epoch 43/50] [Batch 150/235] [D loss: 1.142689, acc: 88.67%] [G loss: 1.275984]\n",
      "[Epoch 43/50] [Batch 151/235] [D loss: 1.233319, acc: 84.18%] [G loss: 1.203853]\n",
      "[Epoch 43/50] [Batch 152/235] [D loss: 1.021729, acc: 85.74%] [G loss: 1.177194]\n",
      "[Epoch 43/50] [Batch 153/235] [D loss: 1.100472, acc: 83.98%] [G loss: 1.101937]\n",
      "[Epoch 43/50] [Batch 154/235] [D loss: 1.100794, acc: 88.48%] [G loss: 1.101378]\n",
      "[Epoch 43/50] [Batch 155/235] [D loss: 1.138234, acc: 88.09%] [G loss: 1.157691]\n",
      "[Epoch 43/50] [Batch 156/235] [D loss: 1.174999, acc: 85.55%] [G loss: 1.110683]\n",
      "[Epoch 43/50] [Batch 157/235] [D loss: 1.093843, acc: 85.16%] [G loss: 1.122634]\n",
      "[Epoch 43/50] [Batch 158/235] [D loss: 1.112166, acc: 85.55%] [G loss: 0.972756]\n",
      "[Epoch 43/50] [Batch 159/235] [D loss: 1.192010, acc: 86.72%] [G loss: 1.247654]\n",
      "[Epoch 43/50] [Batch 160/235] [D loss: 1.100320, acc: 86.33%] [G loss: 1.073037]\n",
      "[Epoch 43/50] [Batch 161/235] [D loss: 1.181535, acc: 88.67%] [G loss: 1.037905]\n",
      "[Epoch 43/50] [Batch 162/235] [D loss: 1.154321, acc: 85.94%] [G loss: 1.267931]\n",
      "[Epoch 43/50] [Batch 163/235] [D loss: 1.040176, acc: 87.89%] [G loss: 1.111068]\n",
      "[Epoch 43/50] [Batch 164/235] [D loss: 1.095484, acc: 88.87%] [G loss: 1.115317]\n",
      "[Epoch 43/50] [Batch 165/235] [D loss: 1.125690, acc: 88.87%] [G loss: 1.170929]\n",
      "[Epoch 43/50] [Batch 166/235] [D loss: 1.106601, acc: 87.89%] [G loss: 1.182361]\n",
      "[Epoch 43/50] [Batch 167/235] [D loss: 1.058749, acc: 87.30%] [G loss: 1.181618]\n",
      "[Epoch 43/50] [Batch 168/235] [D loss: 1.102766, acc: 86.33%] [G loss: 1.165538]\n",
      "[Epoch 43/50] [Batch 169/235] [D loss: 1.118780, acc: 87.89%] [G loss: 1.135187]\n",
      "[Epoch 43/50] [Batch 170/235] [D loss: 1.130507, acc: 86.13%] [G loss: 1.062578]\n",
      "[Epoch 43/50] [Batch 171/235] [D loss: 1.128251, acc: 84.77%] [G loss: 1.028957]\n",
      "[Epoch 43/50] [Batch 172/235] [D loss: 1.125895, acc: 87.50%] [G loss: 1.131353]\n",
      "[Epoch 43/50] [Batch 173/235] [D loss: 1.091358, acc: 86.13%] [G loss: 1.339045]\n",
      "[Epoch 43/50] [Batch 174/235] [D loss: 1.090425, acc: 91.21%] [G loss: 1.060985]\n",
      "[Epoch 43/50] [Batch 175/235] [D loss: 1.073467, acc: 86.72%] [G loss: 1.273096]\n",
      "[Epoch 43/50] [Batch 176/235] [D loss: 1.068454, acc: 87.50%] [G loss: 1.109889]\n",
      "[Epoch 43/50] [Batch 177/235] [D loss: 1.137002, acc: 85.74%] [G loss: 1.193819]\n",
      "[Epoch 43/50] [Batch 178/235] [D loss: 1.120912, acc: 89.45%] [G loss: 1.361557]\n",
      "[Epoch 43/50] [Batch 179/235] [D loss: 1.100611, acc: 88.09%] [G loss: 1.182298]\n",
      "[Epoch 43/50] [Batch 180/235] [D loss: 1.111664, acc: 87.50%] [G loss: 1.279051]\n",
      "[Epoch 43/50] [Batch 181/235] [D loss: 1.113687, acc: 87.50%] [G loss: 1.027538]\n",
      "[Epoch 43/50] [Batch 182/235] [D loss: 1.123818, acc: 89.06%] [G loss: 1.012993]\n",
      "[Epoch 43/50] [Batch 183/235] [D loss: 1.135244, acc: 90.04%] [G loss: 1.100561]\n",
      "[Epoch 43/50] [Batch 184/235] [D loss: 1.098485, acc: 88.28%] [G loss: 1.105039]\n",
      "[Epoch 43/50] [Batch 185/235] [D loss: 1.113439, acc: 87.50%] [G loss: 1.167029]\n",
      "[Epoch 43/50] [Batch 186/235] [D loss: 1.190200, acc: 86.91%] [G loss: 1.136150]\n",
      "[Epoch 43/50] [Batch 187/235] [D loss: 1.075227, acc: 89.84%] [G loss: 1.035663]\n",
      "[Epoch 43/50] [Batch 188/235] [D loss: 1.092761, acc: 87.70%] [G loss: 1.144286]\n",
      "[Epoch 43/50] [Batch 189/235] [D loss: 1.222657, acc: 83.40%] [G loss: 1.163167]\n",
      "[Epoch 43/50] [Batch 190/235] [D loss: 1.095406, acc: 86.72%] [G loss: 1.193159]\n",
      "[Epoch 43/50] [Batch 191/235] [D loss: 1.218472, acc: 87.70%] [G loss: 1.199435]\n",
      "[Epoch 43/50] [Batch 192/235] [D loss: 1.117334, acc: 88.09%] [G loss: 1.122223]\n",
      "[Epoch 43/50] [Batch 193/235] [D loss: 1.091619, acc: 87.11%] [G loss: 1.152145]\n",
      "[Epoch 43/50] [Batch 194/235] [D loss: 1.236605, acc: 83.79%] [G loss: 1.160563]\n",
      "[Epoch 43/50] [Batch 195/235] [D loss: 1.156867, acc: 88.87%] [G loss: 1.209013]\n",
      "[Epoch 43/50] [Batch 196/235] [D loss: 1.035713, acc: 89.65%] [G loss: 1.149346]\n",
      "[Epoch 43/50] [Batch 197/235] [D loss: 1.166446, acc: 88.28%] [G loss: 1.097757]\n",
      "[Epoch 43/50] [Batch 198/235] [D loss: 1.103773, acc: 87.70%] [G loss: 1.164741]\n",
      "[Epoch 43/50] [Batch 199/235] [D loss: 1.086152, acc: 88.87%] [G loss: 1.238912]\n",
      "[Epoch 43/50] [Batch 200/235] [D loss: 1.108156, acc: 85.94%] [G loss: 1.145170]\n",
      "[Epoch 43/50] [Batch 201/235] [D loss: 1.105702, acc: 88.09%] [G loss: 1.074713]\n",
      "[Epoch 43/50] [Batch 202/235] [D loss: 1.093517, acc: 86.52%] [G loss: 1.010658]\n",
      "[Epoch 43/50] [Batch 203/235] [D loss: 1.112815, acc: 87.11%] [G loss: 1.126112]\n",
      "[Epoch 43/50] [Batch 204/235] [D loss: 1.201735, acc: 84.77%] [G loss: 1.215178]\n",
      "[Epoch 43/50] [Batch 205/235] [D loss: 1.053152, acc: 88.87%] [G loss: 1.039418]\n",
      "[Epoch 43/50] [Batch 206/235] [D loss: 1.153655, acc: 85.55%] [G loss: 1.105598]\n",
      "[Epoch 43/50] [Batch 207/235] [D loss: 1.188067, acc: 86.52%] [G loss: 1.300919]\n",
      "[Epoch 43/50] [Batch 208/235] [D loss: 1.110757, acc: 85.94%] [G loss: 1.092617]\n",
      "[Epoch 43/50] [Batch 209/235] [D loss: 1.167219, acc: 87.30%] [G loss: 1.136382]\n",
      "[Epoch 43/50] [Batch 210/235] [D loss: 1.068992, acc: 86.13%] [G loss: 1.145277]\n",
      "[Epoch 43/50] [Batch 211/235] [D loss: 1.129766, acc: 88.09%] [G loss: 1.054280]\n",
      "[Epoch 43/50] [Batch 212/235] [D loss: 1.187711, acc: 88.28%] [G loss: 1.123577]\n",
      "[Epoch 43/50] [Batch 213/235] [D loss: 1.060241, acc: 89.45%] [G loss: 1.265896]\n",
      "[Epoch 43/50] [Batch 214/235] [D loss: 1.015997, acc: 88.09%] [G loss: 1.226716]\n",
      "[Epoch 43/50] [Batch 215/235] [D loss: 1.194554, acc: 85.55%] [G loss: 1.156163]\n",
      "[Epoch 43/50] [Batch 216/235] [D loss: 1.116669, acc: 88.67%] [G loss: 1.139454]\n",
      "[Epoch 43/50] [Batch 217/235] [D loss: 1.105062, acc: 85.94%] [G loss: 1.144949]\n",
      "[Epoch 43/50] [Batch 218/235] [D loss: 1.092848, acc: 87.11%] [G loss: 1.095747]\n",
      "[Epoch 43/50] [Batch 219/235] [D loss: 1.143560, acc: 86.91%] [G loss: 1.210016]\n",
      "[Epoch 43/50] [Batch 220/235] [D loss: 1.110360, acc: 86.72%] [G loss: 1.156321]\n",
      "[Epoch 43/50] [Batch 221/235] [D loss: 1.116331, acc: 86.52%] [G loss: 1.017039]\n",
      "[Epoch 43/50] [Batch 222/235] [D loss: 1.149207, acc: 85.94%] [G loss: 1.100480]\n",
      "[Epoch 43/50] [Batch 223/235] [D loss: 1.080630, acc: 89.45%] [G loss: 1.239460]\n",
      "[Epoch 43/50] [Batch 224/235] [D loss: 1.158623, acc: 89.45%] [G loss: 1.098944]\n",
      "[Epoch 43/50] [Batch 225/235] [D loss: 1.058393, acc: 88.09%] [G loss: 1.138674]\n",
      "[Epoch 43/50] [Batch 226/235] [D loss: 1.081038, acc: 88.09%] [G loss: 1.076051]\n",
      "[Epoch 43/50] [Batch 227/235] [D loss: 1.140535, acc: 87.11%] [G loss: 1.160338]\n",
      "[Epoch 43/50] [Batch 228/235] [D loss: 1.109260, acc: 87.50%] [G loss: 1.052579]\n",
      "[Epoch 43/50] [Batch 229/235] [D loss: 1.104033, acc: 88.87%] [G loss: 1.265105]\n",
      "[Epoch 43/50] [Batch 230/235] [D loss: 1.108366, acc: 88.28%] [G loss: 1.134813]\n",
      "[Epoch 43/50] [Batch 231/235] [D loss: 1.101671, acc: 88.48%] [G loss: 1.054136]\n",
      "[Epoch 43/50] [Batch 232/235] [D loss: 1.062955, acc: 87.11%] [G loss: 1.247244]\n",
      "[Epoch 43/50] [Batch 233/235] [D loss: 1.116760, acc: 86.72%] [G loss: 1.080213]\n",
      "[Epoch 43/50] [Batch 234/235] [D loss: 1.040083, acc: 89.58%] [G loss: 1.164044]\n",
      "[Epoch 44/50] [Batch 0/235] [D loss: 1.106272, acc: 87.11%] [G loss: 1.169975]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/50] [Batch 1/235] [D loss: 1.164270, acc: 87.70%] [G loss: 0.964241]\n",
      "[Epoch 44/50] [Batch 2/235] [D loss: 1.091893, acc: 87.89%] [G loss: 1.060549]\n",
      "[Epoch 44/50] [Batch 3/235] [D loss: 1.130219, acc: 85.94%] [G loss: 1.183726]\n",
      "[Epoch 44/50] [Batch 4/235] [D loss: 1.078044, acc: 86.91%] [G loss: 1.248849]\n",
      "[Epoch 44/50] [Batch 5/235] [D loss: 1.095562, acc: 85.74%] [G loss: 1.058192]\n",
      "[Epoch 44/50] [Batch 6/235] [D loss: 1.135283, acc: 84.77%] [G loss: 1.139029]\n",
      "[Epoch 44/50] [Batch 7/235] [D loss: 1.065718, acc: 88.87%] [G loss: 1.227654]\n",
      "[Epoch 44/50] [Batch 8/235] [D loss: 1.146375, acc: 89.06%] [G loss: 1.161224]\n",
      "[Epoch 44/50] [Batch 9/235] [D loss: 1.137167, acc: 88.87%] [G loss: 1.234064]\n",
      "[Epoch 44/50] [Batch 10/235] [D loss: 1.124256, acc: 88.67%] [G loss: 1.084901]\n",
      "[Epoch 44/50] [Batch 11/235] [D loss: 1.102050, acc: 89.65%] [G loss: 1.124622]\n",
      "[Epoch 44/50] [Batch 12/235] [D loss: 1.131137, acc: 87.30%] [G loss: 1.157416]\n",
      "[Epoch 44/50] [Batch 13/235] [D loss: 1.151280, acc: 85.74%] [G loss: 1.116784]\n",
      "[Epoch 44/50] [Batch 14/235] [D loss: 1.127346, acc: 89.45%] [G loss: 1.234408]\n",
      "[Epoch 44/50] [Batch 15/235] [D loss: 1.045095, acc: 87.70%] [G loss: 1.266325]\n",
      "[Epoch 44/50] [Batch 16/235] [D loss: 1.148047, acc: 87.89%] [G loss: 1.102250]\n",
      "[Epoch 44/50] [Batch 17/235] [D loss: 1.082499, acc: 89.06%] [G loss: 1.261407]\n",
      "[Epoch 44/50] [Batch 18/235] [D loss: 1.095405, acc: 88.09%] [G loss: 1.174076]\n",
      "[Epoch 44/50] [Batch 19/235] [D loss: 1.103636, acc: 88.87%] [G loss: 1.107634]\n",
      "[Epoch 44/50] [Batch 20/235] [D loss: 1.103764, acc: 88.28%] [G loss: 1.123435]\n",
      "[Epoch 44/50] [Batch 21/235] [D loss: 1.137819, acc: 87.89%] [G loss: 1.121463]\n",
      "[Epoch 44/50] [Batch 22/235] [D loss: 1.111044, acc: 87.89%] [G loss: 1.106705]\n",
      "[Epoch 44/50] [Batch 23/235] [D loss: 1.151448, acc: 85.94%] [G loss: 1.160228]\n",
      "[Epoch 44/50] [Batch 24/235] [D loss: 1.184719, acc: 86.72%] [G loss: 1.084853]\n",
      "[Epoch 44/50] [Batch 25/235] [D loss: 1.125425, acc: 88.28%] [G loss: 1.321430]\n",
      "[Epoch 44/50] [Batch 26/235] [D loss: 1.106669, acc: 87.11%] [G loss: 1.286197]\n",
      "[Epoch 44/50] [Batch 27/235] [D loss: 1.095843, acc: 88.87%] [G loss: 1.111649]\n",
      "[Epoch 44/50] [Batch 28/235] [D loss: 1.115339, acc: 86.52%] [G loss: 1.068622]\n",
      "[Epoch 44/50] [Batch 29/235] [D loss: 1.111029, acc: 88.28%] [G loss: 1.228614]\n",
      "[Epoch 44/50] [Batch 30/235] [D loss: 1.162233, acc: 87.30%] [G loss: 1.126476]\n",
      "[Epoch 44/50] [Batch 31/235] [D loss: 1.067831, acc: 86.91%] [G loss: 1.135410]\n",
      "[Epoch 44/50] [Batch 32/235] [D loss: 1.067488, acc: 87.89%] [G loss: 1.030782]\n",
      "[Epoch 44/50] [Batch 33/235] [D loss: 1.140420, acc: 87.70%] [G loss: 1.126244]\n",
      "[Epoch 44/50] [Batch 34/235] [D loss: 1.107718, acc: 88.09%] [G loss: 1.176144]\n",
      "[Epoch 44/50] [Batch 35/235] [D loss: 1.155985, acc: 88.09%] [G loss: 1.088919]\n",
      "[Epoch 44/50] [Batch 36/235] [D loss: 1.162961, acc: 89.06%] [G loss: 1.149050]\n",
      "[Epoch 44/50] [Batch 37/235] [D loss: 1.048384, acc: 88.87%] [G loss: 1.060504]\n",
      "[Epoch 44/50] [Batch 38/235] [D loss: 1.111298, acc: 85.94%] [G loss: 1.216494]\n",
      "[Epoch 44/50] [Batch 39/235] [D loss: 1.110538, acc: 87.30%] [G loss: 1.123578]\n",
      "[Epoch 44/50] [Batch 40/235] [D loss: 1.101492, acc: 87.50%] [G loss: 1.160687]\n",
      "[Epoch 44/50] [Batch 41/235] [D loss: 1.140117, acc: 86.33%] [G loss: 1.115055]\n",
      "[Epoch 44/50] [Batch 42/235] [D loss: 1.111146, acc: 85.74%] [G loss: 1.140384]\n",
      "[Epoch 44/50] [Batch 43/235] [D loss: 1.136251, acc: 86.13%] [G loss: 0.992443]\n",
      "[Epoch 44/50] [Batch 44/235] [D loss: 1.147228, acc: 85.16%] [G loss: 1.180752]\n",
      "[Epoch 44/50] [Batch 45/235] [D loss: 1.146748, acc: 83.98%] [G loss: 1.330452]\n",
      "[Epoch 44/50] [Batch 46/235] [D loss: 1.052680, acc: 87.11%] [G loss: 1.024541]\n",
      "[Epoch 44/50] [Batch 47/235] [D loss: 1.194187, acc: 88.67%] [G loss: 0.919158]\n",
      "[Epoch 44/50] [Batch 48/235] [D loss: 1.084826, acc: 87.70%] [G loss: 1.146935]\n",
      "[Epoch 44/50] [Batch 49/235] [D loss: 1.108130, acc: 88.87%] [G loss: 1.280493]\n",
      "[Epoch 44/50] [Batch 50/235] [D loss: 1.160779, acc: 88.09%] [G loss: 1.232262]\n",
      "[Epoch 44/50] [Batch 51/235] [D loss: 1.108911, acc: 87.89%] [G loss: 1.057240]\n",
      "[Epoch 44/50] [Batch 52/235] [D loss: 1.094812, acc: 89.84%] [G loss: 1.124211]\n",
      "[Epoch 44/50] [Batch 53/235] [D loss: 1.095726, acc: 87.30%] [G loss: 1.203315]\n",
      "[Epoch 44/50] [Batch 54/235] [D loss: 1.110251, acc: 89.26%] [G loss: 1.123810]\n",
      "[Epoch 44/50] [Batch 55/235] [D loss: 1.093377, acc: 88.48%] [G loss: 1.062250]\n",
      "[Epoch 44/50] [Batch 56/235] [D loss: 1.099544, acc: 86.13%] [G loss: 1.062060]\n",
      "[Epoch 44/50] [Batch 57/235] [D loss: 1.147972, acc: 88.87%] [G loss: 1.270423]\n",
      "[Epoch 44/50] [Batch 58/235] [D loss: 1.082018, acc: 88.28%] [G loss: 1.362238]\n",
      "[Epoch 44/50] [Batch 59/235] [D loss: 1.158753, acc: 88.48%] [G loss: 1.229100]\n",
      "[Epoch 44/50] [Batch 60/235] [D loss: 1.114483, acc: 83.79%] [G loss: 1.078802]\n",
      "[Epoch 44/50] [Batch 61/235] [D loss: 1.130718, acc: 85.55%] [G loss: 1.207267]\n",
      "[Epoch 44/50] [Batch 62/235] [D loss: 1.139018, acc: 88.48%] [G loss: 1.279664]\n",
      "[Epoch 44/50] [Batch 63/235] [D loss: 1.118937, acc: 87.30%] [G loss: 1.147843]\n",
      "[Epoch 44/50] [Batch 64/235] [D loss: 1.119790, acc: 87.70%] [G loss: 1.143842]\n",
      "[Epoch 44/50] [Batch 65/235] [D loss: 1.097386, acc: 88.09%] [G loss: 1.078306]\n",
      "[Epoch 44/50] [Batch 66/235] [D loss: 1.108675, acc: 89.26%] [G loss: 1.232003]\n",
      "[Epoch 44/50] [Batch 67/235] [D loss: 1.096221, acc: 90.04%] [G loss: 1.274931]\n",
      "[Epoch 44/50] [Batch 68/235] [D loss: 1.082151, acc: 88.09%] [G loss: 1.179512]\n",
      "[Epoch 44/50] [Batch 69/235] [D loss: 1.163106, acc: 88.48%] [G loss: 1.091485]\n",
      "[Epoch 44/50] [Batch 70/235] [D loss: 1.095108, acc: 89.26%] [G loss: 1.158649]\n",
      "[Epoch 44/50] [Batch 71/235] [D loss: 1.161657, acc: 87.30%] [G loss: 1.135546]\n",
      "[Epoch 44/50] [Batch 72/235] [D loss: 1.107527, acc: 88.28%] [G loss: 1.238618]\n",
      "[Epoch 44/50] [Batch 73/235] [D loss: 1.134762, acc: 87.30%] [G loss: 1.040794]\n",
      "[Epoch 44/50] [Batch 74/235] [D loss: 1.092405, acc: 89.06%] [G loss: 1.144981]\n",
      "[Epoch 44/50] [Batch 75/235] [D loss: 1.116304, acc: 88.67%] [G loss: 1.180707]\n",
      "[Epoch 44/50] [Batch 76/235] [D loss: 1.088138, acc: 87.11%] [G loss: 1.416857]\n",
      "[Epoch 44/50] [Batch 77/235] [D loss: 1.133581, acc: 87.30%] [G loss: 1.177326]\n",
      "[Epoch 44/50] [Batch 78/235] [D loss: 1.105116, acc: 86.52%] [G loss: 1.072116]\n",
      "[Epoch 44/50] [Batch 79/235] [D loss: 1.195778, acc: 87.30%] [G loss: 1.005999]\n",
      "[Epoch 44/50] [Batch 80/235] [D loss: 1.216016, acc: 85.16%] [G loss: 1.079255]\n",
      "[Epoch 44/50] [Batch 81/235] [D loss: 1.124193, acc: 88.48%] [G loss: 1.284407]\n",
      "[Epoch 44/50] [Batch 82/235] [D loss: 1.095679, acc: 88.28%] [G loss: 1.277761]\n",
      "[Epoch 44/50] [Batch 83/235] [D loss: 1.135996, acc: 88.28%] [G loss: 1.080190]\n",
      "[Epoch 44/50] [Batch 84/235] [D loss: 1.088835, acc: 86.33%] [G loss: 1.067396]\n",
      "[Epoch 44/50] [Batch 85/235] [D loss: 1.135280, acc: 87.30%] [G loss: 1.145709]\n",
      "[Epoch 44/50] [Batch 86/235] [D loss: 1.175622, acc: 88.09%] [G loss: 1.121421]\n",
      "[Epoch 44/50] [Batch 87/235] [D loss: 1.051187, acc: 87.50%] [G loss: 1.133589]\n",
      "[Epoch 44/50] [Batch 88/235] [D loss: 1.092713, acc: 89.26%] [G loss: 1.186418]\n",
      "[Epoch 44/50] [Batch 89/235] [D loss: 1.121778, acc: 88.28%] [G loss: 1.238063]\n",
      "[Epoch 44/50] [Batch 90/235] [D loss: 1.150985, acc: 88.67%] [G loss: 1.077363]\n",
      "[Epoch 44/50] [Batch 91/235] [D loss: 1.109439, acc: 88.09%] [G loss: 1.063790]\n",
      "[Epoch 44/50] [Batch 92/235] [D loss: 1.100141, acc: 88.67%] [G loss: 1.218988]\n",
      "[Epoch 44/50] [Batch 93/235] [D loss: 1.146970, acc: 85.94%] [G loss: 1.205268]\n",
      "[Epoch 44/50] [Batch 94/235] [D loss: 1.157078, acc: 87.89%] [G loss: 1.160243]\n",
      "[Epoch 44/50] [Batch 95/235] [D loss: 1.072619, acc: 88.48%] [G loss: 1.255292]\n",
      "[Epoch 44/50] [Batch 96/235] [D loss: 1.095589, acc: 89.26%] [G loss: 0.950371]\n",
      "[Epoch 44/50] [Batch 97/235] [D loss: 1.071002, acc: 86.91%] [G loss: 1.285466]\n",
      "[Epoch 44/50] [Batch 98/235] [D loss: 1.104600, acc: 87.11%] [G loss: 1.279456]\n",
      "[Epoch 44/50] [Batch 99/235] [D loss: 1.160893, acc: 84.38%] [G loss: 1.202388]\n",
      "[Epoch 44/50] [Batch 100/235] [D loss: 1.138258, acc: 88.48%] [G loss: 0.995776]\n",
      "[Epoch 44/50] [Batch 101/235] [D loss: 1.102116, acc: 89.45%] [G loss: 1.118173]\n",
      "[Epoch 44/50] [Batch 102/235] [D loss: 1.124028, acc: 85.35%] [G loss: 1.113424]\n",
      "[Epoch 44/50] [Batch 103/235] [D loss: 1.113972, acc: 87.70%] [G loss: 1.355490]\n",
      "[Epoch 44/50] [Batch 104/235] [D loss: 1.111242, acc: 88.67%] [G loss: 1.371669]\n",
      "[Epoch 44/50] [Batch 105/235] [D loss: 1.078329, acc: 89.45%] [G loss: 1.275057]\n",
      "[Epoch 44/50] [Batch 106/235] [D loss: 1.157133, acc: 91.02%] [G loss: 1.092348]\n",
      "[Epoch 44/50] [Batch 107/235] [D loss: 1.096829, acc: 87.89%] [G loss: 1.044107]\n",
      "[Epoch 44/50] [Batch 108/235] [D loss: 1.062950, acc: 87.11%] [G loss: 1.247678]\n",
      "[Epoch 44/50] [Batch 109/235] [D loss: 1.151429, acc: 85.94%] [G loss: 1.156314]\n",
      "[Epoch 44/50] [Batch 110/235] [D loss: 1.087909, acc: 87.70%] [G loss: 1.097087]\n",
      "[Epoch 44/50] [Batch 111/235] [D loss: 1.101512, acc: 89.45%] [G loss: 1.136660]\n",
      "[Epoch 44/50] [Batch 112/235] [D loss: 1.147114, acc: 85.55%] [G loss: 1.213230]\n",
      "[Epoch 44/50] [Batch 113/235] [D loss: 1.146030, acc: 86.52%] [G loss: 1.016650]\n",
      "[Epoch 44/50] [Batch 114/235] [D loss: 1.167563, acc: 89.26%] [G loss: 1.031771]\n",
      "[Epoch 44/50] [Batch 115/235] [D loss: 1.115049, acc: 87.50%] [G loss: 1.151684]\n",
      "[Epoch 44/50] [Batch 116/235] [D loss: 1.200377, acc: 87.11%] [G loss: 1.033367]\n",
      "[Epoch 44/50] [Batch 117/235] [D loss: 1.095968, acc: 87.50%] [G loss: 1.252577]\n",
      "[Epoch 44/50] [Batch 118/235] [D loss: 1.055095, acc: 87.70%] [G loss: 1.146351]\n",
      "[Epoch 44/50] [Batch 119/235] [D loss: 1.123259, acc: 87.89%] [G loss: 1.036455]\n",
      "[Epoch 44/50] [Batch 120/235] [D loss: 1.086267, acc: 90.23%] [G loss: 1.152366]\n",
      "[Epoch 44/50] [Batch 121/235] [D loss: 1.149822, acc: 88.09%] [G loss: 1.204617]\n",
      "[Epoch 44/50] [Batch 122/235] [D loss: 1.113564, acc: 86.72%] [G loss: 1.169651]\n",
      "[Epoch 44/50] [Batch 123/235] [D loss: 1.165129, acc: 86.52%] [G loss: 1.056050]\n",
      "[Epoch 44/50] [Batch 124/235] [D loss: 1.094046, acc: 85.55%] [G loss: 1.127596]\n",
      "[Epoch 44/50] [Batch 125/235] [D loss: 1.109266, acc: 88.67%] [G loss: 1.221517]\n",
      "[Epoch 44/50] [Batch 126/235] [D loss: 1.115921, acc: 86.72%] [G loss: 1.265793]\n",
      "[Epoch 44/50] [Batch 127/235] [D loss: 1.103741, acc: 87.11%] [G loss: 0.955206]\n",
      "[Epoch 44/50] [Batch 128/235] [D loss: 1.137712, acc: 89.45%] [G loss: 1.185571]\n",
      "[Epoch 44/50] [Batch 129/235] [D loss: 1.053265, acc: 86.91%] [G loss: 1.099027]\n",
      "[Epoch 44/50] [Batch 130/235] [D loss: 1.116118, acc: 88.28%] [G loss: 1.009245]\n",
      "[Epoch 44/50] [Batch 131/235] [D loss: 1.124722, acc: 86.72%] [G loss: 1.126192]\n",
      "[Epoch 44/50] [Batch 132/235] [D loss: 1.114086, acc: 87.50%] [G loss: 1.147064]\n",
      "[Epoch 44/50] [Batch 133/235] [D loss: 1.161842, acc: 86.91%] [G loss: 1.143351]\n",
      "[Epoch 44/50] [Batch 134/235] [D loss: 1.148836, acc: 87.30%] [G loss: 1.212741]\n",
      "[Epoch 44/50] [Batch 135/235] [D loss: 1.143161, acc: 88.28%] [G loss: 1.071215]\n",
      "[Epoch 44/50] [Batch 136/235] [D loss: 1.118887, acc: 88.87%] [G loss: 1.065726]\n",
      "[Epoch 44/50] [Batch 137/235] [D loss: 1.104640, acc: 87.11%] [G loss: 1.139882]\n",
      "[Epoch 44/50] [Batch 138/235] [D loss: 1.162988, acc: 88.28%] [G loss: 1.025650]\n",
      "[Epoch 44/50] [Batch 139/235] [D loss: 1.089104, acc: 87.70%] [G loss: 1.175881]\n",
      "[Epoch 44/50] [Batch 140/235] [D loss: 1.099486, acc: 85.74%] [G loss: 1.233855]\n",
      "[Epoch 44/50] [Batch 141/235] [D loss: 1.093396, acc: 87.70%] [G loss: 1.241166]\n",
      "[Epoch 44/50] [Batch 142/235] [D loss: 1.137488, acc: 88.67%] [G loss: 1.112137]\n",
      "[Epoch 44/50] [Batch 143/235] [D loss: 1.103101, acc: 84.18%] [G loss: 1.061214]\n",
      "[Epoch 44/50] [Batch 144/235] [D loss: 1.122556, acc: 87.30%] [G loss: 1.177443]\n",
      "[Epoch 44/50] [Batch 145/235] [D loss: 1.120622, acc: 88.09%] [G loss: 1.192710]\n",
      "[Epoch 44/50] [Batch 146/235] [D loss: 1.194958, acc: 86.91%] [G loss: 1.177312]\n",
      "[Epoch 44/50] [Batch 147/235] [D loss: 1.139401, acc: 87.30%] [G loss: 1.332645]\n",
      "[Epoch 44/50] [Batch 148/235] [D loss: 1.143371, acc: 86.13%] [G loss: 1.073327]\n",
      "[Epoch 44/50] [Batch 149/235] [D loss: 1.148965, acc: 85.35%] [G loss: 1.084892]\n",
      "[Epoch 44/50] [Batch 150/235] [D loss: 1.117174, acc: 86.72%] [G loss: 1.237358]\n",
      "[Epoch 44/50] [Batch 151/235] [D loss: 1.088775, acc: 85.35%] [G loss: 1.166578]\n",
      "[Epoch 44/50] [Batch 152/235] [D loss: 1.144027, acc: 85.16%] [G loss: 1.105223]\n",
      "[Epoch 44/50] [Batch 153/235] [D loss: 1.115570, acc: 88.48%] [G loss: 1.187260]\n",
      "[Epoch 44/50] [Batch 154/235] [D loss: 1.163529, acc: 87.89%] [G loss: 1.084476]\n",
      "[Epoch 44/50] [Batch 155/235] [D loss: 1.115486, acc: 87.30%] [G loss: 1.198060]\n",
      "[Epoch 44/50] [Batch 156/235] [D loss: 1.068789, acc: 88.87%] [G loss: 1.276847]\n",
      "[Epoch 44/50] [Batch 157/235] [D loss: 1.094649, acc: 86.91%] [G loss: 1.177050]\n",
      "[Epoch 44/50] [Batch 158/235] [D loss: 1.086987, acc: 88.48%] [G loss: 1.223515]\n",
      "[Epoch 44/50] [Batch 159/235] [D loss: 1.085664, acc: 87.30%] [G loss: 1.075040]\n",
      "[Epoch 44/50] [Batch 160/235] [D loss: 1.144372, acc: 88.48%] [G loss: 1.209213]\n",
      "[Epoch 44/50] [Batch 161/235] [D loss: 1.121184, acc: 85.94%] [G loss: 1.138958]\n",
      "[Epoch 44/50] [Batch 162/235] [D loss: 1.056292, acc: 88.28%] [G loss: 1.091514]\n",
      "[Epoch 44/50] [Batch 163/235] [D loss: 1.142051, acc: 87.50%] [G loss: 1.048368]\n",
      "[Epoch 44/50] [Batch 164/235] [D loss: 1.101364, acc: 87.50%] [G loss: 1.115685]\n",
      "[Epoch 44/50] [Batch 165/235] [D loss: 1.061000, acc: 84.96%] [G loss: 1.015193]\n",
      "[Epoch 44/50] [Batch 166/235] [D loss: 1.092022, acc: 86.91%] [G loss: 1.177004]\n",
      "[Epoch 44/50] [Batch 167/235] [D loss: 1.174362, acc: 86.52%] [G loss: 1.122141]\n",
      "[Epoch 44/50] [Batch 168/235] [D loss: 1.106925, acc: 87.70%] [G loss: 1.217823]\n",
      "[Epoch 44/50] [Batch 169/235] [D loss: 1.160255, acc: 91.80%] [G loss: 1.138176]\n",
      "[Epoch 44/50] [Batch 170/235] [D loss: 1.105753, acc: 88.67%] [G loss: 1.029980]\n",
      "[Epoch 44/50] [Batch 171/235] [D loss: 1.135997, acc: 85.74%] [G loss: 1.050506]\n",
      "[Epoch 44/50] [Batch 172/235] [D loss: 1.110158, acc: 88.87%] [G loss: 1.195166]\n",
      "[Epoch 44/50] [Batch 173/235] [D loss: 1.054637, acc: 89.26%] [G loss: 1.066390]\n",
      "[Epoch 44/50] [Batch 174/235] [D loss: 1.114338, acc: 85.35%] [G loss: 1.157393]\n",
      "[Epoch 44/50] [Batch 175/235] [D loss: 1.107016, acc: 87.50%] [G loss: 1.102363]\n",
      "[Epoch 44/50] [Batch 176/235] [D loss: 1.172412, acc: 85.55%] [G loss: 1.032746]\n",
      "[Epoch 44/50] [Batch 177/235] [D loss: 1.127966, acc: 86.91%] [G loss: 1.190492]\n",
      "[Epoch 44/50] [Batch 178/235] [D loss: 1.112885, acc: 88.28%] [G loss: 1.150400]\n",
      "[Epoch 44/50] [Batch 179/235] [D loss: 1.103626, acc: 87.50%] [G loss: 1.123178]\n",
      "[Epoch 44/50] [Batch 180/235] [D loss: 1.131909, acc: 86.72%] [G loss: 1.116473]\n",
      "[Epoch 44/50] [Batch 181/235] [D loss: 1.073717, acc: 87.70%] [G loss: 1.093883]\n",
      "[Epoch 44/50] [Batch 182/235] [D loss: 1.074648, acc: 86.72%] [G loss: 1.039926]\n",
      "[Epoch 44/50] [Batch 183/235] [D loss: 1.155029, acc: 86.91%] [G loss: 1.020135]\n",
      "[Epoch 44/50] [Batch 184/235] [D loss: 1.131452, acc: 87.11%] [G loss: 1.141393]\n",
      "[Epoch 44/50] [Batch 185/235] [D loss: 1.107191, acc: 87.30%] [G loss: 1.105908]\n",
      "[Epoch 44/50] [Batch 186/235] [D loss: 1.130891, acc: 88.48%] [G loss: 1.184420]\n",
      "[Epoch 44/50] [Batch 187/235] [D loss: 1.117642, acc: 87.30%] [G loss: 1.118794]\n",
      "[Epoch 44/50] [Batch 188/235] [D loss: 1.188583, acc: 84.77%] [G loss: 1.295191]\n",
      "[Epoch 44/50] [Batch 189/235] [D loss: 1.066914, acc: 86.33%] [G loss: 1.168101]\n",
      "[Epoch 44/50] [Batch 190/235] [D loss: 1.132575, acc: 86.91%] [G loss: 1.131995]\n",
      "[Epoch 44/50] [Batch 191/235] [D loss: 1.077680, acc: 88.87%] [G loss: 1.171031]\n",
      "[Epoch 44/50] [Batch 192/235] [D loss: 1.104811, acc: 88.28%] [G loss: 1.290612]\n",
      "[Epoch 44/50] [Batch 193/235] [D loss: 1.120622, acc: 88.09%] [G loss: 1.018391]\n",
      "[Epoch 44/50] [Batch 194/235] [D loss: 1.099029, acc: 88.67%] [G loss: 1.130043]\n",
      "[Epoch 44/50] [Batch 195/235] [D loss: 1.090732, acc: 87.89%] [G loss: 1.060888]\n",
      "[Epoch 44/50] [Batch 196/235] [D loss: 1.069328, acc: 87.50%] [G loss: 1.293204]\n",
      "[Epoch 44/50] [Batch 197/235] [D loss: 1.140294, acc: 88.48%] [G loss: 1.231614]\n",
      "[Epoch 44/50] [Batch 198/235] [D loss: 1.186256, acc: 87.30%] [G loss: 0.994727]\n",
      "[Epoch 44/50] [Batch 199/235] [D loss: 1.067971, acc: 87.89%] [G loss: 1.064458]\n",
      "[Epoch 44/50] [Batch 200/235] [D loss: 1.165869, acc: 84.77%] [G loss: 1.283521]\n",
      "[Epoch 44/50] [Batch 201/235] [D loss: 1.196639, acc: 87.11%] [G loss: 1.264491]\n",
      "[Epoch 44/50] [Batch 202/235] [D loss: 1.096282, acc: 85.74%] [G loss: 1.144026]\n",
      "[Epoch 44/50] [Batch 203/235] [D loss: 1.158421, acc: 86.91%] [G loss: 1.119016]\n",
      "[Epoch 44/50] [Batch 204/235] [D loss: 1.083336, acc: 87.50%] [G loss: 1.136319]\n",
      "[Epoch 44/50] [Batch 205/235] [D loss: 1.035279, acc: 87.50%] [G loss: 1.077583]\n",
      "[Epoch 44/50] [Batch 206/235] [D loss: 1.131991, acc: 88.87%] [G loss: 1.097689]\n",
      "[Epoch 44/50] [Batch 207/235] [D loss: 1.106933, acc: 86.52%] [G loss: 1.107492]\n",
      "[Epoch 44/50] [Batch 208/235] [D loss: 1.151903, acc: 86.72%] [G loss: 1.305034]\n",
      "[Epoch 44/50] [Batch 209/235] [D loss: 1.172191, acc: 87.11%] [G loss: 1.065943]\n",
      "[Epoch 44/50] [Batch 210/235] [D loss: 1.154405, acc: 86.91%] [G loss: 1.033662]\n",
      "[Epoch 44/50] [Batch 211/235] [D loss: 1.090453, acc: 86.13%] [G loss: 1.091305]\n",
      "[Epoch 44/50] [Batch 212/235] [D loss: 1.118902, acc: 87.89%] [G loss: 1.292951]\n",
      "[Epoch 44/50] [Batch 213/235] [D loss: 1.075412, acc: 87.11%] [G loss: 1.240789]\n",
      "[Epoch 44/50] [Batch 214/235] [D loss: 1.144408, acc: 88.67%] [G loss: 1.193960]\n",
      "[Epoch 44/50] [Batch 215/235] [D loss: 1.133908, acc: 89.84%] [G loss: 1.018796]\n",
      "[Epoch 44/50] [Batch 216/235] [D loss: 1.156737, acc: 88.48%] [G loss: 1.142906]\n",
      "[Epoch 44/50] [Batch 217/235] [D loss: 1.070236, acc: 86.13%] [G loss: 1.142616]\n",
      "[Epoch 44/50] [Batch 218/235] [D loss: 1.082005, acc: 87.30%] [G loss: 1.316672]\n",
      "[Epoch 44/50] [Batch 219/235] [D loss: 1.132988, acc: 89.45%] [G loss: 1.210381]\n",
      "[Epoch 44/50] [Batch 220/235] [D loss: 1.112260, acc: 86.13%] [G loss: 0.991948]\n",
      "[Epoch 44/50] [Batch 221/235] [D loss: 1.140817, acc: 87.50%] [G loss: 1.210456]\n",
      "[Epoch 44/50] [Batch 222/235] [D loss: 1.126550, acc: 86.91%] [G loss: 1.149979]\n",
      "[Epoch 44/50] [Batch 223/235] [D loss: 1.081182, acc: 86.33%] [G loss: 1.133135]\n",
      "[Epoch 44/50] [Batch 224/235] [D loss: 1.085024, acc: 86.72%] [G loss: 1.136119]\n",
      "[Epoch 44/50] [Batch 225/235] [D loss: 1.189724, acc: 84.57%] [G loss: 1.086306]\n",
      "[Epoch 44/50] [Batch 226/235] [D loss: 1.124952, acc: 88.87%] [G loss: 1.241973]\n",
      "[Epoch 44/50] [Batch 227/235] [D loss: 1.136800, acc: 87.11%] [G loss: 1.153479]\n",
      "[Epoch 44/50] [Batch 228/235] [D loss: 1.151921, acc: 89.06%] [G loss: 1.205452]\n",
      "[Epoch 44/50] [Batch 229/235] [D loss: 1.153518, acc: 86.91%] [G loss: 1.072067]\n",
      "[Epoch 44/50] [Batch 230/235] [D loss: 1.079622, acc: 87.30%] [G loss: 1.197397]\n",
      "[Epoch 44/50] [Batch 231/235] [D loss: 1.161399, acc: 85.55%] [G loss: 1.183135]\n",
      "[Epoch 44/50] [Batch 232/235] [D loss: 1.108876, acc: 88.09%] [G loss: 1.145613]\n",
      "[Epoch 44/50] [Batch 233/235] [D loss: 1.112528, acc: 89.45%] [G loss: 1.153714]\n",
      "[Epoch 44/50] [Batch 234/235] [D loss: 1.101376, acc: 89.58%] [G loss: 1.302038]\n",
      "[Epoch 45/50] [Batch 0/235] [D loss: 1.098451, acc: 88.28%] [G loss: 1.260118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45/50] [Batch 1/235] [D loss: 1.109091, acc: 85.74%] [G loss: 1.121647]\n",
      "[Epoch 45/50] [Batch 2/235] [D loss: 1.134709, acc: 88.09%] [G loss: 1.108248]\n",
      "[Epoch 45/50] [Batch 3/235] [D loss: 1.166512, acc: 87.70%] [G loss: 0.977930]\n",
      "[Epoch 45/50] [Batch 4/235] [D loss: 1.127137, acc: 87.11%] [G loss: 1.236384]\n",
      "[Epoch 45/50] [Batch 5/235] [D loss: 1.112337, acc: 87.70%] [G loss: 1.168737]\n",
      "[Epoch 45/50] [Batch 6/235] [D loss: 1.085725, acc: 86.52%] [G loss: 1.173462]\n",
      "[Epoch 45/50] [Batch 7/235] [D loss: 1.149029, acc: 87.70%] [G loss: 1.046250]\n",
      "[Epoch 45/50] [Batch 8/235] [D loss: 1.133292, acc: 86.91%] [G loss: 1.058466]\n",
      "[Epoch 45/50] [Batch 9/235] [D loss: 1.084894, acc: 87.50%] [G loss: 1.235145]\n",
      "[Epoch 45/50] [Batch 10/235] [D loss: 1.085387, acc: 85.35%] [G loss: 1.155151]\n",
      "[Epoch 45/50] [Batch 11/235] [D loss: 1.098026, acc: 90.82%] [G loss: 1.083366]\n",
      "[Epoch 45/50] [Batch 12/235] [D loss: 1.075920, acc: 87.30%] [G loss: 1.154958]\n",
      "[Epoch 45/50] [Batch 13/235] [D loss: 1.065269, acc: 86.33%] [G loss: 1.253832]\n",
      "[Epoch 45/50] [Batch 14/235] [D loss: 1.091827, acc: 87.70%] [G loss: 1.126844]\n",
      "[Epoch 45/50] [Batch 15/235] [D loss: 1.135330, acc: 86.91%] [G loss: 1.074418]\n",
      "[Epoch 45/50] [Batch 16/235] [D loss: 1.063269, acc: 89.06%] [G loss: 1.167667]\n",
      "[Epoch 45/50] [Batch 17/235] [D loss: 1.080182, acc: 89.84%] [G loss: 1.080222]\n",
      "[Epoch 45/50] [Batch 18/235] [D loss: 1.145539, acc: 89.06%] [G loss: 1.180405]\n",
      "[Epoch 45/50] [Batch 19/235] [D loss: 1.116942, acc: 90.82%] [G loss: 1.174674]\n",
      "[Epoch 45/50] [Batch 20/235] [D loss: 1.060705, acc: 89.45%] [G loss: 1.140803]\n",
      "[Epoch 45/50] [Batch 21/235] [D loss: 1.155659, acc: 85.74%] [G loss: 1.237712]\n",
      "[Epoch 45/50] [Batch 22/235] [D loss: 1.084365, acc: 86.33%] [G loss: 1.099451]\n",
      "[Epoch 45/50] [Batch 23/235] [D loss: 1.151144, acc: 88.09%] [G loss: 1.134799]\n",
      "[Epoch 45/50] [Batch 24/235] [D loss: 1.121550, acc: 87.89%] [G loss: 1.166776]\n",
      "[Epoch 45/50] [Batch 25/235] [D loss: 1.107398, acc: 87.30%] [G loss: 1.405075]\n",
      "[Epoch 45/50] [Batch 26/235] [D loss: 1.106250, acc: 89.26%] [G loss: 1.100127]\n",
      "[Epoch 45/50] [Batch 27/235] [D loss: 1.124798, acc: 88.87%] [G loss: 1.054494]\n",
      "[Epoch 45/50] [Batch 28/235] [D loss: 1.142575, acc: 87.11%] [G loss: 1.176528]\n",
      "[Epoch 45/50] [Batch 29/235] [D loss: 1.107044, acc: 88.87%] [G loss: 1.195104]\n",
      "[Epoch 45/50] [Batch 30/235] [D loss: 1.039914, acc: 88.09%] [G loss: 1.091678]\n",
      "[Epoch 45/50] [Batch 31/235] [D loss: 1.144848, acc: 87.30%] [G loss: 1.026542]\n",
      "[Epoch 45/50] [Batch 32/235] [D loss: 1.082259, acc: 85.16%] [G loss: 1.063585]\n",
      "[Epoch 45/50] [Batch 33/235] [D loss: 1.175137, acc: 86.52%] [G loss: 1.269462]\n",
      "[Epoch 45/50] [Batch 34/235] [D loss: 1.121830, acc: 88.87%] [G loss: 1.110012]\n",
      "[Epoch 45/50] [Batch 35/235] [D loss: 1.117329, acc: 84.96%] [G loss: 1.211768]\n",
      "[Epoch 45/50] [Batch 36/235] [D loss: 1.070906, acc: 88.09%] [G loss: 1.244946]\n",
      "[Epoch 45/50] [Batch 37/235] [D loss: 1.067937, acc: 87.50%] [G loss: 1.140438]\n",
      "[Epoch 45/50] [Batch 38/235] [D loss: 1.048717, acc: 88.67%] [G loss: 1.102683]\n",
      "[Epoch 45/50] [Batch 39/235] [D loss: 1.132226, acc: 87.11%] [G loss: 1.082691]\n",
      "[Epoch 45/50] [Batch 40/235] [D loss: 1.114841, acc: 87.30%] [G loss: 1.162431]\n",
      "[Epoch 45/50] [Batch 41/235] [D loss: 1.117829, acc: 88.67%] [G loss: 1.175352]\n",
      "[Epoch 45/50] [Batch 42/235] [D loss: 1.094419, acc: 87.30%] [G loss: 1.010208]\n",
      "[Epoch 45/50] [Batch 43/235] [D loss: 1.134772, acc: 88.48%] [G loss: 1.101170]\n",
      "[Epoch 45/50] [Batch 44/235] [D loss: 1.164429, acc: 87.50%] [G loss: 1.192325]\n",
      "[Epoch 45/50] [Batch 45/235] [D loss: 1.102555, acc: 87.50%] [G loss: 1.141805]\n",
      "[Epoch 45/50] [Batch 46/235] [D loss: 1.139151, acc: 88.09%] [G loss: 1.190717]\n",
      "[Epoch 45/50] [Batch 47/235] [D loss: 1.111559, acc: 88.48%] [G loss: 1.025473]\n",
      "[Epoch 45/50] [Batch 48/235] [D loss: 1.084416, acc: 87.50%] [G loss: 1.252740]\n",
      "[Epoch 45/50] [Batch 49/235] [D loss: 1.164639, acc: 84.77%] [G loss: 1.135755]\n",
      "[Epoch 45/50] [Batch 50/235] [D loss: 1.102967, acc: 84.96%] [G loss: 1.168329]\n",
      "[Epoch 45/50] [Batch 51/235] [D loss: 1.112213, acc: 86.72%] [G loss: 1.186911]\n",
      "[Epoch 45/50] [Batch 52/235] [D loss: 1.111557, acc: 88.87%] [G loss: 1.055795]\n",
      "[Epoch 45/50] [Batch 53/235] [D loss: 1.156188, acc: 87.11%] [G loss: 1.078166]\n",
      "[Epoch 45/50] [Batch 54/235] [D loss: 1.090854, acc: 89.26%] [G loss: 1.105216]\n",
      "[Epoch 45/50] [Batch 55/235] [D loss: 1.133719, acc: 86.72%] [G loss: 1.294676]\n",
      "[Epoch 45/50] [Batch 56/235] [D loss: 1.155016, acc: 90.04%] [G loss: 1.270497]\n",
      "[Epoch 45/50] [Batch 57/235] [D loss: 1.057037, acc: 85.94%] [G loss: 1.143566]\n",
      "[Epoch 45/50] [Batch 58/235] [D loss: 1.088894, acc: 86.72%] [G loss: 1.171247]\n",
      "[Epoch 45/50] [Batch 59/235] [D loss: 1.110723, acc: 88.48%] [G loss: 1.149393]\n",
      "[Epoch 45/50] [Batch 60/235] [D loss: 1.113080, acc: 88.28%] [G loss: 1.357975]\n",
      "[Epoch 45/50] [Batch 61/235] [D loss: 1.069819, acc: 88.48%] [G loss: 1.124618]\n",
      "[Epoch 45/50] [Batch 62/235] [D loss: 1.124256, acc: 86.72%] [G loss: 1.041220]\n",
      "[Epoch 45/50] [Batch 63/235] [D loss: 1.085331, acc: 91.02%] [G loss: 1.073015]\n",
      "[Epoch 45/50] [Batch 64/235] [D loss: 1.147769, acc: 87.50%] [G loss: 1.231366]\n",
      "[Epoch 45/50] [Batch 65/235] [D loss: 1.126444, acc: 83.98%] [G loss: 1.265356]\n",
      "[Epoch 45/50] [Batch 66/235] [D loss: 1.118924, acc: 86.91%] [G loss: 1.188092]\n",
      "[Epoch 45/50] [Batch 67/235] [D loss: 1.128223, acc: 88.09%] [G loss: 1.322431]\n",
      "[Epoch 45/50] [Batch 68/235] [D loss: 1.053492, acc: 87.50%] [G loss: 1.156939]\n",
      "[Epoch 45/50] [Batch 69/235] [D loss: 1.117519, acc: 85.35%] [G loss: 1.137937]\n",
      "[Epoch 45/50] [Batch 70/235] [D loss: 1.104617, acc: 87.50%] [G loss: 1.116328]\n",
      "[Epoch 45/50] [Batch 71/235] [D loss: 1.101842, acc: 86.72%] [G loss: 1.150117]\n",
      "[Epoch 45/50] [Batch 72/235] [D loss: 1.136353, acc: 88.28%] [G loss: 1.158745]\n",
      "[Epoch 45/50] [Batch 73/235] [D loss: 1.109087, acc: 87.50%] [G loss: 1.285345]\n",
      "[Epoch 45/50] [Batch 74/235] [D loss: 1.078587, acc: 88.67%] [G loss: 1.231492]\n",
      "[Epoch 45/50] [Batch 75/235] [D loss: 1.114310, acc: 90.23%] [G loss: 1.189890]\n",
      "[Epoch 45/50] [Batch 76/235] [D loss: 1.129164, acc: 87.50%] [G loss: 1.121530]\n",
      "[Epoch 45/50] [Batch 77/235] [D loss: 1.134656, acc: 87.11%] [G loss: 1.082921]\n",
      "[Epoch 45/50] [Batch 78/235] [D loss: 1.151914, acc: 84.77%] [G loss: 1.301388]\n",
      "[Epoch 45/50] [Batch 79/235] [D loss: 1.104178, acc: 85.74%] [G loss: 1.090837]\n",
      "[Epoch 45/50] [Batch 80/235] [D loss: 1.110749, acc: 86.91%] [G loss: 1.162459]\n",
      "[Epoch 45/50] [Batch 81/235] [D loss: 1.077217, acc: 87.89%] [G loss: 1.186202]\n",
      "[Epoch 45/50] [Batch 82/235] [D loss: 1.105163, acc: 87.50%] [G loss: 1.194738]\n",
      "[Epoch 45/50] [Batch 83/235] [D loss: 1.127896, acc: 86.33%] [G loss: 1.160337]\n",
      "[Epoch 45/50] [Batch 84/235] [D loss: 1.056025, acc: 87.50%] [G loss: 1.069579]\n",
      "[Epoch 45/50] [Batch 85/235] [D loss: 1.112593, acc: 89.84%] [G loss: 1.074951]\n",
      "[Epoch 45/50] [Batch 86/235] [D loss: 1.090423, acc: 88.48%] [G loss: 1.147722]\n",
      "[Epoch 45/50] [Batch 87/235] [D loss: 1.168323, acc: 88.48%] [G loss: 1.249704]\n",
      "[Epoch 45/50] [Batch 88/235] [D loss: 1.089630, acc: 90.43%] [G loss: 1.262141]\n",
      "[Epoch 45/50] [Batch 89/235] [D loss: 1.192326, acc: 85.55%] [G loss: 1.081280]\n",
      "[Epoch 45/50] [Batch 90/235] [D loss: 1.107940, acc: 86.72%] [G loss: 1.323130]\n",
      "[Epoch 45/50] [Batch 91/235] [D loss: 1.109797, acc: 86.33%] [G loss: 1.305261]\n",
      "[Epoch 45/50] [Batch 92/235] [D loss: 1.095908, acc: 88.48%] [G loss: 1.125193]\n",
      "[Epoch 45/50] [Batch 93/235] [D loss: 1.101510, acc: 88.87%] [G loss: 1.110062]\n",
      "[Epoch 45/50] [Batch 94/235] [D loss: 1.079373, acc: 85.16%] [G loss: 1.129128]\n",
      "[Epoch 45/50] [Batch 95/235] [D loss: 1.097776, acc: 88.87%] [G loss: 1.290578]\n",
      "[Epoch 45/50] [Batch 96/235] [D loss: 1.075605, acc: 86.13%] [G loss: 1.233910]\n",
      "[Epoch 45/50] [Batch 97/235] [D loss: 1.128941, acc: 86.33%] [G loss: 1.155772]\n",
      "[Epoch 45/50] [Batch 98/235] [D loss: 1.096562, acc: 87.50%] [G loss: 1.049879]\n",
      "[Epoch 45/50] [Batch 99/235] [D loss: 1.053944, acc: 87.30%] [G loss: 1.034852]\n",
      "[Epoch 45/50] [Batch 100/235] [D loss: 1.067769, acc: 85.94%] [G loss: 1.166237]\n",
      "[Epoch 45/50] [Batch 101/235] [D loss: 1.138294, acc: 87.50%] [G loss: 1.427680]\n",
      "[Epoch 45/50] [Batch 102/235] [D loss: 1.100003, acc: 90.43%] [G loss: 1.273086]\n",
      "[Epoch 45/50] [Batch 103/235] [D loss: 1.147688, acc: 85.94%] [G loss: 1.003651]\n",
      "[Epoch 45/50] [Batch 104/235] [D loss: 1.178384, acc: 88.87%] [G loss: 1.042650]\n",
      "[Epoch 45/50] [Batch 105/235] [D loss: 1.165264, acc: 87.11%] [G loss: 1.284094]\n",
      "[Epoch 45/50] [Batch 106/235] [D loss: 1.081698, acc: 86.91%] [G loss: 1.259889]\n",
      "[Epoch 45/50] [Batch 107/235] [D loss: 1.037118, acc: 89.45%] [G loss: 1.226476]\n",
      "[Epoch 45/50] [Batch 108/235] [D loss: 1.118543, acc: 86.72%] [G loss: 1.112911]\n",
      "[Epoch 45/50] [Batch 109/235] [D loss: 1.128338, acc: 87.50%] [G loss: 1.160356]\n",
      "[Epoch 45/50] [Batch 110/235] [D loss: 1.127620, acc: 89.26%] [G loss: 1.209252]\n",
      "[Epoch 45/50] [Batch 111/235] [D loss: 1.133532, acc: 89.26%] [G loss: 1.071084]\n",
      "[Epoch 45/50] [Batch 112/235] [D loss: 1.130599, acc: 86.91%] [G loss: 1.040911]\n",
      "[Epoch 45/50] [Batch 113/235] [D loss: 1.093400, acc: 88.09%] [G loss: 1.045268]\n",
      "[Epoch 45/50] [Batch 114/235] [D loss: 1.166244, acc: 86.33%] [G loss: 1.050907]\n",
      "[Epoch 45/50] [Batch 115/235] [D loss: 1.128151, acc: 87.30%] [G loss: 1.293709]\n",
      "[Epoch 45/50] [Batch 116/235] [D loss: 1.092934, acc: 89.26%] [G loss: 1.271048]\n",
      "[Epoch 45/50] [Batch 117/235] [D loss: 1.151978, acc: 87.89%] [G loss: 1.156311]\n",
      "[Epoch 45/50] [Batch 118/235] [D loss: 1.107415, acc: 88.48%] [G loss: 1.110419]\n",
      "[Epoch 45/50] [Batch 119/235] [D loss: 1.218265, acc: 87.30%] [G loss: 1.135594]\n",
      "[Epoch 45/50] [Batch 120/235] [D loss: 1.111287, acc: 86.91%] [G loss: 1.228586]\n",
      "[Epoch 45/50] [Batch 121/235] [D loss: 1.110162, acc: 88.09%] [G loss: 1.157749]\n",
      "[Epoch 45/50] [Batch 122/235] [D loss: 1.160619, acc: 88.67%] [G loss: 1.107202]\n",
      "[Epoch 45/50] [Batch 123/235] [D loss: 1.085500, acc: 89.06%] [G loss: 1.059091]\n",
      "[Epoch 45/50] [Batch 124/235] [D loss: 1.122850, acc: 87.50%] [G loss: 1.184648]\n",
      "[Epoch 45/50] [Batch 125/235] [D loss: 1.073364, acc: 87.70%] [G loss: 1.083185]\n",
      "[Epoch 45/50] [Batch 126/235] [D loss: 1.084953, acc: 88.67%] [G loss: 1.191335]\n",
      "[Epoch 45/50] [Batch 127/235] [D loss: 0.998880, acc: 89.26%] [G loss: 1.217262]\n",
      "[Epoch 45/50] [Batch 128/235] [D loss: 1.106990, acc: 87.50%] [G loss: 1.174305]\n",
      "[Epoch 45/50] [Batch 129/235] [D loss: 1.118314, acc: 88.09%] [G loss: 1.151263]\n",
      "[Epoch 45/50] [Batch 130/235] [D loss: 1.088721, acc: 87.89%] [G loss: 1.052238]\n",
      "[Epoch 45/50] [Batch 131/235] [D loss: 1.238841, acc: 85.16%] [G loss: 1.135538]\n",
      "[Epoch 45/50] [Batch 132/235] [D loss: 1.148251, acc: 85.94%] [G loss: 1.224804]\n",
      "[Epoch 45/50] [Batch 133/235] [D loss: 1.098570, acc: 88.09%] [G loss: 1.132385]\n",
      "[Epoch 45/50] [Batch 134/235] [D loss: 1.113417, acc: 87.50%] [G loss: 1.250989]\n",
      "[Epoch 45/50] [Batch 135/235] [D loss: 1.097704, acc: 87.30%] [G loss: 1.115918]\n",
      "[Epoch 45/50] [Batch 136/235] [D loss: 1.089857, acc: 88.09%] [G loss: 1.219790]\n",
      "[Epoch 45/50] [Batch 137/235] [D loss: 1.168774, acc: 86.91%] [G loss: 1.166504]\n",
      "[Epoch 45/50] [Batch 138/235] [D loss: 1.117850, acc: 88.87%] [G loss: 1.183421]\n",
      "[Epoch 45/50] [Batch 139/235] [D loss: 1.080194, acc: 85.94%] [G loss: 1.112231]\n",
      "[Epoch 45/50] [Batch 140/235] [D loss: 1.128037, acc: 86.52%] [G loss: 1.147816]\n",
      "[Epoch 45/50] [Batch 141/235] [D loss: 1.100726, acc: 90.04%] [G loss: 1.058442]\n",
      "[Epoch 45/50] [Batch 142/235] [D loss: 1.088423, acc: 89.26%] [G loss: 1.236484]\n",
      "[Epoch 45/50] [Batch 143/235] [D loss: 1.072332, acc: 85.74%] [G loss: 1.106847]\n",
      "[Epoch 45/50] [Batch 144/235] [D loss: 1.085903, acc: 87.70%] [G loss: 1.074484]\n",
      "[Epoch 45/50] [Batch 145/235] [D loss: 1.109540, acc: 86.72%] [G loss: 1.095504]\n",
      "[Epoch 45/50] [Batch 146/235] [D loss: 1.130864, acc: 87.11%] [G loss: 1.089809]\n",
      "[Epoch 45/50] [Batch 147/235] [D loss: 1.078698, acc: 88.28%] [G loss: 1.164433]\n",
      "[Epoch 45/50] [Batch 148/235] [D loss: 1.141895, acc: 87.50%] [G loss: 1.153783]\n",
      "[Epoch 45/50] [Batch 149/235] [D loss: 1.132587, acc: 86.52%] [G loss: 1.202476]\n",
      "[Epoch 45/50] [Batch 150/235] [D loss: 1.101147, acc: 85.55%] [G loss: 1.060037]\n",
      "[Epoch 45/50] [Batch 151/235] [D loss: 1.170092, acc: 90.04%] [G loss: 1.154866]\n",
      "[Epoch 45/50] [Batch 152/235] [D loss: 1.044732, acc: 88.48%] [G loss: 1.007743]\n",
      "[Epoch 45/50] [Batch 153/235] [D loss: 1.050603, acc: 88.28%] [G loss: 1.053400]\n",
      "[Epoch 45/50] [Batch 154/235] [D loss: 1.127369, acc: 83.20%] [G loss: 1.067068]\n",
      "[Epoch 45/50] [Batch 155/235] [D loss: 1.150394, acc: 88.67%] [G loss: 1.118932]\n",
      "[Epoch 45/50] [Batch 156/235] [D loss: 1.167208, acc: 91.41%] [G loss: 1.103496]\n",
      "[Epoch 45/50] [Batch 157/235] [D loss: 1.043007, acc: 87.70%] [G loss: 1.065398]\n",
      "[Epoch 45/50] [Batch 158/235] [D loss: 1.140417, acc: 87.50%] [G loss: 1.155873]\n",
      "[Epoch 45/50] [Batch 159/235] [D loss: 1.048032, acc: 88.67%] [G loss: 1.152028]\n",
      "[Epoch 45/50] [Batch 160/235] [D loss: 1.165606, acc: 86.52%] [G loss: 1.096993]\n",
      "[Epoch 45/50] [Batch 161/235] [D loss: 1.115962, acc: 87.50%] [G loss: 1.169509]\n",
      "[Epoch 45/50] [Batch 162/235] [D loss: 1.151848, acc: 86.13%] [G loss: 1.080667]\n",
      "[Epoch 45/50] [Batch 163/235] [D loss: 1.073091, acc: 88.67%] [G loss: 1.067351]\n",
      "[Epoch 45/50] [Batch 164/235] [D loss: 1.150228, acc: 87.70%] [G loss: 0.933349]\n",
      "[Epoch 45/50] [Batch 165/235] [D loss: 1.114009, acc: 86.33%] [G loss: 1.464810]\n",
      "[Epoch 45/50] [Batch 166/235] [D loss: 1.092307, acc: 87.11%] [G loss: 1.387121]\n",
      "[Epoch 45/50] [Batch 167/235] [D loss: 1.110233, acc: 88.48%] [G loss: 1.093665]\n",
      "[Epoch 45/50] [Batch 168/235] [D loss: 1.144312, acc: 86.13%] [G loss: 1.046827]\n",
      "[Epoch 45/50] [Batch 169/235] [D loss: 1.066110, acc: 88.09%] [G loss: 1.173775]\n",
      "[Epoch 45/50] [Batch 170/235] [D loss: 1.089436, acc: 89.45%] [G loss: 1.172641]\n",
      "[Epoch 45/50] [Batch 171/235] [D loss: 1.183392, acc: 88.09%] [G loss: 1.022984]\n",
      "[Epoch 45/50] [Batch 172/235] [D loss: 1.112899, acc: 89.06%] [G loss: 1.128823]\n",
      "[Epoch 45/50] [Batch 173/235] [D loss: 1.150162, acc: 86.33%] [G loss: 1.215491]\n",
      "[Epoch 45/50] [Batch 174/235] [D loss: 1.125420, acc: 90.43%] [G loss: 1.121557]\n",
      "[Epoch 45/50] [Batch 175/235] [D loss: 1.128478, acc: 87.89%] [G loss: 1.159819]\n",
      "[Epoch 45/50] [Batch 176/235] [D loss: 1.107680, acc: 86.91%] [G loss: 1.211200]\n",
      "[Epoch 45/50] [Batch 177/235] [D loss: 1.078363, acc: 86.33%] [G loss: 1.258595]\n",
      "[Epoch 45/50] [Batch 178/235] [D loss: 1.061499, acc: 88.28%] [G loss: 1.297361]\n",
      "[Epoch 45/50] [Batch 179/235] [D loss: 1.106409, acc: 89.45%] [G loss: 1.109302]\n",
      "[Epoch 45/50] [Batch 180/235] [D loss: 1.174366, acc: 84.96%] [G loss: 1.269327]\n",
      "[Epoch 45/50] [Batch 181/235] [D loss: 1.168804, acc: 89.65%] [G loss: 1.232058]\n",
      "[Epoch 45/50] [Batch 182/235] [D loss: 1.107660, acc: 87.70%] [G loss: 1.151027]\n",
      "[Epoch 45/50] [Batch 183/235] [D loss: 1.060158, acc: 86.91%] [G loss: 1.008017]\n",
      "[Epoch 45/50] [Batch 184/235] [D loss: 1.096268, acc: 88.09%] [G loss: 1.076956]\n",
      "[Epoch 45/50] [Batch 185/235] [D loss: 1.085340, acc: 86.72%] [G loss: 1.289247]\n",
      "[Epoch 45/50] [Batch 186/235] [D loss: 1.132102, acc: 86.33%] [G loss: 1.158880]\n",
      "[Epoch 45/50] [Batch 187/235] [D loss: 1.098567, acc: 85.94%] [G loss: 1.195068]\n",
      "[Epoch 45/50] [Batch 188/235] [D loss: 1.091231, acc: 85.94%] [G loss: 1.153859]\n",
      "[Epoch 45/50] [Batch 189/235] [D loss: 1.054540, acc: 87.89%] [G loss: 1.131275]\n",
      "[Epoch 45/50] [Batch 190/235] [D loss: 1.081077, acc: 84.77%] [G loss: 1.177989]\n",
      "[Epoch 45/50] [Batch 191/235] [D loss: 1.077045, acc: 89.84%] [G loss: 1.169982]\n",
      "[Epoch 45/50] [Batch 192/235] [D loss: 1.131735, acc: 86.13%] [G loss: 1.248311]\n",
      "[Epoch 45/50] [Batch 193/235] [D loss: 1.072395, acc: 87.11%] [G loss: 1.281835]\n",
      "[Epoch 45/50] [Batch 194/235] [D loss: 1.141536, acc: 86.13%] [G loss: 1.238634]\n",
      "[Epoch 45/50] [Batch 195/235] [D loss: 1.159650, acc: 84.18%] [G loss: 1.153643]\n",
      "[Epoch 45/50] [Batch 196/235] [D loss: 1.147963, acc: 85.16%] [G loss: 1.094733]\n",
      "[Epoch 45/50] [Batch 197/235] [D loss: 1.100442, acc: 86.91%] [G loss: 1.166453]\n",
      "[Epoch 45/50] [Batch 198/235] [D loss: 1.137439, acc: 88.09%] [G loss: 1.269552]\n",
      "[Epoch 45/50] [Batch 199/235] [D loss: 1.159195, acc: 86.13%] [G loss: 1.179573]\n",
      "[Epoch 45/50] [Batch 200/235] [D loss: 1.103103, acc: 89.06%] [G loss: 1.112245]\n",
      "[Epoch 45/50] [Batch 201/235] [D loss: 1.161388, acc: 86.33%] [G loss: 1.084867]\n",
      "[Epoch 45/50] [Batch 202/235] [D loss: 1.149755, acc: 87.89%] [G loss: 1.289176]\n",
      "[Epoch 45/50] [Batch 203/235] [D loss: 1.086976, acc: 88.28%] [G loss: 1.157274]\n",
      "[Epoch 45/50] [Batch 204/235] [D loss: 1.126254, acc: 88.48%] [G loss: 1.077937]\n",
      "[Epoch 45/50] [Batch 205/235] [D loss: 1.093192, acc: 86.72%] [G loss: 1.156962]\n",
      "[Epoch 45/50] [Batch 206/235] [D loss: 1.130587, acc: 86.72%] [G loss: 1.095073]\n",
      "[Epoch 45/50] [Batch 207/235] [D loss: 1.087450, acc: 87.11%] [G loss: 1.145515]\n",
      "[Epoch 45/50] [Batch 208/235] [D loss: 1.144016, acc: 88.67%] [G loss: 1.142843]\n",
      "[Epoch 45/50] [Batch 209/235] [D loss: 1.096587, acc: 87.89%] [G loss: 1.132183]\n",
      "[Epoch 45/50] [Batch 210/235] [D loss: 1.192966, acc: 85.74%] [G loss: 0.971004]\n",
      "[Epoch 45/50] [Batch 211/235] [D loss: 1.074085, acc: 87.89%] [G loss: 1.234353]\n",
      "[Epoch 45/50] [Batch 212/235] [D loss: 1.123917, acc: 86.72%] [G loss: 1.087236]\n",
      "[Epoch 45/50] [Batch 213/235] [D loss: 1.149578, acc: 87.50%] [G loss: 1.147911]\n",
      "[Epoch 45/50] [Batch 214/235] [D loss: 1.127844, acc: 87.30%] [G loss: 1.155491]\n",
      "[Epoch 45/50] [Batch 215/235] [D loss: 1.164785, acc: 87.50%] [G loss: 1.100762]\n",
      "[Epoch 45/50] [Batch 216/235] [D loss: 1.161940, acc: 88.48%] [G loss: 1.261371]\n",
      "[Epoch 45/50] [Batch 217/235] [D loss: 1.110095, acc: 85.94%] [G loss: 1.102795]\n",
      "[Epoch 45/50] [Batch 218/235] [D loss: 1.135316, acc: 89.26%] [G loss: 1.283571]\n",
      "[Epoch 45/50] [Batch 219/235] [D loss: 1.110079, acc: 89.06%] [G loss: 1.087634]\n",
      "[Epoch 45/50] [Batch 220/235] [D loss: 1.102121, acc: 87.70%] [G loss: 1.227004]\n",
      "[Epoch 45/50] [Batch 221/235] [D loss: 1.086025, acc: 87.30%] [G loss: 1.240904]\n",
      "[Epoch 45/50] [Batch 222/235] [D loss: 1.103548, acc: 88.09%] [G loss: 1.049352]\n",
      "[Epoch 45/50] [Batch 223/235] [D loss: 1.146020, acc: 84.57%] [G loss: 1.171202]\n",
      "[Epoch 45/50] [Batch 224/235] [D loss: 1.136879, acc: 87.30%] [G loss: 1.170584]\n",
      "[Epoch 45/50] [Batch 225/235] [D loss: 1.171345, acc: 88.67%] [G loss: 1.144573]\n",
      "[Epoch 45/50] [Batch 226/235] [D loss: 1.099254, acc: 87.30%] [G loss: 1.269043]\n",
      "[Epoch 45/50] [Batch 227/235] [D loss: 1.054304, acc: 87.50%] [G loss: 1.216164]\n",
      "[Epoch 45/50] [Batch 228/235] [D loss: 1.077931, acc: 86.91%] [G loss: 1.199119]\n",
      "[Epoch 45/50] [Batch 229/235] [D loss: 1.115294, acc: 87.70%] [G loss: 1.112602]\n",
      "[Epoch 45/50] [Batch 230/235] [D loss: 1.090498, acc: 85.74%] [G loss: 1.202068]\n",
      "[Epoch 45/50] [Batch 231/235] [D loss: 1.189689, acc: 83.98%] [G loss: 1.293977]\n",
      "[Epoch 45/50] [Batch 232/235] [D loss: 1.072924, acc: 87.50%] [G loss: 1.187656]\n",
      "[Epoch 45/50] [Batch 233/235] [D loss: 1.090448, acc: 89.65%] [G loss: 1.120557]\n",
      "[Epoch 45/50] [Batch 234/235] [D loss: 1.071853, acc: 91.15%] [G loss: 1.237667]\n",
      "[Epoch 46/50] [Batch 0/235] [D loss: 1.091149, acc: 88.87%] [G loss: 1.114475]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46/50] [Batch 1/235] [D loss: 1.040798, acc: 89.45%] [G loss: 1.139735]\n",
      "[Epoch 46/50] [Batch 2/235] [D loss: 1.126415, acc: 88.09%] [G loss: 1.244642]\n",
      "[Epoch 46/50] [Batch 3/235] [D loss: 1.102575, acc: 89.26%] [G loss: 1.211575]\n",
      "[Epoch 46/50] [Batch 4/235] [D loss: 1.131993, acc: 88.87%] [G loss: 1.193872]\n",
      "[Epoch 46/50] [Batch 5/235] [D loss: 1.163328, acc: 83.40%] [G loss: 1.081177]\n",
      "[Epoch 46/50] [Batch 6/235] [D loss: 1.068663, acc: 88.48%] [G loss: 1.064332]\n",
      "[Epoch 46/50] [Batch 7/235] [D loss: 1.126639, acc: 86.91%] [G loss: 1.108114]\n",
      "[Epoch 46/50] [Batch 8/235] [D loss: 1.082655, acc: 88.67%] [G loss: 1.199016]\n",
      "[Epoch 46/50] [Batch 9/235] [D loss: 1.151708, acc: 85.35%] [G loss: 1.156249]\n",
      "[Epoch 46/50] [Batch 10/235] [D loss: 1.157737, acc: 87.70%] [G loss: 1.121723]\n",
      "[Epoch 46/50] [Batch 11/235] [D loss: 1.142413, acc: 88.09%] [G loss: 1.189766]\n",
      "[Epoch 46/50] [Batch 12/235] [D loss: 1.070552, acc: 89.06%] [G loss: 1.211823]\n",
      "[Epoch 46/50] [Batch 13/235] [D loss: 1.146060, acc: 85.94%] [G loss: 1.130994]\n",
      "[Epoch 46/50] [Batch 14/235] [D loss: 1.125221, acc: 88.48%] [G loss: 1.238734]\n",
      "[Epoch 46/50] [Batch 15/235] [D loss: 1.060380, acc: 89.26%] [G loss: 1.247385]\n",
      "[Epoch 46/50] [Batch 16/235] [D loss: 1.090732, acc: 89.06%] [G loss: 1.100626]\n",
      "[Epoch 46/50] [Batch 17/235] [D loss: 1.125863, acc: 84.57%] [G loss: 0.937946]\n",
      "[Epoch 46/50] [Batch 18/235] [D loss: 1.066417, acc: 88.28%] [G loss: 1.040104]\n",
      "[Epoch 46/50] [Batch 19/235] [D loss: 1.149038, acc: 86.72%] [G loss: 1.333601]\n",
      "[Epoch 46/50] [Batch 20/235] [D loss: 1.138064, acc: 88.28%] [G loss: 1.208667]\n",
      "[Epoch 46/50] [Batch 21/235] [D loss: 1.077068, acc: 88.28%] [G loss: 1.160380]\n",
      "[Epoch 46/50] [Batch 22/235] [D loss: 1.112560, acc: 88.09%] [G loss: 1.138970]\n",
      "[Epoch 46/50] [Batch 23/235] [D loss: 1.125505, acc: 86.72%] [G loss: 1.190713]\n",
      "[Epoch 46/50] [Batch 24/235] [D loss: 1.083878, acc: 89.06%] [G loss: 1.118736]\n",
      "[Epoch 46/50] [Batch 25/235] [D loss: 1.098710, acc: 86.91%] [G loss: 1.244102]\n",
      "[Epoch 46/50] [Batch 26/235] [D loss: 1.155036, acc: 87.89%] [G loss: 1.219038]\n",
      "[Epoch 46/50] [Batch 27/235] [D loss: 1.102931, acc: 88.09%] [G loss: 1.122713]\n",
      "[Epoch 46/50] [Batch 28/235] [D loss: 1.151124, acc: 86.13%] [G loss: 1.164082]\n",
      "[Epoch 46/50] [Batch 29/235] [D loss: 1.071151, acc: 89.26%] [G loss: 1.202998]\n",
      "[Epoch 46/50] [Batch 30/235] [D loss: 1.132191, acc: 85.94%] [G loss: 1.113366]\n",
      "[Epoch 46/50] [Batch 31/235] [D loss: 1.147055, acc: 88.09%] [G loss: 1.132221]\n",
      "[Epoch 46/50] [Batch 32/235] [D loss: 1.130155, acc: 88.28%] [G loss: 1.082561]\n",
      "[Epoch 46/50] [Batch 33/235] [D loss: 1.118231, acc: 89.06%] [G loss: 1.228811]\n",
      "[Epoch 46/50] [Batch 34/235] [D loss: 1.133103, acc: 87.30%] [G loss: 1.148103]\n",
      "[Epoch 46/50] [Batch 35/235] [D loss: 1.095859, acc: 88.09%] [G loss: 1.022278]\n",
      "[Epoch 46/50] [Batch 36/235] [D loss: 1.112480, acc: 86.91%] [G loss: 0.950086]\n",
      "[Epoch 46/50] [Batch 37/235] [D loss: 1.099528, acc: 90.62%] [G loss: 1.141842]\n",
      "[Epoch 46/50] [Batch 38/235] [D loss: 1.155639, acc: 89.45%] [G loss: 1.224184]\n",
      "[Epoch 46/50] [Batch 39/235] [D loss: 1.099615, acc: 87.30%] [G loss: 1.171896]\n",
      "[Epoch 46/50] [Batch 40/235] [D loss: 1.067014, acc: 88.09%] [G loss: 1.130714]\n",
      "[Epoch 46/50] [Batch 41/235] [D loss: 1.137877, acc: 87.89%] [G loss: 1.146620]\n",
      "[Epoch 46/50] [Batch 42/235] [D loss: 1.170815, acc: 87.11%] [G loss: 1.050633]\n",
      "[Epoch 46/50] [Batch 43/235] [D loss: 1.120867, acc: 85.74%] [G loss: 1.098343]\n",
      "[Epoch 46/50] [Batch 44/235] [D loss: 1.172722, acc: 89.84%] [G loss: 1.354195]\n",
      "[Epoch 46/50] [Batch 45/235] [D loss: 1.111979, acc: 88.09%] [G loss: 1.215329]\n",
      "[Epoch 46/50] [Batch 46/235] [D loss: 1.133428, acc: 86.72%] [G loss: 1.138185]\n",
      "[Epoch 46/50] [Batch 47/235] [D loss: 1.108234, acc: 89.06%] [G loss: 1.133802]\n",
      "[Epoch 46/50] [Batch 48/235] [D loss: 1.096867, acc: 86.52%] [G loss: 1.088179]\n",
      "[Epoch 46/50] [Batch 49/235] [D loss: 1.098216, acc: 87.50%] [G loss: 1.302543]\n",
      "[Epoch 46/50] [Batch 50/235] [D loss: 1.079881, acc: 87.70%] [G loss: 1.096714]\n",
      "[Epoch 46/50] [Batch 51/235] [D loss: 1.062825, acc: 86.72%] [G loss: 1.129984]\n",
      "[Epoch 46/50] [Batch 52/235] [D loss: 1.064309, acc: 89.06%] [G loss: 0.932953]\n",
      "[Epoch 46/50] [Batch 53/235] [D loss: 1.108644, acc: 87.50%] [G loss: 1.155644]\n",
      "[Epoch 46/50] [Batch 54/235] [D loss: 1.102909, acc: 85.16%] [G loss: 1.130738]\n",
      "[Epoch 46/50] [Batch 55/235] [D loss: 1.129228, acc: 85.94%] [G loss: 1.069147]\n",
      "[Epoch 46/50] [Batch 56/235] [D loss: 1.104367, acc: 86.91%] [G loss: 1.274613]\n",
      "[Epoch 46/50] [Batch 57/235] [D loss: 1.064630, acc: 90.62%] [G loss: 1.197195]\n",
      "[Epoch 46/50] [Batch 58/235] [D loss: 1.074043, acc: 90.62%] [G loss: 1.214587]\n",
      "[Epoch 46/50] [Batch 59/235] [D loss: 1.137993, acc: 87.30%] [G loss: 1.174968]\n",
      "[Epoch 46/50] [Batch 60/235] [D loss: 1.097023, acc: 85.16%] [G loss: 1.139630]\n",
      "[Epoch 46/50] [Batch 61/235] [D loss: 1.042792, acc: 85.35%] [G loss: 1.191495]\n",
      "[Epoch 46/50] [Batch 62/235] [D loss: 1.130419, acc: 88.28%] [G loss: 1.153389]\n",
      "[Epoch 46/50] [Batch 63/235] [D loss: 1.157554, acc: 89.65%] [G loss: 1.007430]\n",
      "[Epoch 46/50] [Batch 64/235] [D loss: 1.090910, acc: 85.16%] [G loss: 1.077059]\n",
      "[Epoch 46/50] [Batch 65/235] [D loss: 1.096044, acc: 88.09%] [G loss: 1.180973]\n",
      "[Epoch 46/50] [Batch 66/235] [D loss: 1.073047, acc: 88.28%] [G loss: 1.081083]\n",
      "[Epoch 46/50] [Batch 67/235] [D loss: 1.134879, acc: 88.28%] [G loss: 1.221925]\n",
      "[Epoch 46/50] [Batch 68/235] [D loss: 1.100031, acc: 85.35%] [G loss: 1.275236]\n",
      "[Epoch 46/50] [Batch 69/235] [D loss: 1.030182, acc: 88.67%] [G loss: 1.113308]\n",
      "[Epoch 46/50] [Batch 70/235] [D loss: 1.048985, acc: 87.70%] [G loss: 1.064847]\n",
      "[Epoch 46/50] [Batch 71/235] [D loss: 1.130210, acc: 88.67%] [G loss: 1.173517]\n",
      "[Epoch 46/50] [Batch 72/235] [D loss: 1.118487, acc: 85.55%] [G loss: 1.102232]\n",
      "[Epoch 46/50] [Batch 73/235] [D loss: 1.186652, acc: 88.87%] [G loss: 1.080701]\n",
      "[Epoch 46/50] [Batch 74/235] [D loss: 1.085689, acc: 88.87%] [G loss: 1.169512]\n",
      "[Epoch 46/50] [Batch 75/235] [D loss: 1.108571, acc: 84.57%] [G loss: 1.167571]\n",
      "[Epoch 46/50] [Batch 76/235] [D loss: 1.076638, acc: 87.30%] [G loss: 1.158409]\n",
      "[Epoch 46/50] [Batch 77/235] [D loss: 1.135316, acc: 88.28%] [G loss: 1.206347]\n",
      "[Epoch 46/50] [Batch 78/235] [D loss: 1.114268, acc: 85.35%] [G loss: 1.184237]\n",
      "[Epoch 46/50] [Batch 79/235] [D loss: 1.143019, acc: 84.96%] [G loss: 1.122221]\n",
      "[Epoch 46/50] [Batch 80/235] [D loss: 1.096182, acc: 87.11%] [G loss: 1.306578]\n",
      "[Epoch 46/50] [Batch 81/235] [D loss: 1.152627, acc: 86.72%] [G loss: 1.101774]\n",
      "[Epoch 46/50] [Batch 82/235] [D loss: 1.060402, acc: 88.48%] [G loss: 1.092045]\n",
      "[Epoch 46/50] [Batch 83/235] [D loss: 1.106205, acc: 89.26%] [G loss: 1.082688]\n",
      "[Epoch 46/50] [Batch 84/235] [D loss: 1.092248, acc: 85.74%] [G loss: 1.146356]\n",
      "[Epoch 46/50] [Batch 85/235] [D loss: 1.114386, acc: 87.89%] [G loss: 1.142130]\n",
      "[Epoch 46/50] [Batch 86/235] [D loss: 1.108602, acc: 88.87%] [G loss: 1.225003]\n",
      "[Epoch 46/50] [Batch 87/235] [D loss: 1.159138, acc: 87.50%] [G loss: 1.270206]\n",
      "[Epoch 46/50] [Batch 88/235] [D loss: 1.053997, acc: 87.70%] [G loss: 1.260020]\n",
      "[Epoch 46/50] [Batch 89/235] [D loss: 1.150323, acc: 87.30%] [G loss: 1.239458]\n",
      "[Epoch 46/50] [Batch 90/235] [D loss: 1.102229, acc: 86.91%] [G loss: 1.121058]\n",
      "[Epoch 46/50] [Batch 91/235] [D loss: 1.074507, acc: 87.70%] [G loss: 1.091374]\n",
      "[Epoch 46/50] [Batch 92/235] [D loss: 1.067461, acc: 89.45%] [G loss: 1.184468]\n",
      "[Epoch 46/50] [Batch 93/235] [D loss: 1.191340, acc: 86.52%] [G loss: 1.339105]\n",
      "[Epoch 46/50] [Batch 94/235] [D loss: 1.114009, acc: 87.70%] [G loss: 1.276464]\n",
      "[Epoch 46/50] [Batch 95/235] [D loss: 1.088959, acc: 88.87%] [G loss: 0.998182]\n",
      "[Epoch 46/50] [Batch 96/235] [D loss: 1.030976, acc: 86.33%] [G loss: 1.087698]\n",
      "[Epoch 46/50] [Batch 97/235] [D loss: 1.065425, acc: 89.45%] [G loss: 1.166572]\n",
      "[Epoch 46/50] [Batch 98/235] [D loss: 1.089202, acc: 87.50%] [G loss: 1.293149]\n",
      "[Epoch 46/50] [Batch 99/235] [D loss: 1.123172, acc: 85.94%] [G loss: 1.202433]\n",
      "[Epoch 46/50] [Batch 100/235] [D loss: 1.084942, acc: 84.96%] [G loss: 1.165756]\n",
      "[Epoch 46/50] [Batch 101/235] [D loss: 1.183395, acc: 86.91%] [G loss: 1.120178]\n",
      "[Epoch 46/50] [Batch 102/235] [D loss: 1.113438, acc: 86.33%] [G loss: 1.437335]\n",
      "[Epoch 46/50] [Batch 103/235] [D loss: 1.087452, acc: 87.11%] [G loss: 1.138014]\n",
      "[Epoch 46/50] [Batch 104/235] [D loss: 1.092238, acc: 88.28%] [G loss: 1.124583]\n",
      "[Epoch 46/50] [Batch 105/235] [D loss: 1.154369, acc: 89.26%] [G loss: 1.121950]\n",
      "[Epoch 46/50] [Batch 106/235] [D loss: 1.122835, acc: 87.30%] [G loss: 1.063014]\n",
      "[Epoch 46/50] [Batch 107/235] [D loss: 1.168474, acc: 87.70%] [G loss: 1.331419]\n",
      "[Epoch 46/50] [Batch 108/235] [D loss: 1.151977, acc: 85.35%] [G loss: 1.197106]\n",
      "[Epoch 46/50] [Batch 109/235] [D loss: 1.099655, acc: 88.87%] [G loss: 1.204053]\n",
      "[Epoch 46/50] [Batch 110/235] [D loss: 1.122857, acc: 90.04%] [G loss: 1.005820]\n",
      "[Epoch 46/50] [Batch 111/235] [D loss: 1.137286, acc: 88.28%] [G loss: 1.148853]\n",
      "[Epoch 46/50] [Batch 112/235] [D loss: 1.114615, acc: 86.52%] [G loss: 1.084705]\n",
      "[Epoch 46/50] [Batch 113/235] [D loss: 1.192752, acc: 89.06%] [G loss: 1.151843]\n",
      "[Epoch 46/50] [Batch 114/235] [D loss: 1.124575, acc: 90.43%] [G loss: 1.152305]\n",
      "[Epoch 46/50] [Batch 115/235] [D loss: 1.175340, acc: 86.91%] [G loss: 1.146660]\n",
      "[Epoch 46/50] [Batch 116/235] [D loss: 1.027046, acc: 91.41%] [G loss: 1.335239]\n",
      "[Epoch 46/50] [Batch 117/235] [D loss: 1.092162, acc: 87.89%] [G loss: 1.251972]\n",
      "[Epoch 46/50] [Batch 118/235] [D loss: 1.124038, acc: 88.87%] [G loss: 1.113540]\n",
      "[Epoch 46/50] [Batch 119/235] [D loss: 1.099759, acc: 87.30%] [G loss: 1.172198]\n",
      "[Epoch 46/50] [Batch 120/235] [D loss: 1.163046, acc: 87.50%] [G loss: 1.132966]\n",
      "[Epoch 46/50] [Batch 121/235] [D loss: 1.105383, acc: 87.50%] [G loss: 1.254388]\n",
      "[Epoch 46/50] [Batch 122/235] [D loss: 1.085734, acc: 87.89%] [G loss: 1.102626]\n",
      "[Epoch 46/50] [Batch 123/235] [D loss: 1.071768, acc: 89.06%] [G loss: 1.238005]\n",
      "[Epoch 46/50] [Batch 124/235] [D loss: 1.116706, acc: 86.72%] [G loss: 1.100788]\n",
      "[Epoch 46/50] [Batch 125/235] [D loss: 1.140551, acc: 88.09%] [G loss: 1.193678]\n",
      "[Epoch 46/50] [Batch 126/235] [D loss: 1.140884, acc: 85.94%] [G loss: 1.191604]\n",
      "[Epoch 46/50] [Batch 127/235] [D loss: 1.184203, acc: 86.91%] [G loss: 1.276775]\n",
      "[Epoch 46/50] [Batch 128/235] [D loss: 1.109595, acc: 86.91%] [G loss: 1.120042]\n",
      "[Epoch 46/50] [Batch 129/235] [D loss: 1.110632, acc: 88.48%] [G loss: 1.100590]\n",
      "[Epoch 46/50] [Batch 130/235] [D loss: 1.096021, acc: 87.89%] [G loss: 0.981340]\n",
      "[Epoch 46/50] [Batch 131/235] [D loss: 1.089294, acc: 86.91%] [G loss: 1.178462]\n",
      "[Epoch 46/50] [Batch 132/235] [D loss: 1.115302, acc: 89.06%] [G loss: 1.123918]\n",
      "[Epoch 46/50] [Batch 133/235] [D loss: 1.115581, acc: 87.50%] [G loss: 1.271598]\n",
      "[Epoch 46/50] [Batch 134/235] [D loss: 1.092276, acc: 87.50%] [G loss: 1.130696]\n",
      "[Epoch 46/50] [Batch 135/235] [D loss: 1.104137, acc: 89.65%] [G loss: 1.225187]\n",
      "[Epoch 46/50] [Batch 136/235] [D loss: 1.122148, acc: 88.09%] [G loss: 1.065349]\n",
      "[Epoch 46/50] [Batch 137/235] [D loss: 1.154078, acc: 85.16%] [G loss: 1.207272]\n",
      "[Epoch 46/50] [Batch 138/235] [D loss: 1.052705, acc: 89.26%] [G loss: 1.233215]\n",
      "[Epoch 46/50] [Batch 139/235] [D loss: 1.054145, acc: 89.06%] [G loss: 1.247304]\n",
      "[Epoch 46/50] [Batch 140/235] [D loss: 1.097997, acc: 86.72%] [G loss: 1.107640]\n",
      "[Epoch 46/50] [Batch 141/235] [D loss: 1.094284, acc: 87.30%] [G loss: 1.106640]\n",
      "[Epoch 46/50] [Batch 142/235] [D loss: 1.031700, acc: 89.26%] [G loss: 1.082098]\n",
      "[Epoch 46/50] [Batch 143/235] [D loss: 1.109233, acc: 89.84%] [G loss: 1.118174]\n",
      "[Epoch 46/50] [Batch 144/235] [D loss: 1.114743, acc: 85.74%] [G loss: 1.093896]\n",
      "[Epoch 46/50] [Batch 145/235] [D loss: 1.132088, acc: 88.87%] [G loss: 1.231808]\n",
      "[Epoch 46/50] [Batch 146/235] [D loss: 1.109252, acc: 89.65%] [G loss: 1.252577]\n",
      "[Epoch 46/50] [Batch 147/235] [D loss: 1.088323, acc: 86.91%] [G loss: 1.087466]\n",
      "[Epoch 46/50] [Batch 148/235] [D loss: 1.144876, acc: 87.11%] [G loss: 1.143833]\n",
      "[Epoch 46/50] [Batch 149/235] [D loss: 1.104149, acc: 83.79%] [G loss: 1.159913]\n",
      "[Epoch 46/50] [Batch 150/235] [D loss: 1.117363, acc: 87.50%] [G loss: 1.145827]\n",
      "[Epoch 46/50] [Batch 151/235] [D loss: 1.205425, acc: 89.45%] [G loss: 1.264497]\n",
      "[Epoch 46/50] [Batch 152/235] [D loss: 1.161346, acc: 87.30%] [G loss: 1.054870]\n",
      "[Epoch 46/50] [Batch 153/235] [D loss: 1.074932, acc: 86.52%] [G loss: 1.260209]\n",
      "[Epoch 46/50] [Batch 154/235] [D loss: 1.143933, acc: 85.74%] [G loss: 1.192750]\n",
      "[Epoch 46/50] [Batch 155/235] [D loss: 1.106314, acc: 86.72%] [G loss: 1.136340]\n",
      "[Epoch 46/50] [Batch 156/235] [D loss: 1.134780, acc: 87.11%] [G loss: 1.029556]\n",
      "[Epoch 46/50] [Batch 157/235] [D loss: 1.126746, acc: 86.33%] [G loss: 1.139017]\n",
      "[Epoch 46/50] [Batch 158/235] [D loss: 1.106545, acc: 87.50%] [G loss: 1.181066]\n",
      "[Epoch 46/50] [Batch 159/235] [D loss: 1.143832, acc: 88.09%] [G loss: 1.200335]\n",
      "[Epoch 46/50] [Batch 160/235] [D loss: 1.111747, acc: 88.87%] [G loss: 1.162817]\n",
      "[Epoch 46/50] [Batch 161/235] [D loss: 1.174624, acc: 87.11%] [G loss: 1.147482]\n",
      "[Epoch 46/50] [Batch 162/235] [D loss: 1.123273, acc: 89.06%] [G loss: 1.016218]\n",
      "[Epoch 46/50] [Batch 163/235] [D loss: 1.151589, acc: 84.38%] [G loss: 1.144332]\n",
      "[Epoch 46/50] [Batch 164/235] [D loss: 1.058953, acc: 88.09%] [G loss: 1.111283]\n",
      "[Epoch 46/50] [Batch 165/235] [D loss: 1.088391, acc: 86.33%] [G loss: 1.247881]\n",
      "[Epoch 46/50] [Batch 166/235] [D loss: 1.126362, acc: 86.13%] [G loss: 1.261273]\n",
      "[Epoch 46/50] [Batch 167/235] [D loss: 1.098967, acc: 87.70%] [G loss: 1.149980]\n",
      "[Epoch 46/50] [Batch 168/235] [D loss: 1.145660, acc: 87.70%] [G loss: 1.082132]\n",
      "[Epoch 46/50] [Batch 169/235] [D loss: 1.102484, acc: 87.11%] [G loss: 1.128389]\n",
      "[Epoch 46/50] [Batch 170/235] [D loss: 1.088402, acc: 88.28%] [G loss: 1.244463]\n",
      "[Epoch 46/50] [Batch 171/235] [D loss: 1.131676, acc: 86.13%] [G loss: 1.114125]\n",
      "[Epoch 46/50] [Batch 172/235] [D loss: 1.089773, acc: 88.87%] [G loss: 1.214397]\n",
      "[Epoch 46/50] [Batch 173/235] [D loss: 1.149004, acc: 87.50%] [G loss: 1.209701]\n",
      "[Epoch 46/50] [Batch 174/235] [D loss: 1.157888, acc: 90.82%] [G loss: 1.186908]\n",
      "[Epoch 46/50] [Batch 175/235] [D loss: 1.042259, acc: 90.62%] [G loss: 1.098386]\n",
      "[Epoch 46/50] [Batch 176/235] [D loss: 1.137274, acc: 87.11%] [G loss: 1.111512]\n",
      "[Epoch 46/50] [Batch 177/235] [D loss: 1.073190, acc: 89.06%] [G loss: 1.056869]\n",
      "[Epoch 46/50] [Batch 178/235] [D loss: 1.053321, acc: 88.28%] [G loss: 1.164810]\n",
      "[Epoch 46/50] [Batch 179/235] [D loss: 1.100718, acc: 88.67%] [G loss: 1.303988]\n",
      "[Epoch 46/50] [Batch 180/235] [D loss: 1.110466, acc: 88.48%] [G loss: 1.146055]\n",
      "[Epoch 46/50] [Batch 181/235] [D loss: 1.056207, acc: 88.09%] [G loss: 1.100435]\n",
      "[Epoch 46/50] [Batch 182/235] [D loss: 1.089713, acc: 85.74%] [G loss: 1.157479]\n",
      "[Epoch 46/50] [Batch 183/235] [D loss: 1.122139, acc: 87.11%] [G loss: 1.179161]\n",
      "[Epoch 46/50] [Batch 184/235] [D loss: 1.129824, acc: 87.11%] [G loss: 1.242587]\n",
      "[Epoch 46/50] [Batch 185/235] [D loss: 1.160233, acc: 90.04%] [G loss: 1.094640]\n",
      "[Epoch 46/50] [Batch 186/235] [D loss: 1.032586, acc: 87.30%] [G loss: 1.239925]\n",
      "[Epoch 46/50] [Batch 187/235] [D loss: 1.087083, acc: 88.67%] [G loss: 1.217188]\n",
      "[Epoch 46/50] [Batch 188/235] [D loss: 1.189269, acc: 88.28%] [G loss: 1.153161]\n",
      "[Epoch 46/50] [Batch 189/235] [D loss: 1.100709, acc: 88.67%] [G loss: 1.159800]\n",
      "[Epoch 46/50] [Batch 190/235] [D loss: 1.088528, acc: 87.70%] [G loss: 1.307561]\n",
      "[Epoch 46/50] [Batch 191/235] [D loss: 1.102638, acc: 85.55%] [G loss: 1.069167]\n",
      "[Epoch 46/50] [Batch 192/235] [D loss: 1.134566, acc: 89.45%] [G loss: 1.153794]\n",
      "[Epoch 46/50] [Batch 193/235] [D loss: 1.146785, acc: 87.50%] [G loss: 1.225241]\n",
      "[Epoch 46/50] [Batch 194/235] [D loss: 1.064598, acc: 88.48%] [G loss: 1.188671]\n",
      "[Epoch 46/50] [Batch 195/235] [D loss: 1.148063, acc: 87.89%] [G loss: 1.118420]\n",
      "[Epoch 46/50] [Batch 196/235] [D loss: 1.091051, acc: 89.26%] [G loss: 1.202632]\n",
      "[Epoch 46/50] [Batch 197/235] [D loss: 1.150501, acc: 86.91%] [G loss: 1.129320]\n",
      "[Epoch 46/50] [Batch 198/235] [D loss: 1.193304, acc: 88.87%] [G loss: 1.251719]\n",
      "[Epoch 46/50] [Batch 199/235] [D loss: 1.097601, acc: 89.45%] [G loss: 1.285549]\n",
      "[Epoch 46/50] [Batch 200/235] [D loss: 1.125250, acc: 87.50%] [G loss: 1.119324]\n",
      "[Epoch 46/50] [Batch 201/235] [D loss: 1.104297, acc: 89.26%] [G loss: 1.056481]\n",
      "[Epoch 46/50] [Batch 202/235] [D loss: 1.197370, acc: 85.74%] [G loss: 1.012507]\n",
      "[Epoch 46/50] [Batch 203/235] [D loss: 1.112682, acc: 88.48%] [G loss: 1.208822]\n",
      "[Epoch 46/50] [Batch 204/235] [D loss: 1.156368, acc: 85.94%] [G loss: 1.214211]\n",
      "[Epoch 46/50] [Batch 205/235] [D loss: 1.069124, acc: 88.67%] [G loss: 1.099881]\n",
      "[Epoch 46/50] [Batch 206/235] [D loss: 1.033683, acc: 86.13%] [G loss: 1.118035]\n",
      "[Epoch 46/50] [Batch 207/235] [D loss: 1.165207, acc: 85.74%] [G loss: 1.057032]\n",
      "[Epoch 46/50] [Batch 208/235] [D loss: 1.132976, acc: 85.35%] [G loss: 1.229352]\n",
      "[Epoch 46/50] [Batch 209/235] [D loss: 1.095160, acc: 88.67%] [G loss: 1.182575]\n",
      "[Epoch 46/50] [Batch 210/235] [D loss: 1.115821, acc: 84.96%] [G loss: 1.211167]\n",
      "[Epoch 46/50] [Batch 211/235] [D loss: 1.129254, acc: 86.52%] [G loss: 1.180257]\n",
      "[Epoch 46/50] [Batch 212/235] [D loss: 1.167974, acc: 89.26%] [G loss: 1.101074]\n",
      "[Epoch 46/50] [Batch 213/235] [D loss: 1.178051, acc: 86.91%] [G loss: 1.137405]\n",
      "[Epoch 46/50] [Batch 214/235] [D loss: 1.180829, acc: 84.57%] [G loss: 1.089464]\n",
      "[Epoch 46/50] [Batch 215/235] [D loss: 1.106618, acc: 86.52%] [G loss: 1.285219]\n",
      "[Epoch 46/50] [Batch 216/235] [D loss: 1.126283, acc: 87.30%] [G loss: 1.369120]\n",
      "[Epoch 46/50] [Batch 217/235] [D loss: 1.098768, acc: 87.11%] [G loss: 1.216945]\n",
      "[Epoch 46/50] [Batch 218/235] [D loss: 1.086929, acc: 89.84%] [G loss: 1.059082]\n",
      "[Epoch 46/50] [Batch 219/235] [D loss: 1.122814, acc: 89.26%] [G loss: 1.136289]\n",
      "[Epoch 46/50] [Batch 220/235] [D loss: 1.087043, acc: 85.94%] [G loss: 1.144216]\n",
      "[Epoch 46/50] [Batch 221/235] [D loss: 1.120540, acc: 86.91%] [G loss: 1.081274]\n",
      "[Epoch 46/50] [Batch 222/235] [D loss: 1.063619, acc: 87.11%] [G loss: 1.017623]\n",
      "[Epoch 46/50] [Batch 223/235] [D loss: 1.044165, acc: 88.87%] [G loss: 1.177388]\n",
      "[Epoch 46/50] [Batch 224/235] [D loss: 1.164500, acc: 87.70%] [G loss: 1.187200]\n",
      "[Epoch 46/50] [Batch 225/235] [D loss: 1.084097, acc: 85.55%] [G loss: 1.222719]\n",
      "[Epoch 46/50] [Batch 226/235] [D loss: 1.118805, acc: 89.65%] [G loss: 1.107787]\n",
      "[Epoch 46/50] [Batch 227/235] [D loss: 1.096983, acc: 86.52%] [G loss: 1.179353]\n",
      "[Epoch 46/50] [Batch 228/235] [D loss: 1.046927, acc: 89.26%] [G loss: 1.098586]\n",
      "[Epoch 46/50] [Batch 229/235] [D loss: 1.062861, acc: 84.96%] [G loss: 1.119346]\n",
      "[Epoch 46/50] [Batch 230/235] [D loss: 1.161091, acc: 87.30%] [G loss: 1.089865]\n",
      "[Epoch 46/50] [Batch 231/235] [D loss: 1.250714, acc: 84.77%] [G loss: 1.238604]\n",
      "[Epoch 46/50] [Batch 232/235] [D loss: 1.136080, acc: 89.06%] [G loss: 1.141243]\n",
      "[Epoch 46/50] [Batch 233/235] [D loss: 1.069368, acc: 89.65%] [G loss: 1.121063]\n",
      "[Epoch 46/50] [Batch 234/235] [D loss: 1.052153, acc: 86.46%] [G loss: 1.175978]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/50] [Batch 0/235] [D loss: 1.136245, acc: 88.67%] [G loss: 1.172272]\n",
      "[Epoch 47/50] [Batch 1/235] [D loss: 1.103175, acc: 86.72%] [G loss: 1.239026]\n",
      "[Epoch 47/50] [Batch 2/235] [D loss: 1.115156, acc: 87.30%] [G loss: 1.146700]\n",
      "[Epoch 47/50] [Batch 3/235] [D loss: 1.071502, acc: 87.11%] [G loss: 1.129505]\n",
      "[Epoch 47/50] [Batch 4/235] [D loss: 1.106112, acc: 87.70%] [G loss: 1.037018]\n",
      "[Epoch 47/50] [Batch 5/235] [D loss: 1.123025, acc: 87.89%] [G loss: 1.127903]\n",
      "[Epoch 47/50] [Batch 6/235] [D loss: 1.149182, acc: 89.65%] [G loss: 1.224837]\n",
      "[Epoch 47/50] [Batch 7/235] [D loss: 1.147500, acc: 88.09%] [G loss: 1.043203]\n",
      "[Epoch 47/50] [Batch 8/235] [D loss: 1.108712, acc: 89.26%] [G loss: 1.200183]\n",
      "[Epoch 47/50] [Batch 9/235] [D loss: 1.125057, acc: 89.65%] [G loss: 1.339841]\n",
      "[Epoch 47/50] [Batch 10/235] [D loss: 1.086275, acc: 88.67%] [G loss: 1.110491]\n",
      "[Epoch 47/50] [Batch 11/235] [D loss: 1.113267, acc: 89.45%] [G loss: 1.137122]\n",
      "[Epoch 47/50] [Batch 12/235] [D loss: 1.113917, acc: 86.91%] [G loss: 1.128513]\n",
      "[Epoch 47/50] [Batch 13/235] [D loss: 1.085115, acc: 86.33%] [G loss: 1.237508]\n",
      "[Epoch 47/50] [Batch 14/235] [D loss: 1.140877, acc: 88.28%] [G loss: 1.387976]\n",
      "[Epoch 47/50] [Batch 15/235] [D loss: 1.165513, acc: 86.13%] [G loss: 1.119807]\n",
      "[Epoch 47/50] [Batch 16/235] [D loss: 1.097798, acc: 88.67%] [G loss: 1.202063]\n",
      "[Epoch 47/50] [Batch 17/235] [D loss: 1.145563, acc: 88.28%] [G loss: 1.056123]\n",
      "[Epoch 47/50] [Batch 18/235] [D loss: 1.101701, acc: 86.72%] [G loss: 1.041503]\n",
      "[Epoch 47/50] [Batch 19/235] [D loss: 1.078531, acc: 89.06%] [G loss: 1.056334]\n",
      "[Epoch 47/50] [Batch 20/235] [D loss: 1.102554, acc: 87.30%] [G loss: 1.147499]\n",
      "[Epoch 47/50] [Batch 21/235] [D loss: 1.132569, acc: 90.23%] [G loss: 1.237376]\n",
      "[Epoch 47/50] [Batch 22/235] [D loss: 1.095277, acc: 87.50%] [G loss: 1.149569]\n",
      "[Epoch 47/50] [Batch 23/235] [D loss: 1.153091, acc: 85.35%] [G loss: 1.163671]\n",
      "[Epoch 47/50] [Batch 24/235] [D loss: 1.083731, acc: 89.84%] [G loss: 1.208042]\n",
      "[Epoch 47/50] [Batch 25/235] [D loss: 1.151758, acc: 86.91%] [G loss: 1.137174]\n",
      "[Epoch 47/50] [Batch 26/235] [D loss: 1.110678, acc: 86.91%] [G loss: 1.040016]\n",
      "[Epoch 47/50] [Batch 27/235] [D loss: 1.104720, acc: 87.50%] [G loss: 1.060044]\n",
      "[Epoch 47/50] [Batch 28/235] [D loss: 1.108759, acc: 86.52%] [G loss: 1.115974]\n",
      "[Epoch 47/50] [Batch 29/235] [D loss: 1.101551, acc: 88.28%] [G loss: 1.084241]\n",
      "[Epoch 47/50] [Batch 30/235] [D loss: 1.169108, acc: 88.28%] [G loss: 1.302197]\n",
      "[Epoch 47/50] [Batch 31/235] [D loss: 1.164148, acc: 86.52%] [G loss: 1.239841]\n",
      "[Epoch 47/50] [Batch 32/235] [D loss: 1.166650, acc: 87.50%] [G loss: 1.035550]\n",
      "[Epoch 47/50] [Batch 33/235] [D loss: 1.141245, acc: 85.94%] [G loss: 1.118597]\n",
      "[Epoch 47/50] [Batch 34/235] [D loss: 1.106272, acc: 89.45%] [G loss: 1.092673]\n",
      "[Epoch 47/50] [Batch 35/235] [D loss: 1.059811, acc: 87.70%] [G loss: 1.184433]\n",
      "[Epoch 47/50] [Batch 36/235] [D loss: 1.141041, acc: 86.13%] [G loss: 1.057514]\n",
      "[Epoch 47/50] [Batch 37/235] [D loss: 1.096058, acc: 88.28%] [G loss: 1.120582]\n",
      "[Epoch 47/50] [Batch 38/235] [D loss: 1.090254, acc: 88.09%] [G loss: 1.285938]\n",
      "[Epoch 47/50] [Batch 39/235] [D loss: 1.144373, acc: 87.11%] [G loss: 1.264326]\n",
      "[Epoch 47/50] [Batch 40/235] [D loss: 1.123974, acc: 89.06%] [G loss: 1.111026]\n",
      "[Epoch 47/50] [Batch 41/235] [D loss: 1.089416, acc: 88.28%] [G loss: 1.134022]\n",
      "[Epoch 47/50] [Batch 42/235] [D loss: 1.093379, acc: 89.45%] [G loss: 1.149611]\n",
      "[Epoch 47/50] [Batch 43/235] [D loss: 1.120061, acc: 88.28%] [G loss: 1.241464]\n",
      "[Epoch 47/50] [Batch 44/235] [D loss: 1.109183, acc: 86.91%] [G loss: 1.143597]\n",
      "[Epoch 47/50] [Batch 45/235] [D loss: 1.070995, acc: 85.35%] [G loss: 1.075353]\n",
      "[Epoch 47/50] [Batch 46/235] [D loss: 1.085846, acc: 87.89%] [G loss: 1.192730]\n",
      "[Epoch 47/50] [Batch 47/235] [D loss: 1.062395, acc: 88.67%] [G loss: 1.232530]\n",
      "[Epoch 47/50] [Batch 48/235] [D loss: 1.114052, acc: 88.67%] [G loss: 1.100103]\n",
      "[Epoch 47/50] [Batch 49/235] [D loss: 1.099407, acc: 88.48%] [G loss: 1.108602]\n",
      "[Epoch 47/50] [Batch 50/235] [D loss: 1.144155, acc: 88.48%] [G loss: 1.244043]\n",
      "[Epoch 47/50] [Batch 51/235] [D loss: 1.124817, acc: 89.45%] [G loss: 1.251180]\n",
      "[Epoch 47/50] [Batch 52/235] [D loss: 1.103203, acc: 88.09%] [G loss: 1.135568]\n",
      "[Epoch 47/50] [Batch 53/235] [D loss: 1.073435, acc: 87.30%] [G loss: 1.064068]\n",
      "[Epoch 47/50] [Batch 54/235] [D loss: 1.177401, acc: 87.70%] [G loss: 1.081792]\n",
      "[Epoch 47/50] [Batch 55/235] [D loss: 1.187937, acc: 89.26%] [G loss: 1.280921]\n",
      "[Epoch 47/50] [Batch 56/235] [D loss: 1.082142, acc: 83.20%] [G loss: 1.064070]\n",
      "[Epoch 47/50] [Batch 57/235] [D loss: 1.079703, acc: 90.04%] [G loss: 1.200763]\n",
      "[Epoch 47/50] [Batch 58/235] [D loss: 1.105945, acc: 87.11%] [G loss: 1.179184]\n",
      "[Epoch 47/50] [Batch 59/235] [D loss: 1.089541, acc: 86.72%] [G loss: 1.036677]\n",
      "[Epoch 47/50] [Batch 60/235] [D loss: 1.130535, acc: 86.91%] [G loss: 1.322430]\n",
      "[Epoch 47/50] [Batch 61/235] [D loss: 1.148301, acc: 88.87%] [G loss: 1.073134]\n",
      "[Epoch 47/50] [Batch 62/235] [D loss: 1.095917, acc: 87.30%] [G loss: 1.215268]\n",
      "[Epoch 47/50] [Batch 63/235] [D loss: 1.099910, acc: 88.87%] [G loss: 1.226002]\n",
      "[Epoch 47/50] [Batch 64/235] [D loss: 1.080805, acc: 85.35%] [G loss: 1.113989]\n",
      "[Epoch 47/50] [Batch 65/235] [D loss: 1.160532, acc: 86.91%] [G loss: 1.209832]\n",
      "[Epoch 47/50] [Batch 66/235] [D loss: 1.033421, acc: 85.55%] [G loss: 1.226035]\n",
      "[Epoch 47/50] [Batch 67/235] [D loss: 1.080867, acc: 86.72%] [G loss: 1.108506]\n",
      "[Epoch 47/50] [Batch 68/235] [D loss: 1.152093, acc: 88.28%] [G loss: 1.128440]\n",
      "[Epoch 47/50] [Batch 69/235] [D loss: 1.164160, acc: 87.50%] [G loss: 1.285967]\n",
      "[Epoch 47/50] [Batch 70/235] [D loss: 1.143487, acc: 83.98%] [G loss: 1.147935]\n",
      "[Epoch 47/50] [Batch 71/235] [D loss: 1.091570, acc: 87.70%] [G loss: 1.182142]\n",
      "[Epoch 47/50] [Batch 72/235] [D loss: 1.131357, acc: 88.87%] [G loss: 1.054384]\n",
      "[Epoch 47/50] [Batch 73/235] [D loss: 1.088081, acc: 88.67%] [G loss: 1.141905]\n",
      "[Epoch 47/50] [Batch 74/235] [D loss: 1.166947, acc: 89.26%] [G loss: 1.169550]\n",
      "[Epoch 47/50] [Batch 75/235] [D loss: 1.215695, acc: 84.57%] [G loss: 1.076917]\n",
      "[Epoch 47/50] [Batch 76/235] [D loss: 1.134258, acc: 86.91%] [G loss: 1.216318]\n",
      "[Epoch 47/50] [Batch 77/235] [D loss: 1.103591, acc: 85.55%] [G loss: 1.303348]\n",
      "[Epoch 47/50] [Batch 78/235] [D loss: 1.146283, acc: 86.91%] [G loss: 1.242694]\n",
      "[Epoch 47/50] [Batch 79/235] [D loss: 1.130007, acc: 88.28%] [G loss: 1.151643]\n",
      "[Epoch 47/50] [Batch 80/235] [D loss: 1.112435, acc: 86.13%] [G loss: 1.094727]\n",
      "[Epoch 47/50] [Batch 81/235] [D loss: 1.087997, acc: 87.30%] [G loss: 1.244469]\n",
      "[Epoch 47/50] [Batch 82/235] [D loss: 1.118439, acc: 86.52%] [G loss: 1.220336]\n",
      "[Epoch 47/50] [Batch 83/235] [D loss: 1.126561, acc: 87.70%] [G loss: 1.086298]\n",
      "[Epoch 47/50] [Batch 84/235] [D loss: 1.154260, acc: 87.30%] [G loss: 1.054079]\n",
      "[Epoch 47/50] [Batch 85/235] [D loss: 1.092762, acc: 89.26%] [G loss: 1.072014]\n",
      "[Epoch 47/50] [Batch 86/235] [D loss: 1.143614, acc: 88.67%] [G loss: 1.141282]\n",
      "[Epoch 47/50] [Batch 87/235] [D loss: 1.154005, acc: 87.30%] [G loss: 1.184088]\n",
      "[Epoch 47/50] [Batch 88/235] [D loss: 1.125329, acc: 87.11%] [G loss: 1.286658]\n",
      "[Epoch 47/50] [Batch 89/235] [D loss: 1.180002, acc: 87.50%] [G loss: 1.367771]\n",
      "[Epoch 47/50] [Batch 90/235] [D loss: 1.123099, acc: 89.06%] [G loss: 1.359952]\n",
      "[Epoch 47/50] [Batch 91/235] [D loss: 1.198648, acc: 86.52%] [G loss: 1.086730]\n",
      "[Epoch 47/50] [Batch 92/235] [D loss: 1.115623, acc: 87.89%] [G loss: 1.123509]\n",
      "[Epoch 47/50] [Batch 93/235] [D loss: 1.090829, acc: 88.48%] [G loss: 1.151349]\n",
      "[Epoch 47/50] [Batch 94/235] [D loss: 1.097888, acc: 87.50%] [G loss: 1.071800]\n",
      "[Epoch 47/50] [Batch 95/235] [D loss: 1.111495, acc: 86.52%] [G loss: 0.986426]\n",
      "[Epoch 47/50] [Batch 96/235] [D loss: 1.145144, acc: 86.13%] [G loss: 1.090150]\n",
      "[Epoch 47/50] [Batch 97/235] [D loss: 1.074138, acc: 88.48%] [G loss: 1.136294]\n",
      "[Epoch 47/50] [Batch 98/235] [D loss: 1.112052, acc: 85.74%] [G loss: 1.070568]\n",
      "[Epoch 47/50] [Batch 99/235] [D loss: 1.106562, acc: 87.89%] [G loss: 1.008223]\n",
      "[Epoch 47/50] [Batch 100/235] [D loss: 1.160825, acc: 83.01%] [G loss: 1.429780]\n",
      "[Epoch 47/50] [Batch 101/235] [D loss: 1.055088, acc: 88.87%] [G loss: 1.059152]\n",
      "[Epoch 47/50] [Batch 102/235] [D loss: 1.075695, acc: 88.67%] [G loss: 1.116265]\n",
      "[Epoch 47/50] [Batch 103/235] [D loss: 1.064836, acc: 84.96%] [G loss: 1.205644]\n",
      "[Epoch 47/50] [Batch 104/235] [D loss: 1.095120, acc: 88.87%] [G loss: 1.194578]\n",
      "[Epoch 47/50] [Batch 105/235] [D loss: 1.154248, acc: 90.04%] [G loss: 1.279759]\n",
      "[Epoch 47/50] [Batch 106/235] [D loss: 1.125643, acc: 88.67%] [G loss: 1.162118]\n",
      "[Epoch 47/50] [Batch 107/235] [D loss: 1.136505, acc: 86.33%] [G loss: 1.232877]\n",
      "[Epoch 47/50] [Batch 108/235] [D loss: 1.049741, acc: 87.11%] [G loss: 1.139792]\n",
      "[Epoch 47/50] [Batch 109/235] [D loss: 1.112900, acc: 87.30%] [G loss: 1.055379]\n",
      "[Epoch 47/50] [Batch 110/235] [D loss: 1.065717, acc: 88.67%] [G loss: 1.065524]\n",
      "[Epoch 47/50] [Batch 111/235] [D loss: 1.133997, acc: 88.28%] [G loss: 1.167489]\n",
      "[Epoch 47/50] [Batch 112/235] [D loss: 1.115140, acc: 86.91%] [G loss: 1.294530]\n",
      "[Epoch 47/50] [Batch 113/235] [D loss: 1.125770, acc: 87.89%] [G loss: 1.149345]\n",
      "[Epoch 47/50] [Batch 114/235] [D loss: 1.058122, acc: 88.48%] [G loss: 1.021220]\n",
      "[Epoch 47/50] [Batch 115/235] [D loss: 1.116136, acc: 86.52%] [G loss: 1.029482]\n",
      "[Epoch 47/50] [Batch 116/235] [D loss: 1.125339, acc: 86.72%] [G loss: 1.060045]\n",
      "[Epoch 47/50] [Batch 117/235] [D loss: 1.119707, acc: 86.52%] [G loss: 1.249411]\n",
      "[Epoch 47/50] [Batch 118/235] [D loss: 1.151672, acc: 89.26%] [G loss: 1.178919]\n",
      "[Epoch 47/50] [Batch 119/235] [D loss: 1.110028, acc: 88.09%] [G loss: 1.058905]\n",
      "[Epoch 47/50] [Batch 120/235] [D loss: 1.129863, acc: 89.06%] [G loss: 1.082807]\n",
      "[Epoch 47/50] [Batch 121/235] [D loss: 1.112294, acc: 89.26%] [G loss: 1.260211]\n",
      "[Epoch 47/50] [Batch 122/235] [D loss: 1.077013, acc: 86.33%] [G loss: 1.136627]\n",
      "[Epoch 47/50] [Batch 123/235] [D loss: 1.167805, acc: 87.30%] [G loss: 1.132921]\n",
      "[Epoch 47/50] [Batch 124/235] [D loss: 1.106517, acc: 87.70%] [G loss: 1.185376]\n",
      "[Epoch 47/50] [Batch 125/235] [D loss: 1.141843, acc: 87.30%] [G loss: 1.044148]\n",
      "[Epoch 47/50] [Batch 126/235] [D loss: 1.110749, acc: 87.89%] [G loss: 1.097199]\n",
      "[Epoch 47/50] [Batch 127/235] [D loss: 1.077721, acc: 88.48%] [G loss: 1.260656]\n",
      "[Epoch 47/50] [Batch 128/235] [D loss: 1.187190, acc: 85.94%] [G loss: 1.220652]\n",
      "[Epoch 47/50] [Batch 129/235] [D loss: 1.141837, acc: 87.11%] [G loss: 1.045993]\n",
      "[Epoch 47/50] [Batch 130/235] [D loss: 1.140585, acc: 88.09%] [G loss: 1.081575]\n",
      "[Epoch 47/50] [Batch 131/235] [D loss: 1.097817, acc: 86.33%] [G loss: 1.088977]\n",
      "[Epoch 47/50] [Batch 132/235] [D loss: 1.111204, acc: 86.13%] [G loss: 1.159324]\n",
      "[Epoch 47/50] [Batch 133/235] [D loss: 1.056753, acc: 88.28%] [G loss: 1.248169]\n",
      "[Epoch 47/50] [Batch 134/235] [D loss: 1.135560, acc: 86.91%] [G loss: 1.123227]\n",
      "[Epoch 47/50] [Batch 135/235] [D loss: 1.071640, acc: 85.74%] [G loss: 1.206358]\n",
      "[Epoch 47/50] [Batch 136/235] [D loss: 1.089057, acc: 89.26%] [G loss: 0.985798]\n",
      "[Epoch 47/50] [Batch 137/235] [D loss: 1.099610, acc: 87.11%] [G loss: 1.214319]\n",
      "[Epoch 47/50] [Batch 138/235] [D loss: 1.153633, acc: 87.89%] [G loss: 1.325393]\n",
      "[Epoch 47/50] [Batch 139/235] [D loss: 1.083543, acc: 89.45%] [G loss: 1.193269]\n",
      "[Epoch 47/50] [Batch 140/235] [D loss: 1.167731, acc: 91.02%] [G loss: 1.217846]\n",
      "[Epoch 47/50] [Batch 141/235] [D loss: 1.159168, acc: 86.72%] [G loss: 1.108457]\n",
      "[Epoch 47/50] [Batch 142/235] [D loss: 1.088581, acc: 89.06%] [G loss: 1.080656]\n",
      "[Epoch 47/50] [Batch 143/235] [D loss: 1.154435, acc: 86.52%] [G loss: 1.222273]\n",
      "[Epoch 47/50] [Batch 144/235] [D loss: 1.148648, acc: 88.48%] [G loss: 1.093580]\n",
      "[Epoch 47/50] [Batch 145/235] [D loss: 1.085602, acc: 87.50%] [G loss: 1.019220]\n",
      "[Epoch 47/50] [Batch 146/235] [D loss: 1.133962, acc: 87.30%] [G loss: 0.965599]\n",
      "[Epoch 47/50] [Batch 147/235] [D loss: 1.128539, acc: 89.45%] [G loss: 1.238176]\n",
      "[Epoch 47/50] [Batch 148/235] [D loss: 1.159929, acc: 85.94%] [G loss: 1.268431]\n",
      "[Epoch 47/50] [Batch 149/235] [D loss: 1.057854, acc: 88.28%] [G loss: 1.064037]\n",
      "[Epoch 47/50] [Batch 150/235] [D loss: 1.168440, acc: 87.30%] [G loss: 1.047518]\n",
      "[Epoch 47/50] [Batch 151/235] [D loss: 1.113578, acc: 86.33%] [G loss: 1.237637]\n",
      "[Epoch 47/50] [Batch 152/235] [D loss: 1.120296, acc: 85.94%] [G loss: 1.064605]\n",
      "[Epoch 47/50] [Batch 153/235] [D loss: 1.166767, acc: 88.48%] [G loss: 1.054137]\n",
      "[Epoch 47/50] [Batch 154/235] [D loss: 1.123474, acc: 87.70%] [G loss: 1.205352]\n",
      "[Epoch 47/50] [Batch 155/235] [D loss: 1.093216, acc: 89.65%] [G loss: 1.187081]\n",
      "[Epoch 47/50] [Batch 156/235] [D loss: 1.104402, acc: 86.52%] [G loss: 1.059088]\n",
      "[Epoch 47/50] [Batch 157/235] [D loss: 1.090828, acc: 88.48%] [G loss: 1.119768]\n",
      "[Epoch 47/50] [Batch 158/235] [D loss: 1.159652, acc: 88.48%] [G loss: 1.150973]\n",
      "[Epoch 47/50] [Batch 159/235] [D loss: 1.115960, acc: 89.45%] [G loss: 1.283811]\n",
      "[Epoch 47/50] [Batch 160/235] [D loss: 1.165233, acc: 87.11%] [G loss: 1.157247]\n",
      "[Epoch 47/50] [Batch 161/235] [D loss: 1.169966, acc: 88.28%] [G loss: 1.064309]\n",
      "[Epoch 47/50] [Batch 162/235] [D loss: 1.125638, acc: 89.06%] [G loss: 1.157854]\n",
      "[Epoch 47/50] [Batch 163/235] [D loss: 1.055946, acc: 88.67%] [G loss: 1.192170]\n",
      "[Epoch 47/50] [Batch 164/235] [D loss: 1.134389, acc: 89.26%] [G loss: 1.121766]\n",
      "[Epoch 47/50] [Batch 165/235] [D loss: 1.105729, acc: 84.18%] [G loss: 1.061255]\n",
      "[Epoch 47/50] [Batch 166/235] [D loss: 1.156420, acc: 86.91%] [G loss: 1.052862]\n",
      "[Epoch 47/50] [Batch 167/235] [D loss: 1.153133, acc: 87.70%] [G loss: 1.241676]\n",
      "[Epoch 47/50] [Batch 168/235] [D loss: 1.109526, acc: 86.91%] [G loss: 1.420029]\n",
      "[Epoch 47/50] [Batch 169/235] [D loss: 1.088890, acc: 86.72%] [G loss: 1.184042]\n",
      "[Epoch 47/50] [Batch 170/235] [D loss: 1.106069, acc: 88.48%] [G loss: 1.100649]\n",
      "[Epoch 47/50] [Batch 171/235] [D loss: 1.120222, acc: 85.94%] [G loss: 1.104047]\n",
      "[Epoch 47/50] [Batch 172/235] [D loss: 1.182487, acc: 89.06%] [G loss: 1.070171]\n",
      "[Epoch 47/50] [Batch 173/235] [D loss: 1.090544, acc: 86.33%] [G loss: 1.112534]\n",
      "[Epoch 47/50] [Batch 174/235] [D loss: 1.083340, acc: 88.67%] [G loss: 1.023275]\n",
      "[Epoch 47/50] [Batch 175/235] [D loss: 1.092775, acc: 85.94%] [G loss: 1.062233]\n",
      "[Epoch 47/50] [Batch 176/235] [D loss: 1.052271, acc: 90.82%] [G loss: 1.127007]\n",
      "[Epoch 47/50] [Batch 177/235] [D loss: 1.117565, acc: 85.74%] [G loss: 1.273192]\n",
      "[Epoch 47/50] [Batch 178/235] [D loss: 1.075077, acc: 87.70%] [G loss: 1.421257]\n",
      "[Epoch 47/50] [Batch 179/235] [D loss: 1.094421, acc: 88.28%] [G loss: 1.162723]\n",
      "[Epoch 47/50] [Batch 180/235] [D loss: 1.093509, acc: 88.48%] [G loss: 1.116664]\n",
      "[Epoch 47/50] [Batch 181/235] [D loss: 1.127420, acc: 89.84%] [G loss: 1.093694]\n",
      "[Epoch 47/50] [Batch 182/235] [D loss: 1.191548, acc: 89.06%] [G loss: 1.296485]\n",
      "[Epoch 47/50] [Batch 183/235] [D loss: 1.115982, acc: 86.91%] [G loss: 1.213110]\n",
      "[Epoch 47/50] [Batch 184/235] [D loss: 1.114087, acc: 88.28%] [G loss: 1.147834]\n",
      "[Epoch 47/50] [Batch 185/235] [D loss: 1.063950, acc: 87.30%] [G loss: 1.087123]\n",
      "[Epoch 47/50] [Batch 186/235] [D loss: 1.125429, acc: 89.26%] [G loss: 1.225533]\n",
      "[Epoch 47/50] [Batch 187/235] [D loss: 1.085236, acc: 86.13%] [G loss: 1.146130]\n",
      "[Epoch 47/50] [Batch 188/235] [D loss: 1.107451, acc: 87.11%] [G loss: 1.149390]\n",
      "[Epoch 47/50] [Batch 189/235] [D loss: 1.039274, acc: 87.70%] [G loss: 1.092812]\n",
      "[Epoch 47/50] [Batch 190/235] [D loss: 1.108840, acc: 86.72%] [G loss: 1.157353]\n",
      "[Epoch 47/50] [Batch 191/235] [D loss: 1.083697, acc: 88.48%] [G loss: 1.115855]\n",
      "[Epoch 47/50] [Batch 192/235] [D loss: 1.118976, acc: 86.72%] [G loss: 1.194874]\n",
      "[Epoch 47/50] [Batch 193/235] [D loss: 1.098041, acc: 89.84%] [G loss: 1.180678]\n",
      "[Epoch 47/50] [Batch 194/235] [D loss: 1.081289, acc: 89.45%] [G loss: 1.187339]\n",
      "[Epoch 47/50] [Batch 195/235] [D loss: 1.167194, acc: 86.33%] [G loss: 1.192398]\n",
      "[Epoch 47/50] [Batch 196/235] [D loss: 1.111095, acc: 91.02%] [G loss: 1.139202]\n",
      "[Epoch 47/50] [Batch 197/235] [D loss: 1.030756, acc: 88.87%] [G loss: 1.208753]\n",
      "[Epoch 47/50] [Batch 198/235] [D loss: 1.109016, acc: 87.11%] [G loss: 1.234234]\n",
      "[Epoch 47/50] [Batch 199/235] [D loss: 1.081751, acc: 87.30%] [G loss: 1.170133]\n",
      "[Epoch 47/50] [Batch 200/235] [D loss: 1.133965, acc: 86.91%] [G loss: 1.282182]\n",
      "[Epoch 47/50] [Batch 201/235] [D loss: 1.107744, acc: 87.89%] [G loss: 1.280501]\n",
      "[Epoch 47/50] [Batch 202/235] [D loss: 1.157116, acc: 87.50%] [G loss: 1.275276]\n",
      "[Epoch 47/50] [Batch 203/235] [D loss: 1.078187, acc: 88.87%] [G loss: 1.135407]\n",
      "[Epoch 47/50] [Batch 204/235] [D loss: 1.114136, acc: 89.06%] [G loss: 1.109465]\n",
      "[Epoch 47/50] [Batch 205/235] [D loss: 1.139295, acc: 87.50%] [G loss: 1.190947]\n",
      "[Epoch 47/50] [Batch 206/235] [D loss: 1.094673, acc: 88.28%] [G loss: 1.165908]\n",
      "[Epoch 47/50] [Batch 207/235] [D loss: 1.107145, acc: 88.87%] [G loss: 1.174247]\n",
      "[Epoch 47/50] [Batch 208/235] [D loss: 1.112374, acc: 85.74%] [G loss: 1.183204]\n",
      "[Epoch 47/50] [Batch 209/235] [D loss: 1.146680, acc: 86.13%] [G loss: 1.254665]\n",
      "[Epoch 47/50] [Batch 210/235] [D loss: 1.073601, acc: 89.65%] [G loss: 1.042300]\n",
      "[Epoch 47/50] [Batch 211/235] [D loss: 1.047786, acc: 87.11%] [G loss: 1.015226]\n",
      "[Epoch 47/50] [Batch 212/235] [D loss: 1.125729, acc: 85.55%] [G loss: 1.149312]\n",
      "[Epoch 47/50] [Batch 213/235] [D loss: 1.221167, acc: 88.87%] [G loss: 1.116786]\n",
      "[Epoch 47/50] [Batch 214/235] [D loss: 1.134020, acc: 88.09%] [G loss: 1.091110]\n",
      "[Epoch 47/50] [Batch 215/235] [D loss: 1.128208, acc: 85.74%] [G loss: 1.173363]\n",
      "[Epoch 47/50] [Batch 216/235] [D loss: 1.064150, acc: 86.91%] [G loss: 1.174059]\n",
      "[Epoch 47/50] [Batch 217/235] [D loss: 1.206220, acc: 91.02%] [G loss: 1.128217]\n",
      "[Epoch 47/50] [Batch 218/235] [D loss: 1.108623, acc: 86.33%] [G loss: 1.145652]\n",
      "[Epoch 47/50] [Batch 219/235] [D loss: 1.128904, acc: 88.48%] [G loss: 1.048772]\n",
      "[Epoch 47/50] [Batch 220/235] [D loss: 1.147393, acc: 88.87%] [G loss: 1.367949]\n",
      "[Epoch 47/50] [Batch 221/235] [D loss: 1.092587, acc: 84.38%] [G loss: 1.334596]\n",
      "[Epoch 47/50] [Batch 222/235] [D loss: 1.169490, acc: 88.09%] [G loss: 1.102328]\n",
      "[Epoch 47/50] [Batch 223/235] [D loss: 1.146503, acc: 88.09%] [G loss: 1.215727]\n",
      "[Epoch 47/50] [Batch 224/235] [D loss: 1.104021, acc: 87.70%] [G loss: 1.178229]\n",
      "[Epoch 47/50] [Batch 225/235] [D loss: 1.131713, acc: 87.30%] [G loss: 1.212923]\n",
      "[Epoch 47/50] [Batch 226/235] [D loss: 1.083627, acc: 87.50%] [G loss: 1.229438]\n",
      "[Epoch 47/50] [Batch 227/235] [D loss: 1.129058, acc: 87.30%] [G loss: 1.029414]\n",
      "[Epoch 47/50] [Batch 228/235] [D loss: 1.183483, acc: 87.11%] [G loss: 1.190008]\n",
      "[Epoch 47/50] [Batch 229/235] [D loss: 1.133226, acc: 87.50%] [G loss: 1.189632]\n",
      "[Epoch 47/50] [Batch 230/235] [D loss: 1.102438, acc: 86.13%] [G loss: 1.275914]\n",
      "[Epoch 47/50] [Batch 231/235] [D loss: 1.074920, acc: 87.50%] [G loss: 1.105654]\n",
      "[Epoch 47/50] [Batch 232/235] [D loss: 1.174286, acc: 88.48%] [G loss: 1.087680]\n",
      "[Epoch 47/50] [Batch 233/235] [D loss: 1.086108, acc: 87.50%] [G loss: 1.202272]\n",
      "[Epoch 47/50] [Batch 234/235] [D loss: 1.113654, acc: 90.62%] [G loss: 1.277108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/50] [Batch 0/235] [D loss: 1.074716, acc: 88.87%] [G loss: 1.178032]\n",
      "[Epoch 48/50] [Batch 1/235] [D loss: 1.126699, acc: 86.91%] [G loss: 1.200557]\n",
      "[Epoch 48/50] [Batch 2/235] [D loss: 1.034682, acc: 87.30%] [G loss: 1.119344]\n",
      "[Epoch 48/50] [Batch 3/235] [D loss: 1.201830, acc: 84.96%] [G loss: 1.168468]\n",
      "[Epoch 48/50] [Batch 4/235] [D loss: 1.182563, acc: 83.59%] [G loss: 1.221890]\n",
      "[Epoch 48/50] [Batch 5/235] [D loss: 1.087312, acc: 88.48%] [G loss: 1.148967]\n",
      "[Epoch 48/50] [Batch 6/235] [D loss: 1.083574, acc: 88.87%] [G loss: 1.189238]\n",
      "[Epoch 48/50] [Batch 7/235] [D loss: 1.225591, acc: 87.89%] [G loss: 1.247254]\n",
      "[Epoch 48/50] [Batch 8/235] [D loss: 1.107085, acc: 86.72%] [G loss: 1.156566]\n",
      "[Epoch 48/50] [Batch 9/235] [D loss: 1.095098, acc: 88.67%] [G loss: 1.094095]\n",
      "[Epoch 48/50] [Batch 10/235] [D loss: 1.140347, acc: 88.87%] [G loss: 1.163990]\n",
      "[Epoch 48/50] [Batch 11/235] [D loss: 1.039321, acc: 86.72%] [G loss: 1.274433]\n",
      "[Epoch 48/50] [Batch 12/235] [D loss: 1.153624, acc: 87.89%] [G loss: 1.301531]\n",
      "[Epoch 48/50] [Batch 13/235] [D loss: 1.057119, acc: 87.70%] [G loss: 1.162401]\n",
      "[Epoch 48/50] [Batch 14/235] [D loss: 1.127966, acc: 88.09%] [G loss: 1.069512]\n",
      "[Epoch 48/50] [Batch 15/235] [D loss: 1.172344, acc: 88.09%] [G loss: 1.202166]\n",
      "[Epoch 48/50] [Batch 16/235] [D loss: 1.065248, acc: 88.48%] [G loss: 1.412532]\n",
      "[Epoch 48/50] [Batch 17/235] [D loss: 1.070730, acc: 86.33%] [G loss: 1.182832]\n",
      "[Epoch 48/50] [Batch 18/235] [D loss: 1.143871, acc: 85.94%] [G loss: 1.056535]\n",
      "[Epoch 48/50] [Batch 19/235] [D loss: 1.116369, acc: 87.30%] [G loss: 1.099519]\n",
      "[Epoch 48/50] [Batch 20/235] [D loss: 1.074738, acc: 85.55%] [G loss: 1.263990]\n",
      "[Epoch 48/50] [Batch 21/235] [D loss: 1.141967, acc: 86.52%] [G loss: 1.228576]\n",
      "[Epoch 48/50] [Batch 22/235] [D loss: 1.112177, acc: 88.48%] [G loss: 1.170076]\n",
      "[Epoch 48/50] [Batch 23/235] [D loss: 1.154694, acc: 86.52%] [G loss: 1.116792]\n",
      "[Epoch 48/50] [Batch 24/235] [D loss: 1.112836, acc: 86.52%] [G loss: 1.263847]\n",
      "[Epoch 48/50] [Batch 25/235] [D loss: 1.123439, acc: 86.33%] [G loss: 1.135022]\n",
      "[Epoch 48/50] [Batch 26/235] [D loss: 1.071343, acc: 87.50%] [G loss: 1.121928]\n",
      "[Epoch 48/50] [Batch 27/235] [D loss: 1.145779, acc: 87.70%] [G loss: 1.195036]\n",
      "[Epoch 48/50] [Batch 28/235] [D loss: 1.091125, acc: 87.89%] [G loss: 1.167229]\n",
      "[Epoch 48/50] [Batch 29/235] [D loss: 1.103042, acc: 85.55%] [G loss: 1.170214]\n",
      "[Epoch 48/50] [Batch 30/235] [D loss: 1.041468, acc: 88.09%] [G loss: 1.155859]\n",
      "[Epoch 48/50] [Batch 31/235] [D loss: 1.059028, acc: 88.87%] [G loss: 1.086069]\n",
      "[Epoch 48/50] [Batch 32/235] [D loss: 1.134615, acc: 88.48%] [G loss: 1.116221]\n",
      "[Epoch 48/50] [Batch 33/235] [D loss: 1.077570, acc: 85.55%] [G loss: 1.137528]\n",
      "[Epoch 48/50] [Batch 34/235] [D loss: 1.079051, acc: 87.30%] [G loss: 1.207751]\n",
      "[Epoch 48/50] [Batch 35/235] [D loss: 1.188060, acc: 89.06%] [G loss: 1.091868]\n",
      "[Epoch 48/50] [Batch 36/235] [D loss: 1.083583, acc: 87.11%] [G loss: 1.174757]\n",
      "[Epoch 48/50] [Batch 37/235] [D loss: 1.035452, acc: 86.91%] [G loss: 1.183149]\n",
      "[Epoch 48/50] [Batch 38/235] [D loss: 1.133077, acc: 87.11%] [G loss: 1.238403]\n",
      "[Epoch 48/50] [Batch 39/235] [D loss: 1.123100, acc: 90.62%] [G loss: 1.197612]\n",
      "[Epoch 48/50] [Batch 40/235] [D loss: 1.130246, acc: 85.35%] [G loss: 1.010430]\n",
      "[Epoch 48/50] [Batch 41/235] [D loss: 1.133678, acc: 86.33%] [G loss: 1.217873]\n",
      "[Epoch 48/50] [Batch 42/235] [D loss: 1.079011, acc: 87.30%] [G loss: 1.159670]\n",
      "[Epoch 48/50] [Batch 43/235] [D loss: 1.117564, acc: 87.11%] [G loss: 1.045857]\n",
      "[Epoch 48/50] [Batch 44/235] [D loss: 1.141491, acc: 87.89%] [G loss: 1.175220]\n",
      "[Epoch 48/50] [Batch 45/235] [D loss: 1.116034, acc: 86.91%] [G loss: 1.175876]\n",
      "[Epoch 48/50] [Batch 46/235] [D loss: 1.081363, acc: 86.52%] [G loss: 1.365692]\n",
      "[Epoch 48/50] [Batch 47/235] [D loss: 1.138535, acc: 85.35%] [G loss: 1.082118]\n",
      "[Epoch 48/50] [Batch 48/235] [D loss: 1.090148, acc: 90.43%] [G loss: 1.148218]\n",
      "[Epoch 48/50] [Batch 49/235] [D loss: 1.106728, acc: 87.89%] [G loss: 1.135154]\n",
      "[Epoch 48/50] [Batch 50/235] [D loss: 1.196177, acc: 86.91%] [G loss: 1.048589]\n",
      "[Epoch 48/50] [Batch 51/235] [D loss: 1.099095, acc: 89.06%] [G loss: 1.337874]\n",
      "[Epoch 48/50] [Batch 52/235] [D loss: 1.115266, acc: 86.13%] [G loss: 1.249999]\n",
      "[Epoch 48/50] [Batch 53/235] [D loss: 1.070762, acc: 88.09%] [G loss: 1.219903]\n",
      "[Epoch 48/50] [Batch 54/235] [D loss: 1.134125, acc: 88.67%] [G loss: 1.055840]\n",
      "[Epoch 48/50] [Batch 55/235] [D loss: 1.130020, acc: 85.74%] [G loss: 1.215102]\n",
      "[Epoch 48/50] [Batch 56/235] [D loss: 1.144573, acc: 89.84%] [G loss: 1.133163]\n",
      "[Epoch 48/50] [Batch 57/235] [D loss: 1.060076, acc: 90.23%] [G loss: 1.175118]\n",
      "[Epoch 48/50] [Batch 58/235] [D loss: 1.107950, acc: 88.67%] [G loss: 1.133762]\n",
      "[Epoch 48/50] [Batch 59/235] [D loss: 1.062607, acc: 87.11%] [G loss: 1.127143]\n",
      "[Epoch 48/50] [Batch 60/235] [D loss: 1.088188, acc: 86.91%] [G loss: 1.209614]\n",
      "[Epoch 48/50] [Batch 61/235] [D loss: 1.178808, acc: 87.89%] [G loss: 1.214605]\n",
      "[Epoch 48/50] [Batch 62/235] [D loss: 1.156318, acc: 89.26%] [G loss: 1.170299]\n",
      "[Epoch 48/50] [Batch 63/235] [D loss: 1.046701, acc: 88.28%] [G loss: 1.274395]\n",
      "[Epoch 48/50] [Batch 64/235] [D loss: 1.083216, acc: 88.28%] [G loss: 1.214252]\n",
      "[Epoch 48/50] [Batch 65/235] [D loss: 1.147864, acc: 83.20%] [G loss: 0.997532]\n",
      "[Epoch 48/50] [Batch 66/235] [D loss: 1.110788, acc: 86.91%] [G loss: 1.160725]\n",
      "[Epoch 48/50] [Batch 67/235] [D loss: 1.081044, acc: 88.48%] [G loss: 1.181089]\n",
      "[Epoch 48/50] [Batch 68/235] [D loss: 1.036048, acc: 88.28%] [G loss: 1.051005]\n",
      "[Epoch 48/50] [Batch 69/235] [D loss: 1.078599, acc: 88.48%] [G loss: 1.166251]\n",
      "[Epoch 48/50] [Batch 70/235] [D loss: 1.090852, acc: 87.89%] [G loss: 1.292914]\n",
      "[Epoch 48/50] [Batch 71/235] [D loss: 1.098769, acc: 88.28%] [G loss: 1.135664]\n",
      "[Epoch 48/50] [Batch 72/235] [D loss: 1.143845, acc: 90.04%] [G loss: 1.119507]\n",
      "[Epoch 48/50] [Batch 73/235] [D loss: 1.119470, acc: 88.09%] [G loss: 1.199169]\n",
      "[Epoch 48/50] [Batch 74/235] [D loss: 1.059932, acc: 89.26%] [G loss: 1.113192]\n",
      "[Epoch 48/50] [Batch 75/235] [D loss: 1.046046, acc: 89.06%] [G loss: 1.195312]\n",
      "[Epoch 48/50] [Batch 76/235] [D loss: 1.066444, acc: 87.11%] [G loss: 1.023076]\n",
      "[Epoch 48/50] [Batch 77/235] [D loss: 1.048716, acc: 88.09%] [G loss: 1.046442]\n",
      "[Epoch 48/50] [Batch 78/235] [D loss: 1.060723, acc: 89.26%] [G loss: 1.282362]\n",
      "[Epoch 48/50] [Batch 79/235] [D loss: 1.113736, acc: 86.72%] [G loss: 1.217018]\n",
      "[Epoch 48/50] [Batch 80/235] [D loss: 1.089594, acc: 88.48%] [G loss: 1.129378]\n",
      "[Epoch 48/50] [Batch 81/235] [D loss: 1.091619, acc: 88.87%] [G loss: 1.097464]\n",
      "[Epoch 48/50] [Batch 82/235] [D loss: 1.122719, acc: 88.28%] [G loss: 1.113134]\n",
      "[Epoch 48/50] [Batch 83/235] [D loss: 1.094783, acc: 88.67%] [G loss: 1.193460]\n",
      "[Epoch 48/50] [Batch 84/235] [D loss: 1.080358, acc: 85.35%] [G loss: 1.103282]\n",
      "[Epoch 48/50] [Batch 85/235] [D loss: 1.138008, acc: 87.70%] [G loss: 1.206051]\n",
      "[Epoch 48/50] [Batch 86/235] [D loss: 1.152509, acc: 86.72%] [G loss: 1.149132]\n",
      "[Epoch 48/50] [Batch 87/235] [D loss: 1.058174, acc: 88.28%] [G loss: 1.001756]\n",
      "[Epoch 48/50] [Batch 88/235] [D loss: 1.111177, acc: 87.89%] [G loss: 1.116893]\n",
      "[Epoch 48/50] [Batch 89/235] [D loss: 1.090528, acc: 88.67%] [G loss: 1.083343]\n",
      "[Epoch 48/50] [Batch 90/235] [D loss: 1.077717, acc: 86.13%] [G loss: 1.090342]\n",
      "[Epoch 48/50] [Batch 91/235] [D loss: 1.103095, acc: 86.91%] [G loss: 1.137360]\n",
      "[Epoch 48/50] [Batch 92/235] [D loss: 1.115102, acc: 86.52%] [G loss: 1.143434]\n",
      "[Epoch 48/50] [Batch 93/235] [D loss: 1.090925, acc: 87.50%] [G loss: 1.216040]\n",
      "[Epoch 48/50] [Batch 94/235] [D loss: 1.217053, acc: 89.45%] [G loss: 1.059347]\n",
      "[Epoch 48/50] [Batch 95/235] [D loss: 1.072911, acc: 87.30%] [G loss: 1.117479]\n",
      "[Epoch 48/50] [Batch 96/235] [D loss: 1.090779, acc: 86.91%] [G loss: 1.252721]\n",
      "[Epoch 48/50] [Batch 97/235] [D loss: 1.117208, acc: 86.91%] [G loss: 1.152709]\n",
      "[Epoch 48/50] [Batch 98/235] [D loss: 1.109613, acc: 90.43%] [G loss: 1.081201]\n",
      "[Epoch 48/50] [Batch 99/235] [D loss: 1.108527, acc: 88.48%] [G loss: 1.109818]\n",
      "[Epoch 48/50] [Batch 100/235] [D loss: 1.084592, acc: 88.67%] [G loss: 1.139698]\n",
      "[Epoch 48/50] [Batch 101/235] [D loss: 1.110739, acc: 86.72%] [G loss: 1.068423]\n",
      "[Epoch 48/50] [Batch 102/235] [D loss: 1.092005, acc: 86.91%] [G loss: 1.087305]\n",
      "[Epoch 48/50] [Batch 103/235] [D loss: 1.167025, acc: 89.65%] [G loss: 1.097809]\n",
      "[Epoch 48/50] [Batch 104/235] [D loss: 1.189218, acc: 88.09%] [G loss: 1.150975]\n",
      "[Epoch 48/50] [Batch 105/235] [D loss: 1.083130, acc: 88.09%] [G loss: 1.197421]\n",
      "[Epoch 48/50] [Batch 106/235] [D loss: 1.085919, acc: 86.91%] [G loss: 1.136844]\n",
      "[Epoch 48/50] [Batch 107/235] [D loss: 1.191204, acc: 89.45%] [G loss: 1.105092]\n",
      "[Epoch 48/50] [Batch 108/235] [D loss: 1.052024, acc: 87.89%] [G loss: 1.011358]\n",
      "[Epoch 48/50] [Batch 109/235] [D loss: 1.066152, acc: 86.91%] [G loss: 1.097672]\n",
      "[Epoch 48/50] [Batch 110/235] [D loss: 1.098681, acc: 89.45%] [G loss: 1.205554]\n",
      "[Epoch 48/50] [Batch 111/235] [D loss: 1.094446, acc: 86.52%] [G loss: 1.186274]\n",
      "[Epoch 48/50] [Batch 112/235] [D loss: 1.045737, acc: 88.28%] [G loss: 1.132250]\n",
      "[Epoch 48/50] [Batch 113/235] [D loss: 1.153767, acc: 86.52%] [G loss: 1.204461]\n",
      "[Epoch 48/50] [Batch 114/235] [D loss: 1.083251, acc: 89.45%] [G loss: 1.146477]\n",
      "[Epoch 48/50] [Batch 115/235] [D loss: 1.202058, acc: 87.89%] [G loss: 1.284976]\n",
      "[Epoch 48/50] [Batch 116/235] [D loss: 1.111087, acc: 90.23%] [G loss: 1.115007]\n",
      "[Epoch 48/50] [Batch 117/235] [D loss: 1.072024, acc: 88.67%] [G loss: 1.030835]\n",
      "[Epoch 48/50] [Batch 118/235] [D loss: 1.073454, acc: 89.06%] [G loss: 1.098876]\n",
      "[Epoch 48/50] [Batch 119/235] [D loss: 1.118867, acc: 86.52%] [G loss: 1.132904]\n",
      "[Epoch 48/50] [Batch 120/235] [D loss: 1.146595, acc: 88.67%] [G loss: 1.267025]\n",
      "[Epoch 48/50] [Batch 121/235] [D loss: 1.121737, acc: 87.11%] [G loss: 1.038324]\n",
      "[Epoch 48/50] [Batch 122/235] [D loss: 1.102610, acc: 90.43%] [G loss: 0.995219]\n",
      "[Epoch 48/50] [Batch 123/235] [D loss: 1.134007, acc: 85.94%] [G loss: 1.058910]\n",
      "[Epoch 48/50] [Batch 124/235] [D loss: 1.099982, acc: 88.67%] [G loss: 1.164976]\n",
      "[Epoch 48/50] [Batch 125/235] [D loss: 1.135684, acc: 88.48%] [G loss: 1.269427]\n",
      "[Epoch 48/50] [Batch 126/235] [D loss: 1.149629, acc: 86.33%] [G loss: 1.145152]\n",
      "[Epoch 48/50] [Batch 127/235] [D loss: 1.097771, acc: 85.55%] [G loss: 0.935714]\n",
      "[Epoch 48/50] [Batch 128/235] [D loss: 1.091146, acc: 88.67%] [G loss: 1.189867]\n",
      "[Epoch 48/50] [Batch 129/235] [D loss: 1.077312, acc: 88.09%] [G loss: 1.288332]\n",
      "[Epoch 48/50] [Batch 130/235] [D loss: 1.096401, acc: 86.72%] [G loss: 1.123643]\n",
      "[Epoch 48/50] [Batch 131/235] [D loss: 1.083771, acc: 86.72%] [G loss: 1.172464]\n",
      "[Epoch 48/50] [Batch 132/235] [D loss: 1.108750, acc: 87.30%] [G loss: 1.346709]\n",
      "[Epoch 48/50] [Batch 133/235] [D loss: 1.096690, acc: 89.84%] [G loss: 1.181040]\n",
      "[Epoch 48/50] [Batch 134/235] [D loss: 1.221326, acc: 86.72%] [G loss: 1.049470]\n",
      "[Epoch 48/50] [Batch 135/235] [D loss: 1.086973, acc: 87.11%] [G loss: 1.194788]\n",
      "[Epoch 48/50] [Batch 136/235] [D loss: 1.138987, acc: 88.87%] [G loss: 1.313198]\n",
      "[Epoch 48/50] [Batch 137/235] [D loss: 1.137348, acc: 86.13%] [G loss: 1.307437]\n",
      "[Epoch 48/50] [Batch 138/235] [D loss: 1.170340, acc: 88.48%] [G loss: 1.088628]\n",
      "[Epoch 48/50] [Batch 139/235] [D loss: 1.066576, acc: 86.13%] [G loss: 1.032824]\n",
      "[Epoch 48/50] [Batch 140/235] [D loss: 1.183036, acc: 90.04%] [G loss: 1.143401]\n",
      "[Epoch 48/50] [Batch 141/235] [D loss: 1.114142, acc: 89.45%] [G loss: 1.188175]\n",
      "[Epoch 48/50] [Batch 142/235] [D loss: 1.106244, acc: 85.35%] [G loss: 1.119538]\n",
      "[Epoch 48/50] [Batch 143/235] [D loss: 1.076613, acc: 89.84%] [G loss: 1.042249]\n",
      "[Epoch 48/50] [Batch 144/235] [D loss: 1.149746, acc: 87.89%] [G loss: 1.092192]\n",
      "[Epoch 48/50] [Batch 145/235] [D loss: 1.151120, acc: 87.89%] [G loss: 1.180530]\n",
      "[Epoch 48/50] [Batch 146/235] [D loss: 1.072869, acc: 89.06%] [G loss: 1.340770]\n",
      "[Epoch 48/50] [Batch 147/235] [D loss: 1.129897, acc: 89.26%] [G loss: 1.088292]\n",
      "[Epoch 48/50] [Batch 148/235] [D loss: 1.114513, acc: 90.04%] [G loss: 1.053962]\n",
      "[Epoch 48/50] [Batch 149/235] [D loss: 1.064333, acc: 89.06%] [G loss: 1.088882]\n",
      "[Epoch 48/50] [Batch 150/235] [D loss: 1.104844, acc: 89.84%] [G loss: 1.294708]\n",
      "[Epoch 48/50] [Batch 151/235] [D loss: 1.176351, acc: 87.50%] [G loss: 1.180822]\n",
      "[Epoch 48/50] [Batch 152/235] [D loss: 1.037436, acc: 90.43%] [G loss: 1.091239]\n",
      "[Epoch 48/50] [Batch 153/235] [D loss: 1.088990, acc: 88.28%] [G loss: 1.174174]\n",
      "[Epoch 48/50] [Batch 154/235] [D loss: 1.104495, acc: 86.13%] [G loss: 1.203274]\n",
      "[Epoch 48/50] [Batch 155/235] [D loss: 1.117212, acc: 86.52%] [G loss: 1.108794]\n",
      "[Epoch 48/50] [Batch 156/235] [D loss: 1.141605, acc: 85.94%] [G loss: 1.020950]\n",
      "[Epoch 48/50] [Batch 157/235] [D loss: 1.121729, acc: 88.48%] [G loss: 1.111128]\n",
      "[Epoch 48/50] [Batch 158/235] [D loss: 1.103306, acc: 88.09%] [G loss: 1.157726]\n",
      "[Epoch 48/50] [Batch 159/235] [D loss: 1.056771, acc: 86.52%] [G loss: 1.133950]\n",
      "[Epoch 48/50] [Batch 160/235] [D loss: 1.182728, acc: 85.35%] [G loss: 1.260009]\n",
      "[Epoch 48/50] [Batch 161/235] [D loss: 1.089162, acc: 88.28%] [G loss: 1.110247]\n",
      "[Epoch 48/50] [Batch 162/235] [D loss: 1.102543, acc: 88.48%] [G loss: 1.254955]\n",
      "[Epoch 48/50] [Batch 163/235] [D loss: 1.130844, acc: 88.67%] [G loss: 1.078914]\n",
      "[Epoch 48/50] [Batch 164/235] [D loss: 1.072245, acc: 85.94%] [G loss: 1.182011]\n",
      "[Epoch 48/50] [Batch 165/235] [D loss: 1.098260, acc: 85.74%] [G loss: 1.185198]\n",
      "[Epoch 48/50] [Batch 166/235] [D loss: 1.186170, acc: 86.91%] [G loss: 1.199193]\n",
      "[Epoch 48/50] [Batch 167/235] [D loss: 1.082412, acc: 87.30%] [G loss: 1.111596]\n",
      "[Epoch 48/50] [Batch 168/235] [D loss: 1.099173, acc: 87.89%] [G loss: 1.191545]\n",
      "[Epoch 48/50] [Batch 169/235] [D loss: 1.139559, acc: 91.21%] [G loss: 1.164516]\n",
      "[Epoch 48/50] [Batch 170/235] [D loss: 1.165272, acc: 85.94%] [G loss: 1.171884]\n",
      "[Epoch 48/50] [Batch 171/235] [D loss: 1.062544, acc: 87.89%] [G loss: 1.240693]\n",
      "[Epoch 48/50] [Batch 172/235] [D loss: 1.113988, acc: 86.72%] [G loss: 1.244567]\n",
      "[Epoch 48/50] [Batch 173/235] [D loss: 1.139612, acc: 87.89%] [G loss: 1.158423]\n",
      "[Epoch 48/50] [Batch 174/235] [D loss: 1.150107, acc: 85.74%] [G loss: 1.101254]\n",
      "[Epoch 48/50] [Batch 175/235] [D loss: 1.133265, acc: 87.70%] [G loss: 1.124211]\n",
      "[Epoch 48/50] [Batch 176/235] [D loss: 1.114426, acc: 88.09%] [G loss: 1.129092]\n",
      "[Epoch 48/50] [Batch 177/235] [D loss: 1.120507, acc: 87.50%] [G loss: 1.101818]\n",
      "[Epoch 48/50] [Batch 178/235] [D loss: 1.102559, acc: 86.13%] [G loss: 1.337707]\n",
      "[Epoch 48/50] [Batch 179/235] [D loss: 1.141046, acc: 87.50%] [G loss: 1.227983]\n",
      "[Epoch 48/50] [Batch 180/235] [D loss: 1.053155, acc: 87.50%] [G loss: 1.159053]\n",
      "[Epoch 48/50] [Batch 181/235] [D loss: 1.031794, acc: 87.89%] [G loss: 1.213278]\n",
      "[Epoch 48/50] [Batch 182/235] [D loss: 1.071970, acc: 88.67%] [G loss: 1.046209]\n",
      "[Epoch 48/50] [Batch 183/235] [D loss: 1.070011, acc: 86.91%] [G loss: 1.203080]\n",
      "[Epoch 48/50] [Batch 184/235] [D loss: 1.102696, acc: 86.13%] [G loss: 1.169247]\n",
      "[Epoch 48/50] [Batch 185/235] [D loss: 1.114153, acc: 89.06%] [G loss: 1.138509]\n",
      "[Epoch 48/50] [Batch 186/235] [D loss: 1.165995, acc: 88.09%] [G loss: 1.224291]\n",
      "[Epoch 48/50] [Batch 187/235] [D loss: 1.082848, acc: 89.06%] [G loss: 1.016458]\n",
      "[Epoch 48/50] [Batch 188/235] [D loss: 1.133362, acc: 87.70%] [G loss: 1.127042]\n",
      "[Epoch 48/50] [Batch 189/235] [D loss: 1.062080, acc: 87.50%] [G loss: 1.279744]\n",
      "[Epoch 48/50] [Batch 190/235] [D loss: 1.103252, acc: 87.30%] [G loss: 1.192748]\n",
      "[Epoch 48/50] [Batch 191/235] [D loss: 1.052409, acc: 89.06%] [G loss: 1.335868]\n",
      "[Epoch 48/50] [Batch 192/235] [D loss: 1.126619, acc: 86.72%] [G loss: 1.247598]\n",
      "[Epoch 48/50] [Batch 193/235] [D loss: 1.164723, acc: 86.72%] [G loss: 1.164418]\n",
      "[Epoch 48/50] [Batch 194/235] [D loss: 1.112586, acc: 88.87%] [G loss: 1.116840]\n",
      "[Epoch 48/50] [Batch 195/235] [D loss: 1.114206, acc: 90.23%] [G loss: 1.154222]\n",
      "[Epoch 48/50] [Batch 196/235] [D loss: 1.138618, acc: 88.87%] [G loss: 1.279836]\n",
      "[Epoch 48/50] [Batch 197/235] [D loss: 1.142253, acc: 87.11%] [G loss: 1.019342]\n",
      "[Epoch 48/50] [Batch 198/235] [D loss: 1.126400, acc: 88.87%] [G loss: 1.099239]\n",
      "[Epoch 48/50] [Batch 199/235] [D loss: 1.118753, acc: 85.35%] [G loss: 1.297847]\n",
      "[Epoch 48/50] [Batch 200/235] [D loss: 1.079823, acc: 88.09%] [G loss: 1.111915]\n",
      "[Epoch 48/50] [Batch 201/235] [D loss: 1.159381, acc: 87.70%] [G loss: 0.981002]\n",
      "[Epoch 48/50] [Batch 202/235] [D loss: 1.086430, acc: 89.06%] [G loss: 1.183679]\n",
      "[Epoch 48/50] [Batch 203/235] [D loss: 1.103266, acc: 88.48%] [G loss: 1.142968]\n",
      "[Epoch 48/50] [Batch 204/235] [D loss: 1.192862, acc: 86.13%] [G loss: 1.231056]\n",
      "[Epoch 48/50] [Batch 205/235] [D loss: 1.035227, acc: 90.62%] [G loss: 1.170828]\n",
      "[Epoch 48/50] [Batch 206/235] [D loss: 1.120285, acc: 86.72%] [G loss: 1.071376]\n",
      "[Epoch 48/50] [Batch 207/235] [D loss: 1.162701, acc: 86.72%] [G loss: 1.098831]\n",
      "[Epoch 48/50] [Batch 208/235] [D loss: 1.101232, acc: 85.55%] [G loss: 1.199865]\n",
      "[Epoch 48/50] [Batch 209/235] [D loss: 1.080769, acc: 86.33%] [G loss: 1.075127]\n",
      "[Epoch 48/50] [Batch 210/235] [D loss: 1.155518, acc: 88.48%] [G loss: 1.048958]\n",
      "[Epoch 48/50] [Batch 211/235] [D loss: 1.130751, acc: 86.52%] [G loss: 1.209201]\n",
      "[Epoch 48/50] [Batch 212/235] [D loss: 1.167833, acc: 87.11%] [G loss: 1.073356]\n",
      "[Epoch 48/50] [Batch 213/235] [D loss: 1.046570, acc: 87.89%] [G loss: 1.257584]\n",
      "[Epoch 48/50] [Batch 214/235] [D loss: 1.099325, acc: 86.72%] [G loss: 1.096573]\n",
      "[Epoch 48/50] [Batch 215/235] [D loss: 1.147502, acc: 88.09%] [G loss: 1.150792]\n",
      "[Epoch 48/50] [Batch 216/235] [D loss: 1.153862, acc: 85.16%] [G loss: 1.187969]\n",
      "[Epoch 48/50] [Batch 217/235] [D loss: 1.149487, acc: 89.06%] [G loss: 1.108748]\n",
      "[Epoch 48/50] [Batch 218/235] [D loss: 1.148362, acc: 88.87%] [G loss: 1.235869]\n",
      "[Epoch 48/50] [Batch 219/235] [D loss: 1.061630, acc: 89.65%] [G loss: 1.065464]\n",
      "[Epoch 48/50] [Batch 220/235] [D loss: 1.049170, acc: 89.45%] [G loss: 1.086644]\n",
      "[Epoch 48/50] [Batch 221/235] [D loss: 1.107652, acc: 85.74%] [G loss: 1.095547]\n",
      "[Epoch 48/50] [Batch 222/235] [D loss: 1.119582, acc: 85.55%] [G loss: 1.147913]\n",
      "[Epoch 48/50] [Batch 223/235] [D loss: 1.077440, acc: 87.70%] [G loss: 1.230102]\n",
      "[Epoch 48/50] [Batch 224/235] [D loss: 1.083653, acc: 88.67%] [G loss: 1.137803]\n",
      "[Epoch 48/50] [Batch 225/235] [D loss: 1.094195, acc: 88.67%] [G loss: 1.051031]\n",
      "[Epoch 48/50] [Batch 226/235] [D loss: 1.111932, acc: 87.70%] [G loss: 1.118351]\n",
      "[Epoch 48/50] [Batch 227/235] [D loss: 1.240467, acc: 87.50%] [G loss: 1.223619]\n",
      "[Epoch 48/50] [Batch 228/235] [D loss: 1.146165, acc: 87.70%] [G loss: 1.025018]\n",
      "[Epoch 48/50] [Batch 229/235] [D loss: 1.120390, acc: 89.45%] [G loss: 1.107447]\n",
      "[Epoch 48/50] [Batch 230/235] [D loss: 1.086784, acc: 85.16%] [G loss: 1.261492]\n",
      "[Epoch 48/50] [Batch 231/235] [D loss: 1.129304, acc: 88.28%] [G loss: 1.063968]\n",
      "[Epoch 48/50] [Batch 232/235] [D loss: 1.138192, acc: 87.89%] [G loss: 1.132162]\n",
      "[Epoch 48/50] [Batch 233/235] [D loss: 1.077982, acc: 91.02%] [G loss: 1.004568]\n",
      "[Epoch 48/50] [Batch 234/235] [D loss: 1.112651, acc: 86.98%] [G loss: 1.187033]\n",
      "[Epoch 49/50] [Batch 0/235] [D loss: 1.111357, acc: 87.70%] [G loss: 1.115513]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/50] [Batch 1/235] [D loss: 1.048546, acc: 88.67%] [G loss: 1.172060]\n",
      "[Epoch 49/50] [Batch 2/235] [D loss: 1.082897, acc: 89.26%] [G loss: 1.170984]\n",
      "[Epoch 49/50] [Batch 3/235] [D loss: 1.110855, acc: 84.96%] [G loss: 1.204267]\n",
      "[Epoch 49/50] [Batch 4/235] [D loss: 1.054930, acc: 89.84%] [G loss: 1.188701]\n",
      "[Epoch 49/50] [Batch 5/235] [D loss: 1.148772, acc: 87.50%] [G loss: 1.065241]\n",
      "[Epoch 49/50] [Batch 6/235] [D loss: 1.110377, acc: 86.91%] [G loss: 1.091622]\n",
      "[Epoch 49/50] [Batch 7/235] [D loss: 1.122605, acc: 88.28%] [G loss: 1.272010]\n",
      "[Epoch 49/50] [Batch 8/235] [D loss: 1.060560, acc: 87.50%] [G loss: 1.171160]\n",
      "[Epoch 49/50] [Batch 9/235] [D loss: 1.087139, acc: 87.70%] [G loss: 1.093975]\n",
      "[Epoch 49/50] [Batch 10/235] [D loss: 1.099447, acc: 86.13%] [G loss: 0.970551]\n",
      "[Epoch 49/50] [Batch 11/235] [D loss: 1.124580, acc: 87.50%] [G loss: 1.270959]\n",
      "[Epoch 49/50] [Batch 12/235] [D loss: 1.127855, acc: 87.30%] [G loss: 1.269831]\n",
      "[Epoch 49/50] [Batch 13/235] [D loss: 1.102516, acc: 87.11%] [G loss: 1.205860]\n",
      "[Epoch 49/50] [Batch 14/235] [D loss: 1.081365, acc: 88.67%] [G loss: 1.026472]\n",
      "[Epoch 49/50] [Batch 15/235] [D loss: 1.166250, acc: 89.45%] [G loss: 1.103294]\n",
      "[Epoch 49/50] [Batch 16/235] [D loss: 1.144041, acc: 86.33%] [G loss: 1.231325]\n",
      "[Epoch 49/50] [Batch 17/235] [D loss: 1.078465, acc: 86.33%] [G loss: 1.083683]\n",
      "[Epoch 49/50] [Batch 18/235] [D loss: 1.055416, acc: 88.28%] [G loss: 1.098597]\n",
      "[Epoch 49/50] [Batch 19/235] [D loss: 1.142519, acc: 88.09%] [G loss: 1.063796]\n",
      "[Epoch 49/50] [Batch 20/235] [D loss: 1.075489, acc: 88.67%] [G loss: 1.044225]\n",
      "[Epoch 49/50] [Batch 21/235] [D loss: 1.159959, acc: 88.67%] [G loss: 1.212570]\n",
      "[Epoch 49/50] [Batch 22/235] [D loss: 1.126898, acc: 88.67%] [G loss: 1.218809]\n",
      "[Epoch 49/50] [Batch 23/235] [D loss: 1.122483, acc: 88.09%] [G loss: 1.313911]\n",
      "[Epoch 49/50] [Batch 24/235] [D loss: 1.168819, acc: 87.89%] [G loss: 1.292049]\n",
      "[Epoch 49/50] [Batch 25/235] [D loss: 1.141765, acc: 87.50%] [G loss: 1.272251]\n",
      "[Epoch 49/50] [Batch 26/235] [D loss: 1.093561, acc: 88.67%] [G loss: 1.169696]\n",
      "[Epoch 49/50] [Batch 27/235] [D loss: 1.100635, acc: 88.48%] [G loss: 1.120975]\n",
      "[Epoch 49/50] [Batch 28/235] [D loss: 1.118682, acc: 87.89%] [G loss: 1.006151]\n",
      "[Epoch 49/50] [Batch 29/235] [D loss: 1.085188, acc: 86.91%] [G loss: 1.242948]\n",
      "[Epoch 49/50] [Batch 30/235] [D loss: 1.176706, acc: 87.11%] [G loss: 1.381716]\n",
      "[Epoch 49/50] [Batch 31/235] [D loss: 1.145788, acc: 89.45%] [G loss: 1.158279]\n",
      "[Epoch 49/50] [Batch 32/235] [D loss: 1.153454, acc: 84.77%] [G loss: 1.037208]\n",
      "[Epoch 49/50] [Batch 33/235] [D loss: 1.126937, acc: 88.28%] [G loss: 1.119729]\n",
      "[Epoch 49/50] [Batch 34/235] [D loss: 1.069274, acc: 88.28%] [G loss: 1.295778]\n",
      "[Epoch 49/50] [Batch 35/235] [D loss: 1.027118, acc: 88.48%] [G loss: 1.058934]\n",
      "[Epoch 49/50] [Batch 36/235] [D loss: 1.108866, acc: 89.06%] [G loss: 1.107604]\n",
      "[Epoch 49/50] [Batch 37/235] [D loss: 1.043893, acc: 88.28%] [G loss: 1.160672]\n",
      "[Epoch 49/50] [Batch 38/235] [D loss: 1.119409, acc: 87.70%] [G loss: 1.161039]\n",
      "[Epoch 49/50] [Batch 39/235] [D loss: 1.070845, acc: 87.89%] [G loss: 1.171715]\n",
      "[Epoch 49/50] [Batch 40/235] [D loss: 1.129814, acc: 86.13%] [G loss: 1.026903]\n",
      "[Epoch 49/50] [Batch 41/235] [D loss: 1.118396, acc: 85.55%] [G loss: 1.229200]\n",
      "[Epoch 49/50] [Batch 42/235] [D loss: 1.110804, acc: 86.13%] [G loss: 1.286335]\n",
      "[Epoch 49/50] [Batch 43/235] [D loss: 1.105801, acc: 88.48%] [G loss: 1.298209]\n",
      "[Epoch 49/50] [Batch 44/235] [D loss: 1.117740, acc: 86.91%] [G loss: 1.136824]\n",
      "[Epoch 49/50] [Batch 45/235] [D loss: 1.102622, acc: 87.50%] [G loss: 1.116445]\n",
      "[Epoch 49/50] [Batch 46/235] [D loss: 1.109293, acc: 87.50%] [G loss: 1.137548]\n",
      "[Epoch 49/50] [Batch 47/235] [D loss: 1.103115, acc: 89.65%] [G loss: 1.178780]\n",
      "[Epoch 49/50] [Batch 48/235] [D loss: 1.187666, acc: 89.45%] [G loss: 1.264482]\n",
      "[Epoch 49/50] [Batch 49/235] [D loss: 1.085478, acc: 87.30%] [G loss: 1.147142]\n",
      "[Epoch 49/50] [Batch 50/235] [D loss: 1.034538, acc: 88.09%] [G loss: 1.057166]\n",
      "[Epoch 49/50] [Batch 51/235] [D loss: 1.169473, acc: 87.11%] [G loss: 1.187878]\n",
      "[Epoch 49/50] [Batch 52/235] [D loss: 1.098725, acc: 87.50%] [G loss: 1.277326]\n",
      "[Epoch 49/50] [Batch 53/235] [D loss: 1.125109, acc: 87.30%] [G loss: 1.243862]\n",
      "[Epoch 49/50] [Batch 54/235] [D loss: 1.075907, acc: 87.11%] [G loss: 1.143748]\n",
      "[Epoch 49/50] [Batch 55/235] [D loss: 1.098391, acc: 89.26%] [G loss: 1.326759]\n",
      "[Epoch 49/50] [Batch 56/235] [D loss: 1.180043, acc: 86.72%] [G loss: 1.080350]\n",
      "[Epoch 49/50] [Batch 57/235] [D loss: 1.229095, acc: 85.74%] [G loss: 0.998855]\n",
      "[Epoch 49/50] [Batch 58/235] [D loss: 1.099455, acc: 87.11%] [G loss: 1.277691]\n",
      "[Epoch 49/50] [Batch 59/235] [D loss: 1.108873, acc: 90.43%] [G loss: 1.207809]\n",
      "[Epoch 49/50] [Batch 60/235] [D loss: 1.149779, acc: 85.94%] [G loss: 1.345836]\n",
      "[Epoch 49/50] [Batch 61/235] [D loss: 1.132075, acc: 90.23%] [G loss: 1.060743]\n",
      "[Epoch 49/50] [Batch 62/235] [D loss: 1.093454, acc: 87.50%] [G loss: 1.116758]\n",
      "[Epoch 49/50] [Batch 63/235] [D loss: 1.104772, acc: 87.50%] [G loss: 1.252472]\n",
      "[Epoch 49/50] [Batch 64/235] [D loss: 1.111125, acc: 87.11%] [G loss: 1.289951]\n",
      "[Epoch 49/50] [Batch 65/235] [D loss: 1.216112, acc: 84.18%] [G loss: 1.011140]\n",
      "[Epoch 49/50] [Batch 66/235] [D loss: 1.118315, acc: 90.23%] [G loss: 1.364069]\n",
      "[Epoch 49/50] [Batch 67/235] [D loss: 1.093121, acc: 86.33%] [G loss: 1.133811]\n",
      "[Epoch 49/50] [Batch 68/235] [D loss: 1.095350, acc: 90.04%] [G loss: 1.216561]\n",
      "[Epoch 49/50] [Batch 69/235] [D loss: 1.145311, acc: 87.30%] [G loss: 1.097226]\n",
      "[Epoch 49/50] [Batch 70/235] [D loss: 1.164368, acc: 88.28%] [G loss: 0.990444]\n",
      "[Epoch 49/50] [Batch 71/235] [D loss: 1.170423, acc: 86.13%] [G loss: 1.185524]\n",
      "[Epoch 49/50] [Batch 72/235] [D loss: 1.089922, acc: 87.30%] [G loss: 1.363883]\n",
      "[Epoch 49/50] [Batch 73/235] [D loss: 1.154033, acc: 87.70%] [G loss: 1.060875]\n",
      "[Epoch 49/50] [Batch 74/235] [D loss: 1.104002, acc: 87.11%] [G loss: 1.251679]\n",
      "[Epoch 49/50] [Batch 75/235] [D loss: 1.157757, acc: 87.50%] [G loss: 1.219268]\n",
      "[Epoch 49/50] [Batch 76/235] [D loss: 1.072522, acc: 89.06%] [G loss: 1.232450]\n",
      "[Epoch 49/50] [Batch 77/235] [D loss: 1.154336, acc: 87.70%] [G loss: 1.074391]\n",
      "[Epoch 49/50] [Batch 78/235] [D loss: 1.155793, acc: 88.48%] [G loss: 1.168940]\n",
      "[Epoch 49/50] [Batch 79/235] [D loss: 1.118480, acc: 88.67%] [G loss: 1.213167]\n",
      "[Epoch 49/50] [Batch 80/235] [D loss: 1.126711, acc: 86.52%] [G loss: 1.107221]\n",
      "[Epoch 49/50] [Batch 81/235] [D loss: 1.107714, acc: 87.11%] [G loss: 1.032658]\n",
      "[Epoch 49/50] [Batch 82/235] [D loss: 1.190232, acc: 87.30%] [G loss: 1.210400]\n",
      "[Epoch 49/50] [Batch 83/235] [D loss: 1.128486, acc: 83.98%] [G loss: 1.188328]\n",
      "[Epoch 49/50] [Batch 84/235] [D loss: 1.122270, acc: 85.94%] [G loss: 1.245745]\n",
      "[Epoch 49/50] [Batch 85/235] [D loss: 1.110767, acc: 88.09%] [G loss: 1.160169]\n",
      "[Epoch 49/50] [Batch 86/235] [D loss: 1.104498, acc: 87.70%] [G loss: 1.148248]\n",
      "[Epoch 49/50] [Batch 87/235] [D loss: 1.136135, acc: 87.70%] [G loss: 1.172560]\n",
      "[Epoch 49/50] [Batch 88/235] [D loss: 1.085976, acc: 88.67%] [G loss: 1.028805]\n",
      "[Epoch 49/50] [Batch 89/235] [D loss: 1.124525, acc: 88.48%] [G loss: 1.256663]\n",
      "[Epoch 49/50] [Batch 90/235] [D loss: 1.100723, acc: 86.13%] [G loss: 1.117305]\n",
      "[Epoch 49/50] [Batch 91/235] [D loss: 1.112218, acc: 87.70%] [G loss: 1.234380]\n",
      "[Epoch 49/50] [Batch 92/235] [D loss: 1.096771, acc: 84.77%] [G loss: 1.248537]\n",
      "[Epoch 49/50] [Batch 93/235] [D loss: 1.073826, acc: 89.26%] [G loss: 1.174885]\n",
      "[Epoch 49/50] [Batch 94/235] [D loss: 1.150033, acc: 88.48%] [G loss: 1.011163]\n",
      "[Epoch 49/50] [Batch 95/235] [D loss: 1.177850, acc: 85.35%] [G loss: 1.000173]\n",
      "[Epoch 49/50] [Batch 96/235] [D loss: 1.154788, acc: 87.30%] [G loss: 1.252956]\n",
      "[Epoch 49/50] [Batch 97/235] [D loss: 1.106536, acc: 88.09%] [G loss: 1.215802]\n",
      "[Epoch 49/50] [Batch 98/235] [D loss: 1.096924, acc: 85.94%] [G loss: 1.221623]\n",
      "[Epoch 49/50] [Batch 99/235] [D loss: 1.138729, acc: 89.06%] [G loss: 1.190228]\n",
      "[Epoch 49/50] [Batch 100/235] [D loss: 1.134599, acc: 88.09%] [G loss: 1.145179]\n",
      "[Epoch 49/50] [Batch 101/235] [D loss: 1.153726, acc: 89.26%] [G loss: 1.027969]\n",
      "[Epoch 49/50] [Batch 102/235] [D loss: 1.081192, acc: 87.30%] [G loss: 1.216975]\n",
      "[Epoch 49/50] [Batch 103/235] [D loss: 1.140778, acc: 87.70%] [G loss: 1.112257]\n",
      "[Epoch 49/50] [Batch 104/235] [D loss: 1.147435, acc: 87.11%] [G loss: 1.281781]\n",
      "[Epoch 49/50] [Batch 105/235] [D loss: 1.073878, acc: 87.89%] [G loss: 1.264933]\n",
      "[Epoch 49/50] [Batch 106/235] [D loss: 1.059005, acc: 90.04%] [G loss: 1.120809]\n",
      "[Epoch 49/50] [Batch 107/235] [D loss: 1.137063, acc: 87.89%] [G loss: 1.027461]\n",
      "[Epoch 49/50] [Batch 108/235] [D loss: 1.103958, acc: 88.48%] [G loss: 1.089955]\n",
      "[Epoch 49/50] [Batch 109/235] [D loss: 1.096792, acc: 87.70%] [G loss: 1.264859]\n",
      "[Epoch 49/50] [Batch 110/235] [D loss: 1.154642, acc: 87.89%] [G loss: 1.083135]\n",
      "[Epoch 49/50] [Batch 111/235] [D loss: 1.057164, acc: 91.02%] [G loss: 1.171007]\n",
      "[Epoch 49/50] [Batch 112/235] [D loss: 1.099388, acc: 85.55%] [G loss: 1.105347]\n",
      "[Epoch 49/50] [Batch 113/235] [D loss: 1.032019, acc: 88.48%] [G loss: 1.097486]\n",
      "[Epoch 49/50] [Batch 114/235] [D loss: 1.071384, acc: 87.11%] [G loss: 1.068756]\n",
      "[Epoch 49/50] [Batch 115/235] [D loss: 1.132383, acc: 87.50%] [G loss: 1.109138]\n",
      "[Epoch 49/50] [Batch 116/235] [D loss: 1.082331, acc: 89.65%] [G loss: 1.203182]\n",
      "[Epoch 49/50] [Batch 117/235] [D loss: 1.118634, acc: 87.30%] [G loss: 1.234865]\n",
      "[Epoch 49/50] [Batch 118/235] [D loss: 1.111805, acc: 85.94%] [G loss: 1.055648]\n",
      "[Epoch 49/50] [Batch 119/235] [D loss: 1.180416, acc: 87.50%] [G loss: 1.026994]\n",
      "[Epoch 49/50] [Batch 120/235] [D loss: 1.134614, acc: 87.11%] [G loss: 1.065322]\n",
      "[Epoch 49/50] [Batch 121/235] [D loss: 1.109455, acc: 87.50%] [G loss: 1.321663]\n",
      "[Epoch 49/50] [Batch 122/235] [D loss: 1.097723, acc: 87.50%] [G loss: 1.147199]\n",
      "[Epoch 49/50] [Batch 123/235] [D loss: 1.064636, acc: 86.91%] [G loss: 1.230028]\n",
      "[Epoch 49/50] [Batch 124/235] [D loss: 1.096611, acc: 88.87%] [G loss: 1.042055]\n",
      "[Epoch 49/50] [Batch 125/235] [D loss: 1.090703, acc: 88.67%] [G loss: 1.253968]\n",
      "[Epoch 49/50] [Batch 126/235] [D loss: 1.141003, acc: 88.87%] [G loss: 1.201999]\n",
      "[Epoch 49/50] [Batch 127/235] [D loss: 1.118019, acc: 88.28%] [G loss: 1.093701]\n",
      "[Epoch 49/50] [Batch 128/235] [D loss: 1.046815, acc: 88.09%] [G loss: 1.218473]\n",
      "[Epoch 49/50] [Batch 129/235] [D loss: 1.142382, acc: 89.84%] [G loss: 1.216201]\n",
      "[Epoch 49/50] [Batch 130/235] [D loss: 1.144335, acc: 87.70%] [G loss: 1.020257]\n",
      "[Epoch 49/50] [Batch 131/235] [D loss: 1.159601, acc: 89.45%] [G loss: 1.269315]\n",
      "[Epoch 49/50] [Batch 132/235] [D loss: 1.128801, acc: 86.91%] [G loss: 1.226041]\n",
      "[Epoch 49/50] [Batch 133/235] [D loss: 1.048815, acc: 87.50%] [G loss: 1.141679]\n",
      "[Epoch 49/50] [Batch 134/235] [D loss: 1.062261, acc: 87.11%] [G loss: 1.111413]\n",
      "[Epoch 49/50] [Batch 135/235] [D loss: 1.117014, acc: 86.72%] [G loss: 1.094273]\n",
      "[Epoch 49/50] [Batch 136/235] [D loss: 1.129603, acc: 89.06%] [G loss: 1.116662]\n",
      "[Epoch 49/50] [Batch 137/235] [D loss: 1.118487, acc: 86.91%] [G loss: 1.260468]\n",
      "[Epoch 49/50] [Batch 138/235] [D loss: 1.117367, acc: 87.70%] [G loss: 1.106066]\n",
      "[Epoch 49/50] [Batch 139/235] [D loss: 1.146342, acc: 89.65%] [G loss: 1.265811]\n",
      "[Epoch 49/50] [Batch 140/235] [D loss: 1.048180, acc: 89.45%] [G loss: 1.169148]\n",
      "[Epoch 49/50] [Batch 141/235] [D loss: 1.104491, acc: 88.87%] [G loss: 1.139626]\n",
      "[Epoch 49/50] [Batch 142/235] [D loss: 1.141199, acc: 87.89%] [G loss: 1.353832]\n",
      "[Epoch 49/50] [Batch 143/235] [D loss: 1.125463, acc: 87.70%] [G loss: 1.203528]\n",
      "[Epoch 49/50] [Batch 144/235] [D loss: 1.076308, acc: 88.67%] [G loss: 1.264233]\n",
      "[Epoch 49/50] [Batch 145/235] [D loss: 1.145266, acc: 88.09%] [G loss: 1.148732]\n",
      "[Epoch 49/50] [Batch 146/235] [D loss: 1.158991, acc: 88.87%] [G loss: 1.048115]\n",
      "[Epoch 49/50] [Batch 147/235] [D loss: 1.135577, acc: 87.89%] [G loss: 1.175058]\n",
      "[Epoch 49/50] [Batch 148/235] [D loss: 1.094425, acc: 87.50%] [G loss: 1.223072]\n",
      "[Epoch 49/50] [Batch 149/235] [D loss: 1.158903, acc: 85.55%] [G loss: 1.007528]\n",
      "[Epoch 49/50] [Batch 150/235] [D loss: 1.136096, acc: 88.87%] [G loss: 1.099565]\n",
      "[Epoch 49/50] [Batch 151/235] [D loss: 1.060692, acc: 86.52%] [G loss: 1.208522]\n",
      "[Epoch 49/50] [Batch 152/235] [D loss: 1.033915, acc: 87.89%] [G loss: 1.286845]\n",
      "[Epoch 49/50] [Batch 153/235] [D loss: 1.082421, acc: 87.11%] [G loss: 1.208376]\n",
      "[Epoch 49/50] [Batch 154/235] [D loss: 1.121126, acc: 86.33%] [G loss: 1.268842]\n",
      "[Epoch 49/50] [Batch 155/235] [D loss: 1.081982, acc: 87.30%] [G loss: 1.188558]\n",
      "[Epoch 49/50] [Batch 156/235] [D loss: 1.108658, acc: 87.11%] [G loss: 1.218018]\n",
      "[Epoch 49/50] [Batch 157/235] [D loss: 1.117006, acc: 88.87%] [G loss: 1.184840]\n",
      "[Epoch 49/50] [Batch 158/235] [D loss: 1.094002, acc: 86.91%] [G loss: 1.074073]\n",
      "[Epoch 49/50] [Batch 159/235] [D loss: 1.121700, acc: 86.33%] [G loss: 1.153850]\n",
      "[Epoch 49/50] [Batch 160/235] [D loss: 1.093132, acc: 87.30%] [G loss: 1.252457]\n",
      "[Epoch 49/50] [Batch 161/235] [D loss: 1.154474, acc: 86.72%] [G loss: 1.254082]\n",
      "[Epoch 49/50] [Batch 162/235] [D loss: 1.078006, acc: 89.26%] [G loss: 1.227877]\n",
      "[Epoch 49/50] [Batch 163/235] [D loss: 1.093592, acc: 88.67%] [G loss: 1.243478]\n",
      "[Epoch 49/50] [Batch 164/235] [D loss: 1.130586, acc: 86.91%] [G loss: 1.049316]\n",
      "[Epoch 49/50] [Batch 165/235] [D loss: 1.086470, acc: 89.65%] [G loss: 1.113660]\n",
      "[Epoch 49/50] [Batch 166/235] [D loss: 1.168128, acc: 85.74%] [G loss: 1.146685]\n",
      "[Epoch 49/50] [Batch 167/235] [D loss: 1.119128, acc: 87.50%] [G loss: 1.261102]\n",
      "[Epoch 49/50] [Batch 168/235] [D loss: 1.127167, acc: 86.33%] [G loss: 1.180128]\n",
      "[Epoch 49/50] [Batch 169/235] [D loss: 1.050006, acc: 87.70%] [G loss: 1.191013]\n",
      "[Epoch 49/50] [Batch 170/235] [D loss: 1.099486, acc: 88.28%] [G loss: 1.179963]\n",
      "[Epoch 49/50] [Batch 171/235] [D loss: 1.086277, acc: 87.30%] [G loss: 1.108049]\n",
      "[Epoch 49/50] [Batch 172/235] [D loss: 1.154849, acc: 87.89%] [G loss: 1.278638]\n",
      "[Epoch 49/50] [Batch 173/235] [D loss: 1.101217, acc: 86.52%] [G loss: 1.220348]\n",
      "[Epoch 49/50] [Batch 174/235] [D loss: 1.116315, acc: 84.96%] [G loss: 1.151648]\n",
      "[Epoch 49/50] [Batch 175/235] [D loss: 1.119888, acc: 87.89%] [G loss: 1.220727]\n",
      "[Epoch 49/50] [Batch 176/235] [D loss: 1.178102, acc: 86.52%] [G loss: 1.085233]\n",
      "[Epoch 49/50] [Batch 177/235] [D loss: 1.056952, acc: 89.06%] [G loss: 1.111566]\n",
      "[Epoch 49/50] [Batch 178/235] [D loss: 1.090219, acc: 87.70%] [G loss: 1.036407]\n",
      "[Epoch 49/50] [Batch 179/235] [D loss: 1.087065, acc: 86.72%] [G loss: 1.097810]\n",
      "[Epoch 49/50] [Batch 180/235] [D loss: 1.094008, acc: 85.94%] [G loss: 1.174904]\n",
      "[Epoch 49/50] [Batch 181/235] [D loss: 1.089627, acc: 88.67%] [G loss: 1.157640]\n",
      "[Epoch 49/50] [Batch 182/235] [D loss: 1.105936, acc: 87.70%] [G loss: 0.998054]\n",
      "[Epoch 49/50] [Batch 183/235] [D loss: 1.193503, acc: 88.09%] [G loss: 0.995633]\n",
      "[Epoch 49/50] [Batch 184/235] [D loss: 1.123655, acc: 89.26%] [G loss: 1.333043]\n",
      "[Epoch 49/50] [Batch 185/235] [D loss: 1.179958, acc: 88.67%] [G loss: 1.187405]\n",
      "[Epoch 49/50] [Batch 186/235] [D loss: 1.163680, acc: 87.50%] [G loss: 1.233915]\n",
      "[Epoch 49/50] [Batch 187/235] [D loss: 1.111787, acc: 87.30%] [G loss: 1.181194]\n",
      "[Epoch 49/50] [Batch 188/235] [D loss: 1.146638, acc: 85.74%] [G loss: 1.128486]\n",
      "[Epoch 49/50] [Batch 189/235] [D loss: 1.052010, acc: 89.26%] [G loss: 1.164229]\n",
      "[Epoch 49/50] [Batch 190/235] [D loss: 1.034808, acc: 84.77%] [G loss: 1.284727]\n",
      "[Epoch 49/50] [Batch 191/235] [D loss: 1.076277, acc: 89.65%] [G loss: 1.203248]\n",
      "[Epoch 49/50] [Batch 192/235] [D loss: 1.086041, acc: 86.91%] [G loss: 1.200937]\n",
      "[Epoch 49/50] [Batch 193/235] [D loss: 1.216513, acc: 87.50%] [G loss: 0.982107]\n",
      "[Epoch 49/50] [Batch 194/235] [D loss: 1.061885, acc: 88.67%] [G loss: 1.107721]\n",
      "[Epoch 49/50] [Batch 195/235] [D loss: 1.137344, acc: 87.50%] [G loss: 1.168830]\n",
      "[Epoch 49/50] [Batch 196/235] [D loss: 1.120085, acc: 85.74%] [G loss: 1.208932]\n",
      "[Epoch 49/50] [Batch 197/235] [D loss: 1.053341, acc: 88.09%] [G loss: 1.224332]\n",
      "[Epoch 49/50] [Batch 198/235] [D loss: 1.179143, acc: 89.06%] [G loss: 1.046085]\n",
      "[Epoch 49/50] [Batch 199/235] [D loss: 1.105116, acc: 87.70%] [G loss: 1.166791]\n",
      "[Epoch 49/50] [Batch 200/235] [D loss: 1.096098, acc: 89.65%] [G loss: 1.162684]\n",
      "[Epoch 49/50] [Batch 201/235] [D loss: 1.155230, acc: 85.94%] [G loss: 1.158579]\n",
      "[Epoch 49/50] [Batch 202/235] [D loss: 1.073697, acc: 88.87%] [G loss: 1.119524]\n",
      "[Epoch 49/50] [Batch 203/235] [D loss: 1.104260, acc: 87.30%] [G loss: 1.109616]\n",
      "[Epoch 49/50] [Batch 204/235] [D loss: 1.158158, acc: 88.28%] [G loss: 1.411321]\n",
      "[Epoch 49/50] [Batch 205/235] [D loss: 1.079772, acc: 87.50%] [G loss: 1.139716]\n",
      "[Epoch 49/50] [Batch 206/235] [D loss: 1.167304, acc: 88.09%] [G loss: 1.092437]\n",
      "[Epoch 49/50] [Batch 207/235] [D loss: 1.083533, acc: 85.35%] [G loss: 1.114331]\n",
      "[Epoch 49/50] [Batch 208/235] [D loss: 1.122386, acc: 88.09%] [G loss: 1.056249]\n",
      "[Epoch 49/50] [Batch 209/235] [D loss: 1.139588, acc: 87.89%] [G loss: 1.200703]\n",
      "[Epoch 49/50] [Batch 210/235] [D loss: 1.071941, acc: 88.87%] [G loss: 1.237622]\n",
      "[Epoch 49/50] [Batch 211/235] [D loss: 1.020951, acc: 87.30%] [G loss: 1.117480]\n",
      "[Epoch 49/50] [Batch 212/235] [D loss: 1.088191, acc: 87.50%] [G loss: 1.103027]\n",
      "[Epoch 49/50] [Batch 213/235] [D loss: 1.119144, acc: 87.11%] [G loss: 1.142601]\n",
      "[Epoch 49/50] [Batch 214/235] [D loss: 1.146911, acc: 84.18%] [G loss: 1.196277]\n",
      "[Epoch 49/50] [Batch 215/235] [D loss: 1.230331, acc: 86.72%] [G loss: 1.200715]\n",
      "[Epoch 49/50] [Batch 216/235] [D loss: 1.095821, acc: 86.72%] [G loss: 1.161708]\n",
      "[Epoch 49/50] [Batch 217/235] [D loss: 1.031032, acc: 87.89%] [G loss: 1.196207]\n",
      "[Epoch 49/50] [Batch 218/235] [D loss: 1.156268, acc: 87.50%] [G loss: 1.121904]\n",
      "[Epoch 49/50] [Batch 219/235] [D loss: 1.187033, acc: 89.84%] [G loss: 1.051857]\n",
      "[Epoch 49/50] [Batch 220/235] [D loss: 1.115860, acc: 86.91%] [G loss: 1.111381]\n",
      "[Epoch 49/50] [Batch 221/235] [D loss: 1.152881, acc: 88.28%] [G loss: 1.189517]\n",
      "[Epoch 49/50] [Batch 222/235] [D loss: 1.061158, acc: 87.30%] [G loss: 1.115002]\n",
      "[Epoch 49/50] [Batch 223/235] [D loss: 1.124353, acc: 87.50%] [G loss: 1.179878]\n",
      "[Epoch 49/50] [Batch 224/235] [D loss: 1.166933, acc: 88.09%] [G loss: 1.292888]\n",
      "[Epoch 49/50] [Batch 225/235] [D loss: 1.102878, acc: 87.70%] [G loss: 1.161307]\n",
      "[Epoch 49/50] [Batch 226/235] [D loss: 1.148855, acc: 89.26%] [G loss: 1.161083]\n",
      "[Epoch 49/50] [Batch 227/235] [D loss: 1.080065, acc: 85.94%] [G loss: 1.177965]\n",
      "[Epoch 49/50] [Batch 228/235] [D loss: 1.063977, acc: 89.06%] [G loss: 1.229282]\n",
      "[Epoch 49/50] [Batch 229/235] [D loss: 1.051646, acc: 88.28%] [G loss: 1.378589]\n",
      "[Epoch 49/50] [Batch 230/235] [D loss: 1.102491, acc: 87.50%] [G loss: 1.176600]\n",
      "[Epoch 49/50] [Batch 231/235] [D loss: 1.152384, acc: 84.18%] [G loss: 1.116724]\n",
      "[Epoch 49/50] [Batch 232/235] [D loss: 1.109054, acc: 90.23%] [G loss: 1.161465]\n",
      "[Epoch 49/50] [Batch 233/235] [D loss: 1.086542, acc: 89.45%] [G loss: 1.029940]\n",
      "[Epoch 49/50] [Batch 234/235] [D loss: 1.080700, acc: 90.10%] [G loss: 1.146439]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# Track metrics\n",
    "g_losses, d_losses, d_accuracies = [], [], []\n",
    "epoch_confusion_matrices = []\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        batch_size = imgs.size(0)\n",
    "\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "        validity, pred_label = discriminator(gen_imgs)\n",
    "        g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_pred, real_aux = discriminator(real_imgs)\n",
    "        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Store metrics for visualization\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "        d_accuracies.append(d_acc * 100)\n",
    "\n",
    "        if i == len(dataloader) - 1:\n",
    "            cm = confusion_matrix(gt, np.argmax(pred, axis=1))\n",
    "            epoch_confusion_matrices.append(cm)\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch}/{opt.n_epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "            f\"[D loss: {d_loss.item():.6f}, acc: {100 * d_acc:.2f}%] [G loss: {g_loss.item():.6f}]\"\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done, poisoned=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1740401448334,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "UDH7zn9Y9gwV",
    "outputId": "69a9b5ac-e2cd-4aeb-f5df-515050eb25ef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Plotting Metrics ---\n",
    "def plot_metrics(g_losses, d_losses, d_accuracies):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Generator and Discriminator Losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(g_losses, label=\"G Loss\")\n",
    "    plt.plot(d_losses, label=\"D Loss\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Discriminator Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(d_accuracies, label=\"D Accuracy\")\n",
    "    plt.title(\"Discriminator Accuracy\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(g_losses, d_losses, d_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1740401455621,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "5SmUHVr_AN7A",
    "outputId": "4678f838-086b-41a8-c3f0-481aa0d9846c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  def show_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(opt.n_classes))\n",
    "    disp.plot(cmap=\"Blues\", values_format='d')\n",
    "    plt.title(\"Discriminator Confusion Matrix (Last Epoch)\")\n",
    "    plt.show()\n",
    "\n",
    "show_confusion_matrix(epoch_confusion_matrices[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlp4WWVtMQrx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2371,
     "status": "ok",
     "timestamp": 1740401478978,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "GhFt0A7Q8j7E",
    "outputId": "be27ac8f-376f-4d32-95b3-ba38a2adaf74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.72%\n"
     ]
    }
   ],
   "source": [
    "generator.eval()  # Set to evaluation mode\n",
    "discriminator.eval()\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"../../data/mnist\",\n",
    "    train=False,  # Set train=False to load the test dataset\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "#Create the test DataLoader\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=False,  # No need to shuffle the test dataset\n",
    ")\n",
    "\n",
    "# test_dataloader = DataLoader(\n",
    "#     PoisonedMNIST(\n",
    "#         \"../../data/mnist\",\n",
    "#         train=True,\n",
    "#         download=True,\n",
    "#         transform=transforms.Compose(\n",
    "#             [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "#         ),\n",
    "#         poison_fraction=0.1,  # Inject 10% outliers\n",
    "#         attack_type=\"label_flip\"  # Flip labels as the attack\n",
    "#     ),\n",
    "#     batch_size=opt.batch_size,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_validities = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for faster performance\n",
    "    for imgs, labels in test_dataloader:\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "        # Generate predictions from discriminator\n",
    "        validity, pred_labels = discriminator(real_imgs)\n",
    "\n",
    "        # Save predictions and actual labels for evaluation\n",
    "        all_preds.append(pred_labels.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_validities.append(validity.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_validities = np.concatenate(all_validities, axis=0)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "pred_classes = np.argmax(all_preds, axis=1)\n",
    "accuracy = np.mean(pred_classes == all_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1740401669305,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "0Hn6o4qDZ-gx",
    "outputId": "2bfe0882-a1ca-4394-aa91-a6ebb3179aa6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For Heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_mat = confusion_matrix(all_labels, pred_classes)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1740401696430,
     "user": {
      "displayName": "kshitish modi",
      "userId": "08021765203056765340"
     },
     "user_tz": -330
    },
    "id": "33swzHzraHny",
    "outputId": "54561411-59b6-453c-f4b8-82c4db66158a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average AUC: 0.9983\n",
      "Macro-average AUC: 0.9982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarize the labels for multi-class ROC curve calculation\n",
    "n_classes = opt.n_classes\n",
    "labels_binarized = label_binarize(all_labels, classes=list(range(n_classes)))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(labels_binarized[:, i], all_preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = roc_curve(labels_binarized.ravel(), all_preds.ravel())\n",
    "micro_auc = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "mean_tpr /= n_classes\n",
    "macro_auc = auc(all_fpr, mean_tpr)\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure()\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"green\", \"purple\", \"red\", \"yellow\", \"blue\", \"pink\", \"brown\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "# Plot micro and macro average ROC curve\n",
    "plt.plot(fpr_micro, tpr_micro, color='deeppink', linestyle=':', linewidth=4, label=f'Micro-average (AUC = {micro_auc:.2f})')\n",
    "plt.plot(all_fpr, mean_tpr, color='navy', linestyle=':', linewidth=4, label=f'Macro-average (AUC = {macro_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Multi-Class Classification\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Micro-average AUC: {micro_auc:.4f}\")\n",
    "print(f\"Macro-average AUC: {macro_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMlDcM60Nz2X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1KYUCjl-zZk2C21wQ1qHCQVpaiCs8cKnM",
     "timestamp": 1728974903273
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
